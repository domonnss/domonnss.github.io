<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>l4rk&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="l4rk"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="l4rk"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="LinkRead on OmnivoreRead Original Highlights&amp;amp;&amp;amp;Note torch.utils.data.DataLoader and torch.utils.data.Dataset.Dataset stores the samples and their corresponding labels, and DataLoader wraps an i"><meta property="og:type" content="blog"><meta property="og:title" content="l4rk"><meta property="og:url" content="https://l4rk.cn/"><meta property="og:site_name" content="l4rk"><meta property="og:description" content="LinkRead on OmnivoreRead Original Highlights&amp;amp;&amp;amp;Note torch.utils.data.DataLoader and torch.utils.data.Dataset.Dataset stores the samples and their corresponding labels, and DataLoader wraps an i"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://l4rk.cn/img/og_image.png"><meta property="article:published_time" content="2024-05-15T05:33:17.185Z"><meta property="article:modified_time" content="2024-06-07T17:15:55.027Z"><meta property="article:author" content="l4rk"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://l4rk.cn/2024/05/0299e012aa35.html"},"headline":"l4rk's blog","image":["http://l4rk.cn/img/og_image.png"],"datePublished":"2024-05-15T05:33:17.185Z","dateModified":"2024-06-07T17:15:55.027Z","author":{"@type":"Person","name":"l4rk"},"publisher":{"@type":"Organization","name":"l4rk's blog","logo":{"@type":"ImageObject","url":"http://l4rk.cn/img/logo.svg"}},"description":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note torch.utils.data.DataLoader and torch.utils.data.Dataset.Dataset stores the samples and their corresponding labels, and DataLoader wraps an i"}</script><link rel="canonical" href="http://l4rk.cn/2024/05/0299e012aa35.html"><link rel="alternate" href="/atom.xml" title="l4rk&#039;s blog" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><!--!--><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="l4rk&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">文章归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Github" href="https://github.com/domonnss"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-05-15T05:33:17.185Z" title="2024/5/15 13:33:17">2024-05-15</time>发表</span><span class="level-item"><time dateTime="2024-06-07T17:15:55.027Z" title="2024/6/8 01:15:55">2024-06-08</time>更新</span><span class="level-item">14 分钟读完 (大约2039个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><div class="content"><h2 id="Link"><a href="#Link" class="headerlink" title="Link"></a>Link</h2><p><a target="_blank" rel="noopener" href="https://omnivore.app/me/quickstart-py-torch-tutorials-2-3-0-cu-121-documentation-18f760b91f1">Read on Omnivore</a><br><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Read Original</a></p>
<h2 id="Highlights-amp-amp-Note"><a href="#Highlights-amp-amp-Note" class="headerlink" title="Highlights&amp;&amp;Note"></a>Highlights&amp;&amp;Note</h2><blockquote>
<p><code>torch.utils.data.DataLoader</code> and <code>torch.utils.data.Dataset</code>.<code>Dataset</code> stores the samples and their corresponding labels, and <code>DataLoader</code> wraps an iterable around the <code>Dataset</code>.<br><em>Dataset 用于定义和存储数据及标签，而 DataLoader 则将 Dataset 包装成一个可迭代对象，方便进行批量数据处理和多线程数据加载。</em> ^40d33fcf</p>
<p>PyTorch offers domain-specific libraries such as <a target="_blank" rel="noopener" href="https://pytorch.org/text/stable/index.html">TorchText</a>,<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html">TorchVision</a>, and <a target="_blank" rel="noopener" href="https://pytorch.org/audio/stable/index.html">TorchAudio</a><br> ^03b16e1a</p>
<p>To define a neural network in PyTorch, we create a class that inherits from <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">nn.Module</a>. We define the layers of the network in the <code>__init__</code> function and specify how data will pass through the network in the <code>forward</code> function. To accelerate operations in the neural network, we move it to the GPU or MPS if available.</p>
</blockquote>
<p>Using cuda device<br>NeuralNetwork(<br>  (flatten): Flatten(start<em>dim=1, end_dim=-1)<br>  (linear_relu_stack): Sequential(<br>    (0): Linear(in_features=784, out_features=512, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=512, out_features=512, bias=True)<br>    (3): ReLU()<br>    (4): Linear(in_features=512, out_features=10, bias=True)<br>  )<br>)
</em>继承自nn.Module的类来定义一个新的神经网络_ ^60509680</p>
<h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><p>Note</p>
<p>Click <a href="#sphx-glr-download-beginner-basics-quickstart-tutorial-py">here</a>to download the full example code</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a> ||<strong>Quickstart</strong> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/tensorqs%5Ftutorial.html">Tensors</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/data%5Ftutorial.html">Datasets &amp; DataLoaders</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/transforms%5Ftutorial.html">Transforms</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/buildmodel%5Ftutorial.html">Build Model</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/autogradqs%5Ftutorial.html">Autograd</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/optimization%5Ftutorial.html">Optimization</a> ||<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/saveloadrun%5Ftutorial.html">Save &amp; Load Model</a></p>
<h2 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart<a href="#quickstart"></a></h2><p>This section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.</p>
<h2 id="Working-with-data"><a href="#Working-with-data" class="headerlink" title="Working with data"></a>Working with data<a href="#working-with-data"></a></h2><p>PyTorch has two <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html">primitives to work with data</a>:<code>==torch====.utils====.data====.DataLoader==</code> ==and== <code>==torch====.utils====.data====.Dataset==</code>==.==<code>==Dataset==</code> ==stores the samples and their corresponding labels, and== <code>==DataLoader==</code> ==wraps an iterable around<br>the== <code>==Dataset==</code>==.==</p>
<p>import torch<br>from torch import nn<br>from torch.utils.data import <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader">DataLoader</a><br>from torchvision import datasets<br>from torchvision.transforms import <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor" title="torchvision.transforms.ToTensor">ToTensor</a></p>
<p>==PyTorch offers domain-specific libraries such as== ==<a target="_blank" rel="noopener" href="https://pytorch.org/text/stable/index.html">TorchText</a>====,====<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html">TorchVision</a>====, and== ==<a target="_blank" rel="noopener" href="https://pytorch.org/audio/stable/index.html">TorchAudio</a>==, all of which include datasets. For this tutorial, we will be using a TorchVision dataset.</p>
<p>The <code>torchvision.datasets</code> module contains <code>Dataset</code> objects for many real-world vision data like CIFAR, COCO (<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html">full list here</a>). In this tutorial, we use the FashionMNIST dataset. Every TorchVision <code>Dataset</code> includes two arguments: <code>transform</code> and<code>target_transform</code> to modify the samples and labels respectively.</p>
<p>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</a><br>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz</a> to data/FashionMNIST/raw/train-images-idx3-ubyte.gz</p>
<p>  0%|          | 0/26421880 [00:00&lt;?, ?it/s]<br>  0%|          | 65536/26421880 [00:00&lt;01:11, 367533.95it/s]<br>  1%|          | 229376/26421880 [00:00&lt;00:38, 687510.81it/s]<br>  3%|3         | 917504/26421880 [00:00&lt;00:12, 2122627.18it/s]<br> 12%|#1        | 3145728/26421880 [00:00&lt;00:03, 6173840.09it/s]<br> 32%|###1      | 8323072/26421880 [00:00&lt;00:01, 14317420.15it/s]<br> 52%|#####2    | 13860864/26421880 [00:01&lt;00:00, 19911191.27it/s]<br> 73%|#######2  | 19169280/26421880 [00:01&lt;00:00, 23027294.46it/s]<br> 95%|#########4| 25001984/26421880 [00:01&lt;00:00, 26015038.29it/s]<br>100%|##########| 26421880/26421880 [00:01&lt;00:00, 18290784.99it/s]<br>Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw</p>
<p>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</a><br>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz</a> to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz</p>
<p>  0%|          | 0/29515 [00:00&lt;?, ?it/s]<br>100%|##########| 29515/29515 [00:00&lt;00:00, 325111.24it/s]<br>Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw</p>
<p>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</a><br>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz</a> to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz</p>
<p>  0%|          | 0/4422102 [00:00&lt;?, ?it/s]<br>  1%|1         | 65536/4422102 [00:00&lt;00:12, 362694.62it/s]<br>  5%|5         | 229376/4422102 [00:00&lt;00:06, 682437.48it/s]<br> 16%|#5        | 688128/4422102 [00:00&lt;00:02, 1525993.86it/s]<br> 27%|##6       | 1179648/4422102 [00:00&lt;00:01, 1995322.62it/s]<br> 39%|###9      | 1736704/4422102 [00:00&lt;00:01, 2382528.91it/s]<br> 53%|#####2    | 2326528/4422102 [00:01&lt;00:00, 2683842.12it/s]<br> 67%|######7   | 2981888/4422102 [00:01&lt;00:00, 2990009.04it/s]<br> 84%|########4 | 3735552/4422102 [00:01&lt;00:00, 3358051.05it/s]<br>100%|##########| 4422102/4422102 [00:01&lt;00:00, 2867549.97it/s]<br>Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw</p>
<p>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</a><br>Downloading <a target="_blank" rel="noopener" href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz">http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz</a> to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz</p>
<p>  0%|          | 0/5148 [00:00&lt;?, ?it/s]<br>100%|##########| 5148/5148 [00:00&lt;00:00, 38765308.78it/s]<br>Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw</p>
<p>We pass the <code>Dataset</code> as an argument to <code>DataLoader</code>. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.</p>
<p>Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])<br>Shape of y: torch.Size([64]) torch.int64</p>
<p>Read more about <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/data%5Ftutorial.html">loading data in PyTorch</a>.</p>
<hr>
<h2 id="Creating-Models"><a href="#Creating-Models" class="headerlink" title="Creating Models"></a>Creating Models<a href="#creating-models"></a></h2><p>==To define a neural network in PyTorch, we create a class that inherits<br>from== ==<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">nn.Module</a>====. We define the layers of the network<br>in the== <code>==__init__==</code> ==function and specify how data will pass through the network in the== <code>==forward==</code> ==function. To accelerate<br>operations in the neural network, we move it to the GPU or MPS if available.==</p>
<p>==Using cuda device<br>NeuralNetwork(<br>  (flatten): Flatten(start_dim=1, end_dim=-1)<br>  (linear_relu_stack): Sequential(<br>    (0): Linear(in_features=784, out_features=512, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=512, out_features=512, bias=True)<br>    (3): ReLU()<br>    (4): Linear(in_features=512, out_features=10, bias=True)<br>  )<br>)==</p>
<p>Read more about <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/buildmodel%5Ftutorial.html">building neural networks in PyTorch</a>.</p>
<hr>
<h2 id="Optimizing-the-Model-Parameters"><a href="#Optimizing-the-Model-Parameters" class="headerlink" title="Optimizing the Model Parameters"></a>Optimizing the Model Parameters<a href="#optimizing-the-model-parameters"></a></h2><p>To train a model, we need a <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html#loss-functions">loss function</a>and an <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/optim.html">optimizer</a>.</p>
<p>In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters.</p>
<p>def train(dataloader, model, <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss">loss_fn</a>, <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD" title="torch.optim.SGD">optimizer</a>):<br>    size = len(dataloader.dataset)<br>    <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train" title="torch.nn.Module.train">model.train</a>()<br>    for batch, (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>, y) in enumerate(dataloader):<br>        <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>, y = <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>.to(device), y.to(device)</p>
<pre><code>    # Compute prediction error
    [pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;) = model([X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;))
    loss = [loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss &quot;torch.nn.CrossEntropyLoss&quot;)([pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;), y)

    # Backpropagation
    loss.backward()
    [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.step &quot;torch.optim.SGD.step&quot;)()
    [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.zero%5Fgrad &quot;torch.optim.SGD.zero_grad&quot;)()

    if batch % 100 == 0:
        loss, current = loss.item(), (batch + 1) * len([X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;))
        print(f&quot;loss: &#123;loss:&gt;7f&#125;  [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;)
</code></pre><p>We also check the model’s performance against the test dataset to ensure it is learning.</p>
<p>def test(dataloader, model, <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss">loss_fn</a>):<br>    size = len(dataloader.dataset)<br>    num_batches = len(dataloader)<br>    <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval">model.eval</a>()<br>    test_loss, correct = 0, 0<br>    with <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.no%5Fgrad.html#torch.no%5Fgrad" title="torch.no_grad">torch.no_grad</a>():<br>        for <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>, y in dataloader:<br>            <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>, y = <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>.to(device), y.to(device)<br>            <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">pred</a> = model(<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">X</a>)<br>            test_loss += <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss">loss_fn</a>(<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">pred</a>, y).item()<br>            correct += (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">pred</a>.argmax(1) == y).type(<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensor%5Fattributes.html#torch.dtype" title="torch.dtype">torch.float</a>).sum().item()<br>    test_loss /= num_batches<br>    correct /= size<br>    print(f”Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n”)</p>
<p>The training process is conducted over several iterations (<em>epochs</em>). During each epoch, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch.</p>
<h2 id="Epoch-1"><a href="#Epoch-1" class="headerlink" title="Epoch 1"></a>Epoch 1</h2><p>loss: 2.303494  [   64/60000]<br>loss: 2.294637  [ 6464/60000]<br>loss: 2.277102  [12864/60000]<br>loss: 2.269977  [19264/60000]<br>loss: 2.254235  [25664/60000]<br>loss: 2.237146  [32064/60000]<br>loss: 2.231055  [38464/60000]<br>loss: 2.205037  [44864/60000]<br>loss: 2.203240  [51264/60000]<br>loss: 2.170889  [57664/60000]<br>Test Error:<br> Accuracy: 53.9%, Avg loss: 2.168588</p>
<h2 id="Epoch-2"><a href="#Epoch-2" class="headerlink" title="Epoch 2"></a>Epoch 2</h2><p>loss: 2.177787  [   64/60000]<br>loss: 2.168083  [ 6464/60000]<br>loss: 2.114910  [12864/60000]<br>loss: 2.130412  [19264/60000]<br>loss: 2.087473  [25664/60000]<br>loss: 2.039670  [32064/60000]<br>loss: 2.054274  [38464/60000]<br>loss: 1.985457  [44864/60000]<br>loss: 1.996023  [51264/60000]<br>loss: 1.917241  [57664/60000]<br>Test Error:<br> Accuracy: 60.2%, Avg loss: 1.920374</p>
<h2 id="Epoch-3"><a href="#Epoch-3" class="headerlink" title="Epoch 3"></a>Epoch 3</h2><p>loss: 1.951705  [   64/60000]<br>loss: 1.919516  [ 6464/60000]<br>loss: 1.808730  [12864/60000]<br>loss: 1.846550  [19264/60000]<br>loss: 1.740618  [25664/60000]<br>loss: 1.698733  [32064/60000]<br>loss: 1.708889  [38464/60000]<br>loss: 1.614436  [44864/60000]<br>loss: 1.646475  [51264/60000]<br>loss: 1.524308  [57664/60000]<br>Test Error:<br> Accuracy: 61.4%, Avg loss: 1.547092</p>
<h2 id="Epoch-4"><a href="#Epoch-4" class="headerlink" title="Epoch 4"></a>Epoch 4</h2><p>loss: 1.612695  [   64/60000]<br>loss: 1.570870  [ 6464/60000]<br>loss: 1.424730  [12864/60000]<br>loss: 1.489542  [19264/60000]<br>loss: 1.367256  [25664/60000]<br>loss: 1.373464  [32064/60000]<br>loss: 1.376744  [38464/60000]<br>loss: 1.304962  [44864/60000]<br>loss: 1.347154  [51264/60000]<br>loss: 1.230661  [57664/60000]<br>Test Error:<br> Accuracy: 62.7%, Avg loss: 1.260891</p>
<h2 id="Epoch-5"><a href="#Epoch-5" class="headerlink" title="Epoch 5"></a>Epoch 5</h2><p>loss: 1.337803  [   64/60000]<br>loss: 1.313278  [ 6464/60000]<br>loss: 1.151837  [12864/60000]<br>loss: 1.252142  [19264/60000]<br>loss: 1.123048  [25664/60000]<br>loss: 1.159531  [32064/60000]<br>loss: 1.175011  [38464/60000]<br>loss: 1.115554  [44864/60000]<br>loss: 1.160974  [51264/60000]<br>loss: 1.062730  [57664/60000]<br>Test Error:<br> Accuracy: 64.6%, Avg loss: 1.087374</p>
<p>Done!</p>
<p>Read more about <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/optimization%5Ftutorial.html">Training your model</a>.</p>
<hr>
<h2 id="Saving-Models"><a href="#Saving-Models" class="headerlink" title="Saving Models"></a>Saving Models<a href="#saving-models"></a></h2><p>A common way to save a model is to serialize the internal state dictionary (containing the model parameters).</p>
<p>Saved PyTorch Model State to model.pth</p>
<h2 id="Loading-Models"><a href="#Loading-Models" class="headerlink" title="Loading Models"></a>Loading Models<a href="#loading-models"></a></h2><p>The process for loading a model includes re-creating the model structure and loading the state dictionary into it.</p>
<All keys matched successfully>

<p>This model can now be used to make predictions.</p>
<p>classes = [<br>    “T-shirt/top”,<br>    “Trouser”,<br>    “Pullover”,<br>    “Dress”,<br>    “Coat”,<br>    “Sandal”,<br>    “Shirt”,<br>    “Sneaker”,<br>    “Bag”,<br>    “Ankle boot”,<br>]</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval">model.eval</a>()<br><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">x</a>, y = <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST" title="torchvision.datasets.FashionMNIST">test_data</a>[0][0], <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST" title="torchvision.datasets.FashionMNIST">test_data</a>[0][1]<br>with <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.no%5Fgrad.html#torch.no%5Fgrad" title="torch.no_grad">torch.no_grad</a>():<br>    <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">x</a> = <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">x</a>.to(device)<br>    <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">pred</a> = model(<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">x</a>)<br>    predicted, actual = classes[<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor">pred</a>[0].argmax(0)], classes[y]<br>    print(f’Predicted: “{predicted}”, Actual: “{actual}”‘)</p>
<p>Predicted: “Ankle boot”, Actual: “Ankle boot”</p>
<p>Read more about <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/saveloadrun%5Ftutorial.html">Saving &amp; Loading your model</a>.</p>
<p><strong>Total running time of the script:</strong> ( 1 minutes 5.911 seconds)</p>
<p><a target="_blank" rel="noopener" href="https://sphinx-gallery.github.io/">Gallery generated by Sphinx-Gallery</a></p>
</div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/05/502c5eddc639.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item"> </span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/05/7acae0827b9d.html"><span class="level-item"> </span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-2-desktop is-2-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#Link"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Link</span></span></a></li><li><a class="level is-mobile" href="#Highlights-amp-amp-Note"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Highlights&amp;&amp;Note</span></span></a></li></ul><li><a class="level is-mobile" href="#Content"><span class="level-left"><span class="level-item">2</span><span class="level-item">Content</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Quickstart"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Quickstart</span></span></a></li><li><a class="level is-mobile" href="#Working-with-data"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Working with data</span></span></a></li><li><a class="level is-mobile" href="#Creating-Models"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Creating Models</span></span></a></li><li><a class="level is-mobile" href="#Optimizing-the-Model-Parameters"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Optimizing the Model Parameters</span></span></a></li><li><a class="level is-mobile" href="#Epoch-1"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">Epoch 1</span></span></a></li><li><a class="level is-mobile" href="#Epoch-2"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">Epoch 2</span></span></a></li><li><a class="level is-mobile" href="#Epoch-3"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">Epoch 3</span></span></a></li><li><a class="level is-mobile" href="#Epoch-4"><span class="level-left"><span class="level-item">2.8</span><span class="level-item">Epoch 4</span></span></a></li><li><a class="level is-mobile" href="#Epoch-5"><span class="level-left"><span class="level-item">2.9</span><span class="level-item">Epoch 5</span></span></a></li><li><a class="level is-mobile" href="#Saving-Models"><span class="level-left"><span class="level-item">2.10</span><span class="level-item">Saving Models</span></span></a></li><li><a class="level is-mobile" href="#Loading-Models"><span class="level-left"><span class="level-item">2.11</span><span class="level-item">Loading Models</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-2-desktop is-2-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/02literature/"><span class="level-start"><span class="level-item">02literature</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/02literature/book/"><span class="level-start"><span class="level-item">book</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/05area-of-responsibility/"><span class="level-start"><span class="level-item">05area of responsibility</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/05area-of-responsibility/physical-health/"><span class="level-start"><span class="level-item">physical health</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/05area-of-responsibility/%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">数学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/07archive/"><span class="level-start"><span class="level-item">07archive</span></span><span class="level-end"><span class="level-item tag">49</span></span></a><ul><li><a class="level is-mobile" href="/categories/07archive/tech/"><span class="level-start"><span class="level-item">tech</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/07archive/tech/games/"><span class="level-start"><span class="level-item">games</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/07archive/tech/games/101%E5%AE%9E%E9%AA%8C/"><span class="level-start"><span class="level-item">101实验</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/07archive/tutorial/"><span class="level-start"><span class="level-item">tutorial</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">七月 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">五月 2024</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">四月 2024</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">#linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/anki/"><span class="tag">anki</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bazel/"><span class="tag">bazel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cmake/"><span class="tag">cmake</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/code/"><span class="tag">code</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/dn11/"><span class="tag">dn11</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/firewall/"><span class="tag">firewall</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/games/"><span class="tag">games</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/icarus/"><span class="tag">icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/istore/"><span class="tag">istore</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/minio/"><span class="tag">minio</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/openwrt/"><span class="tag">openwrt</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rss/"><span class="tag">rss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rsshub/"><span class="tag">rsshub</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/scoop/"><span class="tag">scoop</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ssh/"><span class="tag">ssh</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tutorial/"><span class="tag">tutorial</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ubuntu/"><span class="tag">ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vim/"><span class="tag">vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vpn/"><span class="tag">vpn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/windows/"><span class="tag">windows</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wireguard/"><span class="tag">wireguard</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E7%AB%AF/"><span class="tag">前端</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"><span class="tag">图形学</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"><span class="tag">服务器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E8%AF%91/"><span class="tag">编译</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%BD%91/"><span class="tag">计网</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AF%E8%B7%AF%E7%94%B1/"><span class="tag">软路由</span><span class="tag">3</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="l4rk&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 l4rk</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/live2d-widget/autoload.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>