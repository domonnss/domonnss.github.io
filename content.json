{"pages":[],"posts":[{"title":"","text":"","link":"/2024/04/09d801fdb356.html"},{"title":"中国历代政治得失","text":"Highlights and Notes ^148d78 前言 首先，要讲一代的制度，必先精熟一代的人事。 第二，任何一项制度，决不是孤立存在的。各项制度间，必然是互相配合，形成一整套。 ^5979a6 第三，制度虽像勒定为成文，其实还是跟着人事随时有变动。某一制度之创立，决不是凭空忽然地创立，它必有渊源，早在此项制度创立之先，已有此项制度之前身，渐渐地在创立。某一制度之消失，也决不是无端忽然地消失了，它必有流变，早在此项制度消失之前，已有此项制度的后影，渐渐地在变质。 第四，某一项制度之逐渐创始而臻于成熟，在当时必有种种人事需要，逐渐在酝酿，又必有种种用意， 第五，任何一制度，决不会绝对有利而无弊，也不会绝对有弊而无利。 第六，我们讨论一项制度，固然应该重视其时代性，同时又该重视其地域性。推 第七，说到历史的特殊性，则必牵连深入到全部文化史。政治只是全部文化中一项目，我们若不深切认识到某一国家某一民族全部历史之文化意义，我们很难孤立抽出其政治一项目来讨论其意义与效用。 一国的政权，究竟该交付与哪些人，这是第一义。至于政府内部各项职权之究应如何分配，这已属第二义，中国历史 第三个范围则讲政府的赋税制度，这是政府关于财政经济如何处理的制度。 第四范围我想讲国防与兵役制度。 （一）皇室与政府 而且中国的立国规模，并不是向外征服，而是向心凝结。汉代的国家体制，显与罗马帝国不同。何况 在封建时代，本来有很多家庭有他们世袭的特权，这些皆所谓贵族。但从秦汉以后，封建制度早已推翻。单只皇室一家是世袭的，除却皇帝可以把皇位传给他儿子以外，政府里便没有第二个职位，第二个家庭，可以照样承袭。郡 不过在那时，还留下一个很大的问题：便是皇室和政府的关系。皇室是不是即算政府？若把皇室和政府划开，这两边的职权又怎样分？这是 皇室和政府是应该分开的，而且也确实在依照此原则而演进。皇帝是国家的唯一领袖，而实际政权则不在皇室而在政府。代表政府的是宰相。皇帝是国家的元首，象征此国家之统一；宰相是政府的领袖，负政治上一切实际的责任。皇权和相权之划分，这常是中国政治史上的大题目。我们这几十年来，一般人认为中国从秦汉以来，都是封建政治，或说是皇帝专制，那是和历史事实不相符合的。 汉代皇帝有六尚，尚是掌管意。六尚是尚衣、尚食、尚冠、尚席、尚浴与尚书。五尚都只管皇帝私人的衣服饮食起居。只有尚书是管文书的，这真是皇宫里的“秘书”了。汉代 若说到宰相的秘书处呢？共有十三个部门，即是当时所谓的十三曹，一个 可见汉代一切实际事权，照法理，该在相府，不在皇室，宰相才是政府的真领袖。以上 （二）中央政府的组织 所以丞是副，相也是副，正名定义，丞相就是一个副官。是什么 为什么又叫宰相呢？在封建时代，贵族家庭最重要事在祭祀。祭祀是最重要事在宰杀牲牛。象征这一意义，当时替天子诸侯乃及一切贵族公卿管家的都称宰。到了秦、汉统一，由封建转为郡县，古人称“化家为国”，一切贵族家庭都倒下了，只有一个家却变成了国家。于是他家里的家宰，也就变成了国家的政治领袖。 本来封建时代，在内管家称宰，出外作副官称相，所以 那时凡具中字的官，都是指是住在皇宫的。皇室 再说汉代的九卿，那是：太常、光禄勋、卫尉、太仆、廷尉、大鸿胪、宗正、大司农、少府。 一、太常：在秦代叫泰常，这个常字，本当作尝。他是管祭祀祖先鬼神的。依四时奉献时物，让祖先鬼神时时尝新，故称泰尝。在 古代的家庭，最重要的，可说不是活人而是死人，祭祖自属大事。宰就是掌管杀牛祭祖的。所以汉廷九卿的第一卿，也是管祭祀的。 依文义讲，勋该就是阍，古音相同，这是皇家的门房。光是大义，光禄该即是大麓，禄麓音同相借。为什么门房称大麓呢？此因古时代的皇帝，多半靠山住家，好像宋江在梁山泊，朱贵在山脚下开设酒店，好通报消息。所以皇帝居山，房门就设在山麓。尚书上说舜管尧的大麓，那便是舜做了尧的宰相。换言之，乃是当了尧的门房。因此光禄与勋是古今语，都指门房言。 卫尉：是一个武职，掌门卫屯兵，这是皇宫的卫兵司令。当时 太仆：犹之是皇帝的车夫，《 廷尉：是掌法的，犯了皇帝的法，都归他管。 太常管皇家太庙，光禄卫尉，一是门房头儿，一是卫兵头儿。这都是在里面的。皇帝出门，随带的是太仆，在外面有人犯法，就是廷尉的事。 胪是传呼义。古礼主宾交接，由主传到主身边的相，再由主身边的相传到宾边的相，由是而再传达到宾之自身。鸿即大义。大胪是传达官。 宗正：是管皇帝的家族，其同姓本家及异姓亲戚的。 大司农管的是政府经济，少府管的是皇室经济。大 （三）汉代地方政府 汉代的地方政府，共分两级：即郡与县。 汉代有一百多个郡，一个郡管辖十个到二十个县。大概 汉代郡长官叫太守，地位 汉代官级分得少，升转极灵活，这 当时全国一百多个郡，太守的名位，都和九卿差不多，因此 （四）中央与地方之关系 ^29d385 在九十月间呈报到中央，这叫做上计。 中央特派专员到地方来调查的叫刺史。全国分为十三个调查区，每一区派一个刺史，平均每一刺史的调查区域，不会超过九个郡。他的调查项目也有限制，政府规定根据六条考察，六条以外，也就不多管。地方 这些刺史，上属于御史丞。皇宫里还有十五个侍御史，专事劾奏中央乃及皇宫里的一切事情的。部刺史和侍御史的意见，都报告到副宰相御史大夫，副宰相再报告到宰相。副宰相所辅助宰相的，便是这一个监察的责任。 二、汉代选举制度 他们的子侄后辈，都得照例请求，送进皇宫当侍卫。待他在皇帝面前服务几年，遇政府需要人，就在这里面挑选分发。这一制度，虽非贵族世袭，但贵族集团，同时便是官僚集团，仕途仍为贵族团体所垄断。这在西方，直到近代还见此制。中国则自汉武帝以后便变了。 但郡县掾属，必得本地人充当。譬如台北市的人，不能当台北市的市长；但台北市政府从市长以下的一切官，在汉代称为掾属的，那就绝对要用台北市的本地人。不过辟用掾属的权，则在长官手里，这叫做辟属。三公、九卿、郡太守、县令，这些是由皇帝由中央政府任命的。宰相下面的十三曹，就由宰相自己辟用。此外各卫门首长以下，全是吏，全由各衙门首长自己任用。现在 一种是无定期的，譬如 策即是一种竹片。问题写在竹简上，故称策问。一道道的策问，请教贤良们大家发表意见，这叫对策。政府 第二种是特殊的选举，譬如 后来又有一种有定期的选举，那就是选举孝廉。汉代 自从武帝以后，汉代逐渐形成了一种一年一举的郡国孝廉，至少每年各郡要新进两百多个孝廉入郎署，十几年就要有两千个。从前皇宫里的郎官侍卫本也只有二千左右。自此制度形成，二三十年后，皇宫里的郎官，就全都变成郡国孝廉，而那些郡国孝廉，又多半是由太学毕业生补吏出身的。如是则皇帝的侍卫集团，无形中也变质了。全变成大学毕业的青年知识分子了。于是从武帝以后，汉代的做官人渐渐变成都是读书出身了。后来郎署充斥，要待分发任用的人才尽多，于是就把无定期选举，特殊选举都无形搁下，仕途只有孝廉察举的一条路，这是到东汉时代的事了。 一个青年跑进太学求学，毕业后，派到地方服务。待服务地方行政有了成绩，再经长官察选到中央，又须经过中央一番规定的考试，然后才始正式入仕。那是当时入仕从政的唯一正途。政府一切官吏，几乎全由此项途径出身。这样 这样的政府，我们只能叫它做读书人的政府，或称士人政府。汉代从昭宣以下的历任宰相，几乎全是读书人，他们的出身，也都是经由地方选举而来。并不是由其血统上和皇帝以及前任大官有什么关系，或者是大军人大富人，才爬上政治舞台。完全是因其是一读书知识分子而获入仕途。这一情形，直从汉代起。我们可说中国历史上此下的政府，既非贵族政府，也非军人政府，又非商人政府，而是一个“崇尚文治的政府”，即士人政府。只许这些人跑上政治舞台，政府即由他们组织，一切政权也都分配在他们手里。 三、汉代经济制度 然而汉代税制，有一个大毛病，当时对于土地政策，比较是采用自由主义的。封建 结果政府的租税愈轻，地主愈便宜，农民卖了地，要纳十分之五的租给地主，地主向政府只要纳三十分之一的税。政府减轻田租，只便宜了地主，农民没有受到分毫的好处。这是讲的田租。 以后中国历史上的土地政策，一面常欣羡古代井田制度之土地平均占有，但一面又主张耕者有其田，承认耕地应归属民间之私产。在这两观念之冲突下，终使土地租税问题得不到一个妥适的解决。 此因封建贵族都已消失，只剩皇帝一家，承袭旧来的封建传统，所有全国的山林池泽，照当时人观念，便全归皇室。再从这一所有权的观念影响到赋税制度，所以当时凡农田租入归诸大司农，充当政府公费。而山海池泽之税则属少府，专供皇帝私用。这一 汉武帝不禁要想：你们的钱究竟由哪里来的呢？岂不是都由我把山海池泽让给你们经营，你们才能煮盐冶铁，发财赚钱。现在我把少府收入都捐献给国家，而你们不响应，那么我只有把全国的山海池泽一切非耕地收还，由我让给政府来经营吧！这便是汉武帝时代有名的所谓盐铁政策。^d2f2d0 官山海 这并不专是一个思想与理论的问题，而实际上则有极占重要的历史传统之现实情况来决定。为了 盐铁论。当然 - 我们概括上述汉代的经济政策，对工商业是近于主张如近人所谓的节制资本的一面，而在对农民田租方面，则也已做到了轻徭薄赋，但并未能平均地权。在 - 王莽起来，就激起了一项大改革，把一切田亩尽归国有，称为皇田，重行分配。当时的意想，实在要恢复封建之井田制，而结果则引生一次大变乱。王莽失败了，从此中国历史上的土地制度也不再有彻底的改革了。 - 再也不进行土地所有制改革,是因为王莽新政 尝试说明此不可为 四、汉代兵役制度 一个壮丁，二十受田，可以独立谋生，但要他为国家服兵役，则应该顾及他的家庭负担。所以当时规定，从二十三岁起，照理他可以有一年储蓄来抽身为公家服役了。这一制度，不仅是一种经济的考虑，实在是一种道德的决定。 近代的中国人，往往蔑视自己以往的政治传统，又说中国没有成套的政治理论，没有大的政治思想家。当然在中国以往著作里，很少有专讲政治理论的书，也很少专以政治思想而成名的人物。这并不是中国人对政治无理论，无思想。只因中国读书人多半做了官，他们对政治上的理论和思想，早可在实际政治中表现了。用不着凭空著书，脱离现实，来完成他书本上的一套空理论。于是中国的政治理论，早和现实政治融化合一了。否则 当卫兵是极优待的，来回旅费由中央供给，初到和期满退役，皇帝备酒席款宴，平时穿的吃的，也不要卫兵们自己花钱。 陈胜吴广的革命，便由此而起。 汉代戍边还只是三天，可是你可以不去，只要一天出一百个钱，三天三百钱，交给政府，便可免戍。有一百个人不去，应该是三百天的免戍费，由政府把来另雇一人肯去的，一去便要他服三百天的戍役。他也得了这一笔钱，不仅足够在边用度，并且还可留一点安家， 太守是地方行政长官，都尉是地方军事首领。地方部队 中央有南北军，边疆有戍卒，地方上有国民兵，国家一旦有事，这三种军队都可以调用。 国家除了服兵役之外，还要服力役，这是春秋战国直至秦汉以下历代一向有的一个大问题，现在 全国壮丁按册籍编定，每人每年一个月，替国家义务做工，这在汉代唤做更卒，更是更替轮番的意思。如是则一个农民，既要到中央当卫兵，又要到边疆当戍卒，还要在地方上服国民兵役， 除了上述三种兵役和一种力役外，每个国民还须纳人口税，连小孩子都有。说到 于是有的人便宁愿出卖自己，做私人家的奴隶。当时 要是在后代，无业谋生，还可以做乞丐、做流氓，政府不会来管。但在汉代是不许可的。你要当义务兵，你要去修飞机场、公路，你要纳人口税，你的名字住址，都在政府册子上，不去就要出钱，出不起钱便是犯法。你 当时做奴隶，并不是出卖自由，只是出卖他对国家法规上一份应尽的职责。政府 罗马的农奴多半是战争得来的俘虏，汉代的奴隶是农民自己游离耕土，来参加大规模的工商新生产集合。如何 汉代除却规定的义务兵役外，民间还有义勇队，志愿从军的。国家有事，可以自由报名。这叫做良家子从军。那些 五、汉制得失检讨 首先在经济方面，土地问题没有解决，形成兼并，富者田连阡陌，穷者无立锥之地，使政府的减轻租税政策，全失功效。至王莽把土地收归国有，此事又激起社会多数人的反对，结果失败了。但王莽的废止奴隶政策，却继续为东汉政府所承袭。东汉时代也屡有废奴的诏令，但只要社会经济情形不便，此项诏令是不会有实效的。 奴隶制度向来被反对 其次说到军队制度，中国地大人众，虽说分区训练各别的兵种，但每年一个月的操练是不够的。中央南北卫，像是常备军，实际上，时期也只一年，数额也仅有七八万人。结果全国皆兵，并不够用。遇到打仗，各地调遣，如会稽吴楚，远赴渔阳上谷，也不方便。所以全国皆兵制，在中国论，一则军队数量太多，二则训练太简略，调动不方便，结果全国皆兵，弄得有名无实，一旦起了问题，还是解决不了。 汉武帝自己是雄才大略，他自己揽权，尚不甚要紧，他死了，他须替他后代小皇帝着想，于是来一位大司马大将军辅政，便出来问题了。汉宣帝以下，霍氏虽败，结果还是大司马大将军外戚辅政，还是内廷权重，外朝权轻，于是有王莽代汉而兴。王莽便是由大司马大将军而掌握大权的。 汉武帝废除太尉,以大司马代太尉的权责 本来三公是宰相、太尉、御史大夫，而实际宰相是全国之首领。后来因有大司马大将军横插进来，所以又把此三公变成大司徒、大司马、大司空三职分别，一个公管领三个卿。在 所以后代中国人批评光武帝有事无政，这是 没有创立合理的制度 经济文化落后的地区和经济文化进步的地区，都一样照人口比例来考选。因此中央政府里，永远有全国各地域人民之参加，不致偏荣偏枯。因此中国政府，始终是代表着全国性的，全国人民都有跑进政府的希望。 北美议会与不列颠议会 而全国各地方声教相通，风气相移，却可使各地文化经济水准，永远走向融和，走向平均，不致隔绝，不致分离。这一制度，自汉代起直至清代始终沿用。这是中国传统政治制度里一最应着眼之点。 客观上极大程度地维护了统一 而且汉代选举，就大体言，最先必进学校读书，才获补吏。补吏以后，才获察举。这由教育而行政实习，由行政实习而选举，再由选举而考试，由考试而任用之几个阶段，骤看极合情理，切实施行，像不会出大毛病。然而依然有毛病存在。因 古代社会，读书机会就不易得。第一是书本不易得，古代书籍都用竹帛书写，很少纸张，更无印刷。印刷术 生活在物质世界 因此当时虽非封建社会，爵位不世袭，而书本却可世袭。虽不是世代簪缨，却是世代经学。世代经学，便可世代跑进政治圈子，便无异一封建传袭的贵族了。那时 学问与书本，却变成了一种变相的资本。所以说黄金满籯，不如遗子一经。这便是一本书的资本价值，胜过了一箩黄金的资本价值了。因此当时一个读书家庭，很容易变成一个做官家庭，而同时便是有钱有势的家庭。当时有所谓家世二千石的。只要家庭里有一个做到二千石的官，他当一郡太守，便可有权察举。他若连做了几郡的太守，他便是足迹遍天下，各地方经他察举的，便是他的门生故吏，将来在政治上得意，至少对他原来的举主，要报些私恩，若有人来到他的郡里做太守，必然也会察举他的后人。因此察举过人的子孙，便有易于被人察举之可能了。上面说过，汉代选举，是分郡限额的，每郡只有几个额，于是却永远落在几个家庭里。如是则每一郡必有几个像样的家庭，这便造成了将来之所谓世族门第，也便是世族门第必然带有郡望之来历了。当时的大门第，依然平均分配在全国各地，大概是每郡都有几家有声望的，我无以名之，名之曰门第的社会。这并非封建社会，也并非资本主义的社会，但一样有不平等。虽非封建贵族，而有书生贵族。虽非工商业资本，而有书籍资本。国家的政治制度，虽没有对那些家庭许下世袭特权，但他们因有家庭凭借，无异于有世袭的特权了。 只有一定的社会关系下,资本才会变成资本 我们可以说，古今中外一切制度，都必如是。否则一项好制度，若能永远好下去，便将使政治窒息，再不需后代人来努力政治了。惟其一切制度都不会永久好下去，才使我们在政治上要继续努力，永久改进。制度也只是历史事项中之一目，人类整部历史便没有百年不变的，哪能有一项制度经过一两百年还算得是好制度呢？ 当至少他们懂得皇权之外有相权，至少已懂得皇室之外有政府了。再说到选举制度，至少他们已懂得政府用人该有一客观标准，不能全凭在上者之私心好恶。至少他们已懂得该项标准，不该是血统的亲疏，不该是势力的大小。亲的贵的强的富的，都不够此项标准，而采取一项以教育与知识与行政实习之成绩，来定取舍进退之标准，而又懂得平均分配到全国各地区，这也不能不说是在当时已算合理化，已算开明与进步的了。至于经济政策，一面主张轻徭薄赋，宽假平民，一面主张裁抑富厚，导致平等，这也不算得黑暗，不算得无理。至于 皇室与政府的关系，终究发生了冲突；选举制度，到底造成门阀新贵族；经济制度、兵役制度都没有弄好，都出毛病了。但我 此下魏晋南北朝，始终没有像样的政府，因此也没有像样的制度产生，直要到唐代。但唐代已不是汉代的老样子，老制度，他又换了崭新的一套。直要待唐代的新制度又出了毛病，宋代又再换一套。此下明代，清代也如此。只因 （一）汉唐相权之比较 唐代政府和汉代之不同，若以现在话来说，汉宰相是采用领袖制的，而唐代宰相则采用委员制。换言之， 汉代宰相下有副宰相，御史大夫，我们也可说，宰相掌握的是行政权，御史大夫掌握的是监察权。唐代宰相共有三个衙门，当时称为三省：一中书省，二门下省，三尚书省。此三省职权会合，才等于一个汉朝的宰相，而监察权还并不在内。 中书省首长为中书令，门下省主管长官为侍中，尚书省长官为尚书令。唐分官阶为九品，第一二品官，均以处元老，不负实际行政责任。三品以下，始为实际责任官吏。中 若论此三省之来历，尚书本是皇宫内廷秘书，已在讲汉代制度时讲过。中书依官名论，也即是在内廷管理文件之意。侍中则是在宫中侍奉皇帝。故就官职名义言，这三个官，原先本都是内廷官。而 换言之，亦即是把以前皇室滥用之权重交还政府。 （二）唐代中央政府三省职权之分配 凡属重要政事之最高命令，一定要皇帝下敕行之。但实际上皇帝自己却并不拟“敕”，而系中书省拟定，此所谓“定旨出命”。在 设有副长官“中书侍郎”。中书侍郎之下，又有“中书舍人”，员额有七八人之多。中书舍人官位并不高，而他们却有拟撰诏敕之权。遇中书发布命令，多由他们拟撰。 而中国人传统，则常求取决于贤人。春秋时即有“贤均从众”之说（见《左传》）。哪一人贤，就采纳哪一人的意见，假若双方均贤，则再来取决于多数。贤属质，众属量，中国传统重质不重量。中国人认为只要其人是贤者，就能够代表多数。不贤而仅凭数量，是无足轻重的。这一 人们自己创造自己的历史,但他们不是随性所欲地创造,并不是在他们选定的条件下创造,而是在直接碰到的,既定的,从过去继承下来的条件下创造。一切已死的前辈们的传统,像梦魇一样缠绕着或活人的头脑。 所以唐代政府定旨出命之权，是操于中书省。皇帝只同意画敕而止。 待门下省主管长官侍中及副长官侍郎接获此项诏书后，即加予复核，这是对此项命令之再审查。在门下省侍中侍郎之下，设有若干第三级官，谓之“给事中”。给 每一命令，必须门下省副署，始得发生正式效能。如门下省不同意副署，中书命令便不得行下。 尚书省则仅有执行命令之权，而于决定命令则无权过问。 （三）中央最高机构政事堂 中央最高机构政事堂 无效。故唐制遇下诏敕，便先由门下省和中书省举行联席会议，会议场所称为“政事堂”。原先 最先尚书仆射都附此职衔，所以三省全是真宰相。但到开元以后，即尚书仆射不再附有出席政事堂之职衔了。如是 在唐代，也并无皇帝决不该不经中书门下而径自颁下诏书之规定。 武则天以下的唐中宗，也便不经两省而径自封拜官职。但中宗究竟心怯，自己觉得难为情，故他装置诏敕的封袋，不敢照常式封发，而改用斜封。所书“敕”字，也不敢用朱笔，而改用墨笔。当时称为“斜封墨敕”。此即表示此项命令未经中书门下两省，而要请下行机关马虎承认之意。在当时便认为这是一件值得大书特书之事，因此在历史上传下。当时唐中宗私下所封之官，时人称之为“斜封官”，因其未经正式敕封手续而为一般人所看不起。 根据这一点看，中国过去的政治，不能说皇权相权绝不分别，一切全由皇帝专制。我们纵要说它是专制，也不能不认为还是一种比较合理的开明的专制。它也自有制度，自有法律，并不全由皇帝一人的意志来决定一切的。我们 开会时有一主席，称为“执笔”。讨论结果，由他综合记录，等于现在之书记长。此项主席轮流充任。有时 （四）尚书省与六部 尚书省共分六部，即吏部、户部、礼部、兵部、刑部、工部。 唐开始时是吏礼兵民（户部）刑工，唐太宗是改为吏礼民（户）兵刑工，至宋朝初年次序是吏兵刑民（户）工礼，宋神宗时王安石变法，其次序为吏户礼兵刑工，这次序遂为以后所沿袭。 汉代九卿，就名义论，只是办理皇室内廷事的家务官，唐代始正式有六部尚书，显然成为管理国家政务的机构，不像汉代只似皇帝的侍从。此为中国政治史上一大进步，无论从体制讲，从观念讲，都大大进步了。 前书为中国先秦时代人之乌托邦，纯系一种理想政府的组织之描写。亦可谓是一部理想的宪法。其最堪重视者，乃为政治理想之全部制度化，而没有丝毫理论的痕迹，只见为是具体而严密的客观记载。我们读此书，便可想见中国古代人之政治天才，尤其在不落于空谈玄想，而能把一切理论化成具体事实而排列开来之一层。所以《周礼》虽不是一部历史书，不能作为先秦时代的制度史，大体上看，而实是一部理论思想的书，应为讲述先秦政治思想之重要材料。 制度的背后，都应有理论和思想。一切制度，决不会凭空无端地产生。 （五）唐代地方政府 中国历史上的地方行政，最像样的还该推汉代。 唐刺史则为地方高级行政首长。 可见唐代的县比汉县为小。 唐代地方长官，其职权比重，较之汉代差逊甚远。 唐代则任用之权集中于中央之吏部。州县长官无权任用部属，全由中央分发。 汉制三年考绩一次，三考始定黜陟，因阶级少，升迁机会优越，故能各安于位，人事变动不大，而行政效率也因之提高。唐代则迁调虽速，下级的永远沉沦在下级，轻易不会升迁到上级去。于是在官品中渐分清浊，影响行政实际效力极大。 （六）观察使与节度使 唐代设御史台，所谓三省六部一台，御史台成为一独立之机构，不属于三省。换言之，监察权是脱离相权而独立了。 唐中宗后，御史台分左右御史，左御史监察朝廷中央政府，右御史监察州县地方政府，此即所谓“分巡”“分察”。监察中央的谓之“分察”，监察地方的谓之“分巡”。 在汉制，刺史规定六条视察，大体范围，不得越出于六条之外。在唐代，名义上仍是巡察使，观察使，明明是中央官，派到各地区活动巡视观察，实际上则常川停驻地方，成为地方更高一级之长官。 故唐代监察使，论其本源，是一御史官，而属于监察之职者。但逐渐演变成了地方长官之最高一级。把府县地方官压抑在下面。如是则地方行政，本来只有二级，而后来却变成三级。然其最高一级则名不正，言不顺，遂形成一种中央集权，对地方行政，极有流弊。 假使此项监察使巡视边疆，在边防重地停驻下来，中央要他对地方事务随宜应付，临时得以全权支配，这即成为节度使。 节度使在其地域，可以指挥军事，管理财政，甚至该地区用人大权，亦在节度使之掌握，于是便形成为“藩镇”。 东汉末年之州牧，即已如此，而唐代又蹈其覆辙。安史之乱，即由此产生。 其先是想中央集权，由中央派大吏到外面去，剥夺地方官职权。而结果反而有中央派去的全权大吏在剥夺地方职权之后，回头来反抗中央，最后终至把唐朝消灭了。 总之中国是一个广土众民的大国家，必需得统一，而实不宜于过分的中央集权。这在中国的政治课题上，是一道值得谨慎应付的大题目。 而由军队首领来充地方行政首长，则更是大毛病。 边疆多用武人 （一）魏晋南北朝时代之九品中正制 说到考试两字之原始意义，考是指的考绩，试是指的试用。 中国传统观念，总谓贤人可以代表群众舆论与公共意见。 至于贤人而实不贤，中正而并不中正，则另是一事实。至少在曹魏初行此制时，总比以前漫无标准各自援用私人好得多。 每一项制度的诞生背后有其合理的逻辑，不论后世看来如何扯淡。虽饮鸩止渴，不可不为 在陈群时，为什么要大中正定由中央大官兼职呢？此因当时地方与中央已失却联系，故只就中央官来兼任大中正，好由他推选他的本乡人士之流亡在中央者备供中央之任用。但又为何中正簿上定要连做官人一并登记品评呢？因为如此做法，便可把当时已经滥用不称职的一批人澄清除去。这些都是陈群创设此制时之苦心。因此九品中正制就其为一时救弊起见，也不算是坏制度。但到后来，因施行的时间空间关系都不同了，而还是照样沿用，遂终于出了大毛病。 理论是此制度之精神生命，现实是此制度之血液营养，二者缺一不可。 其实革命的本质，应该是推翻制度来迁就现实的，绝非是推翻现实来迁就制度的。 （二）唐代之科举 考试及格，即为进士及第。进士及第便有做官资格了。至于实际分发任用，则须经过吏部之再考试，所考重于其人之仪表及口试，乃及行政公文等。大抵礼部考的是才学，吏部考的是干练。又因吏部试有进士、明经诸科，故此制又称科举制。自唐至清，此制推行勿辍。 在西方现行的所谓民主政治，只是行政领袖如大总统或内阁总理之类，由民众公选，此外一切用人便无标准。这亦何尝无毛病呢？ 当知任何一种制度之建立，傥是仅由一二人之私意便能实现了，这便无制度可讲。 凭事实讲，科举制度显然在开放政权，这始是科举制度之内在意义与精神生命。汉代的选举，是由封建贵族中开放政权的一条路。唐代的公开竞选，是由门第特殊阶级中开放政权的一条路。唐代开放的范围，较诸汉代更广大，更自由。所以就此点论，我们可以说唐代的政治又进步了。 但唐代的科举制度，实在亦有毛病。姑举一端言之，当时科举录取虽有名额，而报名投考则确无限制。于是因报考人之无限增加，而录取名额，亦不得不逐步放宽。而全国知识分子，终于求官者多，得官者少，政府无法安插，只有扩大政府的组织范围。唐代前后三百年，因政权之开放，参加考试者愈来愈多，于是政府中遂设有员外官，有候补官，所谓士十于官，求官者十于士，士无官，官乏禄，而吏扰人，这是政权开放中的大流弊。 无官身的生员阶级形成 而中国则不然，可说自两汉以来，早已把政权开放给全国各地，不断奖励知识分子加入仕途，而同时又压抑工商资本。只鼓舞人为大学者，当大官，却不奖励人为大商人，发大财。节制资本，平均地权，大体上是中国历史上的传统政策。政治措施，存心在引导民间聪明才智，不许其为私家财力打算无限制的发展。于是知识分子竞求上政治舞台去做官，仕途充斥，造成了政治上之臃肿病。 并不是我们的传统政治知识专制黑暗，无理性，无法度，却是一切合理性有法度的制度全都该不断改进，不断生长。 （一）唐代的租庸调制 唐代的田赋制度称为“租庸调”。 均田制所与古代的井田制不同者，井田乃分属于封建贵族，而均田则全属中央政府，即国家。均田是郡县制度下的井田，而井田则是封建制度下的均田。 庸”即是役，乃人民对国家之义务劳役。 调”是一种土产贡输，各地人民须以其各地土产贡献给中央，大体上只是征收丝织物和麻织物。 唐代租庸调制，最要用意，在为民制产，务使大家有田地，自可向国家完粮。 （二）唐代账籍制度 依照历史来讲，租庸调制之所以能推行，全要靠账籍之整顿。","link":"/2024/02/6bb848d9a3da.html"},{"title":"Linux安装","text":"BIOS、UEFI、MBR、GPT、GRUB 到底是什么意思？ubuntu20.04.1 下载阿里云镜像https://mirrors.aliyun.com/ubuntu-releases/?spm=a2c6h.25603864.0.0.2b7e45f8SJ9NVf 在阿里云下载的镜像甚至不需要换源?它好像本来就是换好的 安装diskgenius处理磁盘分区rufus写入ISO重启进入bios,调整启动项 根据安装指引一路点点 ubuntu磁盘分区:引导:512m efi系统分区swap:16g根: ext4日志home: ext4日志 注意一定要在混合模式下启动,独显模式,缺少显卡驱动,打不开,后期更换显卡驱动就行了 删除注意要在windows中删除efi中的ubuntu启动引导 cmd 初始化Ubuntu换源apt为软件安装工具,所以所有的源都保存在/etc/apt/source.list中.先备份.bak,再对源内容进行修改12345cd /etc/apt/cp /etc/apt/source.list /etc/apt/source.list.bakvi /etc/apt/source.list 阿里源12345678910111213deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse ## Pre-released source, not recommended. # deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse # deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse 清华12345deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse ## Pre-released source, not recommended. # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 中科大12345678910111213deb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse ## Pre-released source, not recommended. # deb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse ifconfig安装Ubuntu安装ifconfig工具1apt-get install net-tools 硬件信息查看软件信息查看cat /proc/version+ 网络信息查看ip -a ssh远程登录refering:SSH简介及两种远程登录的方法Secure Shell(SSH)是由 IETF(The Internet Engineering Task Force) 制定的建立在应用层基础上的安全网络协议。它是专为远程登录会话(甚至可以用Windows远程登录Linux服务器进行文件互传)和其他网络服务提供安全性的协议，可有效弥补网络中的漏洞。通过SSH，可以把所有传输的数据进行加密，也能够防止DNS欺骗和IP欺骗。还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。目前已经成为Linux系统的标准配置。SSH分为客户端 openssh-client 和服务器 openssh-server，可以利用以下命令确认电脑上是否安装了客户端和服务器。1dpkg -l | grep ssh 安装openssh-server1apt install openssh-server 修改配置文件1234vim /etc/ssh/sshd_config#找到所在行: /PermitRootLogin 把该行的注销取消,并把值改为yes。: wq 重启ssh。1service ssh restart 就可以在第三方客户端访问了 寻找文件位置1locate test.txt 1find -name example 修改网关12cd /etc/netplan/ls 找到example.yml文件修改文件中的gateway12sudo netplan applyroute -n参考","link":"/2024/02/accdd1ffac11.html"},{"title":"OpenClash导致的ssh登录失败","text":"情况说明只能内网访问设备,外网访问设备失败,报错为Connection to &quot;my.domain.cn&quot; closed with error: connection reset by peer ipv4 主路由ikuai ddns已设置 端口映射已开 旁路由openwrt 原使用PassWall,改用OpenClash代理 解决主要看OpenClash的这个issueopenclash开启fake ip模式,服务&gt;&gt;openclash&gt;&gt;插件设置&gt;&gt;黑白名单 &gt;&gt;绕过核心的来源端口添加内网端口","link":"/2024/06/1a44d7a4736a.html"},{"title":"YAML","text":"referingYAML 是一种较为人性化的数据序列化语言，可以配合目前大多数编程语言使用。","link":"/2024/02/bff407af237e.html"},{"title":"api","text":"api能实现程序之间的数据交流,也能实现,客户端与服务器端口的数据交流. 服务器API接口,是指在自己的服务器上构建一个API，以便其他应用程序可以通过网络请求与之交互。","link":"/2024/02/014e726913db.html"},{"title":"anki-sync-server","text":"dependences必要公网IPv4linux服务器dockerdocker-compose 可选ddns 没有ddns,可以将服务器同步地址改为你的ipv4地址,例如http://69.31.25.33:8080端口映射 不一定要用ikuai的,路由器自带的端口映射也可以用 服务器配置123456789101112131415l4rk@l4rkserver:~/docker-compose$ cat docker-compose.ymlversion: &quot;3.7&quot;services: anki_sync_server: image: jeankhawand/anki-sync-server:23.12.1 restart: unless-stopped ports: - &quot;52502:8080&quot; #将docker容器中的8080端口映射到linux主机的52502端口 environment: - SYNC_USER1=账号:密码 volumes: - anki_data:/home/anki # network_mode: host 没有网络问题,不直接走主机的网络volumes: anki_data: #创建anki_data的卷来专门存放anki的数据 docker项目暂时只有24.04,23.12.1,23.10这几个tag,后续版本更新不知道是否会同步适配.但既然已经在anki官方库中提交了PR应该会继续维护. 启动1docker-compose up -d ddnsikuai[[07archive/tech/软路由#ddns配置|ddns配置]]中写了如何配置ddns,不展开本人使用的ddns为dn11.l4rk.cn 端口映射再配置[[07archive/tech/端口映射|端口映射]] AnkiDroid与Anki for windows设置 总结使用docker-compose,再加上公网ipv4,与ikuai的ddns &amp; 端口映射,实现公网同步anki数据.AnkiDroid与Anki for windows都可以完美使用,就可以体验到超快同步速度有没有🥳🥳🥳","link":"/2024/04/3140bf7ee5dd.html"},{"title":"bazel","text":"转载自什么是Bazel—教程、实例和优势作者：方石剑链接：https://juejin.cn/post/7120840097863303199来源：稀土掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 Bazel是一个开源的构建工具，由谷歌开发，用于自动化大规模软件的构建过程。Pinterest、Adobe、SpaceX、Nvidia和LinkedIn等公司都使用它。在本教程中，你将了解什么是Bazel，它如何工作，以及它的重要好处。你还会学到如何为你的monorepo项目生成Bazel构建。 你为什么要使用Bazel？Bazel的工作原理与Make、Maven或Gradle等其他构建工具类似。然而，与其他工具不同的是，Bazel是为具有多语言依赖性的项目量身定做的。 例如，你可以有一个Rust或Go的服务器，一个flutter的移动客户端，和一个Angular的网络客户端。在这种情况下，如果你要手动编写自己的构建文件，以迎合每种语言的生态系统，这可能是一项艰巨的任务。幸运的是，Bazel为你完成了所有繁重的工作： Bazel最吸引人的特点之一是你可以轻松地将它与你的项目的CI/CD挂钩。这可以帮助你提高团队的生产力，因为你可以产生更可靠的构建，定期和严格地测试你的软件。因此，你也可以很容易地出货和发布更强大的构建。 然而，Bazel不仅仅是处理多语言的依赖关系。让我们来探讨一些使它如此强大的好处。 Bazel有哪些优点？以下是使Bazel成为出色的构建工具的关键优势。 可重复性：Bazel产生纯功能构建，你的输出文件严格依赖于你的输入。这给你的构建带来两个重要的特点。首先，你的构建是密封的，这意味着只有你明确提到的输入可以被你的构建步骤所读取。第二，你的构建是可重复的，或者换句话说，是可复制的。如果你使用一组固定的输入，Bazel每次都会产生相同的构建。可重复的构建使调试你的构建操作更加方便。 与Docker和Kubernetes集成：归功于其多功能性，Bazel补充了现代平台和系统，如Docker和Kubernetes。例如，你可以为你的monorepo准备一个方便的Docker容器，其中包含一个web客户端和一堆微服务。然后你可以用它来启动一个类似于生产环境的测试环境。这样你就可以通过你的容器来测试你的Bazel构建。此外，你可以启用增量构建，并使用AWS Fargate或Kubernetes等协调引擎管理你的部署。 可扩展性：Bazel的发明源于谷歌的一个内部构建工具Blaze。在谷歌内部，Bazel处理包含超过10万个源文件的项目的构建。换句话说，Bazel非常适合拥有庞大代码库的大型项目。虽然它提倡单程序模式，但它也能轻松处理微服务架构。Dropbox使用Bazel来扩展他们的CI/CD管道，以减少对他们的提交执行的测试数量。Uber也采用了Bazel来扩展他们的Go monorepo。他们利用Bazel的密封式构建来支持增量构建的生成，以支持他们的分布式基础设施。 声明式编程：为项目编写构建配置应该尽可能简单。Bazel是使用Starlark构建的，这是一种源自Python的高级语言。因此，它为开发者提供了一种更方便的方式来编写构建配置和属性，这些配置和属性都是可读的。此外，Bazel的抽象性使开发者无需处理复杂的东西，如编译器和链接器。 平行性和缓存：大规模的构建工具必须是高性能的。Bazel使用缓存机制来加快你的构建速度。它智能地将你的后续构建与你以前的缓存构建进行比较，只构建那些开发者更新的文件。这确保了Bazel只把你的CPU资源花在构建那些需要重新构建的项目部分。Bazel还允许你以并行的方式生成并发的构建，以节省分布式代码库的时间。你可以在单台机器上，也可以在多台机器上远程生成并行构建。 庞大且不断增长的开源社区：Bazel的第一个版本是在2019年推出的，差不多有2年时间。从那时起，谷歌在两年的时间里推送了100多个版本，试图为开发者不断发展这个工具。Bazel的Github repo有17.4k颗星，在Stack Overflow上有超过2K个标记的问题和超过6K个搜索结果。这些微小但不断增长的数字表明，它在社区中获得了相当快的吸引力。 Bazel术语和基础知识解释现在，让我们来看看Bazel使用的一些重要术语： 工作区工作区通常是Bazel从你的源代码构建你的项目的构建文件的目录。它以嵌套的层次方式包含各种源文件。在工作区的最高层或根层，你的项目可能也有一个专门的WORKSPACE 文本文件。它包含了对你的项目所需的所有外部依赖的引用，以生成你的构建。准确地说，工作区是你的输入被提取并转换为输出以生成所需的构建文件的地方。 软件包包是位于工作区顶级目录下的简单目录。它们包含你的构建文件，可以命名为BUILD 或BUILD.bazel ，以及其他相关文件和指定的依赖关系。一个包可以嵌套在另一个包中，因为你的源代码是以分层的方式组织的。考虑一下下面的工作目录。 css 复制代码 src/application/BUILD src/application/main/render.txt src/application/staging/BUILD 该应用程序是一个包，因为它包含自己的BUILD 文件。同样，staging 是另一个包，但由于它直接属于application ，所以可以被认为是一个子包。然而，main 不是一个子包，而只是你的application 包内的一个普通目录，因为它没有自己的BUILD 文件。 目标你的包内的所有东西都可以被认为是目标。它包括你的团队的开发人员编写并添加到你的项目中的源文件或Bazel根据你的构建配置构建的生成文件。除了文件之外，目标通常涉及到管理你的输入文件和输出文件之间关系的规则。换句话说，目标规则规定了Bazel如何构建你的构建文件，它要采取的中间步骤以及它需要执行的每个可执行操作。你的目标规则的输入文件可以是源文件或生成文件。不过，你的输出文件总是生成文件，因为它是构建工具本身的结果。你可以指定你的目标规则，以连锁你的输入和输出，进行连续的构建操作。例如，你可以使用前一个步骤的生成文件作为未来另一个步骤的输入文件。 标签一个目标的命名法被称为标签。它只是一种识别属于一个包的不同目标的方法，并将它们与相同或不同包中的其他目标区分开来。考虑一下下面这个标签： java 复制代码 @repo//application:application_source 上面的标签描述了一个包内的目标application_source 应用。同样地，在下面的例子中，main_binary 描述了在包application 下的子包main 内的一个目标： ruby 复制代码 @repo//application/main:main_binary 两个目标都有不同的标签，你可以期望每个标签都能唯一地识别一个目标。 依赖关系当你构建你指定的目标时，一个或多个目标在构建过程中可能依赖于另一个目标。后者是一种依赖关系。为了进一步解释，考虑两个目标Target1 和Target2 。假设Target1 在构建或执行时需要Target2 。我们可以把这种关系表达为一个有向无环图，表明在这个过程中Target1 是如何依赖于`Target12的。Bazel称其为依赖图，用于区分实际依赖和声明依赖。 构建文件早些时候，我们说过，在一个WORKSPACE ，每个包都包含自己的BUILD 文件。构建文件包含使Bazel为你的项目生成所需构建的程序。它是用Starlark来评估的，包含一个由Bazel执行的顺序语句列表。构建文件包含你声明的规则，执行这些规则的函数，以及以简单语法形式要求的变量。 我们知道Bazel会缓存以前的构建文件以加快构建过程。每当你的源文件发生变化时，Bazel就会引用BUILD 文件来了解底层的变化。 命令Bazel提供了一系列的命令，允许你执行某些操作。你可以运行的最简单的命令是检查Bazel是否成功安装在你的系统中： css 复制代码 $ bazel --version bazel 4.0.0 其他重要的命令有：bazel build,bazel run 和bazel test 。build命令，顾名思义，是为指定的输入或目标建立你的输出文件： yaml 复制代码 $ bazel build //foo INFO: Analyzed target //foo:foo (14 packages loaded, 48 targets configured). INFO: Found 1 target... Target //foo:foo up-to-date: bazel-bin/foo/foo INFO: Elapsed time: 9.905s, Critical Path: 3.25s INFO: Build completed successfully, 6 total actions run命令运行你的输出文件，test命令相当于同时运行build和run命令： 用Bazel构建/编译代码现在我们知道了常见的Bazel术语，让我们明白我们可以用Bazel构建或编译我们的代码，具体步骤如下。 1..bazelrc 文件我们做的第一步是在一个专门的.bazelrc 文件中写入我们的构建选项。这些选项决定了每次Bazel构建你的项目时要考虑的设置。下面是一个典型的.bazelrc 文件的样子，如果你正在构建一个JavaScript项目： lua 复制代码 build --disk_cache=~/.cache/bazel-disk-cache build --enable_platform_specific_config build --symlink_prefix=dist/ test --test_output=errors test:debug --test_output=streamed --test_strategy=exclusive --test_timeout=9999 --nocache_test_results --define=VERBOSE_LOGS=1 run:debug --define=VERBOSE_LOGS=1 -- --node_options=--inspect-brk build:debug --compilation_mode=dbg build --nolegacy_external_runfiles build --incompatible_strict_action_env run --incompatible_strict_action_env coverage --instrument_test_targets try-import %workspace%/.bazelrc.user 2.添加buildifier 依赖关系为了确保你所有的构建文件都以类似的方式格式化，Bazel使用了一个名为buildifier 的依赖项。你可以通过运行，把它安装为你项目的开发时依赖： css 复制代码 npm install --save-dev @bazel/buildifier 它可以确保你所有的构建文件看起来都是一样的，以便在你项目的各个构建步骤中保持一致性。当Bazel使用其缓存的工件将你当前的构建与以前的构建进行比较时，这还有助于加快你的构建过程。 3.创建目标这是你编写Bazel需要构建的所有源代码的地方。还记得Bazel如何为你指定的目标构建输出文件吗？那基本上就是与你的项目有关的应用级代码。一旦你定义并声明你的目标，Bazel就知道在构建所需的输出时要使用哪些输入。 4.添加构建规则当我们完成了我们的构建选项，我们需要使用一些规则来构建我们的项目。在这一步，你可以选择自动生成的规则或定义你自己的自定义规则。谨慎的做法是利用自动生成的规则，请记住，在Bazel的官方资源库里有少量的规则。我们在构建文件中定义这些规则。 5.构建/编译项目在你指定了你的构建规则后，Bazel通常会接收你的构建文件作为输入并将其加载到分析器。接下来，它根据你的目标和依赖关系产生一个动作图，并在你声明的输入上借口构建动作。最后，它产生构建输出，并将其存储在缓存工件中，供后续构建使用。 让我们在行动中扩展这个理论，逐步看到这个过程是如何让我们用Bazel构建一个JavaScript单体的。 用Bazel建立一个monorepo项目为了开始，我们可以使用@bazel ，在一个新的NodeJS项目中直接设置Bazel： kotlin 复制代码 npm init @bazel bazel_js_monorepo 下面是上述命令运行成功后，你应该在终端上得到的结果： 你会注意到，现在你的项目中已经有了buildifier ，还有其他所需的文件，如用于管理你的JavaScript依赖的package.json ，你的项目的WORKSPACE ，以及最重要的BUILD.bazel 文件。 你还需要安装Babel和其他相关的依赖项来转译你的JavaScript代码： bash 复制代码 npm install @babel/core @babel/cli @babel/preset-env 如果你前往WORKSPACE 文件，你会看到它是如何阐明Bazel在构建你的项目时需要获取的依赖项的。你需要明确地告诉Bazel你将使用哪些规则来生成你的构建。为了简洁起见，我们将使用自动生成的规则。 进入你项目根部的BUILD.bazel 文件，添加以下一行： perl 复制代码 load(&quot;@npm//@babel/cli:index.bzl&quot;, &quot;babel&quot;) 因此，你也需要为你的项目配置Babel。在您的项目根目录下创建一个新的文件，名为es5.babelrc 文件。回顾一下，我们之前看到的.babelrc 文件的目的是描述我们的构建选项，在其中添加以下代码： perl 复制代码 { &quot;sourceMaps&quot;: &quot;inline&quot;, &quot;presets&quot;: [ [ &quot;@babel/preset-env&quot;, { &quot;modules&quot;: &quot;systemjs&quot; } ] ] } 上面的配置类似于webpack将Babel添加到你的普通JavaScript项目中。 在添加你的构建规则之前，你需要向Bazel提供你的输入或源文件。本质上，这些输入是Bazel视为构建你的构建的目标。让我们在根目录下创建一个名为app.js 的文件。我们将创建一个简单的JavaScript类，名为User ，里面有一个将用户名字转换为大写字母的函数： kotlin 复制代码 class User{ constructor(name){ this.name=name } uppercaseName(){ this.name=this.name.toUpperCase(); return this.name; } } const user=new User(&quot;FuzzySid&quot;) user.uppercaseName(); 接下来，你需要声明这个文件作为Bazel构建的输入。之前，我们已经在BUILD.bazel 文件中加载了构建规则。让我们用这些规则来声明我们在BUILD.bazel 文件中构建的输入和输出： ini 复制代码 babel( name = &quot;compile&quot;, data = [ &quot;app.js&quot;, &quot;es5.babelrc&quot;, &quot;@npm//@babel/preset-env&quot;, ], outs = [&quot;app.es5.js&quot;], args = [ &quot;app.js&quot;, &quot;--config-file&quot;, &quot;./$(execpath es5.babelrc)&quot;, &quot;--out-file&quot;, &quot;$(execpath app.es5.js)&quot;, ], ) 最后，你可以运行构建命令，让Bazel为你施展魔法： arduino 复制代码 npm run build 你应该在终端看到以下输出： 在你的项目中，你现在应该有一个bazel-out 和一个dist 目录： 你转换的JavaScript代码应该出现在dist/bin/app.es5.js 。功夫不负有心人，你已经成功地用Bazel编译了一个JavaScript单程序","link":"/2024/02/52f793c64d0c.html"},{"title":"cdn","text":"全称为内容分发网络,Content Delivery Network，简称CDN.建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。内容分发网络（CDN）是一个互连服务器网络，可加快数据密集型应用程序的网页加载速度。CDN 可以表示内容分发网络或内容分配网络。当用户访问某个网站时，来自该网站服务器的数据必须通过互联网传输到用户的计算机。如果用户距离该服务器较远，则加载大文件（例如视频或网站图像）将需要很长时间。相反，如果网站内容存储在距离用户较近的 CDN 服务器上，就可以更快到达他们的计算机。 对于每一个资源请求,响应一个最近的边缘服务器.如果边缘服务器中没有需要的资源,再去源服务器请求.减小源服务器的压力.","link":"/2024/02/f8b6251437b2.html"},{"title":"cmake","text":"CMake前言： CMake是一个跨平台的安装编译工具，可以用简单的语句来描述所有平台的安装(编译过程)。 CMake可以说已经成为大部分C++开源项目标配 1 Cross-platform developmentLet’s assume you have some cross-platform project with C++ code shared along different platforms/IDEs. Say you use Visual Studio on Windows, Xcode on OSX and Makefile for Linux: What you will do if you want to add new bar.cpp source file? You have to add it to every tool you use: To keep the environment consistent you have to do the similar update several times. And the most important thing is that you have to do it manually (arrow marked with a red color on the diagram in this case). Of course such approach is error prone and not flexible. CMake solve this design flaw by adding extra step to development process. You can describe your project in CMakeLists.txt file and use CMake to generate tools you currently interested in using cross-platform CMake code: Same action - adding new bar.cpp file, will be done in one step now: Note that the bottom part of the diagram was not changed. I.e. you still can keep using your favorite tools like Visual Studio/msbuild, Xcode/xcodebuild and Makefile/make! 2 语法特性介绍 基本语法格式：指令(参数 1 参数 2…) 参数使用括弧括起 参数之间使用空格或分号分开 指令是大小写无关的，参数和变量是大小写相关的 123set(HELLO hello.cpp)add_executable(hello main.cpp hello.cpp)ADD_EXECUTABLE(hello main.cpp ${HELLO}) 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名 3 重要指令和CMake常用变量3.1 重要指令 cmake_minimum_required 指定CMake的最小版本要求 语法： cmake_minimum_required(VERSION versionNumber [FATAL_ERROR]) 12# CMake最小版本要求为2.8.3cmake_minimum_required(VERSION 2.8.3) project 定义工程名称，并可指定工程支持的语言 语法： project(projectname [CXX] [C] [Java])12# 指定工程名为HELLOWORLDproject(HELLOWORLD) set 显式的定义变量 语法：set(VAR [VALUE] [CACHE TYPE DOCSTRING [FORCE]]) 12# 定义SRC变量，其值为sayhello.cpp hello.cppset(SRC sayhello.cpp hello.cpp) &lt;a&gt; include_directories 向工程添加多个特定的头文件搜索路径 —&gt;;相当于指定g++编译器的-I参数 语法： include_directories([AFTER|BEFORE] [SYSTEM] dir1 dir2 …)12# 将/usr/include/myincludefolder 和 ./include 添加到头文件搜索路径include_directories(/usr/include/myincludefolder ./include) link_directories 向工程添加多个特定的库文件搜索路径 —&gt;;相当于指定g++编译器的-L参数 语法： link_directories(dir1 dir2 …) 12# 将/usr/lib/mylibfolder 和 ./lib 添加到库文件搜索路径link_directories(/usr/lib/mylibfolder ./lib) add_library 生成库文件 语法： add_library(libname [SHARED|STATIC|MODULE] [EXCLUDE_FROM_ALL] source1 source2 … sourceN) 12# 通过变量 SRC 生成 libhello.so 共享库add_library(hello SHARED ${SRC}) add_compile_options 添加编译参数 语法：add_compile_options(&lt;option&gt; …) 12# 添加编译参数 -Wall -std=c++11 -O2add_compile_options(-Wall -std=c++11 -O2) add_executable 生成可执行文件 语法：add_executable(exename source1 source2 … sourceN) 12# 编译main.cpp生成可执行文件mainadd_executable(main main.cpp) target_link_libraries 为 target 添加需要链接的共享库 -&gt;;相同于指定g++编译器-l参数 语法： target_link_libraries(target library1&lt;debug | optimized&gt; library2…) 12# 将hello动态库文件链接到可执行文件maintarget_link_libraries(main hello) add_subdirectory 向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置 语法： add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 12# 添加src子目录，src中需有一个CMakeLists.txtadd_subdirectory(src) aux_source_directory 发现一个目录下所有的源代码文件并将列表存储在一个变量中，这个指令临时被用来自动构建源文件列表 语法： aux_source_directory(dir VARIABLE) 1234# 定义SRC变量，其值为当前目录下所有的源代码文件aux_source_directory(. SRC)# 编译SRC变量所代表的源代码文件，生成main可执行文件add_executable(main ${SRC}) 3.2 CMake常用变量 CMAKE_C_FLAGS gcc编译选项 CMAKE_CXX_FLAGS g++编译选项 12# 在CMAKE_CXX_FLAGS编译选项后追加-std=c++11set( CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -std=c++11&quot;) CMAKE_BUILD_TYPE 编译类型(Debug, Release) 1234# 设定编译类型为debug，调试时需要选择debugset(CMAKE_BUILD_TYPE Debug)# 设定编译类型为release，发布时需要选择releaseset(CMAKE_BUILD_TYPE Release) CMAKE_BINARY_DIR PROJECT_BINARY_DIR &lt;projectname&gt;_BINARY_DIR &gt; 这三个变量指代的内容是一致的。如果是 in source build，指的就是工程顶层目录。如果是 out-of-source 编译,指的是工程编译发生的目录。PROJECT_BINARY_DIR 跟其他指令稍有区别，不过现在，你可以理解为他们是一致的。 CMAKE_SOURCE_DIR PROJECT_SOURCE_DIR&lt;projectname&gt;_SOURCE_DIR &gt; 这三个变量指代的内容是一致的,不论采用何种编译方式,都是工程顶层目录。也就是在 in source build时,他跟 CMAKE_BINARY_DIR 等变量一致。PROJECT_SOURCE_DIR 跟其他指令稍有区别,现在,你可以理解为他们是一致的。 CMAKE_C_COMPILER：指定C编译器 CMAKE_CXX_COMPILER：指定C++编译器 EXECUTABLE_OUTPUT_PATH：可执行文件输出的存放路径 LIBRARY_OUTPUT_PATH：库文件输出的存放路径 4 CMake编译工程CMake目录结构：项目主目录存在一个CMakeLists.txt文件 两种方式设置编译规则： 包含源文件的子文件夹包含CMakeLists.txt文件，主目录的CMakeLists.txt通过add_subdirectory添加子目录即可； 包含源文件的子文件夹未包含CMakeLists.txt文件，子目录编译规则体现在主目录的CMakeLists.txt中； 4.1 编译流程在 linux 平台下使用 CMake 构建C/C++工程的流程如下: 手动编写 CMakeLists.txt。 执行命令 cmake PATH生成 Makefile ( PATH 是顶层CMakeLists.txt 所在的目录 )。 执行命令make 进行编译。 123456# important tips. # 表示当前目录./ # 表示当前目录.. # 表示上级目录../ # 表示上级目录 4.2 两种构建方式 内部构建(in-source build)：不推荐使用 内部构建会在同级目录下产生一大堆中间文件，这些中间文件并不是我们最终所需要的，和工程源文件放在一起会显得杂乱无章。 12345## 内部构建# 在当前目录下，编译本目录的CMakeLists.txt，生成Makefile和其他文件cmake .# 执行make命令，生成targetmake 外部构建(out-of-source build)：推荐使用 将编译输出文件与源文件放到不同目录中 12345678910## 外部构建# 1. 在当前目录下，创建build文件夹mkdir build# 2. 进入到build文件夹cd build# 3. 编译上级目录的CMakeLists.txt，生成Makefile和其他文件cmake ..# 4. 执行make命令，生成targetmake 5 【实战】CMake代码实践针对第五章写的两个小项目来写对应的CMakeLists.txt 5.1 最小CMake工程12345678# Set the minimum version of CMake that can be usedcmake_minimum_required(VERSION 3.0)# Set the project nameproject (HELLO)# Add an executableadd_executable(hello_cmake main.cpp) 5.2 多目录工程 - 直接编译1234567891011121314151617# Set the minimum version of CMake that can be usedcmake_minimum_required(VERSION 3.0)#project nameproject(SWAP)#head file patinclude_directories( include )#source directory files to varadd_subdirectory( src DIR_SRCS )#add executable fileadd_executable(swap_02 ${TEST_MATH})#add link librarytarget_link_libraries(${FS_BUILD_BINARY_PREFIX}sqrt ${LIBRARIES}) 5.3 多目录工程 - 生成库编译123456789101112131415161718192021222324252627282930313233# Set the minimum version of CMake that can be usedcmake_minimum_required(VERSION 3.0)#project nameproject(SWAP_LIBRARY)#add compile optionsadd_compile_options(&quot;-Wall -std=c++11&quot;)#set CMAKE_BUILD_TYPEset( CMAKE_BUILD_TYPE Debug )# set output binary pathset(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)############################################################# Create a library#############################################################Generate the static library from the library sourcesadd_library( swap_library STATIC src/Swap.cpp )target_include_directories( swap_lib PUBLIC ${PROJECT_SOURCE_DIR}/include )############################################################# Create an executable############################################################# Add an executable with the above sourcesadd_executable( swap_01 main.cpp )# link the new swap_01 target with the swap_lib targettarget_link_libraries( swap_01 swap_liby )","link":"/2024/02/f23e4ff746d8.html"},{"title":"cuda","text":"一文讲清楚CUDA、CUDA toolkit、CUDNN、NVCC关系无敌了老黄,居然后面的Nvidia驱动居然还兼容之前的cuda版本","link":"/2024/03/23c37ceeb4e5.html"},{"title":"code style","text":"以下是goole code style guide.","link":"/2024/02/aef6225eb1d3.html"},{"title":"dn11 peer流程","text":"my infoPublickey:0bBel8q6++FmOuPrepFpWaIUHWur4ppB09LKN4UmLiQ=172.16.36.2544211116657dn11.l4rk.cn:325xx /etc/wireguard生成的公钥私钥保存在该文件下在这个文件夹下面编写一个新的 example.conf example=对方名称12345678910[Interface]PrivateKey = QOiaOOemHPKsACOyiGVvZ4btQ344rqx07poiiW2WRmw=ListenPort = 32501PostUp = /sbin/ip addr add dev %i 172.16.36.254/32 peer 172.16.2.254/32 Table = off [Peer]Endpoint = open.iraze.top:42025PublicKey = jEAB/Yl4Oqz2fAyt8V/5MKb0j4FmD7XEhYRvjnDtNV0=AllowedIPs = 0.0.0.0/0 wg-quick-op在颤巍巍的帮助下顺利完成 有柏喵师傅写的wg-quick-op https://github.com/BaiMeow/wg-quick-opwg-quick-op:编写一个 /etc/wg-quick-op.yaml wg-quick-op.yaml主要用来处理开机时候,设备启动的问题,不用太管 reference:https://dn11.top/connect/bgp.html bird2编辑 /etc/bird.conf 参考 https://dn11.top/connect/bgp.html 用birdc s p看看具体情况 123protocol bgp xxx from BGP_peers{ neighbor 172.16.xx.254%xx as 421111xxxx;} 修改openwrt 防火墙编辑该区域 一些命令wg-quick-op up iraze “启用iraze,不是写iraze.confwg-quick-op down iraze “停止irazeroute -n “查看所有路由情况wg “查看wireguard信息birdc c “更新bird配置 wireguard/example.config是用来","link":"/2024/02/e810fea9af75.html"},{"title":"dns","text":"DNS（Domain Name Server，域名服务器）是进行域名(domain name)和与之相对应的IP地址(IP address)转换的服务器。 IP地址是唯一确定的.但访问网页的时候输入的往往是域名,例如: https://www.baidu.com. 想要访问这个网址,DNS服务器就会对网址进行解析,找到网址对应的IP地址,并将IP地址返回,从而实现访问. 常用的dns 相同 114.114.114.114和8.8.8.8，这两个IP地址都属于公共域名解析服务DNS其中的一部分，而且由于不是用于商业用途的，这两个DNS都很纯净，不用担心因ISP运营商导致的DNS劫持等问题，而且都是免费提供给用户使用的。 区别: 114.114.114.114 114.114.114.114是国内移动、电信和联通通用的DNS，手机和电脑端都可以使用，干净无广告，解析成功率相对来说更高，国内用户使用的比较多，而且速度相对快、稳定，是国内用户上网常用的DNS。 8.8.8.8 8.8.8.8是GOOGLE公司提供的DNS，该地址是全球通用的，相对来说，更适合国外以及访问国外网站的用户使用。","link":"/2024/02/a3d28fa4aa55.html"},{"title":"docker","text":"what is docker采用了容器概念,本质上每个容器都是一台vm.但相对于vm,性能需求更低.Docker 只是一个管理这些容器的平台，因此您可以轻松构建不同的特定环境。 容器容器包括应用程序运行的所有库和工具。容器的作用是将这些应用程序与应用程序的库和工具一起打包在容器中，这样它就可以在任何地方运行，而不必依赖宿主的环境。同时也能隔绝不同环境之间的干扰. 用户docker安装(root与非root)refering 图形化docker管理工具安装docker的端口是:9000后台地址为 192.168.33.4:9000居然是不需要https://的...如果把地址写成https://192.168.33.4:9000,访问不了中文portainer 问题: Docker Compose stuck downloading or pulling fs layer 描述:0bad1d247b5b: Pulling fs layer ,某一个哈希值一直下载不出来restart也没有用 想起来一件事,没有对docker进行换源 换源12service restart docker.servicedocker info 牢记,linux系统一般都是要进行镜像换源的 安装汉化portainer安装教程 报错教程 下载文档问题 用wget命令就行了… 一个报错1Error response from daemon: Conflict. The container name &quot;/portainer&quot; is already in use by container &quot;9226aa8941ce67663089515cb68f462a90654642fbb2c7a72b8e57253dea7f48&quot;. You have to remove (or rename) that container to be able to reuse that name. 原因是我本来就下载了一个英文版本的portainer,汉化并非是汉化补丁,而是直接安装一个中文版本的portainer,因此出现了命名冲突.删除掉原来的portainer就行了12docker stop portainerdocker rm portainer 镜像拉取refering利用docker pull,从docker hub 中获取镜像12345$ docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]# docker pull ubuntu:18.04# 地址没有给出,使用默认的Docker Hub(docker.io) 仓库名字为library/ubuntu(library为默认) 标签为18.04# docker pull zhayujie/chatgpt-on-wechat# 如果出现pull latest问题,可能是因为镜像站还没有更新导致的,指定之前版本的标签就行了.123456docker pull zhayujie/chatgpt-on-wechatdefault:latest# 没有进度的# 换成docker pull zhayujie/chatgpt-on-wechat:1.3.2# 搞定 docker 的文件结构refering 12345# 进入docker 目录 cd /var/lib/dockerls# 出现名叫containers与image的文件# containers有容器的序列号 image有镜像信息 docker composeDocker Compose 是用于定义和运行多容器Docker 应用程序的工具。 在Compose 中，可以使用YAML 文件来配置应用程序的服务。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。https://cloud.tencent.com/developer/article/2348142https://cloud.tencent.com/developer/article/1942706 dockers容器大赏","link":"/2024/02/f34789be9642.html"},{"title":"html","text":"","link":"/2024/02/063b219d319e.html"},{"title":"istore 使用wireguard接入dn11","text":"柏喵喵师傅写得很详细啊,为什么dn11教程用的不是这个版本… ok,meva告知,dn11上的很久没更新过,直接看柏喵的博客就行","link":"/2024/03/58df0e350f2a.html"},{"title":"linux ssh root用户登录","text":"操作修改/etc/ssh/sshd_config文件.此文件为ssh配置文件找到#PermitRootLogin yes,去掉注释#.重启ssh服务就可以了12sudo vim /etc/ssh/sshd_configsudo systemctl restart ssh Related[[Omnivore/2024-06-05/SSH原理与运用（一）：远程登录 - 阮一峰的网络日志|SSH原理与运用（一）：远程登录 - 阮一峰的网络日志]][[07archive/tech/OpenClash导致的ssh登录失败|OpenClash导致的ssh登录失败]]","link":"/2024/06/6f96ca6328c8.html"},{"title":"lisp","text":"Lec1a 编程就像念咒语 从另外一个角度看computer sciencecomputer science是一个糟糕的名字.这门学科中所包括的不仅仅是computer,并且它也并不是科学,而更接近于tech or engineering.geometry,几何学,名字来源于gaia meaning to earth,and metron meaning to measure.埃及祭司用来计算每年被尼罗河摧毁的土地边界,从而创立了几何学.对于他们来说,geometry确实是用来测量土地.但几何学本身的内容早就已经超出了最开始的范围.cs也是这样.它不仅仅是介绍计算机使用.但是回过头看千年前埃及人的工作,他们开始形式化地对空间与时间进行描述.并且归纳出了一套讨论数学真理的形式化方法.这直接导致了公理化方法,促进了现代数学的诞生,指明了一种精确讨论何为真理的方法.同样的,千年之后的人类回头看我们现在的cs,会作何评价?我们只是摆弄着一个叫做计算机的小玩意,但却真正意义上开始了对于计算过程的形式化表示,并结合实际需求,发展出一套问题处理过程精确描述的方法.下面来举个栗子： 我们都知道平方根的定义： $\\sqrt{x}$是满足$y^2=x$同时$y≥0$ 这个定义告诉了你平方根是什么，却没有告诉你如何求一个平方根。这里提供亚历山大Heron提出的一叫连续取均值求平方根法。下面列出形式化的描述： 如何求$\\sqrt{x}$的平方根？1.随便猜一个数叫$G$2.改进你的猜想通过计算 $G$ 和 $X/G$的平均值3.不断重复步骤2，直到满意为止 对于cs来说,我们要完成的是拥有一个定义之后,实现它的具体而精确的计算过程. Lec2b 数据抽象 data abstraction用构造函数与选择函数来分隔 数据的表示与数据的使用例如构建一段关于点,线的代码段从层次结构上看,分成了三层segmentsmake-seg seg-start seg-end (构造函数与选择函数)vectorsmake-vertor xcor ycor (构造函数与选择函数)pairs 重要的不是某个小功能的本身,而是我能够用这个小block来搭建什么 模糊数据与过程的边界是有利的.Lec3a 封闭性(closure)是一个非常良好的特性.在缺少封闭性的语言中,你可以使用字符串,数字等去构造数组.但不能用数组去构造数组.例如用cons去构建cons123cons(1 cons(1 2)) regard the procedure and data as the same thing 当你有一项任务要完成时候,有两种情况你把它分解成为几个sub-tasks,再把sub-tasks分解成又几个sub-tasks,成为一个树的形状.或者,选择使用层级结构.在每个层级只讨论描述该层级的事件,从而实现良好的分层.层级结构与书级结构的差距在于:层级是为了讨论整个事件,而树形只是为了解决这个具体的问题.原因在于,对于相似的事件,他们有相似的层级结构,但在树形上,因为处理到的具体细节的不同,存在较大的差距.层级具有更好的robust,当你做出某些改变时,会做出相应的回应.想要改变某层的效果,只要去更改更底层的内容.并且,在每一层都有完备的语言去描述具体的操作.因而,想要实现某些变化的时候,你可以选择在某个具体的层级改变.这使得计算机科学比其他的工程学更加强大Lec3b","link":"/2024/02/ca400735bb55.html"},{"title":"oos","text":"首先OSS的英文全称是Object Storage Service, 直译过来就是”对象存储服务“。 严谨的解释是：OSS是一种使用HTTP API存储和检索非结构化数据和元素的数据对象的工具。 要点： HTTP API风格 存储数据 检索数据 通俗易懂的说就是：OSS就是通过HTTP restful风格的API进行数据上传，存储和获取的云端数据库服务。你也可以简单的理解成网盘。 服务供应商： 阿里云，蓝队云，移动云，AWS存储","link":"/2024/02/93cdd64a9e19.html"},{"title":"openwrt","text":"Luci是什么Luci简介：lua是一个小巧的脚本语言，容易嵌入其他语言。轻量级LUA语言的官方版本只包含一个精简的核心和最基本的库，使lua体积小、启动速度快，从而适合嵌入在别的程序里。 what is luci 科学上网三大插件SSRPlus、PassWall、OpenClash SSRPlus：简称：酸酸乳Plus，使用简单，主流玩法，兼容大多数资源网站，建议新手使用。 PassWall：支持 SS/SSR/V2ray，选项多使用灵活自由度高，支持DNS，支持简单分流，建议新手使用。 OpenClash：简称：小猫咪，支持众多协议，有高级策略分流，自定义项目多，不是每个资源网站都提供服务，但有转换协议方案，上手不太顺手。 本来选择了openclash,但鉴于clash内核已经删库跑路,转用v2rayv2ray有点难搞啊,教程太少,换成ssr Plus参考轻松搞定 不知道为什么ssr plus有点问题ip测试还是我本地的ip,而不是vps的ip.和dns有关系应该 暂时有点搞定不了换passwall试试非常完美passwall好用多了 奇怪了,passwall犯病了,不知道为什么上不去github.com,代理规则里面也写了github走代理.用v2ray代理,选用相同的节点,没有任何问题.应该是passwall本身出毛病了.还有steamcommunity.com和store.steampowered.com也都不行.之前还是好好的. ipcheck.ing结果:passwall内结果: 代理规则: 猜测可能是adhome_guard导致.但对照开关adhome_guard的情况,排除这一可能. ping与nslookup看着也没问题 搞不懂,换用helloworld试试 沟槽的,是windows的hosts出问题了,我用火绒---安全工具---断网修复修下hosts就好了了… 24.4.3不知道抽什麽風,又出问题了…","link":"/2024/04/0031ec29eea6.html"},{"title":"openwrt防火墙","text":"由于openwrt与ikuai网关互指,并且没有做转发设置,不能在ikuai中监控设备流量情况,openwrt的监控流量插件也不好用,遂研究下接口与防火墙. 现在的网络情况为i快开启dhcp,openwrt关闭.所有设备的IP由ikuai分配.由于科学上网的需求,openwrt跑passwall,dhcp网关设置为openwrt.这就导致,虽然ikuai,openwrt,设备处于同一个网段下,但由于ikuai的dhcp设置,下属所有设备不论是上传还是下载,所有数据报是都要经过openwrt解包 处理 封包 转发处理,再去ikuai.上传1234567graph LR A((设备)) --&gt;|数据报| B[OpenWRT] B --&gt;|解包 处理 封包 转发| C[ikuai] C --&gt;|数据报| D[internet]下载1234graph LR D[Internet] --&gt;|数据报| C[iKuai] C --&gt;|解包 处理 封包 转发| B[OpenWRT] B --&gt;|数据报| A((设备))对openwrt性能损耗高. 通过对防火墙与接口设置,实现,下载直接到设备,上传经过openwrt.上传1234567graph LR A((设备)) --&gt;|数据报| B[OpenWRT] B --&gt;|解包 处理 封包 转发| C[ikuai] C --&gt;|数据报| D[internet]下载1234graph LR C[Internet] --&gt;|数据报| B[iKuai] B --&gt;|数据报| A((设备)) 鉴于这几位都在一个网关下,只要设置下 参考","link":"/2024/02/7e782987e3df.html"},{"title":"pve lvm磁盘管理","text":"理论磁盘磁盘有三种类型 physic volume logic volume volume group下面分别用pv,lv,vg简称抽象的一点是,lv大小可以超过pv的大小例如,pv A的大小是5G,而在pv上的lv a的磁盘大小可以设置为10G,已经超出了物理限制.但是,lv a对应的虚拟机a认为,你有10G磁盘大小.虚拟机a不会阻止你占用超过5G的磁盘.当磁盘占用超过5G时,你的虚拟机就会进入io/error的状态.😅😅😅这点要注意 pve磁盘pve会默认创建两个存储分区local与local-lvm(下称lvm)pve使用local,一般情况下,虚拟机使用lvm. 可能会存在lvm过小,而local过大的情况. 方案有两种思路: 减小local,增大lvm 移动lvm中的内容至local 很不幸,由于pve使用的是local,对local进行减小操作是困难的.如果你想尝试可以参考这个 所以我选择第二种方法,将lvm所有虚拟机移动到local上.并删除lvm,将释放的空间分配给local. 操作编辑存储内容目标是只是用一个磁盘,所以将所有格式的文件都放在同一个lv下数据中心-存储-local 备份虚拟机gui可以直接将放置在lvm上的虚拟机备份.备份文件默认存放在local位置. 删除lvm将lvm上所有的虚拟机进行备份之后,删除这些虚拟机,再进入pve控制台12lvremove /dev/pve/data #删除lvm对应的`/dev/pve/data`lvextend -rl +100%FREE /dev/pve/root #将多余空间全部扩容至local 此时你在web中还是能够看到lvm的存在.在数据中心-存储中删除local lvm.(操作时候没截图,图片来自参考)就能彻底删除lvm了. 备份恢复在local中找到备份,选中再还原就可以了.","link":"/2024/04/d72be0fe0eca.html"},{"title":"pve下的虚拟机扩容","text":"在web端硬件-磁盘-磁盘操作增加磁盘大小 再依靠gparted,没有的话就安装下1apt install gparted 12345678910111213141516171819202122232425262728293031323334353637383940root@l4rkserver:~/omnivore# parted /dev/sdaGNU Parted 3.4Using /dev/sdaWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) print Warning: Not all of the space available to /dev/sda appears to be used, you can fix the GPT to use all of the space (an extra 10485760 blocks) or continue with the current setting?Fix/Ignore? fix Model: QEMU QEMU HARDDISK (scsi)Disk /dev/sda: 26.8GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 2150MB 2147MB linux-swap(v1) swap 3 2150MB 21.5GB 19.3GB ext4(parted) resizepart 3 100%Warning: Partition /dev/sda3 is being used. Are you sure you want to continue?Yes/No? y(parted) print Model: QEMU QEMU HARDDISK (scsi)Disk /dev/sda: 26.8GBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 2150MB 2147MB linux-swap(v1) swap 3 2150MB 26.8GB 24.7GB ext4root@l4rkserver:~/omnivore# resize2fs /dev/sda3 resize2fs 1.46.5 (30-Dec-2021)Filesystem at /dev/sda3 is mounted on /; on-line resizing requiredold_desc_blocks = 3, new_desc_blocks = 3The filesystem on /dev/sda3 is now 6028795 (4k) blocks long. 搞定","link":"/2024/04/40a37fcdc042.html"},{"title":"remote ssh 配置","text":"安装并配置本教程仅仅适用于:本来就在windows主机与实验室linux主机上用git生成过密钥,且windows主机能够通过ssh登录到linux主机上 在windows主机上安装好remote ssh插件, 配置remote ssh设置! 自定义配置路径,remote-ssh.config内容如下123456Host 10.1.21.164 HostName 10.1.21.164 User yzh Port 22 IdentityFile &quot;C:\\Users\\28763\\.ssh\\id_rsa&quot; ForwardAgent yes 解释:123456Host &lt;远程主机名称&gt; HostName &lt;远程主机IP&gt; User &lt;用户名&gt; Port &lt;ssh端口，默认22&gt; IdentityFile &lt;本机SSH私钥路径&gt; ForwardAgent yes &lt;VSCode 自己添加的，不用管&gt; 在 linux 主机的.ssh 文件夹下，新建 authorized_keys 文件; 将 id_rsa.pub 文件中的内容全部复制到 authorized_keys 文件即可; 重启vscode,点击remote ssh插件,即可连接成功排除报错暂时没有","link":"/2024/04/82d6924038f6.html"},{"title":"rsshub 部署","text":"主要订阅内容 [x] 微博 [ ] eh [ ] 哔哩哔哩 [ ] 公众号(发现完全不看公众号) [ ] 少数派 [ ] 论文期刊(读研再说吧) dependence docker docker-compose rsshub rssradar 初次部署使用本地 RSS 客户端来浏览在线 RSS 帐户。客户端用fluent reader 账户用inoreader对于eh可以直接使用，但对于exhentai，好像只能自己部署来实现放弃项目 第二次部署重新启动!用omnivore之后,为了订阅微博上的关注,在软路由上重新部署了rsshub. 部署很简单,建议使用docker-compose部署,详情见Docker Compose 部署. 最大的难题在于,pve上,给ubuntu虚拟机的磁盘大小不够,导致docker-compose up -d时,磁盘爆了,虚拟机挂掉解决见[[07archive/tech/pve下的虚拟机扩容|pve下的虚拟机扩容]],[[07archive/tech/pve lvm磁盘管理|pve lvm磁盘管理]]. 使用rsshub衍生的浏览器插件chrome rssradar能够简单地生成rss订阅链接在插件设置中,将RSSHub 实例改为自己部署的ip/域名:port 微博图片设置微博为了商业利益,限制了跨域名图片加载.如果不修改docker-compose.yml文件,微博图片无法加载.这里可以使用cdn,百度或者wordpress的服务我使用的wordpress在docker-compose.yml中添加123environment: HOTLINK_TEMPLATE: 'https://i3.wp.com/$${host}$${pathname}' HOTLINK_INCLUDE_PATHS: /weibo 微博group订阅已经不再使用,重新对每个订阅displayArticle参数使用不了导致微博内容抓取不全 一个一个生成订阅rss是不是很麻烦?其实可以直接订阅关注的某一个group.参考微博 group订阅与配置根据教程获得group cookie与group idgroup cookie,就是SUBP=......那一大串,group id就是gid=后面的数字填入docker-compose.yml中12environment: WEIBO_COOKIES: group cookie生成指定group的订阅链接http://selfhost/weibo/group/group id WARNING由于微博官方未提供自定义分组相关 api, 此方案必须使用用户Cookie进行抓取因微博 cookies 的过期与更新方案未经验证，部署一次 Cookie 的有效时长未知微博用户 Cookie 的配置可参照部署文档 微博路由templateweibo/user/5734186676/readable=1&amp;showEmojiForRetweet=1&amp;showTimestampInDescription=0&amp;displayArticle=1&amp;displayComments=1&amp;showEmojiInDescription=1&amp;showLinkIconInDescription=0具体参数解释可以看这里 ehentai设置查看你的ehentai cookie中的内容并填入docker-compose.yml文件12345environment: EH_IPB_MEMBER_ID: YOUR_ID EH_IPB_PASS_HASH: YOUR_PASS_HASH EH_SK: YOUR_SK EH_IGNEOUS: YOUR_IGNEOUS如果账号有exhentai的权限,就能在exhentai.org的cookie中看到igneous值.rsshub在路由层面进行了处理,会自动进入exhentai画廊. 主要用来订阅Artist或者Group.因为ehentai普通用户只有100个tag的订阅权限. 暂时还没想好ehentai的rss订阅链接怎么处理.配合qbtorrent自动化下载也许是个好主意 订阅链接出错要注意,rssradar生成的订阅链接不一定正确,可能出现订阅链接无效的情况例如想要获取e-hentai.org网站的订阅链接,2024/5/12时最新的rssradar,会根据两种不同的规则,生成订阅链接 http://selfhost/ehentai/tag/artist:taihei+tengoku http://selfhost/e-hentai/tag/artist:taihei+tengoku下面这个订阅链接是无效的 如果你想对订阅内容做出更多自定义,建议在rsshub库中直接看代码,会有相当详细的注释.例如对ehentai.org的rss,阅读RSSHub/lib/routes/ehentai文件下的代码,就可以配置更多自定义参数. 即使如此,订阅链接仍然有可能出错误,那么就可以提交issue了.一般几天之内会处理.","link":"/2024/02/dd9c91e177c3.html"},{"title":"scoop","text":"参考 Scoop介绍Scoop是一款适用于Windows平台的命令行软件（包）管理工具，这里是Github介绍页。简单来说，就是可以通过命令行工具（PowerShell、CMD等）实现软件（包）的安装管理等需求，通过简单的一行代码实现软件的下载、安装、卸载、更新等操作。其灵感来源于macOS的Homebrew，Mac用户可以去了解了解。 当然如果用过Linux系统，使用apt-get工具安装过软件，或者用过Python，知道pip工具用于管理Python各种依赖包，那么理解Scoop就比较容易，这些工具的设计理念与使用方法都非常类似。 Scoop一般用来管理绿色软件，即是一种通过解压压缩包即可就地使用的软件，对于比较专业软件（比如Office、Adobe等）支持不好windows的包管理工具 设置PowerShell权限为了让PowerShell可以执行脚本，首先需要设置PowerShell执行策略，通过输入以下命令Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser即可。（如果之前已开启，可忽略。） 安装Scoop通过以下命令，可以将Scoop安装到默认目录（C:\\Users\\&lt;username&gt;\\scoop）： 1Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh') 或者另一条更短的命令： 1iwr -useb get.scoop.sh | iex 如果你需要更改默认的安装目录，则需要在执行以上命令前添加环境变量的定义，通过执行以下命令完成： 12$env:SCOOP='D:\\Applications\\Scoop'[Environment]::SetEnvironmentVariable('SCOOP', $env:SCOOP, 'User') 其中目录D:\\Applications\\Scoop可根据自己的情况修改。 完成之后，相应位置就会生成一个scoop文件夹，如图所示： Scoop常用命令Scoop的操作命令十分简单，基本结构是scoop + 动词 + 对象，动词就是一个操作动作，如安装、卸载，对象一般就是软件名了（支持通配符*操作），当然这需要你先打开命令行工具。比如我想安装typora，通过输入scoop install typora即可自动完成软件的官网进入+下载+安装等操作。 以下是一些常用的命令说明： search——搜索仓库中是否有相应软件。 install——安装软件。 uninstall——卸载软件。 update——更新软件。可通过scoop update *更新所有已安装软件，或通过scoop update更新所有软件仓库资料及Scoop自身而不更新软件。 hold——锁定软件阻止其更新。 info——查询软件简要信息。 home——打开浏览器进入软件官网。 如果忘记了，可通过输入scoop help来查询语法，以及更多不怎么常用的操作指导。 管理员权限以管理员权限启动Pow­er­Shell就行. 或者在windows上安装sudo更简单的方式是先安装 sudo，然后用 sudo 命令来提权执行：12scoop install sudo sudo scoop install -g &lt;app&gt; 仓库管理参考查看现有仓库stars排序的Scoop-directory 现在使用仓库如下 其中apps这个bucket比较特殊,此仓库每天自动合并其他scoop仓库的更新,所以东西特别多.以CopyTranslator为例apps这个bucket的软件版本不知道为什么有点旧,已停用. 123456#添加bucketscoop bucekt add &lt;bucket&gt;#指定某一个bucket下载scoop install &lt;bucket&gt;/appname#移除某一个bucketscoop bucekt rm &lt;bucket&gt; 开启多线程下载使用 Scoop 安装 Aria2 后，Scoop 会自动调用 Aria2 进行多线程加速下载。 1scoop install aria2 使用 scoop config 命令可以对 Aria2 进行设置，比如 scoop config aria2-enabled false 可以禁止调用 Aria2 下载。以下是与 Aria2 有关的设置选项： aria2-enabled: 开启 Aria2 下载，默认true aria2-retry-wait: 重试等待秒数，默认2 aria2-split: 单任务最大连接数，默认5 aria2-max-connection-per-server: 单服务器最大连接数，默认5 ，最大16 aria2-min-split-size: 最小文件分片大小，默认5M 博主在这里推荐以下优化设置，单任务最大连接数设置为 32，单服务器最大连接数设置为 16，最小文件分片大小设置为 1M 123scoop config aria2-split 32scoop config aria2-max-connection-per-server 16scoop config aria2-min-split-size 1M 常用命令总结12345678910111213141516171819202122232425262728# 更新 scoop 及软件包列表scoop update## 安装软件 ### 非全局安装（并禁止安装包缓存）scoop install -k &lt;app&gt;# 全局安装（并禁止安装包缓存）sudo scoop install -gk &lt;app&gt;## 卸载软件 ### 卸载非全局软件（并删除配置文件）scoop uninstall -p &lt;app&gt;# 卸载全局软件（并删除配置文件）sudo scoop uninstall -gp &lt;app&gt;## 更新软件 ### 更新所有非全局软件（并禁止安装包缓存）scoop update -k *# 更新所有软件（并禁止安装包缓存）sudo scoop update -gk *## 垃圾清理 ### 删除所有旧版本非全局软件（并删除软件包缓存）scoop cleanup -k *# 删除所有旧版本软件（并删除软件包缓存）sudo scoop cleanup -gk *# 清除软件包缓存scoop cache rm *","link":"/2024/03/418392d76e7f.html"},{"title":"teamspeak 教程","text":"安装下载地址下载TS3 Client,WINDOWS对应的版本 一路安装就行了,安装路径自己选一个 安装完成后直接运行软件,出来一个协议需要同意之后会要你登录一个账号,不用管,直接$X$掉 汉化确保teamspeak没有启动,再进行汉化.下载Chinese_Translation_zh-CN.ts3_translation打开你的安装路径位置,将Chinese_Translation_zh-CN.ts3_translation放到文件目录下使用TeamSpeak程序目录下的 package_inst.exe 来打开汉化包 Chinese_Translation_zh-CN.ts3_translation并安装界面就变成中文力 连接连接到ts.l4rk.cn,没有密码,昵称自己定连接成功 设置大部分设置都能在工具-设置里面调整","link":"/2024/03/45f076a94960.html"},{"title":"team speak搭建","text":"汉化包主要教程参考按照教程就行,没什么问题. 唯一的困难在于环境不一样,我的ubuntu在虚拟机上,直接访问ip不行 ikuai上部署了ddns还有端口映射,所以可以将ts用到的端口映射到外网三个9987,10011,30033三个必须映射,其他随意 端口 协议 使用说明 是否必须 9987 UDP 默认语音服务端口 是 10011 TCP ServerQuery raw 端口 是 10022 TCP ServerQuery SSH 端口(3.3.0 以上版本服务端) 否 10080 TCP WebQuery(HTTP) 否 10443 TCP WebQuery(HTTPS) 否 30033 TCP 文件传输端口（上传每个房间的头像这个端口就必须开） 是 41144 TCP TSDNS服务端口 否","link":"/2024/03/fad93aae616e.html"},{"title":"v2rayN","text":"v2ray for windows","link":"/2024/03/4c9978bc051e.html"},{"title":"ufw","text":"概览参考由于Linux原始的防火墙工具iptables过于繁琐，所以ubuntu默认提供了一个基于iptable之上的防火墙工具ufw。ubuntu 系统默认已安装ufw。ubuntu 9.10默认的便是UFW防火墙，它已经支持界面操作了。在命令行运行ufw命令就可以看到提示的一系列可进行的操作。注意,主机上某些服务需要外部对本机的访问,例如图床服务,必须使用ufw对外开放端口,以minio图床为例12sudo ufw allow 9090sudo ufw allow 9000 1.安装12sudo apt-get install ufwsudo ufw enable #启用ufw,代替iptables,默认 sudo apt-get install ufw 2.启用sudo ufw enablesudo ufw default deny运行以上两条命令后，开启了防火墙，并在系统启动时自动开启。关闭所有外部对本机的访问，但本机访问外部正常。 apt-get install ufwufw enableufw default deny 5.UFW 使用范例：123456789101112131415161718#查看防火墙状态ufw status#允许 53 端口 ufw allow 53#禁用 53 端口 ufw delete allow 53#允许 80 端口 ufw allow 80/tcp#禁用 80 端口 ufw delete allow 80/tcp#允许 smtp 端口 ufw allow smtp#删除 smtp 端口的许可 ufw delete allow smtp#允许某特定 IP ufw allow from 192.168.254.254#删除上面的规则 ufw delete allow from 192.168.254.254 linux 2.4内核以后提供了一个非常优秀的防火墙工具：netfilter/iptables,他免费且功能强大，可以对流入、流出的信息进行细化控制，它可以实现防火墙、NAT（网络地址翻译）和数据包的分割等功能。netfilter工作在内核内部，而iptables则是让用户定义规则集的表结构。 但是iptables的规则稍微有些“复杂”，因此ubuntu提供了ufw这个设定工具，以简化iptables的某些设定，其后台仍然是 iptables。ufw 即uncomplicated firewall的简称，一些复杂的设定还是要去iptables。","link":"/2024/03/d90d4393b9d5.html"},{"title":"wechat bot部署","text":"根据chatgpt-on-wechat项目部署,采用docker compose.根据快速部署文档实操.由于初次部署访问不上chatgpt,网络环境有问题.感觉可能是compose.yml&gt;&quot;proxy&quot;: &quot;&quot;,没设置的问题.最后发现,由于docker本身的特性,docker compose并不会直接访问宿主机网络,而是创建了一个虚拟网桥,与宿主机环境进行隔离.想要直接走宿主机网络,需要添加network_mode: host最后该项目的配置为 12345678910111213141516171819202122232425version: '2.0'services: chatgpt-on-wechat: image: zhayujie/chatgpt-on-wechat container_name: chatgpt-on-wechat security_opt: - seccomp:unconfined environment: OPEN_AI_API_KEY: 'your api key' MODEL: 'gpt-3.5-turbo' PROXY: '' SINGLE_CHAT_PREFIX: '[&quot;bot&quot;, &quot;@bot&quot;]' SINGLE_CHAT_REPLY_PREFIX: '&quot;[bot] &quot;' GROUP_CHAT_PREFIX: '[&quot;@bot&quot;]' GROUP_NAME_WHITE_LIST: '[&quot;ChatGPT测试群&quot;, &quot;花开富贵&quot;]' IMAGE_CREATE_PREFIX: '[&quot;画&quot;, &quot;看&quot;, &quot;找&quot;]' CONVERSATION_MAX_TOKENS: 1000 SPEECH_RECOGNITION: 'False' CHARACTER_DESC: '你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。' EXPIRES_IN_SECONDS: 3600 USE_GLOBAL_PLUGIN_CONFIG: 'True' USE_LINKAI: 'False' LINKAI_API_KEY: '' LINKAI_APP_CODE: '' network_mode: host 报错:[CHATGPT] RateLimitError: You exceeded your current quota, please check your plan and billing details.疑似要添加chatgpt api付费方式最早的用户有12个月18美刀的api额度之后注册的用户有3个月,5美刀的api额度但都要添加payment method才能调用 要开一张虚拟银行卡…麻烦,懒得搞,试试别人的api先问相🐏要了api,成功部署.接下来就是等azure的申请通 改换用aruze申请api公司申请学生申请 换用gemini apiAIzaSyDkPocgRTs_fEf_pI0hI7_FWTi7yeciDBs gemini api只支持美国地区使用,并且没有改proxy的接口.可以魔改proxy懒得搞","link":"/2024/02/6e6d8d5493a2.html"},{"title":"前端","text":"前段语言串讲 HT ML 骨架 CSS表现 JavaScript行为123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;My first web&lt;/title&gt;&lt;/head&gt;&lt;body&gt; my article &lt;hr&gt; &lt;!-- 标题标签 --&gt; &lt;h1&gt;head 1&lt;/h1&gt; &lt;h2&gt;head 2&lt;/h2&gt; &lt;!-- 换行标签 --&gt; this is (强制换行) &lt;br&gt; body &lt;br&gt; &lt;!-- crtl + / 注释快捷键 --&gt; 分割线 &lt;hr&gt; test &lt;p&gt;段落标签p1&lt;/p&gt; &lt;p&gt;段落标签p2&lt;/p&gt; &lt;!-- 段落之间会有一个段落间距的空白 --&gt;&lt;b&gt;加粗&lt;/b&gt; &lt;strong&gt;强调加粗&lt;/strong&gt;&lt;u&gt;下划线&lt;/u&gt; &lt;ins&gt;强调下划线&lt;/ins&gt;&lt;i&gt;斜线&lt;/i&gt; &lt;em&gt;强调斜线&lt;/em&gt;&lt;s&gt;删除线&lt;/s&gt; &lt;del&gt;强调删除线&lt;/del&gt;&lt;hr&gt;&lt;h1&gt;image tags&lt;/h1&gt;&lt;!-- width 与 height 会自适应 --&gt;&lt;img src=&quot;https://p.sda1.dev/12/bab6341cd5c384fbf70077b146d29da9/image.png&quot; alt=&quot;load failed&quot; title=&quot;it's a note and it appears when you put the cursor on the img&quot; width=&quot;1920&quot; height=&quot;800&quot;&gt;&lt;h1&gt;audio tags&lt;/h1&gt;&lt;audio src=&quot;C:\\Users\\28763\\Videos\\Captures\\这是27岁的老将枪法？绝境美队一滴血极限四杀1v4！_哔哩哔哩bilibili_精彩集锦 - Google Chrome 2023-03-19 00-11-16.mp4&quot; controls &gt; &lt;/audio&gt;&lt;!-- autoplay 自动播放 loop 循环播放 仅仅支持MP3.Wav.Ogg--&gt;&lt;h1&gt;video tags&lt;/h1&gt;&lt;video src=&quot;C:\\Users\\28763\\Videos\\Captures\\这是27岁的老将枪法？绝境美队一滴血极限四杀1v4！_哔哩哔哩bilibili_精彩集锦 - Google Chrome 2023-03-19 00-11-16.mp4&quot; controls autoplay muted&gt;&lt;/video&gt;&lt;!-- autoplay 自动播放(在chrome中要配合muted) loop 循环播放 MP4,WebM,Ogg--&gt;&lt;br&gt;&lt;h1&gt;超链接&lt;/h1&gt;&lt;!-- a anchor --&gt;&lt;b&gt;&lt;a href=&quot;https://www.bilibili.com&quot; target=&quot;_blank&quot;&gt;霹雳霹雳&lt;/a&gt; &lt;/b&gt;&lt;br&gt;&lt;a href=&quot;./balnk.html&quot; target=&quot;_self&quot;&gt;跳转到blank.html&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#&quot;&gt;空链接&lt;/a&gt;&lt;h1&gt;列表&lt;/h1&gt;&lt;h2&gt;有序&lt;/h2&gt;&lt;ol&gt; &lt;li&gt;有序1&lt;/li&gt; &lt;li&gt;有序2&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;无序&lt;/h2&gt;&lt;ul&gt; &lt;li&gt;无序1&lt;/li&gt; &lt;li&gt;无序2&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;自定义列表 definition list&lt;/h2&gt;&lt;dl&gt; &lt;dt&gt;主题&lt;/dt&gt; &lt;dd&gt;part1&lt;/dd&gt; &lt;dd&gt;part2&lt;/dd&gt;&lt;/dl&gt;&lt;h1&gt;表格标签&lt;/h1&gt;&lt;table border=&quot;1&quot;&gt; &lt;caption&gt;test&lt;/caption&gt; &lt;tr&gt; &lt;th&gt;x\\y&lt;/td&gt; &lt;td&gt;y=1&lt;/td&gt; &lt;td&gt;y=2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;x=1&lt;/td&gt; &lt;td&gt;1,1&lt;/td&gt; &lt;td&gt;1,2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;x=2&lt;/td&gt; &lt;td&gt;2,1&lt;/td&gt; &lt;td&gt;2,2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;table border=&quot;1&quot;&gt; &lt;caption&gt;test&lt;/caption&gt; &lt;thead&gt; &lt;td&gt;x\\y&lt;/td&gt; &lt;td&gt;y=1&lt;/td&gt; &lt;td&gt;y=2&lt;/td&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;x=1&lt;/td&gt; &lt;td&gt;1,1&lt;/td&gt; &lt;td&gt;1,2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;x=2&lt;/td&gt; &lt;td&gt;2,1&lt;/td&gt; &lt;td&gt;2,2&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;tfoot&gt; &lt;tr&gt; &lt;td&gt;last line&lt;/td&gt; &lt;td&gt;last line&lt;/td&gt; &lt;td&gt;last line&lt;/td&gt; &lt;/tr&gt;&lt;/tfoot&gt;&lt;/table&gt;&lt;br&gt;&lt;h1&gt;input &lt;/h1&gt;&lt;h2&gt;常规&lt;/h2&gt;&lt;p&gt;&lt;input placeholder=&quot;请输入&quot;&gt; &lt;/p&gt;&lt;p&gt;&lt;input type=&quot;text&quot;&gt; &lt;/p&gt;&lt;p&gt;&lt;input type=&quot;date&quot; min=&quot;2023-1-1&quot;&gt; &lt;/p&gt;&lt;p&gt;&lt;textarea name=&quot;hello&quot; id=&quot;world&quot; cols=&quot;30&quot; rows=&quot;10&quot; &gt;hello world &lt;/textarea&gt; &lt;/p&gt;&lt;h2&gt;多选&lt;/h2&gt;&lt;label &gt;&lt;input type=&quot;checkbox&quot;&gt;option1&lt;/label&gt;&lt;label &gt;&lt;input type=&quot;checkbox&quot;&gt;option2&lt;/label&gt;&lt;h2&gt;单选&lt;/h2&gt;&lt;!-- 是通过name相同实现的 --&gt; &lt;input type=&quot;radio&quot; name=&quot;sport&quot;&gt;option1 &lt;input type=&quot;radio&quot; name=&quot;sport&quot;&gt;option2 &lt;!-- 无提示选择 --&gt; &lt;p&gt; &lt;select name=&quot;&quot; id=&quot;&quot;&gt; &lt;option value=&quot;&quot;&gt;op1&lt;/option&gt; &lt;option value=&quot;&quot;&gt;op2&lt;/option&gt; &lt;/select&gt;&lt;/p&gt;&lt;p&gt; &lt;!-- 有提示选择 --&gt; &lt;input list=&quot;countries&quot;&gt; &lt;datalist&gt; id=&quot;countries&quot; &lt;option value=&quot;&quot;&gt;UK&lt;/option&gt; &lt;option value=&quot;&quot;&gt;USA&lt;/option&gt; &lt;option value=&quot;&quot;&gt;CN&lt;/option&gt; &lt;/datalist&gt;&lt;/p&gt;&lt;h1&gt;引用&lt;/h1&gt;&lt;!-- 有 block ，cite ， q ，code--&gt;&lt;!-- block 长引用 --&gt;&lt;!-- cite 章节 作品名称 --&gt;&lt;!-- q 具体的话 会有引号--&gt;&lt;!-- code 代码引用 --&gt;&lt;blockquote cite=&quot;https://www.huxley.net/bnw/four.html&quot;&gt; &lt;p&gt; Words can be like X-rays, if you use them properly—they’ll go through anything. You read and you’re pierced. &lt;p&gt; &lt;q&gt; test &lt;/q&gt; &lt;/p&gt; &lt;p&gt; &lt;code lang=&quot;C&quot;&gt; i=10； i=i++; &lt;/code&gt; &lt;/p&gt; &lt;/p&gt; &lt;footer&gt;—Aldous Huxley, &lt;cite&gt;Brave New World&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;&lt;/body&gt;&lt;/html&gt;s 前端入门 - 基础语言篇HTMLhyper text markup language hyper text 指的是图片标题链接表格 markup language指的是标记语言语义化的html语言 html中的元素，属性以及属性值都有某些含义CSScascading style sheets 层叠样式引入方式 嵌入式 写在head标签的style标签中 外链式 写在单独的css中，用 link标签引入 内联式 经常配合div使用，直接在标签里面写同时存在内联与外联的情况下，还是能够同时生效。谁在后面，谁决定结果选择器渲染规则种类 标签选择器/类型选择器 1234567 p{ color: red; font-size: 30px; background-color: aqua; width: 100px; height: 300px; } id选择器12345678#first { color: black; }&lt;body&gt; &lt;p id=&quot;first&quot;&gt; test &lt;/p&gt;&lt;/body&gt; 类选择器(class)1234567891011&lt;style&gt; .done { text-decoration: line-through; }&lt;/style&gt;&lt;body&gt;&lt;ul&gt; &lt;li class=&quot;done&quot;&gt;task1&lt;/li&gt; &lt;li class=&quot;done&quot;&gt;task2&lt;/li&gt; &lt;/ul&gt;&lt;/body&gt; 属性选择器12345678&lt;style&gt; a[href$=&quot;.jpg&quot;]{ color: blue; }&lt;/style&gt;&lt;body&gt; &lt;a href=&quot;a.jpg&quot;&gt;this is a jpg&lt;/a&gt;&lt;/body&gt; 状态伪类12345678910111213/* 对于a不同的状态进行选择 */a:link{ color: blue; } a:visited{ color: cornflowerblue; } a:hover{ color: bisque; } a:active{ color: orange; } 结构伪类12345678910111213141516 /* 结构伪类 */ li{ border-bottom: 1px solid; } li:first-child{ color: antiquewhite; } li:last-child{ padding: 0.5em; border-bottom: none; }&lt;ul&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt;&lt;/ul&gt; 组合选择器 1234567891011121314151617181920212223&lt;article&gt; &lt;h1&gt;拉森火山国家公园&lt;/h1&gt; &lt;p&gt;拉森火山国家公园是位于...&lt;/p&gt; &lt;section&gt; &lt;h2&gt;气候&lt;/h2&gt; &lt;p&gt;因为拉森火山国家公园...&lt;/p&gt; &lt;p&gt;高于这个高度，气候非常寒冷...&lt;/p&gt; &lt;/section&gt;&lt;/article&gt;&lt;style&gt;/*article 中的所有子p*/ article p { color: black; }/*article直接的p标签*/ article &gt; p { color: blue; }/*h2紧跟的p标签*/ h2 + p { color: red; }&lt;/style&gt; 选择器组1234 /* 选择器组 */ h1 , h2{ font: 100; } 特异度 计算规则选择器生效的情况是看选择器的特异度(specificity),特异度高决定css样式(A,B,C)A:ID选择器 B:类选择器、属性选择器和伪类 C:类型选择器和伪元素优先级的计算，从A级开始到C级结束，如果到C级是两个选择器的优先级还是相等的那么有限选择靠后的选择器 选择器 优先级 (A, B, C) .class.class (0, 2, 0) .class (0, 1, 0) 继承 父继承1234567891011121314&lt;!-- strong从p父中继承 --&gt;&lt;p&gt;This is a &lt;em&gt;test&lt;/em&gt; of &lt;strong&gt;inherit&lt;/strong&gt;&lt;/p&gt;&lt;style&gt; body { font-size: 20px; } p { color: blue; } em { color: red; }&lt;/style&gt; 显式继承通过inherit关键词显式继承1234567*{ box-sizing: inherit;}html{ box-sizing: border-box;} 初始值12345/* 将p重置为初始值 */p{ background-color: initial;} 颜色12345 &lt;h1&gt;颜色表示&lt;/h1&gt; &lt;p style=&quot;color: rgb(111, 222, 111, 0.2);&quot;&gt;rgba&lt;/p&gt; &lt;p style=&quot;color: hsl(200, 50, 44, 0.47);&quot;&gt;hsla&lt;/p&gt; 字体 font-family 对同一个选择器指定多个字体1234567/* font-family */ h1{ font-family: Bitstream Vera Serif Bold,Times,sans-serif,Georgia,; } webfont 从网络中获取字体123456789/* web fonts */ @font-face { font-family: &quot;Bitstream Vera Serif Bold&quot;; src: url(&quot;https://mdn.github.io/css-examples/web-fonts/VeraSeBd.ttf&quot;); } font-size 关键字 small medium large 长度 px em 百分数 相对于父元素1234567891011121314151617181920&lt;section&gt; &lt;h2&gt;A web font example&lt;/h2&gt; &lt;p class=&quot;note&quot;&gt;Notes: Web fonts ...&lt;/p&gt; &lt;p&gt;With this in mind, let's build...&lt;/p&gt;&lt;/section&gt;&lt;style&gt; section { font-size: 20px; } section h1 { font-size: 2em; } section .note { font-size: 80%; color: orange; }&lt;/style&gt; font-style 1234567891011121314151617&lt;p class=&quot;normal&quot;&gt;Normal Text&lt;/p&gt;&lt;p class=&quot;italic&quot;&gt;Italic Text&lt;/p&gt;&lt;style&gt; p { font-size: 36px; font-family: &quot;Helvetica Neue&quot;, sans-serif; } .normal { font-style: normal; } .italic { font-style: italic }&lt;/style&gt; font-weight1234567891011121314151617181920212223&lt;ul&gt; &lt;li class=&quot;w1&quot;&gt;锦瑟无端五十弦（100）&lt;/li&gt; &lt;li class=&quot;w2&quot;&gt;锦瑟无端五十弦（200）&lt;/li&gt; &lt;li class=&quot;w3&quot;&gt;锦瑟无端五十弦（300）&lt;/li&gt; &lt;li class=&quot;w4&quot;&gt;锦瑟无端五十弦（400-normal）&lt;/li&gt; &lt;li class=&quot;w5&quot;&gt;锦瑟无端五十弦（500）&lt;/li&gt; &lt;li class=&quot;w6&quot;&gt;锦瑟无端五十弦（600）&lt;/li&gt; &lt;li class=&quot;w7&quot;&gt;锦瑟无端五十弦（700-bold）&lt;/li&gt; &lt;li class=&quot;w8&quot;&gt;锦瑟无端五十弦（800）&lt;/li&gt; &lt;li class=&quot;w9&quot;&gt;锦瑟无端五十弦（900）&lt;/li&gt;&lt;/ul&gt;&lt;style&gt; .w1 { font-weight: 100 } .w2 { font-weight: 200 } .w3 { font-weight: 300 } .w4 { font-weight: 400 } .w5 { font-weight: 500 } .w6 { font-weight: 600 } .w7 { font-weight: 700 } .w8 { font-weight: 800 } .w9 { font-weight: 900 }&lt;/style&gt; line-height12345678910111213141516&lt;section&gt; &lt;h1&gt;Font families recap&lt;/h1&gt; &lt;p&gt;As we looked at in fundamental text and font styling, the fonts applied to your HTML can be controlled using the font-family property. This takes one or more font family names. &lt;/p&gt;&lt;/section&gt;&lt;style&gt; h1 { font-size: 30px; line-height: 45px; } p { font-size: 20px; line-height: 1.6; }&lt;/style&gt; text-align spacing text-indent text-decoration white-space 控制空白符 control shift i 调试工具 layout常规,盒子模型参数列表: width height padding border margin overflow 处理超出的内容 块级 vs 行级 行内排版inline formatting context IFC以行为单位呈现 12345678910111213141516171819&lt;div&gt; This is a paragraph of text with long word Honorificabilitudinitatibus. Here is an image &lt;img src=&quot;https://assets.codepen.io/59477/cat.png&quot; alt=&quot;cat&quot;&gt; And &lt;em&gt;Inline Block&lt;/em&gt;&lt;/div&gt;&lt;style&gt; div { width: 10em; //overflow-wrap: break-word; background: #411; } em { display: inline-block; width: 3em; background: #33c; }&lt;/style&gt; overflow-wrap处理超出范围的文本inline-block为行内块状 块内排版block formatting context BFC以块为单位呈现123456789101112131415161718&lt;span&gt; This is a text and &lt;div&gt;block&lt;/div&gt; and other text.&lt;/span&gt;&lt;style&gt; span { line-height: 3; border: 2px solid red; background: coral; } div { line-height: 1.5; background: lime; }&lt;/style&gt; flex-box布局对于flex来说默认排版方向是从左到右,虽然还是块状呈现12345678910111213141516171819202122232425262728&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;a&quot;&gt;A&lt;/div&gt; &lt;div class=&quot;b&quot;&gt;B&lt;/div&gt; &lt;div class=&quot;c&quot;&gt;C&lt;/div&gt;&lt;/div&gt;&lt;style&gt; .container { display: flex; border: 2px solid #966; } .a, .b, .c { text-align: center; padding: 1em; } .a { background: #fcc; } .b { background: #cfc; } .c { background: #ccf; }&lt;/style&gt; 效果 主轴与侧轴 控制主轴的对齐 控制侧轴的对齐 flexibility使用flex,进行拉伸 123456789101112131415161718192021222324&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;a&quot;&gt;A&lt;/div&gt; &lt;div class=&quot;b&quot;&gt;B&lt;/div&gt; &lt;div class=&quot;c&quot;&gt;C&lt;/div&gt;&lt;/div&gt;&lt;style&gt; .container { display: flex; } .a, .b, .c { width: 100px; }/* 拉伸倍数为2 */ .a { flex-grow: 2; } .b { flex-grow: 1; }&lt;/style&gt; 效果: flex缩写解释 grid布局相较于flex-box,进化为二维的排版 template grid line 网格线示例:12345.a {grid-row-start: 1;grid-column-start: 1;} float主要用来处理文字环绕的效果float left 绝对定位 relative absolute相对于根元素进行定位1234567891011121314151617181920212223&lt;h1&gt;页面标题&lt;/h1&gt;&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;box&quot;&gt;&lt;/div&gt; &lt;p&gt;段落内容段落内容 1&lt;/p&gt; &lt;p&gt;段落内容段落内容 2&lt;/p&gt; &lt;p&gt;段落内容段落内容 3&lt;/p&gt; &lt;p&gt;段落内容段落内容 4&lt;/p&gt;&lt;/div&gt;&lt;style&gt; .container { background: lightblue; } .box { position: absolute; top: 0; left: 0; width: 100px; height: 100px; background: red; }&lt;/style&gt; fixed相对于窗口进行定位12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;nav&gt; &lt;a href=&quot;#&quot;&gt;首页&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;导航1&lt;/a&gt; &lt;a href=&quot;#&quot;&gt;导航2&lt;/a&gt;&lt;/nav&gt;&lt;main&gt; &lt;section&gt;1&lt;/section&gt; &lt;section&gt;2&lt;/section&gt; &lt;section&gt;3&lt;/section&gt; &lt;section&gt;4&lt;/section&gt; &lt;section&gt;5&lt;/section&gt;&lt;/main&gt;&lt;a href=&quot;#&quot; class=&quot;go-top&quot;&gt;返回顶部&lt;/a&gt;&lt;style&gt; nav { position: fixed; line-height: 3; background: rgba(0, 0, 0, 0.3); width: 100%; } .go-top { position: fixed; right: 1em; bottom: 1em; color: #fff; } nav a { padding: 0 1em; color: rgba(255, 255, 255, 0.7); } nav a:hover { color: #fff; } body { margin: 0; font-size: 14px; } a { color: #fff; text-decoration: none; } section { height: 100vh; color: #fff; text-align: center; font-size: 5em; line-height: 100vh; } section:nth-child(1) { background: #F44336; } section:nth-child(2) { background: #3F51B5; } section:nth-child(3) { background: #FFC107; } section:nth-child(4) { background: #607D8B; } section:nth-child(5) { background: #4CAF50; }&lt;/style&gt; 刚好铺满整个窗口","link":"/2024/02/e2704d03db77.html"},{"title":"博客搭建","text":"原理用hexo+github page搭建.hexo生成静态网页HTML,GitHub page展示HTML github page每个仓库都有一个pages服务，可用来展示项目，通过简单的设置项目的index.html，并以此做为入口供用户参观访问.当然也可以用来跑博客. ^dca042 hexo hexo g：生成静态文件。将我们的数据和主题相结合生成静态文件的过程。 hexo d：部署文件。部署主要是根据在 _config.yml 中配置的 git 仓库或者 coding 的地址，将 public 文件上传至 github 或者 coding 中。然后再根据上面的 github 提供的 pages 服务呈现出页面。source储存mdthemes储存主题md+主题 生成静态HTMLhexo_repo文件下还有一个public的文件夹.执行hexo clean,会清除public,执行hexo d会生成public.还会生成.deploy_git文件夹，这个文件夹就是我们部署到github或者gitee上面的文件.只有public的文件才会上传到github.如果github page的结果不对,可能是hexo没有执行好 hexo deploy命令.而hexo server执行,依赖的不是public文件内容.可能会导致localhost展示结果与github page不同.source -&gt; public -&gt; .deploy_git执行hexo generate，根据source，更新public。执行hexo deploy，根据public，更新.deploy_git。12hexo cleanhexo g -d 是最优解详解Hexo搭建博客的底层原理搭建reference:ubuntu 安装hexo已经放弃,转windows hexo由于是在git bash里面操作,没区别…可以直接参考ubuntu系统下的安装域名绑定:https://blog.csdn.net/weixin_45961774/article/details/108402406cpolar + PHP study本地配置网站,再内网穿透到公网 不需要我有ipv4 icarus修改live2d使用的是张书樵的live2d-widgetlive2d模型添加live2d模型库,超多色色依赖cdn服务,直接从别人的服务器上拉取的live2d.所以hexo库里面并没有原生的live2d文件好像要自己部署cdn服务,再调用api添加新的live2d模型有点难度,暂时放弃,以后有机会接触到cdn,本地api部署再说 进阶修改文章加宽参考1主要是修改三个文件\\themes\\icarus\\include\\style\\responsive.styl\\themes\\icarus\\layout\\layout.jsx\\themes\\icarus\\layout\\common\\widgets.jsxresponsive.styl负责管理几个既定的参数 gap mobile tablet fullhd widescreenlayout.jsx负责管理文章widgets.jsx负责管理侧边栏注意,使用的12块分配,对于单侧边栏, 侧边栏+文章=12对于双侧边栏, 侧边栏*2+文章=12 share管理使用addtoany搞不懂什么情况,实现不了,放弃试试换成sharethis在_config.yml中增加12share: type: sharejs在_config.icarus.yml中增加12share: type: sharejs对sharejs 的效果不满意,放弃share模块,有机会再搞分享设置 [ ] https://wiki.kunzhang.me/tech/%E5%91%A8%E8%BE%B9%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/hexo.html#widgetlatex添加参考1参考2问题:x_{a}y_{b}中间的下划线都会被识别为斜体符号,需要转义.更改inline.js文件中的em行12//em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 记得hexo cleancategories设置categories 自动化注意修改depth指定文章隐藏https://github.com/im0o/hexo-generator-index-custom/blob/master/README_zh.mdhttps://blog.csdn.net/qq_42777659/article/details/126516780跳过某些文件hexo skip render设置在_config.yml中设置123skip_render: - _posts/fleeting/**/**/**/* - _posts/templates/* 目录设置在_config.yml中开启1toc: true 在_config.icarus.yml中123456789101112widgets: # 目录 小部件配置 - # 小部件显示位置 position: left type: toc # 是否显示每个标题的索引 index: true # 是否在看不到副标题时折叠副标题 collapsed: true # 标题显示的最高水平 depth: 5 对于过长的标题,需要处理显示器不够大,目录无法完全显示的情况参考可滚动目录参考图片添加自定义css对于前端三件套不熟悉,只能自己看12345678.is-2-column { background-image: url(/img/backgroud.png); background-position: center center; background-repeat: no-repeat; background-attachment: fixed; background-size: cover; // background-color: #f5f5fa;} 这段代码只对2列的排版生效,不会对于三列排版生效.要改成12345678 .is-3-column { background-image: url(/img/backgroud.png); background-position: center center; background-repeat: no-repeat; background-attachment: fixed; background-size: cover; // background-color: #f5f5fa;} 添加readmore功能采用插件hexo-excerptgithub仓库实现文章根据最近的更新排序,而不是发布时间创建时间排序修改node_modules\\hexo-generator-index\\lib\\generator.js中的内容修改结果为12345678910111213141516171819202122232425262728293031'use strict';const pagination = require('hexo-pagination');const { sort } = require('timsort');module.exports = function(locals) { const config = this.config; const posts = locals.posts.sort(config.index_generator.order_by);// sort(posts.data, (a, b) =&gt; (b.sticky || 0) - (a.sticky || 0)); posts.data = posts.data.sort(function(a, b) { if(a.top &amp;&amp; b.top) { // 当两篇文章top都有定义时 if(a.top == b.top) return b.updated - a.updated; // 若top值一样，则按照文章更新日期降序排列 else return b.top - a.top; // 否则按照top值降序排列 } else if(a.top &amp;&amp; !b.top) { // 以下两种情况是若只有一篇文章top有定义，则将有top的排在前面（这里用异或操作居然不行233） return -1; } else if(!a.top &amp;&amp; b.top) { //上一条已解释 return 1; } else return b.updated - a.updated; // 若都没定义，则按照文章更新日期降序排列}); const paginationDir = config.pagination_dir || 'page'; const path = config.index_generator.path || ''; return pagination(path, posts, { perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: { __index: true } });}; 别人的icarusAnne Wu配置peiyingchi配置站点google收入google console中验证站长的身份验证身份部分可以google console中的引导或者看其他博客.添加sitemapsitemap由插件辅助完成在hexo目录下安装hexo-generator-sitemap插件1npm install hexo-generator-sitemap --save 在_config.yml添加12sitemap: path: sitemap.xml 注意在_config.yml,你应该设定好了自己的url.例如我的是1234author: l4rklanguage: zh-CNtimezone: Asia/shanghaiurl: http://domonnss.github.io hexo-generator-sitemap会根据这里的url生成xml文件. 如果提示此位置的 Sitemap 不允许此网址。,可能是因为生成的xml文件中的url与你的域名不同xml中为123456&lt;url&gt;&lt;loc&gt;http://domonnss.github.io/2023/10/f85834e8ad59.html&lt;/loc&gt;&lt;lastmod&gt;2023-12-18&lt;/lastmod&gt;&lt;changefreq&gt;monthly&lt;/changefreq&gt;&lt;priority&gt;0.6&lt;/priority&gt;&lt;/url&gt;而我填入的站点地图为https://l4rk.cn/sitemap.xml domonnss.github.io与l4rk.cn不是同一个域名.就会出现这个报错提示修改_config,yml的url为url: http://l4rk.cn输入命令hexo clean &amp;&amp; hexo g &amp;&amp; hexo d生成新的xml文件为123456&lt;url&gt;&lt;loc&gt;http://l4rk.cn/2023/10/f85834e8ad59.html&lt;/loc&gt;&lt;lastmod&gt;2023-12-18&lt;/lastmod&gt;&lt;changefreq&gt;monthly&lt;/changefreq&gt;&lt;priority&gt;0.6&lt;/priority&gt;&lt;/url&gt;当xml文件中的url与站点地图的网址域名相同时,就不会出现报错啦☺ 等待几天时间,google就会收录网站 obsidian+hexo把md推到github,再从github推到hexo,再在hexo上要不把hexo配置到windows,要不放弃hexo,围绕obsidian配置博客尝试用插件选择在windows环境下重新配置hexo.reference:windows hexo+obsidian+github 写的特别棒https://zhuanlan.zhihu.com/p/613429644 问题hexo d 无法连接至github更改_config.yml内容123456789101112131415161718192021222324252627l4rk@l4rkserver:~/hexo$ hexo dINFO Validating configInferno is in development mode.Inferno is in development mode.INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝=============================================INFO === Checking package dependencies ===INFO === Checking theme configurations ===INFO === Registering Hexo extensions ===INFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...On branch masternothing to commit, working tree cleanfatal: unable to access 'https://github.com/domonnss/domonnss.github.io/': Failed to connect to github.com port 443 after 129455 ms: Connection timed outFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.htmlError: Spawn failed at ChildProcess.&lt;anonymous&gt; (/home/l4rk/hexo/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (node:events:514:28) at ChildProcess._handle.onexit (node:internal/child_process:294:12)reference:https://blog.csdn.net/weixin_48927364/article/details/123405585 hexo deploy 报错:reference:https://blog.csdn.net/nineya_com/article/details/103301870完美解决12345678910111213141516171819202122232425262728293031323334l4rk@l4rkserver:~/hexo$ hexo deployINFO Validating configInferno is in development mode.Inferno is in development mode.INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝=============================================INFO === Checking package dependencies ===INFO === Checking theme configurations ===INFO === Registering Hexo extensions ===INFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...Author identity unknown*** Please tell me who you are.Run git config --global user.email &quot;you@example.com&quot; git config --global user.name &quot;Your Name&quot;to set your account's default identity.Omit --global to set the identity only in this repository.fatal: unable to auto-detect email address (got 'l4rk@l4rkserver.(none)')error: src refspec HEAD does not match anyerror: failed to push some refs to 'https://github.com/domonnss/domonnss.github.io'FATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.htmlError: Spawn failed at ChildProcess.&lt;anonymous&gt; (/home/l4rk/hexo/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (node:events:514:28) at ChildProcess._handle.onexit (node:internal/child_process:294:12) github master与main的问题https://juejin.cn/post/7135335154716770341 不知道为什么npm无法在git bash中使用直接换成cnpm就行.换源,清除缓存都失效… 每次hexo g -d github库中的CNAME都会不在在/d/hexo_repo/source中添加 CNAME文件 Pio酱和Tia酱的模型不能像在其他网站看到的那样可以换装reference:https://akilar.top/posts/5b8f515f/ TypeError: Cannot read properties of null (reading ‘type’)在原来的_config.icarus.yml文件中,由于注释语法不正确引起的12345 # # 谷歌分析插件设置 # # https://analytics.google.com # google_analytics: # # Google Analytics tracking ID # tracking_id:多个#注释,出现错误修改注释方式或者直接删除注释内容就好了 高亮问题 ==高亮== 语法,hexo无法为它添加高亮使用`高亮`可以效果:高亮 挂了代理之后,hexo d的出错kex_exchange_identification: Connection closed by remote hostConnection closed在储存ssh密钥的位置.我的windows上位置为C:\\Users\\28763\\.ssh\\.增加config文件,内容为1234Host github.com HostName ssh.github.com User git Port 443再次hexo d,会有一个弹窗出来,填入yes就行","link":"/2024/02/cb9669760f30.html"},{"title":"域名备案","text":"如果域名已备案，域名却过期了，一定要续费，因为域名过期了，但备案不会过期，怕别人注册了你的域名做不良网站。所以，要么一直续费到底，要么把备案号吊销，这是很重要的事情。 如果域名不走国内环境就不一定需要备案 先不搞这个,等暑假学了前端,自己搭建了博客再说 24.2.14 更新依赖github page服务实现博客搭建.[[07archive/tech/博客搭建|博客搭建]]域名买了腾讯的,现在还不需要备案.备案的对象是实体的云服务器,而不是域名.自己的机器是不能备案的,只能是云服务商家的机器.太贵了云服务器…","link":"/2024/02/d646952e6d55.html"},{"title":"公网ipv4访问内网","text":"环境:学校电信提供公网ipv4:60.176.40.164ikuai检测到的外网地址,只要拨号没有掉,ip地址就是确定的使用ikuai的端口映射功能 内网ip有其对应的远程访问端口例如openwrt,内网端口要设置为80才能访问,外网端口随意 ikuai的外网访问直接在系统设置-登陆管理修改 还要找到Ubuntu,pve端口pve:8006ubuntu ssh端口:22虽然获得了公网IP地址，但是，这个IP地址是动态发放的，不是一直保持不变的，每次我们重启光猫或者重新拨号后，电信会重新给我们一个公网IP，每次的IP地址都是不一样的。也就是说每次我们外网访问的时候都要重新查询到这个新的公网IP地址，加上端口号才能进行访问，就比较麻烦了，要么在家的时候查看，要么让家里人查看。要解决这个问题就需要DDNS 动态域名服务了，可以把变化的 IP 自动动态地映射到域名上，通过不变的域名访问变化 IP 的主机。不想依靠外网ip,靠ip地址做解析 已依靠ddns解决. 参考:https://www.youtube.com/watch?v=KWHZhcbOOYI","link":"/2024/02/51fcd0cbc96d.html"},{"title":"自建图床","text":"[x] 域名好像不用也行. 无所谓现在有自己的域名 [x] 服务器,跑在自己的j4125上晚点再搞 备选方案 docker compose容器 使用chevereto openwrt下用宝塔 与 lskypro ubuntu下MinIO安装 配合obsidian 就选minio了 Minio介绍MinIO是一个用Golang开发的基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。Minio使用纠删码erasure code和校验和checksum来保护数据免受硬件故障和数据损坏。因此，即便您丢失一半数量（N/2）的硬盘，您仍然可以恢复数据。 安装ubuntu下MinIO安装Minio + PicGo自建图床配合obsidian 有一点很好,minio支持通过本机ip生成访问地址.这样我在pc上就能够访问到管理地址http://dn11.l4rk.cn:52501 buckets命名为picture-bucket 存放位置为:~/miniodata/picture-host/`12345l4rk@l4rkserver:~$ cd miniodata/picture-host/l4rk@l4rkserver:~/miniodata/picture-host$ pwd/home/l4rk/miniodata/picture-hostl4rk@l4rkserver:~/miniodata/picture-host$ ls -a. .. .minio.sys picture-bucket picture-host access key:ix7qTyJxDrlzqryIDth8kctIHqsxWjvCC1teRpBh 也可以通过mc:minio client工具管理 minio启动minio server /home/l4rk/miniodata/picture-host","link":"/2024/02/f2d6c0042842.html"},{"title":"软路由","text":"软路由的性能由cpu决定,r2s以上都可以跑满1000m虚拟机内存需求极大物理机1-2g足够了 硬件硬盘不存在大量的读写 nvme协议 u盘协议 网口 WAN接口是用来连接外网的，也被称之为广域网接口(Wide Area Network) LAN接口用来连接内网中的设备(Local Area Network)一个路由器通常有一个WAN口，多个LAN口。网卡intel更加友好,尤其是对虚拟机2.5g内网性能足够的软路由&gt;交换机＋弱软路由 总结 网卡上限 cpu下限 nas最好x86,尽可能cpu足够好 虚拟机 ESXi，注重企业支持，界面简单易用，自身功能较强，对硬件要求较高，扩展性较低。适合初学者、不想太折腾的、有服务器主板的（例如Gen8这种家用服务器）。迷茫的时候，优选ESXi吧。不支持Docker，估计未来也不会支持，毕竟不是Linux。你只能先装个linux虚拟系统，再用docker。 PVE，兼容性最好，扩展性好，界面友善度欠佳，需要一定Linux基础。 适合低端机型、懂Linux的、爱折腾的。PVE玩得溜了之后，看其它的系统都像是弟弟。（可惜我玩不溜）。本身不直接支持Docker，但是可以自己安装相关软件。 unRaid，Docker、磁盘阵列、显卡直通、虚拟U盘等都是亮点。必须U盘引导有点麻烦（廉价U盘7x24工作，心还是很慌）。特色功能多，出新快，因此问题也多。 可以运行Docker，还有方便的界面支持。但是虚拟缓存有点麻烦（内存不足时才用），算是瑕疵。适合直接做NAS、玩PT，尤其适合做家庭影视库、HTPC，玩一拖二也是个不错的选择。比较有可玩性，又不会难度特别高。选择PVE软路由系统 以下是一些常用的软路由系统： 1、DD-WRT DD-WRT是一种广泛使用的开源软路由系统，支持多种硬件平台，如ARM、MIPS和x86等。它提供了路由、VPN、防火墙、QoS、WiFi等多种功能，并且有着友好的Web管理界面。 2、OpenWrt OpenWrt是一种基于Linux的开源路由器操作系统，它支持众多的硬件平台，如x86、ARM、MIPS等。OpenWrt提供了许多的包管理器，用户可以通过这些管理器来安装各种不同的软件模块，实现个性化的网络服务。 3、pfSense pfSense是一种基于FreeBSD的开源软路由系统，它提供了路由、VPN、防火墙、负载均衡等多种功能，适合中小型企业和数据中心使用。 4、OPNsense OPNsense是一种基于HardenedBSD的开源软路由系统，它提供了与pfSense类似的功能，但在安全性方面更为重视，采用了许多安全增强措施。 5、RouterOS RouterOS是一种商业软路由系统，它由Latvian公司MikroTik开发，支持x86和MIPS等多种硬件平台。RouterOS提供了许多高级网络功能，如BGP、OSPF、VRRP、HotSpot等。 6、iKuai iKuai是一个开源软件（基于CentOS Linux），但它被用于HPE（惠普企业）服务器上，以创建一个多功能的服务器、网络和网关IT平台。 主要就是OP与ikuai选择在pve上跑ikuai和OP的虚拟机,ikuai主路由,OP旁路由 旁路由「旁路由」这并不是一个严谨的词汇，在官方的技术用语里，正确的叫法应该是「旁路网关」而所谓的「旁路网关」，是指挂靠在主路由网络下的一个旁系网络，他分担了一部分路由器的功能，因此被大众简称为「旁路由」，本质上它是一个通过 LAN 口与主路由连接的一个客户端设备。 这种主旁路由构成的网络架构可以分成两种，一种是发烧友在软路由系统中，通过虚拟化的形式，安装两套路由系统，它们各司其职，在软件层面上形成了主旁网络架构。另一种就是通过使用两个实体路由器，通过连接和配置打造的硬件形式上的主旁网络结构。 购买挑选如果还想装个黑群晖，EMBY啥的，那独显解码才有用 j4125 - n5105 功耗高,但是比5095低 价格高 被动散热可能压不住 性能不上不下的，当主机只能做日常工作，当软路由又剩太多。然后这些以软路由去设计小主机只能接一个2.5寸硬盘，当nas也很尴尬。 路由系统配置拓扑图12345678910111213141516171819202122232425262728293031323334flowchart TD A[电信] --&gt;|提供外网ipv4 60.176.42.201| B(猫\\n网关:192.168.1.1) H --&gt;G{pve: \\n ip 172.16.36.3 \\n gateway 172.16.36.1 \\n 管理口为enp1s0/eth0 \\n dns:114.114.114.114\\n8.8.8.8} B --&gt;H(主路由 ikuai pppoe上网:\\nlan1 管理口: ip 172.16.36.1 \\n ddns:dn11.l4rk.cn \\n 虚拟网卡vmbr0\\n lan2: ip172.16.36.2 eth2 \\nwan: ip gateway 拨号自动配置) H --&gt;I(旁路由:\\n immortalwrt \\n172.16.36.2 \\n 通过wireguard与bird连接其他dn11成员) H --&gt;J(ubuntu 22.04.3 server\\n 172.16.36.4) J --&gt;K(docker) J --&gt;L(hexo) 寝室光猫设置 管理界面http://192.168.1.1useradminadmin wifi密码hzdzkjdx217217 物理层 eth0 enp1s0 mac:60:be:b4:03:1f:5a eth1:enp2s0 mac:60:be:b4:03:1f:5b eth2:eno1 mac:60:be:b4:03:1f:5c 主板内置网卡 eth3:enp4s0 mac:60:be:b4:03:1f:5d ens、eno、enp网口的区别扩展知识内容： en标识etherneto：主板板载网卡，集成是的设备索引号p：独立网卡，PCI网卡s：热插拔网卡，USB之类的扩展槽索引号nnn（数字）：MAC地址+主板信息计算得出唯一序列 eno1：代表由主板bios内置的网卡 ens1:代表有主板bios内置的PCI-E网卡 enp2s0: PCI-E独立网卡 eth0：如果以上都不使用，则回到默认的网卡名 【linux】linux配置网口IP|RDMA配置IP|ens、eno、enp网口的区别https://blog.51cto.com/devin223/2925982 pve pve系统镜像写入 安装 网卡直通 网卡直通之后,进不去pve ikuai配置了错误的网卡直通,删除就行 Proxmox VE(PVE) 进行网卡直通,中断映射 ikuaiPS:四网口设备只能给3个直通PCI设备给虚拟机，管理口默认是最小数值得那个 default 网卡直通失败 是因为eth0是pve管理口,分配给ikuai会崩,访问补上pve后台 ikuai的后台管理地址修改的是lan口 网线插在pve的管理口上才会给 软路由分配地址,是不是因为内网与外网在一个网段上导致的电信 脑残,只能有一个拨号 ddns配置非常简单,参考需要使用dnspod中的功能创建token,编辑记录只对ikuai配置ddns,openwrt不管它https://www.ikuai8.com/zhic/ymgn/lyym/2019-12-13-06-35-05/60588.htmlhttps://console.dnspod.cn/dns/l4rk.cn/record immortalWRT IP:172.16.36.2 网卡直通 eth2 reference:安装https://sspai.com/post/68511https://www.jackiewu.top/article/best-alternative-solution-for-transparent-gateway ubuntu172.16.36.4 docker LXC（Linux Containers）是一种基于Linux 的内核级虚拟化技术。 它将应用软件打包成一个软件容器，内含应用软件本身代码以及所需要的操作系统核心、相关依赖库，创造出应用程序独立的沙箱运行时环境。 google 是lxc 最大的支持者，k8s 未开源前在google 内部使用的就是lxc。ssh要对pve上的其他系统添加serial设备,虚拟显示器serial1 iKuaiserial2 immortal 依靠端口映射实现远程ssh访问 错误Error: XHR request aborted by browserthrough SSH &gt; vim /etc/config/uhttpd &gt; option http_keepalive '0'参考 强制直连与强制不直连失效更新浏览器与操作系统的dns,再重新启动在win cmd中1ipconfig /flushdns在浏览器中访问chrome://net-internals/#dns,清除就行.清除操作没有反馈. 问题汇总路由器后台管理地址（closed） 推测： 由于软路由给ap模式下的路由器分配的地址是192.168.33.x；而ap的管理地址是192.168.1.75。所以即使，电脑同时连接网线与wifi，有两个不同网段的ip地址的情况下，仍然会出现无法访问路由器后台地址的情况。 解决： 不使用自带的一键ap功能，自己去设置ap用网线连在软路由上，实现相同192.168.33.x，现在可以通过软路由给ap路由器分配的地址，来进行后台管理192.168.33.11lxc的ubuntu没有网络(closed)虚拟网桥设置问题。当时只对pve下的vmbr0进行了设置。但ubuntu绑定的是vmbr2。导致连接不上网络。更改网桥设置之后,重启pve,网络掉了vmbr0的IP是安装时设置的IP，即访问web管理画面登录所使用的IP破案了,因为我把网桥vmbr0改成了192.168.33.8但是为什么,访问不了 https://192.168.33.2:8006还是网桥配置的问题.当配置为 时候,访问不了后台但改为 时候,能够正常运行育成建议:你要不先把其余的网桥都注释掉然后ifrelaod -a重载一下配置,一个一个来 哔哩哔哩封面,动态加载慢dns有问题,用的是谷歌的8.8.8.8,对国内解析不是特别好换成114.114.114.114 解决bilibili的广告也和dns服务器有关,换成114.114.114.114后,广告也没有了不知道之前的dns是啥,试了试8.8.8.8和8.8.0.0.没有广告问题 update:114.114.114.114也会有广告,之前换dns之后没广告到底是怎么回事呢🤔 更换网络环境之后,pve无法上网怀疑是物理层网口插错了? eth3什么情况,插上它就会烂,不管是把它当作lan口还是wan口 是因为wan口的虚拟网桥被我删掉了吗 受不了了,直接重装 电信是桥接模式,ikuai做主路由要进行pppoe拨号上网,再把网关给pve,pve才能上网 光猫改为桥接模式之后,访问不了192.168.1.1由于使用自己的软路由进行拨号,网段不在192.168.0.0/24,自然是访问不了的.在ikuai上,wan口设置为静态,ip定为192.168.x.x.这样ikuai下的所有设备都可以临时访问光猫后台","link":"/2024/02/6d6300cc123e.html"},{"title":"Vim使用笔记","text":"vim经典键位图","link":"/2024/02/466b99d74205.html"},{"title":"Zettelkasten flow","text":"把感兴趣或者觉得自己将来会用到的笔记收集起来，然后用一种标准化的方式去处理这些笔记，建立笔记之间的*联系*。*连接*is every thing大脑：专注于创造，思考卡片盒：储存细节和参考资料 我应该把zk部分放在哪里呢? 用卡片盒方法做笔记写论文的流程 做临时笔记。 写在diary里面,主要白天微博阅读的内容,自己的一些想法 做文献笔记。读书时候的highlights和notes,导入到highlights文件夹下 做永久笔记。找到碎片化笔记之间的联系,找到一个主题,输出东西 每个笔记只包含一个想法，记笔记的时候要像写给别人看的一样：用整句话，解释来源，参考了什么，用词尽量准确、简单、清晰。做完之后，就可以把第一步的瞬时笔记扔掉，把第二步的文献笔记放进你的文献管理系统。你现在可以把它们忘掉了。所有重要的东西已经在你的卡片箱里了。 把永久笔记放到你的卡片盒。注意点：1）把新笔记放在相关笔记的旁边；2）添加相关笔记的链接；3）要确保你可以重新找到这条笔记（可以做一个索引卡，上面列出所有相关的笔记）。 构建主题。从你的笔记中地构建出你写作的主题、研究的问题等等。 撰写草稿。把你的笔记转写成一个文章的草稿。 修改润色。重读草稿，润色。重复。 卡片盒所遵循的几个原则： 所有的思考都是在写的过程中发生的。写是唯一重要的事情。 没有人的写作是从零开始的，你的笔记就是你做的准备。 不要从上到下给你的笔记分类，而是从下往上（bottom-up）慢慢归纳出你的主题分类。 工具不会改变你的流程，工具只是帮你把你的流程更顺利地运转下去。 my conclusion在实践书中这套工作流程时，给自己更多的耐心，在学习和实践方面交替进行多次![[02literature/book/卡片笔记写作法：如何实现从阅读到写作#^9c11d4]]用自下而上的流程整理[[02literature/book/卡片笔记写作法：如何实现从阅读到写作]]笔记记忆有两块:提取强度与储存强度。加强联系提升前者，加强记忆提升后者。具体手段是，zk与anki 文献卡片：文献和文献内容的简要说明。每当有值得记录的内容，就写下内容与简要笔记。利用obsidian，我好像不用简要笔记 主卡片：对所阅读的内容产生的想法。阅读文献卡片中的简要笔记，写下想法，一张卡片就一个(可以试试card模式) 想法，笔记只有在它本身的上下文下才有意义。但如果只这么做，只能得到一些片段的文字，而不存在普遍的联系。要对笔记进行标准化的处理。在不同的语境下引用标准化处理后的笔记，要像翻译一样，根据语境本身，用不同的词汇描述，但尽量保持原本的意思。使得卡片获得全新的联系。可以将同一条笔记添加到不同的上下文中。 根据相关笔记的链接，来对某个主题进行整理。 我要做的是对各种资料进行处理，而不是因为原本的立场而去寻找资料。因为写作的过程是动态的，而不是静态的。在写作的过程中，你的观点往往会发生变化。如果按照一个预设的观点去寻找资料，就会陷入两种状况 对原本的观点质疑，却不得不继续支持。因为已经投入了太多，否定原来的想法成本太高。使得写作变成一种痛苦。继续围绕原本的观点写，明知是错误还要继续走下去 改变观点，很可能因为缺少别的观点的资料，又要从头再写起，几乎前功尽弃。而且你不会知道在这次从头再来的过程中你的观点是否会再次变化 利用卡片盒，可以同时开展多项工作。当某方面遇到困难就可以转向别的方向。 记笔记本身就是在思考 必须把想法外显化，写出，讲出来 fleetingnotes记录瞬间的想法，可以很随便，稍后再处理。如果时间足够可以仔细写完，直接放permanentnotes里面。被处理之后就可以被丢掉要在短时间内对它处理。当我不明白自己的意图，或者这个想法已经无关紧要的时候，就是超出了短时间的范畴。最好1-2day之内。 literaturenotes目的：有助于永久笔记的写作。精心挑选，在用自己语言组织的过程中去理解含义，对文本进行浓缩重写 引文和感想 一些重要的内容为的是收集，担负起储存大部分客观信息的作用存入文献管理系统中每读完一本就写下它的永久笔记。 permanentnotes是不能被忘记的仔细阅读fleetingnotes 或者literaturenotes 的内容。要及时去做，不能忘记为什么记它。对literaturenotes中已经被浓缩重写的部分进行再一次的重写，使得它标准化，并且能够脱离语境存在，成为真正属于你的东西即使忘了当时的上下文，permanentnotes依然能够被我理解。思考它们与我的研究，思考，兴趣有什么联系，从而生成新的想法，讨论，论点。方法：与我脑中或者卡片盒中的东西 矛盾 一致 印证 补充 结合为每一个新想法写下一条笔记，并且要保持良好的格式，能够轻易被理解，引用包含以下内容 语句本身清晰准确简短 标注来源 提供参考资料把每条permanentnotes链接添加到相关笔记后注意一点,当时写下literaturenotes的时候就有了一些笔记。在这一步的时候，需要判断在literaturenotes中的笔记 直接加入permanentnotes 改良之后加入 丢弃permanentnotes与literaturenotes中笔记最根本的区别是，permanentnotes中是我要紧紧牢记的，而literaturenotes中的是不太需要花力气记住的。需要非常非常谨慎细致,一目了然通过卡片盒洞见我的兴趣，想法，问题，放到weekly里面。在weekly里总结好了之后，就放那呗。以后看看要不要做monthly projectnotes和某个特定的项目有关,当这个项目结束的时候就可以抛弃了 相关文献收集 大纲 草稿片段 备忘录 代办事项 草稿本身 索引系统利用好obsidian本身的关系图谱，反向链接，双向链接的功能，对主题进行概述，以它作为切入点，引出后续的一系列笔记选择合适的关键词，指导关键词的原则是：什么样的关键词，能让我在忘记它的情况下想起来？而关键词往往不是文本中的某一个词。例如：在库恩看来，突然增加的特例假设是正常科学阶段可能陷入危机的迹象（Kuhn,1967）的关键词是 模式变换同时，相同的句子，对于不同的人来说关键词也是不一样的。 链接： 写作流程将积攒的想法整理出一个主题。把资料集中起来，看看哪些多余，哪些不足。同时要积极的思考，来改进结构，想法，论点 把笔记改成初稿 编辑校对稿子 要注意，之前的流程并不是只服务于一个主题。往往是多线程并进。在不同的阶段写出许多不同的想法。","link":"/2024/02/9faa5d71be27.html"},{"title":"completor","text":"增加对中文的补全支持\\u4e00-\\u9fa5","link":"/2024/03/4f62dd68bca2.html"},{"title":"","text":"P.A.R.A.即 项目（Project）、领域（Area）、资源（Resource）、 档案（Archive）的简称。Project —— “与目标关联的一系列任务，每个任务都有明确的完成期限”。Area of responsibility —— “一个需要持续一段时间的任务领域”。Resource —— “持续感兴趣的话题或主题”。Archives —— “其他三个类别以外的非活动项目”。","link":"/2024/04/07123552b731.html"},{"title":"latex","text":"refering 数学模式行内与行间排版有所不同,行内更适合短式子,行间更适合长式子或者公式推导 行内公式${f(x)=anx^n+a{n-1}x^{n-1}+a_{n-2}x^{n-2}}+\\cdots$ 行间公式 {f(x)=a_nx^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}}+\\cdots \\tag{1.1} 输入上下标^ 表示上标, _ 表示下标。$\\sum_i^na_i$1$\\sum_i^na_i$ 除法一般的输入形式$x=2\\div3$分数的输入形式为 \\frac{分子}{分母}$P(v)=\\frac{1}{1+exp(-v/T)}$1$P(v)=\\frac{1}{1+exp(-v/T)}$ 上下划线与花括号\\begin{array} \\overline{a+b+c} \\\\ \\underline{a+b+c} \\\\ \\overleftarrow{a+b} \\\\ \\underleftarrow{a+b} \\\\ \\underleftrightarrow{a+b} \\\\ \\vec x = \\vec{AB} \\\\ \\overbrace {a+b}^\\text{a,b} \\\\ a+\\rlap{\\overbrace{\\phantom{b+c+d}}^m}b+\\underbrace{c+d+e}_n+f \\end{array}输入根号$\\sqrt{12}$$\\sqrt[n]{12}$ 矩阵 \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} & 0 \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} & 0 \\\\ \\end{vmatrix}向量表示方法$\\vec {a}$or$\\boldsymbol {a}$点乘：$a \\cdot b$ 叉乘：$a \\times b$ 除以：$a \\div b$ 单位向量: $\\hat{a}$ 绝对值$\\lvert a \\rvert$ $A^T=(x,y)$ 矩阵不同的括号名字不同 $\\begin{pmatrix} a \\ b \\end{pmatrix}$ \\begin{pmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{pmatrix} \\chi(\\lambda) = \\begin{vmatrix} \\lambda - a & -b & -c \\\\ -d & \\lambda - e & -f \\\\ -g & -h & \\lambda - i \\end{vmatrix}","link":"/2024/02/6e971e7462de.html"},{"title":"markdown","text":"Markdown语言入门html语法在markdown中也能用 标题1标题2标题3标题4标题5标题6粗体文本 或 粗体文本斜体文本 或 斜体文本删除线文本 无序 项目1 项目2 项目3有序 项目1 项目2 项目3 this is a website 引用内容引用2 ​ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} & 0 \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} & 0 \\\\ \\end{vmatrix}表格 First Header Second Header viva viva 脚注您可以像这样创建脚注footnote footnote: horizontal line 下划线hello 粗体hello 删除线wrong sentence 内联数学公式 $\\lim_{x \\to +\\infty}$ todo [ ] todo list 块引用[[#^3050ca06]]![[02literature/book/中国历代政治得失#^29d385]] 首行缩进Ob笔记基于markdown语法，没有首行缩进功能，如果照习惯按tab想要缩进，软件理解为转为代码块，即使输入几个空格也不能模拟缩进，还是转为代码块。 script1234567891011- Title:: {{title}}- Authors:: {{authors}}- **Highlights and Notes** {{#sections}} - ## {{sectionTitle}} {{#highlights}} - {{highlight}} &lt;!-- - **{{type}}** --&gt; {{/highlights}} {{/sections}} 12345include &lt;iostream.h&gt;int main(){ printf(&quot;hello world&quot;,\\n); } 隐藏/注释 插入视频 在线视频以哔哩哔哩为例high_quality=1以最高画质播放autoplay=0取消自动播放 以本地视频为例controls召唤控件 双向链接 链接到某一篇[[tech/博客搭建|博客搭建]][[07archive/tech/博客搭建|博客搭建]] 链接到某个title[[tech/博客搭建#域名绑定|博客搭建#域名绑定]][[07archive/tech/博客搭建#域名绑定|博客搭建]] 链接到某块[[tech/博客搭建#^dca042|某块]][[07archive/tech/博客搭建#^dca042|某块]] 链接到外部文件[测试](file:///D:\\screenshots\\2024-02-03-17-41-29.png)测试 调试模式/控制台ctrl+shift+i","link":"/2024/02/2d443556a6e4.html"},{"title":"","text":"mjj版的linux入门教程本文的首要目的是给予Linux初学者一个简单、易学的教程，以便在看完本文后对Linux系统有一个基础的认识（而非系统级的深入），可以对常见的软件和功能进行配置，甚至可以自己写一写一键脚本。 本教程写于2021年下半年，采用的系统为Debian GNU/Linux 11 (bullseye)。 0 前言吐槽CentOS解释使用Debian而不是CentOS的原因 国内首批接触Linux系统的人主要集中在科研院校，大多数是延续了Unix-like的背景，在千禧年前后才有了真正意义上的Linux使用者：纯Linux平台开发、运行服务和应用，他们或直接或间接地推广了Linux系统。红帽（Red Hat, Inc.）在1994年就开始发布了同名的操作系统：Red Hat Linux（后改组为Red Hat Enterprise Linux，缩写为RHEL）。得益于红帽优秀的团队和商业支持，RHEL这一发行版迅速占领了国内市场。彼时的国内计算机市场远不如今日繁荣，在口口相传和红帽的推广中，RHEL成为了Linux入门的主流选项，即使后来号称用户友好的Ubuntu出现了，绝大多数尝鲜的人依然能看到众多网站里面只提供RHEL版本的教程。 CentOS是根据RHEL的源码重新编译的，等于换商标版本的RHEL，软件层面上，两者无本质区别。但CentOS是反人类的，至少是反入门用户的。使用RHEL的基本为商业用户，可以付费获得红帽的技术支持，或者干脆有一个自己的维护团队；而CentOS作为一个社区自发形成的操作系统，拥有落后的软件源/包，繁琐的配置，和对个人用户而言根本没有必要的SElinux等。举个例子，很多入门者修改SSH端口的时候，发现所有的操作都没有问题，但是死活无法生效，最终发现是没有在SElinux里面放行。如果你想安装个软件，你就得考虑是从落后主流版本好几代的软件源/包里面安装，还是自己下载源码进行编译以获取主流的使用体验。对于入门者而言，CentOS的安全性和稳定性是个虚假的概念，毕竟让一个刚接触Linux的人去自己编译源码安装，无异于让小学生上战场，输了就说是小学生战斗力太弱。 所以本文以Debian GNU/Linux（后续简称为Debian）来演示，也有着推广Debian的意思在里面，毕竟相比于Ubuntu往系统里面塞包括snap在内的一系列私货而言，Debain始终遵循着一个纯净的Linux的要求。而其他一些发行版，要么是专用性太强（如SUSE），要么是入门者不友好（如 Arch Linux），权衡之后，选择了写本文时，最新的Debian系统，即Debian GNU/Linux 11 (bullseye)。 1 环境搭建1.1 系统选择与安装Debian的安装包有一系列的前缀或者后缀，例如在默认的下载地址https://www.debian.org/download中的是debian-11.0.0-amd64-netinst.iso。其中， 11代表大版本是11，代号是bullseye，各版本代号都来源于电影《玩具总动员》中的角色名称； amd64是指系统为64位的，i386或者x86是32位的，amd64或者x86-64是64位的，32位系统已经被逐步弃用，目前仅在特定行业中使用； netinst是网络安装版本，只是个安装器，安装过程需要联网，而DVD后缀的是完整版（如：debian-11.0.0-amd64-DVD-1.iso），如果系统太大，会在DVD后面加数字，默认DVD-1是完整版本，其后数字的是软件源/包； 带firmware前缀的是包含第三方非开源驱动的（如：firmware-11.1.0-amd64-DVD-1.iso），其中就包含intel和Realtek等公司的闭源网卡驱动。 VPS全称为virtual private server（虚拟专用服务器），如果需要安装纯净版的Debian 11系统，推荐使用vicer的Linux一键重装脚本（如下）： 1bash &lt;(wget --no-check-certificate -qO- 'https://raw.githubusercontent.com/MoeClub/Note/master/InstallNET.sh') -d 11 -v 64 -p &quot;自定义root密码&quot; -port &quot;自定义ssh端口&quot; 1.2 常用的命令cat 用于查看文本文件的内容，如cat /etc/os-release 将显示系统信息，如下： 123456789PRETTY_NAME=&quot;Debian GNU/Linux 11 (bullseye)&quot;NAME=&quot;Debian GNU/Linux&quot;VERSION_ID=&quot;11&quot;VERSION=&quot;11 (bullseye)&quot;VERSION_CODENAME=bullseyeID=debianHOME_URL=&quot;https://www.debian.org/&quot;SUPPORT_URL=&quot;https://www.debian.org/support&quot;BUG_REPORT_URL=&quot;https://bugs.debian.org/&quot; touch 新建文本文件，如touch /home/hello.py 将在home 文件夹下新建一个Python文件。 ls 列出所有文件，但默认只是显示出最基础的文件和文件夹，如果需要更详细的信息，则使用ls -la，这将列出包括隐藏文件在内的所有文件和文件夹，并且给出对应的权限、大小和日期等信息。 cd 进入指定文件夹，如cd /home 将进入home目录。返回上层目录的命令是cd ..，返回刚才操作的目录的命令是cd -。 mkdir 新建文件夹，如mkdir /home/Python 将在home 文件夹下新建一个Python 文件夹。 mv 移动文件和文件夹，也可以用来修改名称，如mv /home/hello.py /home/helloworld.py 将上文的hello.py重命名为helloworld.py，mv /home/helloworld.py /home/Python/helloworld.py 将helloworld.py 由home文件夹移动到了次级的Python文件夹。 cp 复制文件，cp /home/Python/hellowrold.py /home/Python/HelloWorld.py 将helloworld.py复制为HelloWolrd.py。注意：Linux系统严格区分大小写，helloworld.py和HelloWolrd.py是两个文件。如果想复制整个文件夹，则需要带r，即cp -r，但此命令无法复制隐藏文件夹，需要使用cp -r pathA/. pathB 注意这个点.是灵魂。 rm 删除，即江湖传说中rm -rf ，r为递归，可以删除文件夹中的文件，f为强制删除。rm /home/Python/helloworld.py 可以删除刚才的helloworld.py 文件，而想删除包括Python 在内的所有文件，则是rm -rf /home/Python 。 du -lh 查看当前文件夹下，各文件、文件夹的大小，l是硬链接（软连接类似于快捷方式），h是让文件自动使用K/M/G显示而不是只有K。 1.3 基础文本编辑器nano、vimLinux系统的一大优势（同时也是劣势）是默认不需要GUI，因此节省了大量的性能开支，无GUI版本的Debian 11可以在512M甚至更小内存的VPS上正常启动和运行。但缺少GUI加大了入门者修改文件的难度，所幸Debian 11自带了简便易用的nano文本编辑器。以下以修改系统的更新源为例 1nano /etc/apt/sources.list #打开sources.list文件，在Linux系统中，#是注释符，其后的内容会被忽略 如图所示，即为nano打开sources.list后的界面，最下面两行为提示，比如Ctrl+E为退出，如果文档被改动了，则会出现下图，询问是否保存。如果没有被更改，则会直接退出。 Y则保存，N则不保存，Ctrl+C取消操作。此处输入Y，则会如下图： 此时按下Enter键就会保存了。 这里多提一句关于Debian 11的更新源内容，一般是以下6行。 12345678deb http://deb.debian.org/debian bullseye main contrib non-freedeb-src http://deb.debian.org/debian bullseye main contrib non-freedeb http://deb.debian.org/debian-security/ bullseye-security main contrib non-freedeb-src http://deb.debian.org/debian-security/ bullseye-security main contrib non-freedeb http://deb.debian.org/debian bullseye-updates main contrib non-freedeb-src http://deb.debian.org/debian bullseye-updates main contrib non-free deb表示为已经编译好的安装包，类似于Windows上的MSI安装包，deb-src是源文件，万一没有打包好，提供自己本地编译安装的机会。总共分三大行，第一行是系统主文件，第二行是安全性更新，第三个是一些更新补充，推荐三个都写上。在每行的末尾都有main contrib non-free字样，其中main是官方给的包/源，严格遵守相关开源协议；contrib是包/源本身遵守相关开源协议，但是它们的依赖则不是；non-free是私有的软件，比如上文提到的Realtek的WiFi驱动等。除此之外，其实还有个Backports作为第四大行，是将比较陈旧的软件移植过来的，很少会用到，一般默认不写上。 nano虽然好，但是功能简单，只适合一些简单的文本文件编辑功能，而发展自vi的vim则被成为编辑器之神（Emacs被称为神之编辑器，Linux之父Linus Torvalds就在用）。系统会自带vi但是不带vim，正好我们可以使用上述修改过的更新源来安装vim作为示例。 12apt update # 更新一下源apt install vim -y #安装vim这个软件 -y是确认安装 使用vim /etc/apt/sources.list打开更新源文件，如下图所示： vim功能众多，使用复杂，得慢慢说。左下角是此文件的路径和名称，右下角是光标此时的行数和列数。此时是无法直接输入，要先按下insert或者i键变成插入模式才行。此时，左下角如下图，变成了INSERT/插入模式。 然后就是该怎么写就怎么写，一些快捷键去百度谷歌必应吧，说的肯定比我详细。但是必须提到如何保存文件：insert模式下按esc键（一般是键盘最左上角，99%的人可能都不怎么用的一个键），INSERT会消失不见，如下图： 这个时候再按下:键，界面上也会出现一个冒号，如下图。注意，这个冒号是半角的，全角冒号是没用的。 这个时候，按下wq这两个键，即可保存内容。w是write/写入的意思，q是quit/退出的意思。如果你不想保存，则只输入q键即可，但是有时候因为文件已经被修改了，vim不让退出，这时候输入q!就可以了，感叹号是强制执行的意思，执行后文件不会被修改并且会退出vim。 1.4 更新系统至此，不管是使用nano还是vim都可以对更新源进行编辑了，让我们来具体了解一下如果更新系统和相关指令。 123apt updateapt list --upgradableapt upgrade -y 以上三行，分别是和更新源同步，显示出哪些软件可以更新，以及进行更新。 如上文中，安装了vim，若想卸载vim，则有以下两个命令，任意一个即可，但之间存在差别。 12apt remove vim -yapt purge vim -y 第一个会址卸载vim软件本身，配置文件仍然会本留下；第二种连带着配置文件和相关依赖一起卸载了，所以存在一定风险。除此之外，apt autoremove是对整个系统进行整理，将不需要的依赖卸载了，不针对于特定软件。 2 SSH连接和基础配置一般VPS供应商都会提供SSH的链接方式，包括用户名，密码和端口号，一些注重安全性的会修改端口号甚至只有采用密钥才能登陆VPS。这里使用纯净版的系统和默认配置进行演示。 2.1 连接SSH的软件和相关操作SSH软件有开源的和不开源的，有付费的和免费的，整理了一个常见SSH客户端（Windows平台）的对比表格和相关信息。其实在2021年，macos、Linux和windows 10都自带SSH功能，这里先不讨论。个人目前主用mobaxterm，偶尔使用xshell。 名称 免费与否 下载地址 Xshell 家庭/学校免费 https://www.netsarang.com/zh/free-for-home-school/ MobaXterm 家庭版免费 https://mobaxterm.mobatek.net/download.html FinalShell 基础功能免费 https://www.hostbuf.com/t/988.html electerm 免费+开源 https://github.com/electerm/electerm/releases PuTTY 免费+开源 https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html Xshell：传播广泛，自带中文，个人使用完全免费，但是会话窗口限制最多只能打开四个SSH连接，再多之后就会自动新建会话窗口了，传输文件需要配合Xftp才行。目前国区被臭名昭著的思杰马克丁代理了，如需使用，请前往官网下载，在输入邮件和姓名后，会收到一封邮件，邮件里面给出下载连接。 MobaXterm：只有英文版本，偶尔会反应慢半拍，除此之外没缺点。功能极其强大，传输文件、性能监控、串口通信、X11支持、IP检测、宏、WSL、远程桌面等，能想到的功能都有，而且个人使用免费。 FinalShell：国人开发，所以本地化很好，全中文，日常需要的功能也都有。有一些进阶功能需要付费，也可以云端保存SSH账号，虽然也是付费功能。缺点的话，和MobaXterm一样，JAVA写的东西，总是让人觉得慢半拍。 electerm：日常所需功能都有，完全开源和免费，还可以通过GitHub实现免费的云端保存SSH账号功能，适合自己折腾和魔改。基于electron开发的，从而实现了跨平台，Windows、Mac和Linux都有客户端。不过缺点也显而易见，electron本质上是个浏览器，占内存和硬盘空间。 PuTTY：由Simon Tatham开发和维护的，老牌中的老牌，但是缺少人性化设置，不推荐。 2.2 SSH配置文件介绍和修改SSH的配置文件在/etc/ssh/sshd_config中，是一个纯文本文件，可以使用nano或者vim打开和编辑。打开文件后，在前几行就能看到#Port 22字样，这个代表使用了默认的22端口作为SSH连接使用。因为大家都在使用22端口，所以会有一些扫描机器使用弱密码不断尝试登录，使用lastb命令可以查看登录失败的记录，如下图。233333是尝试登录的账号，144.214.xxx.xxx是发起者的IP，最后面是尝试登录的时间。 因此，我们可以改成高端口，比如35261这种没有特殊含义/排列的随机数，以减小被攻击的可能。要注意端口只能在0-65535之间，并且很多低位数的端口，已经被共识的程序占领了，比如80端口是http的，443端口是https的，就如22是SSH的一样。此处，我们修改/etc/ssh/sshd_config中的端口数后，还需要重启SSH服务才行，否则只会在系统下次重启后才启用新的端口。 1systemctl restart ssh #重启SSH服务 systemctl是systemd的命令，用于启动和监控系统服务的，在系统内核启动后，systemd就会开始服务，restart即重启的意思。关于systemd的相关内容，后文会详细说明。 除此之外，把密码改的复杂一些，也可以有效的降低系统被黑的风险，使用passwd root命令，即可修改root账号的密码，会提示New password:，此时输入新密码，注意这里是看不见任何输入反馈的，随后在显示Retype new password:后再次输入一遍，如果两次密码相同，就会更新root密码了。 2.3 使用密钥登陆SSH即使更改了端口，但因为使用密码即可登录，考虑到不是所有人都会使用强密码，所以SSH提供了使用密钥登录的功能，可以简单理解成是一长串复杂的并且可以相互验证的密码。以root用户为例，演示如何将SSH由密码登录改成密钥登录。 输入ssh-keygen -t rsa，随后一路enter键，如下图 在显示完成后，在/root/.ssh/文件夹下，你将看到id_rsa和id_rsa.pub两个文件，id_rsa是私钥，下载下来并妥善保存，id_rsa.pub是公钥，放在服务器上的。将id_rsa.pub写入到SSH的密钥文件中： 12touch authorized_keyscat id_rsa.pub &gt;&gt; authorized_keys 除此之外，还需要给文件和相关文件夹合适的权限： 12chmod 600 authorized_keyschmod 700 ~/.ssh 这里有个~，它代表的是当前用户，比如现在是root用户，那~就是root，所以chmod 700 ~/.ssh等于chmod 700 /root/.ssh 现在密钥已经配对好了，还需要修改SSH的配置文件，打开/etc/ssh/sshd_config文件，查找并修改如下： 123PubkeyAuthentication yes # yes表示允许密钥登陆AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2 # 指定密钥的文件位置，这里是去掉了开头的#PasswordAuthentication no # 不允许使用密码登陆，等测试密钥登陆成功了再修改此条，以防无法登陆 使用systemctl restart ssh重启SSH服务，此刻，你将只能使用密钥才能登录，一旦私钥遗失了，就再也进不去了。 3 Linux文件系统3.1 文件系统格式与Windows分割硬盘（甚至一个硬盘被划分成了好几个）不同，Linux的是将所有硬盘都挂载在了一起。简单来说，Windows分C盘D盘等，还针对软盘额外给予了A盘和B盘，Linux把所有的硬盘都放在了/下，即根目录，这也是Linux中root账户的权限最大的原因，root即为根，如同树根一样，所有的内容都要基于根才有了可能。文件系统是另外一个极其复杂的内容，这里只提到Windows使用的是NTFS，而Linux普遍采用EXT4格式，这两种文件系统互不兼容，装在Linux系统上的硬盘，在Windows上是无法直接读写的，必须使用额外的软件才能访问。反过来，在Linux上读取Windows下的硬盘中的内容，需要安装ntfs-3g才行。这两种文件系统各有优缺点，一般人用就行了，不要问，问就是用默认。实际上，目前在广泛使用的文件系统种类繁多，所有需要在它们之间交换文件的时候，会使用exFAT格式的U盘/硬盘（exFAT是FAT的替代品，因为FAT下单个文件最大不能超过4G）。 3.2 文件树、文件夹功能和权限在/目录下，使用ls -la会显示出所有的文件和文件夹（如下图所示），a是列出所有文件，l是显示详细信息。 第一列是文件/文件夹的权限，一共有10个字符，第一位是文件类型，比如d代表文件夹，l代表链接。之后，三个为一组，总共3组。r是读，w是写，x是执行，也可以通过数字来区分，r是4，w是2，x是1，所以有了常见的一把梭chmod +777。第二列是硬链接数量，即这个文件/文件夹下有多少真实放着的文件。第三列和第四列是这个件分别属于谁，以及这个人是哪个组的。这里的组概念来源于最开始的unix是个多用户系统，所有会把用户分类，比如某软件用户放一个组，系统维护人员放一个组等。第六列是文件/文件夹大小，默认单位是K。第七八九列是修改的日期。最后一列是文件/文件夹的名字。我们会发现有一些-&gt;的字样，这是指软链接。软连接类似于Windows上的快捷方式，而硬连接类似于复制了一份（但并不会真的占用空间）。 bin或者usr/bin：应用程序，比如Python的主程序就在这里 boot：系统启动文件 dev：外部硬件设备，Linux下一切皆文件，所以外部硬件设备也是以文件形式出现 etc：系统的配置文件，比如上述提到的SSH的配置文件就在这里 home：用户目录，类似于Windows上的桌面 initrd.img：启动文件，可以看到它被软连接到了boot目录中 lib：库文件，类似于Windows的dll，程序的依赖都在这里 lost+found：丢失寻找文件，系统被强迫关机后，会在这里记录下来 media：媒体文件，如果系统发现了光盘之类的，会自动挂载到这里 mnt：临时挂载目录，上述的光盘，还有U盘硬盘，如果手动挂载，都会选择这里 opt：系统额外软件的安装位置，极少使用，比如甲骨文的数据库会放一些东西在这里 proc：系统进程/内核会把一些信息放到这里，本质上是反应系统状态而不是文件 root：root用户的“桌面”，普通用户在home中 run：系统启动后存放临时文件 sbin：root用户的”bin” srv：放服务运行而需要的文件 sys：文件系统，里面包括进程信息，设备信息和终端信息 tmp：临时文件 usr：共享资源，类似于Windows安装软件的默认目录 var：不断变化的文件会放在这里，比如日志 vmlinuz：启动文件，可以看到它被软连接到了boot目录中 如果我们自己写了一个程序，还放在系统里面运行，那一般是在/usr/local/中新建目录，这遵循着Linux系统的默认规则。 3.3 示例：挂载U盘如果是Ubuntu桌面的话，会自动挂载U盘，但是无GUI版本的Linux大概率不会，所以会需要手动挂载，又或者加了一块新的硬盘，需要我们自己挂载。 1234fdisk -lmkdir /mnt/usbmount /dev/sda1 /mnt/usbumount /mnt/usb fdisk -l是显示出所有的储存，会显示出来类似于/dev/sda1等，mkdir /mnt/usb在mnt目录里面新建一个文件夹，即挂载点，假设sda1就是我们插入的U盘，mount /dev/sda1 /mnt/usb将这块U盘挂载到了/mnt/usb中，这时候我们就能在/mnt/usb中看到U盘里的文件。如果不再需要了，要手动移除这个U盘，使用umount /mnt/usb命令。 4 Shell/Dash入门让人头大，Shell本身就能写一本书了，少说得有300页！这里面夹杂着从Unix开始的一大堆事情，shell的发展，bash和dash的区别与联系，本身的命令，调用系统的命令，交互方式。累了，姑且先把它当成一堆命令拼凑起来的脚本吧。 还是写个例子，简单介绍一下实际内容，等以后有时间了再继续补充。比如我们想写一个查看CPU和内存使用率的脚本： 1234567891011121314151617#!/bin/bashecho &quot;which useage do you want to konw?&quot;echo &quot;1 for CPU, 2 for RAM&quot;read choiceif [ $choice -eq 1 ]then echo &quot;CPU usage&quot; grep 'cpu ' /proc/stat | awk '{usage=($2+$4)*100/($2+$4+$5)} END {print usage &quot;%&quot;}'elif [ $choice -eq 2 ]then echo &quot;RAM usage&quot; free -m | grep Mem | awk '{print ($3/$2)*100 &quot;%&quot;}'else echo &quot;WRONG INPUT&quot;fi 细说每一行内容 #!/bin/bash是指定此文件由/bin下面的bash这个程序来执行。 在Debian 11里面，bash其实是dash，别问dash是什么，就写bash，天王老子来了也写bash。Bash全称是GNU Bourne-Again Shell，bash被从NetBSD（一个Unix的分支）上移植到Debian上，所以叫dash (Debian Almquist Shell)。 echo &quot;which useage do you want to konw?&quot;是输出冒号内的文字 12echo &quot;1 for CPU, 2 for RAM&quot;read choice 把输入内容赋值给choice这个变量，即数字1或者2。rcho -p &quot;1 for CPU, 2 for RAM&quot; choice也可以实现相同功能。 1234567891011if [ ... ]then ... ...elif [ ... ]then ... ...else ...fi 这是一个if…elif…else的判断语句，先经过两次判断，如果都不能成功，那就执行最后一行。 choice -eq 1`把刚才的`choice`这个输入变量和数字1对比，注意，要有`才代表变量，不然就默认是文字，-eq是等于的意思。判断是否等于1，是的话就给出CPU使用量，如果不等于1，那就继续判断是否等于2，是的话就给出RAM使用量，如果不等于2，那就输出错误提醒，然后结束。grep是抓取有关键词的那一行，$2是这一行的第几个内容，如下： grep Mem抓取到了第二行，即真实内存这一行，$2是内存总量，$3是已经使用了的内存，因此($3/$2)*100就是已经使用了百分之多少的内存， 5 Crontab定时任务Crontab用于定时任务，比如设定周五晚上运行脚本备份网站，又或者每分钟检查一下CPU使用率等。但除此之外，crontab还有个@reboot功能，即可以在系统启动的时候自动运行指定程序。 推荐crontab -e，其中的-e是指当前用户，不建议直接使用crontab。首次运行crontab -e的时候，会让选择使用何种编辑工具，这个随便，nano和vim basic都行，什么顺手和习惯就用什么。 如上图，将每隔15分钟，就会使用位于usr/bin中的python3运行位于/usr/local/weather中的weather.py程序。前五个星号其实是设置的时间，推荐去 https://crontab.guru/ 这里直接设置时间（如下图）。第一个星号是分钟，第二个星号是小时，第三个星号是天，第四个星号是月份，第五个星号是每周的第几天。 6 系统权限6.1 root和user，以及sudo上述已经简单的减少了root来源，由于root的权限太高，以至于在实际使用中发现并不安全，而且作为一个初始目的是多用户多终端的操作系统，Linux主要操作都不需要发生在root用户上的。所以这里就有了user这个角色，如果用户多了起来，为了便于管理，也会把某些用户分组，就有了group的概念。以下演示使用root用户新建一个user用户并进入此用户： 如图所示，adduser mjj为新建一个叫做mjj的用户，由于此前并没有除了root之外的用户，所以会使用这个名字作为group/组的名字，并且在/home文件夹里面生成一个mjj文件夹，即mjj的”桌面“。所以输入两次密码，之后会问一堆问题，都是例行的，一路enter就好，最后会问一下信息对不对，输入y就完成添加新用户了。 但此时，mjj这个用户的权限是很小的，四舍五入等于没有，连某些文件夹都不能进去更别说执行软件了。使用su mjj切换到mjj用户中，可以在终端中看到已经从root@rn变成了mjj@rn，rn是这台服务器的名字，即为某某在rn这台服务器上。查看以下root文件夹下有些什么东西，结果发现权限不够而被拒绝访问/Permission denied。 所以我们要给一个能够临时使用root权限的能力，这被称为sudo。 123su root #切换回root账号apt install sudo -y #有些时候，纯净安装的Debian系统是没有sudo的，所以要安装一下usermod -aG sudo mjj ##给予mjj用户sudo权限 此时，我们再切换到mjj用户上，在刚才的命令前加上sudo，临时获取root权限，就可以查看了： 在用户首次使用root权限的时候，系统会提示三个准则，也请谨记： 尊重他人隐私； 输入之前请三思； 能力越大，责任越大。 6.2 chmod和chownchmod的全称是change mode，是针对于文件夹或者文件，改变它们的权限，这样就可以让某些用户正常使用了。这里不深入探讨chmod的使用详解，仅演示一些常见的内容。chmod +x helloworld.py 这里的x在上面说过，是执行的意思，即赋予此程序被执行的权限，多见于一键脚本里面，让脚本能够正常运行。+是新增权限，如果是-则是去除对应的权限。chmod -R 755 folder/ -R如上述的rm -rf中的r一样，是递归，即从这里开始，下面不论多少层文件夹，都执行这个命令。755是换算下来，则是root用户可以读写执行（1+2+4=7），用户和用户组只能读和执行（1+4=5），不能对文件进行更改。某些程序会对文件的权限有着极其严重的控制，比如上说的SSH密钥，分别给authorized_keys600的权限和.ssh文件夹700的权限，意味着只能被所有者/owner读写，在例子中即为只能被root账户读写。这种设计让没有相应权限的人无法修改密钥登陆的方式，换而言之，隔绝了用户之间的操作，从而增强安全性。 chown的全称是change owner，是用于设置文件所有权的。由于归属者的概念并没有文件这个概念常见，所有chown比较少见到，大多数人接触到的时候，大概是建网站的时候用chown -R www-data:www-data-group /var/www/html来确定文件关联。这句的意思是，将/var/www/html这个文件夹及里面的所有文件都归给www-data-group用户组的www-data用户。这样做的目的是实现权限分离，文件分离，从而让服务器可以更方便的被维护，以及明确使用途径。不过考虑到mjj大部分都是使用VPS的，可能很难遇到需要chown的情况吧。 不要chmod +777！不要chmod +777！不要chmod +777！人才是服务器安全的最大漏洞！ 7 Systemd入门和配置7.1 开机自启和进程守护Systemd是由Redhat家的Lennart Poettering开发的，其人以创造性和不靠谱闻名，Systemd在最开始的时候，和init相比没有明显优势，经过多次迭代才有了今天的稳定性和适用性，现在就让老旧的init进入历史垃圾桶吧。事实上，在Linux系统启动的时候，一旦kernel运行了，Systemd就会跟随启动，之后由Systemd唤醒并维护各个程序的正常运行，比如网卡，显示器，SSH服务等。你会在/etc/systemd/system/文件夹中发现一个叫做sshd.service的文件，并且还是enable模式的，这意味着SSH是开机自启的，并且系统会一直监控这这个程序，如果程序崩溃，系统会尝试自动重启它以确保能够正常运行。 以著名的内网穿透frp的服务器端的Systemd文件为例（下节将详细介绍如何搭建frp），将frps.service放到/etc/systemd/system/文件夹中，使用以下命令 1234systemctl enable frps.servicesystemctl start frps.servicesystemctl status frps.servicesystemctl restart frps.service systemctl是systemd在系统中的程序名字，enable是指让这个程序能够开机自启，start为让程序现就运行，status是查看这个程序现在的状态，restart是重启程序。 当然，我们也可以自己写systemd的service文件，这里以 https://github.com/cnsilvan/UnblockNeteaseMusic 解锁网易云音乐的程序做参考 1234567891011121314[Unit]Description=UnblockNeteaseMusicAfter=network.targetWants=network.target[Service]Type=simpleWorkingDirectory=/usr/local/UnblockNeteaseMusicExecStart=/usr/bin/node app.js -e http://music.163.com -s -p 8888RestartPreventExitStatus=23Restart=always[Install]WantedBy=multi-user.target 一共分为三组，分别为Unit，Service和Install。Unit是这个服务的名称，示例中为UnblockNeteaseMusic而After和Wants指明的network.target意味希望这个程序在网络服务启动后再启动，毕竟是个网络功能，不能还没有网就启动了。Service是核心部分，Type指定了类型,Simple是默认的类型，发现有网了就启动。此外，常见的还有fork和idle，前者意味着程序依赖于另外一个程序的运行，通常还会配置PIDFile，后者是等系统空闲了再启动，属于一点都不急的。WorkingDirectory是工作目录，ExecStart是执行的命令，实例中，是用位于/usr/bin/的nodejs执行位于工作目录的app.js这个文件，并且还带了参数http://music.163.com -s -p 8888。RestartPreventExitStatus是指如果报错信息为23则不会再重启了，具体报错信息是运行的程序决定的。Restart=always指只要不是23的报错信息，那就一旦服务停了，Systemd就会去重启。最后一部分，Install中的WantedBy=multi-user.target指网络服务已经正常启动，也可以让用户登录了，但是并没有开启GUI服务，这个部分不用去探究。 7.2 Timer代替Crontab我写了一个自动登录百度贴吧并签到的shell脚本，想每天都运行一次帮我拿积分，但是又不想用crontab实现定时任务，那么Systemd也是有类似的功能的，名字叫做Timer，即定时器。这个功能需要两个文件，比较繁琐。 需要再/etc/systemd/system/中写两份配置文件，tieba.service和tieba.timer，前缀必须一样，后缀不同。 前者很简单，就是个脚本（如下），名字和程序的路径： 12345[Unit]Description=Tieba Sign[Service]ExecStart=/home/tieba.sh 后者tieba.timer需要详细解释： 12345678[Unit]Description=Tieba Sign Timer[Timer]OnCalendar=*-*-* 12:00:00[Install]WantedBy=timers.target Timer的名称需要是service名字后面加一个Timer，用以提高准确性。OnCalendar类似于corntab的* * * * *，实例中的意味每天中午12点的时候执行以下tieba.service中的位于/home文件夹的tieba.sh这个程序。此处的WantedBy是timers.target，指明是个定时器。 8 手动配置系统：以frp为例frp是个内网穿透软件，可以将局域网设备通过frp服务端映射出来，实现公网服务，常见的有SSH、http/https服务等。这里以将内网设备的SSH映射到有公网IP的服务器上为例，从而不在家也能服务家里面的服务器了。 在这里下载最新版的安装包 https://github.com/fatedier/frp/releases 如图所示，0.38.0是版本号；后面的是系统，darwin是MacOS，freebsd是UNIX的一个分支，这里我们选择linux；紧跟着的是CPU架构，由于本次服务器的客户端是装了64位系统的树莓派4B（arm架构的CPU），所以选择frp_0.38.0_linux_arm64.tar.gz，而服务端是普通的VPS，所以选择frp_0.38.0_linux_amd64.tar.gz。 服务端配置 注意：版本号和CPU架构须按照实际情况决定。 123456789101112131415161718wget https://github.com/fatedier/frp/releases/download/v0.38.0/frp_0.38.0_linux_amd64.tar.gz# 使用wget下载软件包tar -zxvf frp_0.38.0_linux_amd64.tar.gz# 解压下载的软件包cd frp_0.38.0_linux_amd64/# 进入解压后的文件夹mkdir /etc/frp/# 新建一个frp的文件夹mv frps.ini /etc/frp/frps.ini# 把服务器端的配置文件放到刚才新建的文件夹mv frps /bin/# 把服务器端软件放到/bin中mv systemd/frps.service /etc/systemd/system/frps.service# 放置Systemd文件systemctl enable frps.service# 设置开机自启systemctl start frps.service# 立即运行 客户端配置 1234567wget https://github.com/fatedier/frp/releases/download/v0.38.0/frp_0.38.0_linux_arm.tar.gztar -zxvf frp_0.38.0_linux_arm.tar.gzcd frp_0.38.0_linux_arm/mkdir /etc/frp/mv frpc.ini /etc/frp/frpc.inimv frpc /bin/mv systemd/frpc.service /etc/systemd/system/frpc.service 上述与服务器配置类似，就不重复了，但需要额外修改服务端的配置文件，让它知道该和谁连接，打开/etc/frp/frpc.ini配置文件 123456789[common]server_addr = 服务器ipserver_port = 7000[raspi]type = tcplocal_ip = 127.0.0.1local_port = 本地服务器的SSH端口remote_port = 远程端口 其中，需要填写服务器端的IP，7000端口是握手和保活用的，默认就好了。[raspi]是客户端的名字，不可以重复，local_port是客户端的SSH端口，remote_port是远程的端口，此处假设是6000。 12systemctl enable frpc.servicesystemctl start frpc.service 设置开机自启并立即运行，此时在SSH软件上，通过 服务器IP:6000就可以连接到这台内网的树莓派了。 9 网站环境搭建网站搭建，说简单也简单，安装一个nginx放个html页面就算是了，但也可以做的极其复杂以至于需要一个团队，比如淘宝。这里提供了两个搭建网站的方法：面板和手动搭建。对于小白用户，还是推荐用用面板吧，不然出问题，网站被黑都不知道如何解决。 9.1 宝塔解人忧宝塔面板是个伪开源的一键式建站面板，国内版可以在 https://www.bt.cn/ 中找到安装方式，目前的安装命令是wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh &amp;&amp; bash install.sh 。需要注意的是，国内版需要登陆并且验证手机号后才能操作，宝塔也有强制后台升级的前科。 除此之外，还有国际版的叫做aapanel，安装地址为 https://www.aapanel.com/install.html ，安装命令是wget -O install.sh http://www.aapanel.com/script/install_6.0_en.sh &amp;&amp; bash install.sh。相对而言，国际版的隐私保护会更好一些，不会要求手机号等信息，但是默认语言是英文，如果会哪怕一点点英文，都推荐使用国际版的。 宝塔有一点不好的地方是动辄编译（原先是在CentOS上开发的，所以有这个臭毛病），面板是python3写的，安装起来很快，但是要安装一些服务的话，如果VPS性能不好，则需要花费相当长一段时间来编译安装，普遍30分钟起步。 9.2 手动搭建宝塔面板是将网站搭建可视化了，本质上和手动搭建没有区别。这里主要是介绍常见的相关软件和Let’s Encrypt配置SSL证书的方法。 9.2.1 Apache和NginxApache和Nginx都是Web服务器。前者是老牌Web服务器软件，对PHP有着优秀的支持，并且动态响应优秀，但是对性能和内存要求高。后者是俄罗斯出品，对静态网站支持良好，性能消耗也更小，反代和简单的网站都倾向于使用Nginx，甚至还有一系列基于Nginx衍生出来的版本，比如Tengine就是淘宝从Nginx衍生出来的，用以支撑淘宝的各种服务。除此之外，还有个Caddy也用的比较多，这是由golang语言写出来的，所以对多线程高并发的支持很好，并且自带SSL证书申请的功能。 入门用户首选Nginx，毕竟网站没有什么服务，对VPS的性能消耗也少点。当然，选择Apache也完全可以，入门用户其实很难用到需要对比选择Apache和Nginx的时候。Caddy的话，先不推荐入门用户了。 安装Apache使用以下命令 1apt install apache2 安装Nginx使用以下命令 1apt install nginx 这两个软件安装完后，都会开机自启和立刻运行，浏览器中输入http://ip就可以看到默认的网页，比如Nginx的是这样： 9.2.2 PHP安装了Nginx之后，可以实现静态网页，但是常见的网站平台，比如Wordpress和typecho都是PHP写的，所以还需要安装PHP才能运行。 1apt install php-fpm 安装完php还不算完事，还得让Nginx知道，也就是需要更改Nginx的配置文件。 进入目录/etc/nginx/sites-available/中，将默认的文件default重命名为网站的域名，比如mjj.hostloc.com，即mv default mjj.hostloc.com，打开mjj.hostloc.com，在下述的第二行末尾加入index.php 12# Add index.php to the list if you are using PHPindex index.html index.htm index.nginx-debian.html index.php; # 注意加入了index.php 并且将下述的_改成网站域名 12server_name _;# 改成 server_name mjj.hostloc.com; 随后，重新软链接，并重启Nginx 123rm /etc/nginx/sites-enabled/defaultln -s /etc/nginx/sites-available/mjj.hostloc.com /etc/nginx/sites-enabled/mjj.hostloc.comsystemctl restart nginx 注意域名不要填错了，重启完后，Nginx将能够和PHP一起支持动态网站。 9.2.3 MySQL和MariaDBMySQL是一个市场占有率极大的数据库软件，应用场景极其广泛，最开始是SUN公司开发的，2009年被甲骨文收购。甲骨文作恶多端，所以MySQL的一部分作者则独立出来，直接做了一个复刻版的，被命名为MariaDB，Maria是作者女儿的名字，Linux社区逐步放弃MySQL而采用MariaDB。所以在近期发布的各Linux版本中，默认是没有MySQL的，一律采用MariaDB。 12apt install mariadb-server # 安装数据库mysql_secure_installation # 首次配置 由于是首次使用，所以在如下提示中，直接enter键就可以了，因为数据库的root用户此时并没有密码 123456789NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!In order to log into MariaDB to secure it, we'll need the currentpassword for the root user. If you've just installed MariaDB, andyou haven't set the root password yet, the password will be blank,so you should just press enter here.Enter current password for root (enter for none): 随后，会询问是否要设置数据库的root密码，怎么说呢，反正就建个站而已（不涉及多用户多服务），有没有无所谓，我习惯性的不设置（输入N） 123456OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MariaDBroot user without the proper authorisation.Set root password? [Y/n] N 现在，新建一个用户和对应的数据库 12345678910111213141516mysql # 进入数据库，如果有root密码，则是mysql -u root -pCREATE DATABASE name; # 新建数据库，name是数据库名字Query OK, 1 row affected (0.00 sec) #此段为mySQL反馈提示，不需要输入。CREATE USER user@localhost; # 新建用户，user是用户名字Query OK, 0 rows affected (0.00 sec) #此段为mySQL反馈提示，不需要输入。SET PASSWORD FOR user@localhost= PASSWORD(&quot;密码&quot;); # 给用户设置一个密码Query OK, 0 rows affected (0.00 sec) #此段为mySQL反馈提示，不需要输入。GRANT ALL PRIVILEGES ON name.* TO user@localhost IDENTIFIED BY '密码'; # 把name这个数据库和user这个用户关联Query OK, 0 rows affected (0.00 sec) #此段为mySQL反馈提示，不需要输入。FLUSH PRIVILEGES; # 完成设置exit # 退出数据库 9.2.4 Let’s Encrypt，SSL/TLShttp连接，由于不是加密的，所以任何人都可以查看内容，这对于一些金融服务有着巨大的危害，比如使用信用卡在网上购物的时候，账号和密码会被获知。所以网景（Firefox浏览器的前身）提出了SSL（安全套接层/Secure Sockets Layer）这个概念（后来演变升级为TLS，即传输层安全性协议/Transport Layer Security），http变成了https，电脑会内置证书，而网站也会有一个证书，只有两者相互验证成功，才能正常浏览玩网页，并且全程加密（DNS部分并不是加密的，所以有个DoH，dns over https）。 SSL/TLS证书是个垄断行业，电脑内置的证书就那么几家，如果想网站被大多数浏览器/系统接受，那就只能去申请其中某家的证书，这里面层层签发转售，几近无本万利。不过好在还是有很多免费的SSL/TLS证书的，比如Let’s Encrypt提供三个月的免费证书，而亚洲诚信通过第三方公司，提供一年免费的证书。这里以Let’s Encrypt为例演示，相关链接为 https://certbot.eff.org/instructions ： Let’s Encrypt提供的SSL/TLS工具叫做cerbot，可以通过snap或者pip安装。snap是Ubuntu强推的一种软件部署和软件包管理系统，把所有需要的东西都放一起。pip是通过python3的pip安装，pip和snap没有功能上的区别，不想被Ubuntu强推就使用pip。 snap安装cerbot申请SSL/TLS证书 123456apt install snapdsnap install coresnap refresh coresnap install --classic certbotln -s /snap/bin/certbot /usr/bin/certbotcertbot --nginx 然后按照提示，输入邮箱和同意服务协议，并且在提示域名的时候，注意不要输错。 pip安装cerbot申请SSL/TLS证书 1234567apt install python3 python3-venv libaugeas0python3 -m venv /opt/certbot//opt/certbot/bin/pip install --upgrade pip/opt/certbot/bin/pip install certbot certbot-nginxln -s /opt/certbot/bin/certbot /usr/bin/certbotcertbot --nginxecho &quot;0 0,12 * * * root /opt/certbot/bin/python -c 'import random; import time; time.sleep(random.random() * 3600)' &amp;&amp; certbot renew -q&quot; | sudo tee -a /etc/crontab &gt; /dev/null 相比于snap自动每三个月更新证书，pip需要通过crontab加一个定时任务（上述最后一行），另外，也需要偶尔检查以下certbot有没有更新，即使用此命令/opt/certbot/bin/pip install --upgrade certbot certbot-nginx 10 Docker快速入门Docker的本意是“码头工人”，即搬运别人打包好的集装箱。之所以取这个名字，是因为Docker的功能与此类似：将系统和里面的应用一起打包好，别人“搬走”就能直接使用——可以将Docker粗略的理解成一个包含了系统和应用的虚拟机（严格来说，Docker是使用了沙箱机制的虚拟化容器）。常见的例子就是别人把某一个软件配置好了，用户直接下载下来，简单设置一下就可以使用了，不需要繁杂的配置过程，所以在批量服务中有着广泛的应用场景。Docker分为社区版/CE（Community Edition，免费的）和企业版/EE（Enterprise Edition，收费的），两者功能无本质区别，以下默认使用社区版。 10.1 安装Docker环境12apt update # 同步更新源apt install -y ca-certificates curl gnupg lsb-release # 安装必要依赖软件 添加GPG密钥，注意这里和上面一样，必须是root权限（如下命令）。这里简单介绍一下GPG，全称是GnuPG，真·全称是GNU Privacy Guard，一个密码学软件，用来验证通信中的安全性，防止传输过程中被篡改，前身是Pretty Good Privacy/PGP。 1curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg 选择使用稳定版，如果需要nightly或者test版，可以把下面的stable改成对应的版本。 1echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable&quot; | tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 更新并安装Docker 12apt updateapt install -y docker-ce docker-ce-cli containerd.io 期间会下载几百兆的文件，网络不好的话，可能会需要一段时间，当完成安装后，使用docker run hello-world命令来测试功能是否正常，理论上会输出下图内容： 至此，系统已经安装好了Docker环境，可以自己写一个Docker的应用，或者直接拉取别人写好的为自己所用。 10.2 安装别人打包好的的Docker先说一下常用的Docker命令，然后以安装Docker版本的Nextcloud为例。Nextcloud是一个开源的网盘系统，类似于私有版本的百度云，可以自己搭建从而确保数据都在自己手上而不会被8秒。 10.2.1 常用Docker命令docker ps 列出所有正在运行的容器，如果需要查看所有的容器（包括未运行或者启动失败的）则使用docker ps -la，这点类似于ls和ls -la的区别。 docker start/stop/restart CONTAINER ID 开启/停止/重启特定容器，后面要加上指定的ID，CONTAINER ID见下文。 docker rm CONTAINER ID 删除容器，如果是删除镜像，则需要把rm换成rmi 10.2.2 安装Docker版Nextcloud在 https://hub.docker.com/ 中直接搜索Nextcloud，找到官方版本的镜像，点击进去，在右侧有拉取镜像的命令，直接运行即可。 安装过程中会下载各个组件，等全部显示Pull conplete即表示下载完成，之后会自动校验并提示完成。 使用docker run -d -p 80:80 nextcloud 运行，此时使用docker ps可以查看到具体的详细信息 CONTAINER ID类似于身份证号码；IMAGE是身份证上的姓名；COMMAND是实际运行的程序；CREATED是创建的时间；STATUS是此时的运行状态；PORTS是端口，上述我们把容器的80端口定向到服务器的80，并且默认ipv4和ipv6都可以访问，接受所有IP的访问（0.0.0.0代表接受所有IP）；NAMES是容器的名字，可以理解为外号。 之后就是通过IP或者绑定的域名访问，进行最后的安装。这里就能看出来Docker的优势了：用户无需了解具体操作和搭建步骤，提供者负责维护，这可以极大的简化用户的使用步骤，还可以标准化环境，无论使用Debain还是REHL，镜像/容器都是提供者给定的。 如果不再需要Nextcloud，则首先停止容器，随后再删除： 12docker stop c30d348f1ef1docker rm c30d348f1ef1 10.3 建自己的DockerDocker通过Unix socket与它的引擎进行通信，出于安全考虑，一般只有root用户和在docker组的用户才能正常访问Unix socket。所以，如果想建一个完善的Docker应用，那么建议额外新增一个用户，并加入docker用户组。","link":"/2024/03/d18cec1537a7.html"},{"title":"","text":"译序：考试里有学习的奥秘？！前苹果系统工程师手把手教学 注：正文中的[数字]表示的是注释，可以善用 Ctrl+F 进行页面内搜索。本文有两万五千多字，可以在你做卡片时作为参考。 小时候，我时常做这样的白日梦，只要像打游戏那样敲对作弊代码，电脑就「哔哔」两声，自动给我打开神奇的世界，让我拥有和游戏主角一样超凡的力量，摆脱这单调乏味的生活。 以上幻想多半是游戏玩太多的缘故，但那神奇的感觉正与我后来使用「间隔重复系统」（Spaced Repetition Systems , 下称「SRS」或「SR系统」）的体验别无二致。如果使用得当，能产生魔法般的效果，让你掌控记忆的主动权，而不是听天由命。它可以提高学习效率、催化创意工作，或者带来更多令人兴奋的事情。当然，它也要像童年幻想那样，先要「按对作弊代码」，奇迹才会显现 —— 换句话说，设法写出好卡片，才能芝麻开门。（即实践时，你在卡片上整理的问答） 一个 SR 系统的优劣，完全取决你能给出的卡片。新手阶段，因为你不知道什么样的卡片是好的，所以可能写出很差的卡片也无从改进。在我的早期阶段，对 SR 系统的实验一如我童年乱按作弊码：把它当做阿拉丁神灯那样去拨弄、琢磨，希望能无意中唤醒它的魔力。 幸运的是，卡片撰写从来不是玄学，而是体系完整的知识可以帮你分辨卡片的有效性、理解制卡的方法论。这类内容网上数不甚数，而本指南的重点，是帮助你从制卡资料（演讲、文章等）的语境中，创造并总结一种理解 —— 我一向认为，卡片不仅要帮助消化吸收作者表达的知识，也要从中衍生为你生活和创新工作所用理解。 对于不熟悉「间隔重复」的读者，本文会帮你克服那些常见的、让你从入门到放弃的阻碍；对于有经验的读者，后续章节会涵盖不常见的一些编卡理念，以加深你的 SRS 实践。我们讨论的东西概括性较强，主要集中在制卡的纲领层面，因此无论你用什么 具体的 SR 系统，相信都有所受益。 「提取练习」—— SRS的核心卡片的具体应用有很多，但编写卡片时最好记住，不管表面如何，你正在给未来的自己编制任务，一个重复再重复的任务。因此请牢牢记住，「设计卡片」即「设计任务」。 如果某张卡片「见效」了，那不是碰巧，而是因为你对该任务的执行，用某种有用的方式「改变」了自己。根据这点，我们值得花一点时间去了解这些「改变」背后的机制。这样就能有针对性地编制任务，并设计你想产生的改变了。 SR 任务对你产生「改变」的最核心、最常见的机制，被称为「提取练习」（retrieval practice） 。简而言之：你的回忆即对记忆的提取，提取行为往往会强化记忆，并且这个效应会减缓遗忘。因此，有策略地规划每次提取之间的间隔，可以有效阻止遗忘。尽管它物理层面的机制尚不明确，但数百名认知科学家对此已做过大量的实验探索，涉及不同学科、不同知识类型（事实、概念、程序、运动）乃至不同测试方式（选择、简答、口答），都复现出同样的结论。 流畅记忆的价值并不仅仅在于记住一些事实。许多实验并非用鹦鹉学舌式的记忆问题来测试学生，而是要求他们进行推理，绘制概念图，或回答开放式的问题。在这些研究中，记忆力的提高能够转化为一般理解能力，及解决问题能力的提高。 ^fdc3d0 提取（Retrieval）是 SRS 有别于传统学习模式的关键。仅仅简单回顾材料（如多读几遍）既没有加强记忆，更不能增进问题解决能力，而「提取」往往可以。这种通过「提取以掌握」的现象也被称为「测试效应」，因为往往发生在做自我测试时，故此得名。它形似学校考试，目的上又有所相反：「提取练习」是为了从测试中进行学习，而非「评估」学习成果。 SRS 的设计目的便是实现测试效应。如果想用它强化某方面的理解，那你必须学会卡片化相关的全部细节，一个不漏地做提取。 受限于资料，可查的文献远不够作出最准确的指导，因此有必要走出故纸堆去理解卡片制作。我将提炼自己数千张的制卡经验，在本指南中提供建议，并尽可能利用实验证据提供支持。 本指南本身，是一个关于所谓助记媒介[5]（我和 Michael Nielsen 所命名）的例子。文中嵌入了一系列 SR 卡片[Jarrett 1]，来例证自己的建议。 所用用卡片系统是 Orbit ，原理与你[6]自用的 SR 软件差不多，但还有更深一层愿景：通过在阅读中嵌入一系列专家认证的卡片，使读者在内化文章意图时事半功倍 —— 如果你也用Orbit，本指南不仅会帮助你如何写出好的卡片，也对写要发布的稿件有益。当然，你也可以仅阅读而不回答这些内嵌的红色卡片，不过希望您能试试。（*译注：原网页中是交互的红色卡片，我将其截图搬运而来，手机端狂喜） 2022-03-19 update：目前将本文制作成带交互卡片的助记媒介，访问地址如下https://l-m-sherlock.github.io/thoughts-memo/post/how-to-write-good-prompts/ 此外，第一个「助记媒介」的实验是一篇量子计算的入门读物《量子国度》，但它比较硬核 —— 定义，符号，定律那些 …… 你懂的。相比之下，本指南更侧重于展示制卡中应有的意识（heuristic）、思维模型，并提供一些指导建议。 —— 本文是一项实验，你可以告诉我自己的体验。（译注：原文「heuristic」，指人处理事务时，不通过逻辑思考，而是下意识就知道怎么决策的认知，故此处翻译为「制卡意识」。在这满是 CSer 的世界，它还有个黑话叫「启发式」） 局限性注意！本指南的出发点，是在材料已经明确表达的内容的基础上，教你写出带个人理解的卡片。但 Orbit用户目前还不能对已经自带作者版卡片的材料添卡（比如本文）。未来会向这个方向前进。 有效的「提取练习」—— 卡片应有什么样的属性「写出优质卡片」与翻译文章惊人地相似：翻译时，你会不断问自己「选哪些词，会让读者阅读时有如体验原著」，并且在脑海中「点亮相同的”思维灯泡”？」 这种翻译不可能是一板一眼的，因为文章往往涉及典故/ 隐喻/ 幽默，为了让文化背景不同的读者也能身临其境，遣词造句必须考究。 SR 卡片的制作与文章翻译颇为相似。当知识的细节「完全载入」你的脑海中后，它们会点亮一个个的「思维灯泡」。而为了对这些细节触发「提取练习」，你会问自己：哪些任务（即卡片）一起执行时，需要答题的你点亮同样这么一组「思维灯泡」？ 这样的「有效卡片」会拥有怎样的主要属性，其实就隐含在提取练习本身的机制里。我们将在这里简要回顾，并在后文详尽示例以继续深入。 这些属性不是自然法则，而类似「语法」那种「规则」 —— 你可以学到手，也能（也应该！）像优秀的作家打破语法那样，在合适的时候有所突破，激发最应景的效果。（当然这要有丰富的制卡经验支撑，需要理解什么时候可以任性一把） 「有效卡片」应该拥有的属性： 卡片的焦点应明确（Focused）：细节太多的问答不会让你专注，回答时的「提取效应」无法完整地刺激记忆、点亮全部的「思维灯泡」。不够聚焦的问题，还让你更难判断回答是否全面、差异在哪里。因此，最佳做法一般是：一次问答只聚焦一个细节。 卡片应能精确引导答案 （Precision） ：模糊的问题只会引出模糊答案，不能可靠地点亮你要的「思维灯泡」。 卡面应能诱导出一致的回答（Consistent），让每次任务都点亮相同的「思维灯泡」：否则，你可能遭遇「提取引发遗忘」（retrieval-induced forgetting）[7]—— 这是一种干扰现象，即已记住的会更牢，没记住的更易遗忘。（后文将讨论一种新的卡片，每次重复时都要求一个新答案，但它产生改变的效应不是「提取练习」） 卡片问答应该可控（tractable）：为了避免复习时，因为干扰过强而混乱、烦恼，你应用心写出自己几乎不会错答的卡片（ almost always answer correctly）。这通常依赖任务分解，或者添加线索[8]。（译注：此处应指不容易答偏，SR 的核心效应是「提取」，「可控（tractable）」和费工夫不冲突） 卡片应让提取费工夫（effortful）：卡片练习的重点，是让你从记忆中提取答案， 而不应让你简单地从卡面「推测」答案（此外，「线索」很重要，我们稍后讨论）。实际上，提取练习的努力程度与效果正相关。这点正是强调复习和复习之间要有间隔的动机之一：如果回忆答案太容易，那提取练习效果不大[9]。 组织这样一张卡片，要点是让题目的考察范围充分狭窄，否则回答时或是「提取」不够聚焦、或是答案难以一致/ 精准、或是问题不好驾驭。但要写一个足够紧确的题目，难度超乎常人想象，你得把知识一点点掰开揉碎，才可重新组合成题目。对了，知识点一旦揉碎，复习会变得更精耕细作 —— SR 软件的复习规划器，可以差别处理难易不同的知识点，让你更多地回顾难点。 现在，请想象我们正在读一篇长文，是你没见过的主题。然后问自己能否清晰地解释给别人，并思考自己能回答哪些问题，才肯定自己「学会」了这篇文章？还是用翻译做比喻：如果「知识」是一门语言，那你需要将它从内容中「翻译」出来。为此你首先要会「读」，明白它是怎么被「书写」的 —— 识别得出「知识」的词性，句子结构、叙事节奏 —— 才能给出合适的翻译。其中有些细节是无关紧要，有些是核心中的核心。更进一步，好的「翻译者」不能只停留于纸面，还得留心其中的内涵，以及概念之间的联系。 因此，去编制有效的练习卡，我们需要两个技能：1，首先，如何精准地刻画你要强化的知识？ 2，其次，如何有效提问? 菜谱「鸡肉高汤」——目前我们的讨论太过抽象，不如从稍后一个菜谱《鸡肉高汤》继续。 某种意义上，你可能觉得菜谱是微不足道的编卡对象，但它其实也是个简短、自成体系的领域。我有数百个卡片记录菜谱和厨房心得，在此将简述我的经历 。（留意卡片能用到哪些不寻常的领域，本身就是一项编卡必备技能） 这些卡片是我三年前开始编写的。而在此之前，我已经相当认真地做了十年饭。尽管对很多技术要点、配比、搭配了然于心，然而一旦做起复杂的菜品，我依然得停停歇歇地查菜谱，这让我步履维艰。要说那种体验，非常像我学编程的头几年 —— 几乎感觉不到什么「心流」。我最终是在全职工作了几年后才内化了编程的必备知识的。因此，我如今确信下厨也是这个路子，只不过我不是专业的，所以这个过程可能还需几十年的时间。 SRS 则从本质上改变了我的厨房生活。卡片催生了我选菜的能力：菜市场上一旦看中某个原料，我都能毫不费力地用它搭配出复杂的菜品。这能力极让我满意，我知道要买哪些东西去配菜 —— 如果看中那个洋姜，那我就再买点刚才路过的芥菜，它们是很好的搭档。于是，在回家之前，我就知道这一餐该怎么做了。 我对烹饪感到得心应手，在厨房杂事中来去自如。就事论事，尽管本文的长篇大论让你觉得我有点那啥，但这些卡片的用时并没想象中大。我会把一些有意思的事情稍微花几分钟做成卡片，一两周一次就已经足够影响深远了。 （译者提醒：下面的菜谱建议另开一个网页对照阅读，不然回读挺麻烦的。PS：本文献的原网页，菜谱是全程悬浮在右侧的） 《鸡肉高汤》介绍一家像样的餐馆里，即使最常见的菜肴，也往往比家里做的好吃。蔬菜浓郁，谷物更香，酱汁甘美。其秘诀之一是「高汤」，一种味道鲜美的汤式「积木」，平日在家直接加水的步骤，餐馆经常换用高汤，比如炒蔬菜、化果酱、炖全麦等。 高汤也是许多酱汁、汤和炖菜的基础。用滋味比较丰厚的原料，可以炖出不同种类的高汤：鸡肉高汤、蔬菜高汤、蘑菇高汤、猪肉高汤…等等。但不同于典型的「肉」汤，高汤用肉，不是为了突出肉味，而是给菜肴打下多样化的味道基础。 其中鸡肉高汤是最常用的高汤之一。加进素菜里不是为了让它们吃起来像鸡肉，而是让味道更完满、可口。这种高汤富含来自鸡骨的吉利丁（*译注：明胶），因此尝起来口感更浓郁。制作鸡肉高汤只需几分钟，材料一般可以直接在家里中获得，因为它用的主料是鸡骨。所以常吃鸡的话，你可以在煮鸡肉时顺手把骨头留下，冰冻起来。 《鸡肉高汤》- 菜谱 2 磅（~ 1 千克）鸡骨 2 夸脱（~ 2 升）水 1 个洋葱，切块 2 个胡萝卜，切块 2 根芹菜，切块 4 瓣大蒜，捣碎 半束新鲜的香菜 把所有原料一起放进大锅里。 小火炖到沸腾（约1小时）。用小火的话，味道就能明亮、干净；如果温度较高，汤的色、味就比较暗淡。 降低火候，小火慢炖一个半小时。 过滤，等其冷却后转移到容器里储藏。 鸡肉高汤放在冷藏层可以存一周，放在冷冻层可以无限期保存。使用前，需要撇去高汤上的一层脂肪，这些脂肪可以在其他要提味的地方，用来代替植物油或者黄油。 用量上，则可以根据你鸡骨的数量等比例缩放。骨头和水的比例是 1:1（磅/夸脱），蔬菜的种类和比例可以随性调整。 《鸡肉高汤》- 菜谱变体如想尝尝偏法式的鸡肉高汤，可以用韭菜代替芹菜，再加入月桂叶、黑胡椒和百里香。如果想要更浓的鸡肉高汤，可以预先烤一下鸡骨和蔬菜，这样便是做成所谓的「棕色鸡肉高汤」。（之前的菜谱相对是「白色鸡肉高汤」，味道不强烈，但更细腻、万能） 《鸡肉高汤》—— 如何使用鸡肉高汤下面是一些鸡肉高汤的使用建议： 煮「大麦」、「法罗」、「蒸粗麦粉」和其他谷物。 与烤蔬菜泥一起做汤。 将「甘蓝」、「甜菜」或「散叶甘蓝」等蔬菜放入油中，然后加入少许高汤，闷透。 （在平底锅烤肉或煎肉之后），将高汤倒在滚烫的平底锅底上，做成速成酱汁用于餐中。 为了组织我们的阅读成果，我们可以问：具体要知道哪些东西，才意味着你「学会」这些材料？我认为，「学会」这段材料的人应该： 知道如何「制作」和「储存」鸡肉高汤； 知道什么是鸡肉高汤，并（至少是浅显地）理解它为什么、什么时候很重要； 知道鸡肉高汤的具体作用和意义； 知道使用鸡肉高汤的一些方法，包括一些具体的例子； 知道一些常见变体以及何时可以使用它们； 这些内容中，有些知识是「事实性」的，有些是「过程性」的，还有些是「概念性」的。与之对应的制卡策略，将在后文一一陈述。 但「理解」是很个人的事。真要既「知」且「道」某件事情，往往必须超越内容本身，将其与你生活之方式、探索之想法，以及其他心目中有意义的活动联系起来。如何编写这种卡片，我们也会同样探索。 本指南会假设读者对家庭烹饪有兴趣，且从未做过高汤，因此不具备例子中所需要的各项技能。请试着思考在这种人设下[10]，「我」该如何去内化材料的内核。 我们会穷尽式地处理这份阅读材料，以最详尽地展示这些通用的制卡原则。请注意，实践中你通常不会也不必这么系统地学习。你一般只会关注文章中你认为最有价值的部分，然后在非常有必要的时候跳回原始材料，寻找与你理解最相关的信息并做成卡片 —— 这值得一赞！完美主义会过度消耗你的动力，穷尽式处理只是表面正确，实际上是浪费你的注意力，它们本应该放到更有价值的地方。这类问题会在后面更深入地讨论。 如何制作和储存鸡肉高汤：「事实性」和「程序性」知识《鸡肉高汤》开头段落，更偏向概念性知识，因此我们直接从「菜谱」段开始，它具体描述了如何制作和存储鸡肉高汤。「菜谱」作为一类清单，包含的知识结构比「散文」形式更为明确，这给我们写卡初の体验提供了一些辅助。 我们先谈一谈「知道制作鸡肉高汤的必要原料」，此类知识主是「事实类」，「概念类」或「概念之间的关联」的成分比较少，其中主要包含了是无需加工的原始信息，给你打下学习下一层知识的基础。 「简单事实」类知识（Simple fact）我们假如直接这么写卡：「制作鸡肉高汤需要什么？」，那么在回答的时候因为数量或者原料名称未作要求，所以很难作答。这样的卡片不够准确，也不够聚焦 ：同时要求提取的细节太多，所以想要加强的记忆不会全部被强力激活；并且因为它要的答案太多，因此的一致性、可控性也不好：每次回答，你会记起一些，又忘掉另一些。因此激活不够一致，容易导致记忆受到侵蚀。 所以，得把答案中的原料表分解为实际会学到的要素。如果你从未听说过高汤的话，你可以像下面第一问一样，先简单地澄清取用部位： 问：取鸡身上哪个「类型」的部位做高汤原料？答：骨头。（Bones） 这个问题仅聚焦一处文章细节，想要的答案也毫不含糊（「哪个 “部位” 」），而「骨头」在每次回答中也都是一致的。这样的卡回答容易控制，但要对记忆做的「提取」仍不失努力。 在谈及事实时，我们自然会想添加一些解释。我个人会在细节不容易想到，或者事实背后的解释比较有意思的时候，添加一张「解释卡」，相必你也有同样的冲动。因为即使身为大厨，不在乎上面那张卡，但依然可能受益于这张： 问：为什么我们做鸡肉高汤要用骨头？答：它们富含明胶（吉利丁，gelatin），可以产生浓郁的口感。 解释卡能强化「事实性」提问中的知识，而「解释」本身也让事实富有意义—— 这点也许更重要。此类卡片像钩子一样，将烹饪生涯中的想法与学到的「事实」相互关联起来。比如你学完这张卡的第二天，如果正好吃到「果冻鸡爪」，就可能考虑拿鸡爪作高汤材料（因为这是鸡身上明胶最丰富的部分），因为今天这张卡让你知道明胶能提升口感。（*译者的经历：今天吃饭的时候我盯着甲鱼浮想联翩，因为它的裙边和 jio 富含明胶） 还想说一点，知识点并非集中于文章中一块儿。像上面这两张卡，它们的答案汇集自文章各处！写卡如拼图，你需要去文中各处翻找知识碎片。 这张「为什么」是一个不错的初の尝试，但仍可以更精确。因为像「骨头很便宜」也属于一种回答（尽管在设计之外）。如果你希望对信息的提取得毫无歧义，那下面这张会更好。 问：骨头如何产生鸡肉高汤的浓郁口感？答：它们富含吉利丁。 （你是否留意到红色的复习卡中仍有一张不符合「一致性」的原则？它并非为了提取练习，而是一个小实验，稍后讨论） 「清单」类知识回到原料表中的内容，「鸡肉高汤」从定义上显然就该包含水和鸡肉（稍后会处理分析），但剩下的香料都是变量，取决于应用场合。 因此，我们不如先从功能组别上去理解原料，会更好地帮我们内化菜谱结构： 问：鸡肉高汤是用鸡肉、水和其他什么类别的原料制成的？答：香料。 分组后，我们可以提子问题： 问：鸡肉高汤中使用的典型香料是什么？答：洋葱、胡萝卜、芹菜、大蒜和香菜 但是，除非你有一定经验，否则这个卡片对你来说可能并不可控，或是每次记的原料不一致。这样的无序列表要转化为好卡片，颇具难度。 对此，一个好策略是创建一组问题，并对选项分别挖空，并要求你逐一填空（下面用？？？指挖的孔）： 问：典型的鸡肉高汤香料：- ？？？ 胡萝卜 芹菜 大蒜 香菜 答：洋葱 问：典型的鸡肉高汤香料： 洋葱- ？？？ 芹菜 大蒜 香菜 答：胡萝卜 …以此类推。这里注意到选项列表顺序没有变动，这样你在重复回忆时，最终一定程度上会形成视觉形状上的记忆。 大多数 SR 软件都有快速生成这样一组套卡的功能，卡片之间互为变体。即所谓「完形填空/ 填空题/ 挖空题」（cloze deletions），一次复习，只推送一个版本的问题要你填空。这很重要，因为只答一种版本，容易遗忘其余的选项。 当然，如果能在需要时回想起全部选项是最好的。尽管单选填空已足够应付大多数的做卡材料，但对于复杂的内容，你可能得在彻底记住单选结果之后，还要添加一些综合性的卡片（不同类别的「综合性」定义不同）。例如对于「清单」，可能要求你随着复习逐渐多选——我不知道是否有这样的 SR 软件，但似乎值得一试。 另一个帮自己理解「清单」的方法是为每个成分写一些解释卡——为什么胡萝卜是鸡肉高汤的好佐料？（注：胡萝卜提供植物糖，同盐一样能提亮其他味道）如果你知道原料的对应解释，也许不需要「填空」也能记住全部了。如前面所提，解释让「事实」更好被理解。本案的菜谱中，没有说为什么要这些香料，所以你需要自己去寻求解释。（译注：血泪提醒：「别做完美主义」） 「线索」和「精细编码」如果你对这些问题感到挣扎，那么可以添加一个「线索（cue）」： 问：典型的鸡肉高汤香料： 洋葱 胡萝卜 芹菜 大蒜- ？？？（一种味重的香料） 答：香菜 但要确保你的线索不会让卡片失去灵魂，努力地记忆中提取答案，是重中之重。 这样子就很拉胯： 问：典型的鸡肉高汤香料： 洋葱- ？？？（英文与「parrots」押韵） 芹菜 大蒜 香菜 答：胡萝卜 这种卡片实质上是要你猜一个谐音梗，而无需对所问的知识做「硬提取」—— parrots 只和 carrot 押韵，所以不看问题也能作答，压根就不存在对菜谱的知识做提取。总之，不能影响卡片的「提取」是写「线索」的基本要求。相比之下，上一版的线索「味重的香料」仍考验你的硬回忆。毕竟「香料」有很多种，范围虽然有所缩小，却仍要你记住菜谱指定的那个。 问：典型的鸡肉高汤香料： 洋葱- ？？？ 芹菜 大蒜 香菜 答：胡萝卜（英文 carrots 与「鹦鹉 parrots」押韵：想象一群鹦鹉叼着胡萝卜飞行，把它们丢进一锅汤里） 这类线索涉及另外一种记忆现象，也是认知科学家的实验对象 ——「精细编码 （elaborative encoding）」[11]：将信息与其他记忆相关联，它会变得更好回忆 。当然，原料清单这种，不容易搭配出有意义联想，但这种情况下，你仍可自己编造一个助记词来利用「精细编码」。生动的联想效果会更好，因此尽量从多个方面寻找联系。比如从视觉、有意义的个人经历、情绪（幽默、厌恶等）等方面。（译注：1.「elaborative」一词包含了「协作」的意思，所以不需要懵逼地去想「哪儿精细了」；2. 友情提示：助记词写在卡背，线索写在卡面） 这里有个通用的技巧：万物皆可制卡，助记词也是如此。如果你要记的信息比较随意或零散，直接把助记词括起来放在答案栏里就行。要还是很难回答，就专门把助记词提成一张卡： 问：鸡肉高汤中「胡萝卜」的助记词？答：英文 carrots 与「鹦鹉 parrots」押韵：想象一群鹦鹉叼着胡萝卜飞行，把它们丢进一锅汤里 此外，图像也能触发「精细编码」，也很适合挖掉做「填空题」，你可能会发现这张卡片比文字更有记忆点： 问：鸡肉高汤的香料： 答：胡萝卜 当然了，做「线索」和「精细编码」会增加制卡负担。因此没必要见一张做一张，不然容易精疲力尽。但如果你估摸着某张卡可能比较难记，它仍然是个有用的技术。 「再解释」以及经验法则「超量制卡」现在，高汤用什么原料已经解决了，数量上如何做卡？ 唔，你可以尝试这样问：「一份鸡肉高汤里有多少鸡骨？」，其中「一份」是什么，仍然不够精确。对此我们可以将问题和指定清单绑定起来，如「Andy版的鸡肉高汤配方里有多少鸡骨？」。不过这仍然不是我们实际想知道的 —— 鸡肉高汤的菜谱明确指出，量要随机应变。写好卡片往往涉及对原文的解读（「再解释」） ，这是让理解超脱文章本身局限的第一步。就像下面这样。 问：鸡肉高汤中鸡骨和水的比例是多少？答：每磅骨头一夸脱水 问：一磅鸡骨在鸡肉高汤中应使用多少洋葱？答：半颗洋葱 问：一磅鸡骨的鸡肉高汤中要用多少胡萝卜/ 芹菜？答：1 根胡萝卜/芹菜 问：一磅鸡骨的鸡肉高汤中要用多少大蒜？答：2 个捣碎的大蒜 其中没提香菜，这是另一例「再解释」：原文的「一束」无论如何也不是一个确切的单位，所以我才不管到底多少，反正我只抓一把。 注意到，为了保证聚焦而精确，这里将原料表分解成很多个问答。新手常常有节约用卡的强迫症，多写一张就跟多掏钱一样，倾向于把卡片的「数量」写得少少的、把「范围」写得泛泛的 —— 但这适得其反，因为你要掌握的「知识量」不会随着你的卡片数量而减少（除非特意排除某些内容），把卡片数量减少、内容变糙，并没有让必学的知识减量，反而让材料更难做重复练习，容易「齁」。（译注：薄的高数书只会更难。吾愿称之为 知 识 守 恒 律 ） 卡片的复习用时比你想象中要少 —— 第一年里，一张低难度的卡片每次会花费10-30 秒，然后逐年剧减。如果你暂时没法把握时间开销，那么试着接受这个经验法则：永远比舒适量多写几张 （write more prompts than feels natural.）（译注：我愿称之为 过 饱 和 写 卡，张数再多些、复习难度再低些 —— 有的（其实是全部）译注就是废话，当助记词吧） 卡片不贵，但也绝非免费 —— 会有情绪上的开销：数量爆炸的低难度卡片容易让你崩溃，因为没人愿意花时间复习一堆闭眼都会的材料。 因此，如果材料讨论的东西已经相当熟悉，卡片应该写少一点 —— 并非说熟悉的领域可以写得含糊，而是因为边际效应，你要捕获的知识量本身就少。 例如，我自己的卡组中，没有包括本例的原材料预处理，这对我没必要—— 蔬菜要小切、大蒜要捣碎，对于一个厨师，如果不粗心的话一般是自然而然的处理。不过你觉得有用的话就还是写一下吧。 还有一点与此相关，一张卡片「聚焦」在何种尺度上，取决于你已了然于心的概念规模。本例中的香料对我来说太熟了，我将其作为一个原子单位去记 （“意式香料”） 而不是拆开。 复杂的概念会随着融会贯通（「流畅性」的建立），逐渐组块化为新的基本单元，这样一来，你在对复杂概念写卡时，既不会丢失细节，又足够聚焦。实际上，一个专家的重要特征，可能就是基于越来越复杂的「组块」思考[12]。从这个角度看，各种助记系统扮演了一个「组块催化剂」的角色，它促进了你对某个方面组块的「有效大小」的增长（译注：Andy 不方便说得太绝对，但不妨碍我加料：因此，硬记忆通过组块化提升理解能力） 「程序性」知识现在我们已经写好了关于原料的卡片，接下来烹饪的步骤更多是「程序性」知识，也就是用来执行特定任务的知识，对于「程序」，我们更多地是要知道“HOW”而不是“WHAT”. 制卡方式一程序如果列好步骤，依然是某种意义上的「清单」，所以我们可以用「挖空」去做，例如第一个步骤： 问:1. ？？？ 用小火炖到沸腾（约1h）。我们要用小火让其产生明亮、干净的味道，如果用温度较高的火，汤的味道和颜色都比较黯淡。 降低火候，保持一个半小时的沸腾。 过滤，等其冷却后转移到储存容器中。 答：在一个大锅中混合所有的食材。 （其余四个步骤以此类推）。 不过这张卡片完全谈不上聚焦。它糅杂了太多次要细节，掩蔽了你真正想提取的知识。个人而言，我会被这种卡片分散注意力，让回答含混不清、心不在焉。 我们可以简单删减文字来改进，细枝末节则移到新的卡片上去（如有必要）。下面这样就比上面好： 问：1. ？？？ 小火慢沸 保持90分钟咕嘟咕嘟* 滤出，冷却后储存。 答：混合所有食材 *译者注： 原文「bare simmer」描述一种极轻微的沸腾程度。 制卡方式二如果从整个流程的角度，我们重新编辑这个程序，可以更好地观察过程中的知识。首先我们有如下观察：几个关键词/词组承载了核心细节：小火慢沸，微沸 90 分钟，而其他的词句只是程序的框架。由此得到第二个观察：第一和第四步不值得写卡 —— 因为有初步了解之后，你当然知道自己是用「锅」熬食材，当然知道炖完以后要「过滤保存」，这是常识。 以这种方式强调关键词后，写卡就像是在玩《危险边缘》，「现在你有xxx秒内回答如下问题」: 问：你应该以什么速度加热一锅鸡肉高汤的原料？答：慢慢地。 问：在制作鸡肉高汤时，你应该在什么时候降低火候？答：在锅里沸腾后。 问：在制作鸡肉高汤时，在锅内达到沸腾后，你应该做什么？答：将温度降至轻微沸腾。 问：鸡肉高汤必须炖多长时间？答：90 分钟。 这里是用「列关键词」的方式制的卡，在「列清单」的方式上进行了修订。反映了我对这个程序个性化的理解。 一个程序往往可以被分解为几个关键词：重要动词是什么；何时转移到下一个动作；哪些是关键形容词、副词，以及关键的主语、宾语。我们的高汤配方中，动词不是关键：「降温」、「过滤」——你煮东西的动作都很显而易见。但在动作之间跳转的条件和启发式很重要：水「降温」之前，不仅要沸腾，还要轻沸 90 分钟。同时对于「缓慢地加热」而言，副词「缓慢地」要比「加热」更重要。 鸡肉高汤中的程序相当线性，而更复杂的程序可能会有分支，包括特殊情况下的备选项。这样的谓词结构（Predicate structure） 往往值得写卡。如果分支实在太多，你可以考虑画一个流程图。（译注：「谓词 （Predicate）」—— 简单地讲， if (A&gt;B) {…}，中的 A&gt;B就是一个谓词，它决定了你走入下面哪一步。这里特别提出来是因为我想秀） 那么，「列关键词」的方式是不是比「列清单」更好呢？这取决于你的需求，如果文中离散的信息对你比较重要性、不够直观，那选择前者。它侧重于强调组成知识的 “零件”，可以精确表达知识（而且，回答聚焦的问题总是比较愉悦）。如果你只是想要概括性的大纲，那么列个清单可能更简单。 上文卡组中，一些有用的细节没被包含。现在我们单独添进卡里： 问：加热一批鸡肉高汤（含 2 磅骨头）需要多长时间？答：大约一个小时 这类「当心！」型信息看似不起眼，却往往藏着程序中的有用信息。比如你知道要加热多久，便在实操时有了对照：锅热了这么久还没有反应，是不是可以停了？汤这么快就开，是不是得赶紧停下？（译注：菜谱无法教你如何对所有可能性做处理，但条件约束上可以推断出好多东西。） 解释卡 对「程序」学习有特殊价值：它避免你死记硬背，并帮你深入建立理解 —— 问：为什么 Andy 的菜谱声称我们应该用小火准备鸡肉高汤？答：「更明亮、更干净」的味道。 请注意，这次的例子中我们只深入了一层「为什么」—— 为什么要小火？菜谱只说能让味道更干净，至于为什么能更干净则没提到。于此同时，你也自然想知道什么味道算是更「亮」或「干净」，于是卡片写完，理解上的缺漏也一起暴露，这简直不能更棒。这里要注明的是，这些答案虽然不够刨根问底，但我们暂时选择继续前进。你无需为此特别标注，只要在制作卡片时写成例子中这样，明确体现出此答案是依赖于某种外部要求而暂定的即可。 每当处理主观、暂时、或不全面的信息时，最好都体现出它的这种性质。因为大部分卡片给出的内容，或多或少都有暂时性（比如换个菜谱可能用不同方式处理相同步骤），因此理论上我们可以把一切卡片都表述得不那么绝对，然而这弊大于利，因为太容易让人分心。平衡这个矛盾的一个办法是，我们简单记录信息来源（SRS 系统一般都有元数据项可以链接到原始菜谱），这在一般情况下已经足够了。 练习：如何储存鸡肉高汤？我们已经写了关于如何制作鸡肉高汤的卡片，现在轮到你了。请利用我们到目前为止所学的知识，在笔记上写出带上你自己理解的卡片： 「这将产生大约 1.5 夸脱鸡肉高汤，可以冷藏一周，也可以在冷冻里无限期保存。使用前，需要脱去高汤上的一层脂肪，这些脂肪可以在别的要增味的地方代替植物油或者黄油。」 ​ 给 你 一 炷 香 的 时 间 以下是我的卡片： 问：2 磅鸡骨大约能产出多少汤？答：1.5 夸脱 问：？？？磅鸡骨大约可以得到 1.5 夸脱的汤汁？答：2 磅 问：鸡肉高汤在冷藏区里能保存多长时间？答：一个星期 问：鸡肉高汤在冷冻区里能保存多长时间？答：无限期 问：冷却后，在使用新的一批鸡肉高汤之前，我应该做什么？答：刮除表层的脂肪 问：我应该如何处理从鸡肉高汤中刮除的脂肪？答：保留并作为咸味烹饪油脂使用。 看完后思考以下问题：这些卡片与你的卡片相比如何？这些卡片是否包括了你没有涉及的细节？你是否涵盖了这些卡片遗漏的任何细节？这些差异对你有什么影响？你的卡片覆盖的知识/问题范围与这些相比如何？ 何为高汤？为何重要：「概念性」知识一个能自己转动而不能带动任何东西转动的轮子，就不是机器的一部分 —— Ludwig Wittgenstein，《哲学研究》。 现在我们回头看菜谱最开始的段落，它介绍了鸡肉高汤的。「定义」看起来像是最简单的卡片内容了：学校里那种类型的 “闪卡” 就最爱这么干（白眼）。 例如，这样考察定义怎么样？： 问：什么是高汤？答：鲜美的的液体烹饪积木（liquid building block）。 问：描述鲜美的液体烹饪积木的烹饪术语？答：高汤。 先不提卡片的「聚焦性」、「精确性」、「一致性」。我们完全可以逐字逐句记住第一个问题中的答案，名称放在正面也可以帮你记住术语，但只能复述答案完全不等于明白高汤是何物。 「高汤」是一种概念。知道一个「概念」所指何物，与高中闪卡式的知识（例如「意大利语 “correre” 等于 “跑步” 」）不同。想要内化它，你需要了解组成概念的元素以及元素之间形成的结构。因此对于这类知识，你的目标是设计一套卡片，联合起来，一起框定「高汤」这个概念。（译注：学CS 的同学可以用「数据结构」去理解这段话） 现在我将介绍一些视角，用来帮助理解「概念」。它们可以看作一组工具套件，从知识中帮你提取需要的部分。它们附带的示例比较适合新手厨师，老道的厨师通常知道高汤是什么概念（尽管不一定会做）。 视角一：特性和倾向*：什么让高汤之所以为「高汤」？对于高汤来说，哪些断言或描述「永远」/「有时」/ 「永不」为真？（*译注：原文「 Attributes」，显然又是个 CS 黑话） 问：高汤通常是如何制作的？答：在水中炖煮具有丰厚滋味的原料。 问：为什么高汤通常没有突出的味道？答：为了使它们更广泛地兼容多种菜肴。 视角二：辨析异同：要知道什么是高汤，就要知道它与其他近似概念的关系和区别。 问：高汤与广义上的「汤」有什么不同？答：普通的汤本身味道更完整；而高汤往往作为辅料。 视角三：部分和整体：有哪些高汤的具体例子？高汤是否有重要的「次级概念」？「高汤」是否是某类更广概念的次级概念？请想象一个概念和概念之间的韦恩图，虽然没有非常明确的边界。 问：至少说出三个高汤的例子。答：如鸡肉高汤、蔬菜高汤、蘑菇高汤、猪肉高汤。 问：高汤很少直接食用，它最好被认为是一种? （用乐高比喻）答：积木。 视角四：因果关系：高汤是「做什么」的？什么让它「实现那个效果」？它没有「做到什么」？「什么时候」用它？ 问：为什么餐馆使用高汤而不是水作为烹饪介质？（请说出两个原因）答：增加味道，改善口感。 问：高汤是_的常见基础（至少说出两个）答：e.g. 酱汁、汤、炖菜。 问：餐馆经常使用高汤作为烹饪媒介，而家庭厨师可能使用？？？。答：水 视角五：意义和影响：「为什么」高汤很重要？它表示了什么？注意：请让这个概念对你有个人意义。 问：哪种液体积木可以解释为什么简单的餐厅菜肴往往比家里的菜肴更美味？答：高汤。 问：如果我注意到我在做料理时使用了水，我应该问自己什么？答：「我应该用高汤代替吗？」 最后这张卡并非取自原文，只是示范一种个人理解。同时也要注意，它更多试图对「行为」做改变，而不是「智识」方面。在鸡肉高汤的应用章节中，我们将详述如何使用卡片来改变行为。 练习：何为鸡肉高汤，为何有意义？下面一段介绍了鸡肉高汤在烹饪中扮演的角色，为了练习对「概念」性知识的建模，请尝试对自己的理解编制卡片： 「鸡肉高汤是最普遍、最有用的高汤之一，并非为了让一切菜肴染上鸡肉味，而像是为菜肴加入“和弦”，协调其主味。例如在做素菜时加入它，会让菜肴的味道更加完满。而其中来自鸡骨的明胶成分，也让口感也更丰厚。至于成本，这种高汤既不占用时间，也无额外开销。它的原料来自鸡骨，如果你经常用鸡肉做饭，可以在冰箱里顺手存上很多」 [ 给你一炷香的时间X2 ] 我可能写出如下的卡片： 问：鸡肉高汤不会使素菜吃起来像鸡肉，而是使它们吃起来更??? （根据安迪的菜谱）答：味道完满 问：鸡肉高汤使素菜的味道「更完满」，因为它加入了？？？，从而像为主味加入？？？（音乐比喻）。答：支持性（supporting）的声音；和弦 问：除了改善味道，鸡肉高汤给菜肴增加了丰厚的？？？。答：口感 问：撇开味道和饮食偏好，为什么用鸡肉高汤而不是蔬菜或蘑菇高汤？答：鸡肉高汤中含有明胶，创造丰厚口感 问：为什么鸡肉高汤很经济？答：它的主料（骨头）可以免费积累，如果用鸡肉做饭的话。 问：我应该如何处理烤鸡的边角料？答：冻起来，做鸡肉高汤 我发现还有一张我自己很想写的卡片，但光靠原文没办法写出来： 问：什么时候使用「鸡肉高汤」而非其他肉类做的高汤？答：？？？ 卡片写作有助于揭露我们理解上的缺失。追随你敏感的大脑去查谷歌、去查文献，不要拘泥于原文。即使你不打算立刻「补缺」，光是写下这些卡，也能让自己敏于「查漏」、保持好奇。这有益于在未来的探索。 请考虑下面问题：这些卡片与你自己卡片相比如何？我是否包括了你没有涉及的任何细节？你是否涵盖了我遗漏的任何细节？这些差异对你有什么影响？你的卡片范围与这些相比如何？ 你会注意到，我并不一定会用上之前介绍的所有「视角」。例如「部分/整体」和「核心特征」视角——我不觉得鸡肉高汤有什么部分和整体结构，也不觉得鸡肉高汤的核心特征（用鸡制作）不傻。 使用鸡肉高汤：「开放式清单」和「启明卡」高汤光看不用没有意义，所以菜谱里还给了建议用法列出了清单，此类型的知识又该如何建立理解呢？ 「开放式清单」「清单」类知识的处理技术我们已经学习，试试此处是否也适用？： 问：可以用鸡肉高汤做什么： ？？？ 将丰盛的绿蔬打蔫并蒸熟 做西式浓汤 在平底锅上「刺啦」一下 答：用它烹饪谷物 这卡片显然毫无帮助，因为第一个空里看起来填什么都合理。你也许已经发现，这个列表的「任意性」要大于之前部分的原料清单，问题没有固定的答案。此类便是「开放式 清单（Open list）」类的知识，相对应地，原料表则是封闭式清单（closed list)，它的成员固定。开放式清单无需记住所有内容，不过可以按需记一些 —— 但如果你会一直下厨，不要这么做，不然会越记越多，然后把一辈子都搭在这个清单上。 我个人把封闭式清单看做一种复合后的「事实类」知识，它们几乎是个静态的等式： 地球的半径 = 6,371 km 鸡肉高汤的原料 = 洋葱、胡萝卜、芹菜、大蒜、香菜。 而开放性清单我喜欢看做标签 （tags），就像你可能在数字书签系统中用的那种。本案例中可以这么认为：我头脑档案柜中有一种 tag 叫做「鸡肉高汤的用法」，我把它贴在关于浓汤制作的笔记上[13] 。（译者注：「 purée soups」 是用蔬菜泥，土豆泥，水果泥，起司等做的糊糊，典型用法是蘸烤法棍片当餐点主食。此处指给所有糊糊的做法都贴上这个 tag） 我发现有三类卡片可以帮助「开放式清单」的编码：首先是我打好 tag 的普通提取卡，它将卡片实例和 tag 关联起来；之后若注意到 tag 中蕴藏的模式（pattern），我可能将 tag 提成单独一张卡；最后我还常写一个举例卡，要我围绕 tag 举例，以此将 tag 和其实例松散地产生联系。（译者注：实例)是一个抽象物的实体，比如世界上有个名叫「特斯拉」的猫，那么它就是「猫」的一个实例。模式（pattern）指实例中存在的相似结构，比如做浓汤时总是要加水） 例如，下面这张卡将一个实例关联到 tag 上： 问：做蔬菜浓汤时，怎样才能既不增加油脂，又产生更丰富的味道？答：用鸡肉高汤而不是水稀释蔬菜泥。 写了几张之后，假设察觉到 tag 的共同模式（都是用水做汤），因此将这个模式提为卡片： 问：如果我注意到我在用水做咸口的菜，我应该问自己什么？答：「我应该用高汤代替吗？」 我希望必要时能回想起具体实例，因此我们另起一张卡片，将 tag 松散地链接到实例： 问：说出两种使用鸡肉高汤的用法。答：如：烹调谷物、蒸煮蔬菜、做清汤、「刺啦」撒在烤盘上 最后这类卡不怎么费脑子，因此易被滥用。这类卡极度依赖其他卡片。否则，你可能会忘记其他项，而总用固定的一两个案例作答。即使每次答案确实 轮换了不同的实例，但卡片也不再满足我们说的「一致性」，并且干扰效应可能让记忆变得不可靠。 如果你刚刚习得的概念高度开放，可用范围极广阔，那么你可以将「案例生成卡」转变为如下的「创意卡」： 问：请说出你可能尝试用鸡肉高汤制作的蔬菜浓汤（不允许和以前的答案重复）答：e.g. 土豆、防风草、芹菜、苏子、莎草、南瓜、胡萝卜、胡椒、扁豆…… 「不允许和以前的答案重复」这是个很有意思的小把戏，尽管过一两年可能还是会重复（这可以接受）。我要说的重点在于，一开始就概括了应用场景的问题很难写。换句话说，你得写卡前就知道高汤怎么用，这是要一定烹饪经验的。 「创意卡」更类似教科书上的习题，它引导你创造性使用知识点。与「提取卡」相反，它极力避免 从记忆中提取固定答案，而是要求你创造性地思考片刻。由于你想到的答案次次不同，就不会强化某个固定答案的记忆，而是强化在生成 各种结果时，你大脑里一致依赖的知识。同时，你的创新也可能勾起有意义的联系，并触发「精细编码」强化记忆。这些联系因为是你自己生成，所以会格外牢靠 —— 即所谓「生成效应」。[14] 严谨地说，目的对「创意卡」的内蕴机制理解有限，远不如对「提取卡」的。一些课题仍待研究[15]：在我们的记忆和理解中，这些任务产生哪些特殊效应（如果有的话）？通过什么机制？要设计何种适用环境、使用原则？适用何种间隔重复计划？ 「启明卡」和「Baader-Meinhof 现象」我们讨论的很多卡片除了影响记忆和理解外，还有另一个重要功效：保持你对 idea 的长期思考（keep you in contact with an idea over time）。 你是否有过这样的经历，明明是第一次了解某个事物，却突然发现你到处都能见着它？比方说学习了一个类似「mellifluous」的罕见词，之后几天能看到它好几次。这个现象被称作Baader-Meinhof 现象（*译注：也称频率错觉）。因 1994 年某网友投稿说自己一天里注意到两次该冷门恐怖组织而得名。斯坦福大学语言学教授 Arnold Zwicky 认为，这种效应本质是是一种「选择性注意」：新的 idea 在意识里总是更靠前（「凸显性/ 显著性」），所以对应的信息更引人注意，而客观上，出现频率并没有变化。正所谓「塞给你一个锤子，看什么都像钉子」。 但对于某个idea来说，这种效应并非总是正面的，因为新的「锤子」不一定适用所有「钉子」。要真正内化它，你需要自己生活中有所代入、赋予其意义。特别是学习一个新技能时，除非多实践几次，否则可能只是浅薄理解而不自知。（译注：避免新学一个概念后滥用和过度泛化） 如果不快点把 idea 和有实义的东西联系起来，它的「凸显性」会消退，你也逐渐停下对周边机会的觉察。但这种凸显性的消退不正如知识的遗忘吗？因此始终在脑中 “置顶” 你的 idea，也是 SR 卡的价值所在。Gwern Branwen 认为[*]此类卡片实际是对控制、扩展 Baader-Meinhof 现象的有效尝试。 我们关于「凸显性」写了一些卡： 问：如果我注意到我在咸口的烹饪中使用了水，我应该问自己什么？答： 「我应该用高汤代替吗？」 问：我应该如何处理烤鸡骨头？答：冻起来，做鸡肉高汤。 问：请说出你可能尝试用鸡肉高汤制作的蔬菜浓汤（不允许和以前的答案重复）答：e.g. 土豆、防风草、芹菜、苏子、莎草、南瓜、胡萝卜、胡椒、扁豆…… 这些卡片旨在「提示」而非对答案的「传授」，从而尝试激发新的灵感或者创造新的行为。从这个角度看，SR 卡让这些 idea 长久保持了「凸显」，让人对相关内容保持敏感，直到遇到机会，将自己生活中有意义的事物与其联系起来。就像经济学家布拉德-德隆（Brad DeLong）认为的那样，SR 卡在复习环节和世俗版的「教理问答」惊人地相似（译注：教理问答 —— 一种宗教教育的教材，形式上也是问答体。通过问答来潜移默化地记住、思考、理解。） 本指南中的许多 Orbit 卡片（*译注：红卡）都是这种类型的。它们的目的是让你与这些想法保持联系，直到你在写自己的卡片时仍然能保持对它们的了解。虽然可能有点怪，但我在创作过程中经常写这种关于自己的想法的卡片。它们帮助我在几周或几个月内能够持续沉思一个只有泛泛理解的事情或者是一个问题，直到其有希望发展出更多或更深入的东西。这是编写卡片的一种方式。使用这种方法可以比简单地从文本中获取知识创造出更深入的理解。 你应该想想 idea 可能在生活中用到的场景，并在写启明卡的时候代入，它们具有潜在的意义。例如很多人做饭可能不喜欢买整鸡，现在为了凑骨头，而打算略作让步。下面这张卡示例了如何针对某个特定场景制卡： 问：为了保持满冰箱的鸡肉高汤，我买鸡时一定要用？？？而不是？？？。答：买整只鸡；买鸡的部分 这个例子还辅助说明了一个更广泛的问题：「知道 idea 能解决什么问题，不等于解决问题时知道用什么 idea」[16]。它们之间的区别是否有逻辑充分的解读，我目前不得而知。依我经验，带上下文的卡片（如刚才的例子）能帮助我们从理论迈向实践。我想，这正是另一个「新、旧想法要紧密结合（densely connect new ideas to old ones）」的理由，一如我们在「概念」类知识的学习中做的那样 —— 不准确地说，概念之间联系得越紧密，越容易触发新知。（译注：原文 Just because you can answer a factual question about an idea, that doesn’t mean the idea will spontaneously occur to you when it’s useful） 最后思考：什么因素，是最可能让 SR 卡片改变你的行为/ 促进新的想法的？对刚才这类的卡片，如何安排 SR 策略？最后，如果不为记忆，回顾时的回答按钮（「忘记」/「记住」）又如何调整？这些仍是开放性问题。 练习：菜谱变体 材料里有一段是菜谱的变体版本。这仍然一定程度的「开放式清单」。写下卡片，展现你对它的理解： 如想尝尝偏法式的鸡肉高汤，可以用韭菜代替芹菜，再加入月桂叶、黑胡椒和百里香。为了获得更「深」的味道，可以先把鸡骨和蔬菜烤成所谓的「棕色鸡肉高汤」（原本的相对是「白色鸡肉高汤」，味道不强烈，但更细腻、通用）。 请在下面输入框中尝试练习，你写的东西不会被传送或保存。 【译者：假装此处有文本框】 实践写卡迭代式地写卡本指南为了演示写卡技术，刻意对案例进行了详尽分析。而实际上你如果是第一次碰菜谱，我绝不建议像前文那样，一次写上好几十个卡片。如此穷尽、全面地分析你的读物，很容易浪费大量时间，耗竭精力。 何况，你也不能指望第一次接触新的知识，就能轻松写出优质的卡片。此时的你尚在建立把握、区分重点的意识（无论是客观还是个人意义的重点）。因此你难以知道哪些内容特别难记（并特别关照），也可能不太了解作者的想法。所以编写的卡片要么无法连通其「本质」，要么不能捕捉其中微妙。因此，你还需和新学的知识 “相处” 一些时日，你才能写出好卡片，并与自己的情况鲜活地联系起来。 于是，一切都在呼唤一种迭代式的写卡方式： 想象你正在阅读一篇有趣的文章，试着给自己设下一个可触及的目标：一刷时，要求写下少量的卡片（ 如 5-10 张），描述任何看起来最重要、最有意义或最有用的东西。 设下这样的目标改变了我的阅读方式，无论是正式还是随性地阅读。在最初用 SRS 读书时，我有种强迫感，想把一切都写进卡里，这导致阅读体验极差。相比之下，每次只要求增添一点关键卡，会让我倍感自由[17]。于是我读得更积极了，脑海深处似有一种挠人的痒：「哦上帝，那看起来真多汁，让我来摘下它！」 如果材料相当简单，我们可能尚有余力一边阅读、一边写卡。但如果材料太难，或者不是熟悉的主题，那最好只标记或记录最重点 —— 写写停停地切换实在太打断思考了。之后你可以在文本的结尾或找一个合适的停顿处，一次性将你的理解写成卡。如果主题难度非常高，一开始先老老实实地聚焦在基本细节上面是最佳做法：比如「事实类」知识的原文、术语、符号约定等。 书籍阅读要比文章更复杂，因为种类多、阅读方式也多。虽然文章也可以多种多样，但「书」这类载体放大了它的复杂性。一方面，书不太可能像文章那样线性阅读（也就是逐步从头读到尾）；另一方面，它们的篇幅显然更长，制卡量也不会少。因此编卡没有固定的最佳做法，而是取决于你读它的「目的」和「方式」（Why &amp; How）。不过一般来说，如果我要内化一本书（非小说虚构类），我会在我第一遍读某个章节或者主要部分时，设一个目标作为起点（「写上一些关键卡」）。 至少最初阶段，好多材料写一遍卡足矣。但如果有一段文本是「富矿」，你正试图彻底内化它，那么哪怕是首个阅读环节，也常常值得反复多写几次卡。这么做不一定会让负担翻倍，因为每次就只要添一点点比较关键的卡片[18]。每次迭代时，你可能会发现，自己能理解（并卡片化）越来越复杂的细节。你的关注点可能逐渐转移到其中的模式（pattern）、联接（connection）乃至图景更宏大的洞察（insight）。更妙的是，你或许会跳出作者的内容，开始聚焦在自己的观察和疑问上。但同样要注意见好就收，不能永无尽头地去深化。实际上，事无巨细地写下全部细节并非一种美行，保持住对兴趣和好奇心的敏锐响应，远远比一丝不漏地卡片化重要。 如果感到「收集所有细节」的强迫症发作，请默念「以后总有机会继续」。事实上，卡片的价值不止是细节控，能让你被有意义的东西鼓舞[19]或许会更好 —— 比如发现新的知识联系，或者理解上的漏洞，你因此鼓舞。 让我们再来考虑一次我们的菜谱，这次我是个有抱负却孤陋寡闻的厨师，以前没听说过什么「高汤」。对我来说，可能会做的全部就是先写一些卡片指向概念本身 ：「高汤是什么」、「高汤的意义」—— 这些细节的覆盖面看起来不止一个菜谱，而且和我有过的美食经历相关。直到我真做完一罐高汤后，我就清楚哪些步骤很显然、哪些细节还得查菜谱了。此时若期待下一次制作，那就将这些更细节的东西提出来，写到卡上 —— 原料的配比、时间控制之类。我还会留意之前制作过程中感到费力的地方，我知道它们的相关内容我「读过，但不能确定细节」。等我用完第一批高汤后，我大概会将使用经验添进卡组，如此往复 有效性检测写散文时，文法检查器可以帮你避免容易犯的错误，而 SRS 方面，没有「卡片低级错误检查器」。因此找一些简单的测验会有所帮助。 1. 检测「假阳性*」：在不真正了解目标信息的情况下，你如何确定正确答案是怎么产生的？（*译注：统计黑话，指标阳性 ≠ 推论阳性，此处应指「回答正确」不等于「了解信息」） 抑制模式匹配 ：如果你写了一个长问题，措辞上用了不常见的词或线索（提示你这是哪张卡），你最终可能会记住这个问题的「形状」和它对应的答案 —— 你只是通过机械的模式关联答题，而不是真的思考了相关知识。「完形填空」类的卡片似乎容易产生此种问题，尤其要留意复制/ 段落编辑而来的卡。最好的避免办法，是让问题简短。 避免二元提问 : 要求回答「是/否」或「这个/那个」的问题往往不需要努力提取，而且产生不了深层理解。我个人经常可以不加理解地答对这样的卡片。解决二元化的提问，最佳做法是转述成开放性的问题。例如，对下面第一问进行改进： 问：鸡肉高汤是否会使素菜吃起来像鸡肉？答：不会。 问：鸡肉高汤如何影响素菜的味道的？（根据「安迪的菜谱」）答：它使它们的味道更「全面」。 要改进二元提问，往往需要结合其他东西，如一个例子或一个暗示。前文的「概念类知识」中提供的思考视角在这方面很有用。 2. 检测「假阴性*」的方法： 有没有可能知道卡片指向的信息，但是没 能正确作答？这类错答往往由于上下文给的不够充分。（*译注：统计用语，指标阴性 ≠ 效应阴性，比如核酸阴性不代表一定没感染新冠） 你很容易不小心写出一问多答的卡片 —— 正确答案不止卡背上的那一个。因此卡片必须给足语境，能显然排除掉合理的替代答案，但又不能给太多，避免把问题写太长，导致模式匹配或卡片「失焦」。 例如，如果你读完一个煎蛋菜谱立即提问「做煎蛋的第一个步骤是什么？」 ，此时答案可能是显而易见的：「用平底锅热黄油」！但六个月后再次回答，你可能想到很多合理的答案：「打蛋」，「用平底锅热黄油」，「把蘑菇剁碎做馅」等等，这不好。 一个解决方案是提供极其精确的背景：「Bon Appetit 18 年 6 月的煎蛋菜谱的第一步是什么？」但这种强限定，表明知识本身就比实际上更广。如果可能，在能避免歧义的情况下，普遍性强的知识应当被普遍地表达。这或许也意味着你需要换个切入点提问；例如这样：「做煎蛋时，在加入鸡蛋之前，锅必须如何准备？」 假阴性的卡片常像是学校考试中最无聊的废话：「哦，是的，回答正确，但它不是标准答案。再试试？」Soren Bjornstad 指出，一个不能排除多种回答的卡片，需要你记住设问的信息本身，还要额外记住「卡片在问什么」。 随时间推移修订卡片很多问题在写卡的同时我们往往不明显，而只在复习时暴露，有时还在好几轮复习之后（那时重复间隔甚至可以长达数月）。卡片 bug 的反馈周期并不短，因此其修订也重在渐进，一如渐进地写卡，此过程中，你也会留意其中的问题和机会。 复习环节中，请警惕「望卡兴叹」的感觉：「哦上帝，这个卡片 ——我永远都记不住答案」或者「每当刷到这张卡，我都知道答案，但并不真正理解它的含义」。倾听这些内心反应，并由其驱动你的修订。为了避免打断复习，大部分 SRS 允许在复习中标记待订正的卡片。你可以在复习完后，查看它们，并做改进。 学习卡片编写，就像学习散文的遣词造句。[20] 所用技能看似平凡，但个个上限很高。无论写卡或炼句，修订它们都要从整体着手。散文里的单句比较糟糕时，可能要合并整个段落、修改叙事方式，或大段大段变更文本结构。我在改卡时也有类似如上的观察，有时可以单独提改，但每当我理解有变时，常希望对整套卡组开刀 —— 这里合并、这里重构、那里细分。[21] 不幸的是，大部分 SRS 界面都将卡片视作一个独立的单元，这让自下而上做修订变得困难。就仿佛要改的论文被锁定住，必须申请一句、改一句。未来的 SRS 可能优化这方面问题，但当下按我的观察，只需主观上保持一个对整体性的渴望，即可更高效地修改。 在前文 ，除了细筛案例、陈例制卡的效用原则，数量上也有所建议：制卡应超出你的舒适量（write more prompts than might feel natural.）所以，我想提供一个反向考虑下的建议来结束全文。 我们探索的重点，始终是如何用卡片对多种多样的『理解』进行有效地表达。但仅满足有效性规则的卡片，却不一定值得重复。我相信最重要的、可以「优化」SR 练习的方面，莫过于「重复」本身与「重复内容」之间产生的情绪联系（the emotional connection to your review sessions and their contents）。如果突然发现，所重复的内容不再是自己关心的，你应有所行动 —— 要是想起当初制卡的动机，你可以通过修订来提示它，但绝大多数时候，直接砍掉是最佳做法。 我们可以从制卡的反面来理解这个建议：什么材料应该 是你写卡的？何时是 SRS 值得一用的？许多人刚开始用 SRS 时感到棘手，虽然兴致盎然，却对自己的情况无从下手。另一些人从背诵所谓「你应该知道的xxx件事」开始（如所有美国总统的名字），通常会倍感无聊、萌生退意。最好的开始，是研究怎么用它做一些事情，和自己息息相关的那种 —— 例如，用来撬动 idea，强化你核心工作里对创意的理解。随着积累，你对 SRS 的收益和成本便深有体会了，这可能带来更多应用点（就像我的烹饪）。如果你找不到任何方法，将 SRS 用于自己的重要事情上，那或许本就不该费心去用它。 进一步阅读这些资源对我来说特别有用，因为我已经对如何写出好卡片有了一定的了解： Piotr Wozniak 的有效学习：制定知识的二十条原则[2]和更详细的基于主动回忆的学习中的知识结构和表述[3]从不同的角度处理了与本指南相同的问题。 Michael Nielsen 的增强长期记忆[4]：全面回顾了 SR 的原理，以及你为什么应该关心；更详细地介绍了如何实际地将卡片写作结合进你的阅读实践，特别是在阅读学术文献、对创造性工作记笔记时；以及更多。 Michael Nielsen 的利用间隔重复系统看透数学作品[5]展示了如何利用间隔重复卡片作为杠杆，迭代加深对数学作品的理解。 更多观点和相关话题，请参见： Soren Bjornstad 的记忆系统系列涵盖了维护卡片库的许多实用主题，包括一些关于写卡的建议。 Nicky Case 的如何永远记住任何事情介绍了间隔重复法，并通过有趣的插图介绍了一些卡片写作的技巧。 我们怎样才能开发变革性的思想工具？[6]（来自 Michael Nielsen 和本 Andy）讨论了卡片写作在「助记媒介」的挑战，其中包括将卡片嵌入叙事性散文中。 致谢感谢 Peter Hartree、Michael Nielsen、Ben Reinhardt 和 Can Sar 对本指南的有益反馈；感谢我在编写本指南时举办的卡片写作研讨会的许多与会者；感谢 Gwern Branwen 和 Taylor Rogalski 对写卡的有益讨论，这些讨论为本工作提供了信息。我特别感谢 Michael Nielsen 多年来围绕记忆系统进行的对话和合作，这些对话和合作塑造了我对这一主题思考的各个方面。 本指南（和 Orbit，其内嵌的间隔重复系统）是由我的 Patreon 社区提供的众筹研究经费促成的。如果你觉得我的工作有趣，你可以成为会员，以获得持续的幕后更新和新作品的早期访问。 特别感谢我的赞助商级别的赞助者。Adam Wiggins, Andrew Sutherland, Bert Muthalaly, Calvin French-Owen, Dwight Crow, fnnch, James Hill-Khurana, Lambda AI Hardware, Ludwig Petersson, Mickey McManus, Mintter, Patrick Collison, Paul Sutter, Peter Hartree, Sana Labs, Shripriya Mahesh, Tim O’Reilly. 许可证和署名本作品以 CC BY-NC 4.0 授权，这意味着你可以复制、分享和建立在这篇论文上（注明出处），但不能出售。 在学术工作中，请将此引用为： Andy Matuschak, “How to write good prompts: using spaced repetition to create understanding”, https://andymatuschak.org/prompts, San Francisco (2020). 注释 [1] 本指南假定你对间隔重复系统有基本的熟悉。有关介绍，请参阅 Michael Nielsen 的《增强长期记忆》[4](2018年)，该文也是「让记忆成为一种选择」这句话的来源。 [2] 如果你没用过间隔重复系统，我建议你下载 Anki 并阅读之前提过的那篇 Michael 的文章[4]。 [3] 更多的背景资料，请参阅 Roediger 和 Karpicke 的《测试记忆的力量》 (2006)。Gwern Branwen 关于间隔重复的文章[7]是比较公认的一个的好综述。 [4] 例如，见 Karpicke 和 Blunt 的提取练习比使用概念图的精细学习产生更多的学习效果 (2011)；以及 Blunt 和 Karpicke 的《用基于提取的概念图学习》 (2014)。 [5] 关于助记媒介的更多背景，见 Matuschak 和 Nielsen，我们如何才能开发出变革性的思想工具？[6](2019)。 [Jarrett 1] 遗憾的是，嵌入卡片需要 Orbit 项目的支持，无法在普通的网站上实现这一效果。想要了解这种嵌入卡片具体形式的读者，可以阅读原文，亲自体验一番。 [6] 你可能会发现在两个地方复习卡片很烦人。随着 Orbit 的成熟，我们将发布导入/导出工具来解决这个问题。 [7] 这种效应已经在许多实验中产生，但还没有得到很好的理解。概述见Murayama 等人的《遗忘是提取的结果：提取诱导遗忘的元分析回顾》(2014)。 [8] SuperMemo 的算法（也被大多数其他主要系统使用）被调整为 90% 的准确率。如果你以更低的准确率为目标，每一次复习都可能对你的记忆产生更大的影响——参阅例如 Carpenter 等人的《使用间隔来增强不同形式的学习》 (2012)。更高的准确率目标以效率换取可靠性。 [9] 关于困难的提取比容易的提取有更大的影响这一概念，见关于 Bjork 的讨论，以及 Bjork的《废用新理论和刺激性波动旧理论》 (1992)。Pyc 和 Rawson 的《测试提取努力假说：更大的正确回忆信息的难度是否会导致更高的记忆水平？》 (2009) 对这一理论提供了一些集中的实验测试，他们将其称为「提取努力假说」。 [10] 如果你是一个素食主义者，我希望你能看淡关于骨头的讨论：选择这个例子涉及到许多权衡。 [11] 例如，见 Bradshaw 和 Anderson 的《精细编码是对加工水平的一种解释》 (1982). [12] 一个令人信服的证明，可以见 Chase 和 Simon 的《国际象棋中的感知》(1973)，它通过实验证实了国际象棋大师是如何操作较大的组块的。 [13] 事实上，如果您是一位经验丰富的厨师，您可能会将鸡肉高汤的原料也视作开放式清单——如果是这样，最好以这种方式代表它们！ 这是人类尺度下，封闭式清单的共同命运。 [14] 见 Slamecka and Graf, The Generation Effect: Delineation of a Phenomenon (1978). [15] Michael Nielsen 和我在量子力学中尝试了以应用为中心的SR卡片，但我们觉得并没理解它们。 [*] 私人通讯中 [16] 这是教育心理学中称为「学习迁移」的一个广泛问题的一个方面：人们如何将他们在一种情况下学到的东西转移到另一种情况？ [17] 正如 Michael Nielsen 笔记，类似的轻量级卡片写作目标可以活跃研讨会、专业对话、活动等。 [18] 有关数学中这一过程的生动描述，请参见 Michael Nielsen，使用间隔重复系统看穿一段数学[5] (2019)。 [19] 间隔重复的先驱 Piotr Wozniak 一直在开发一种他称之为 渐进阅读[8] 的系统，该系统试图积极支持这种迭代、增量卡片写作。 [20] 对句子的类比来自 Matuschak 和 Nielsen，我们如何开发思维变革工具？[6] (2019)。 [21] 如果您尝试过这些练习，您可能会注意到，在同一文本字段中撰写多个问题时，跨问题边界进行修改要比仅单卡修改会更容易。 作为一项实验，我 2020 年所写的全部新卡片都是简单的“Q. / A. 一种。” 使用老式文本编辑器而不是专用界面嵌入明文笔记中的行（如本指南中的示例）。 我发现在大多数情况下我更喜欢这种方法。 以后我可能会发布一些工具，允许其他人以这种方式编写卡片。 更多有关制卡原则的内容，请关注： 制卡原则与知识表述1.3 万浏览 · 418 关注收藏夹 原文：How to write good promptsAndy Matuschak December 2020 参考 ^可使用间隔重复系统对注意力编程 https://zhuanlan.zhihu.com/p/414293765 ^有效的学习：处理知识的20条规则[直译版] https://www.yuque.com/supermemo/articles/20rules ^基于主动回忆的学习中的知识结构与表述 https://zhuanlan.zhihu.com/p/297790034 ^abc量子物理学家是如何使用 Anki 的？ https://zhuanlan.zhihu.com/p/65131722 ^ab如何用Anki学数学? https://zhuanlan.zhihu.com/p/359350968 ^abc我们如何才能开发出变革性的思想工具？ https://zhuanlan.zhihu.com/p/394795804 ^高效学习的间隔重复 https://zhuanlan.zhihu.com/p/420105707 ^渐进阅读 https://www.yuque.com/supermemo/wiki/incremental_reading","link":"/2024/03/f85bf8f85f26.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 每年咱们国庆的时候，他们街道都会挂上中国的国旗，当年我们的《战狼2》、《红海行动》、《流浪地球》、《我和我的祖国》电影上映时，塞尔维亚街头都会出现大幅电影海报。 同为遭受过苦难、压迫的第三世界国家，我们和塞尔维亚人民之间，是有共同感情的。 ^a09c631d 塞尔维亚、克罗地亚、黑山、斯洛文尼亚、波黑、马其顿……他们曾经都有一个祖国，叫做“南斯拉夫”——南斯拉夫社会主义联邦共和国。 曾经，他们是社会主义兄弟，他们还是欧洲唯一一个不靠苏联红军、不靠欧美盟军、而是靠自己的革命力量战胜纳粹，赢得民族解放的伟大国家。 ^f6563399 他们甚至也有着自己的“长征”。 在前两次“围剿”铁托和游击队失败之后，德意法西斯与伪军又发起第三次“围剿”。来势十分凶猛，法西斯军队不仅占领革命根据地，而且大肆屠杀无辜百姓，制造广泛的“无人区”，隔绝游击队与人民的联系。南反法西斯斗争进入最困难的时期。南共中央决定突破敌人封锁线进行战略转移，这样就开始了堪称欧洲的“长征”。 ^b1c8e8e7 南斯拉夫长征甚至也有自己的“遵义会议”，在战斗最惨烈的苏杰斯卡战役后（苏捷斯卡战役很像“湘江血战”），游击队司令部在一个小磨坊召开会议，这就是南斯拉夫的遵义会议，会议上铁托决定向敌人力量薄弱的波斯尼亚地区转移，在那里建立新的根据地。 ^3092b473 南斯拉夫人民曾经也有一个统一、富强、独立的大国梦啊，只可惜，在内外敌人的联手破坏、绞杀下破灭了，国家被拆散，四分五裂，人民被轰炸被屠杀，民选的领导人被抓捕，被国际法庭审判，死得不明不白。 ^612fd013 分裂的背后，往往都是国际强权的阴谋和阳谋。那些顶级的掠食者，不愿意另一个统一的、强大的挑战者出现，不愿意他们成长起来，所以，他们花钱策反，动用媒体和舆论、文化入侵，鼓动分裂和内斗，鼓吹独立和自由，甚至直接武装干涉，最终把潜在的对手一一肢解，然后掠夺他们的人才和资源。 所以，中国人民一直和塞尔维亚人民站在一起，我们都是站着、不肯跪的一群人。 ^a09d50c3 Content为什么说塞尔维亚是铁板朋友塞尔维亚朋友对我们的崇拜和喜爱是真诚的，塞尔维亚有一首歌，叫做《假如塞尔维亚像中国一样强大》，歌词比较惊人，有兴趣的朋友自己去搜一搜。 ==每年咱们国庆的时候，他们街道都会挂上中国的国旗，当年我们的《战狼2》、《红海行动》、《流浪地球》、《我和我的祖国》电影上映时，塞尔维亚街头都会出现大幅电影海报。== ==同为遭受过苦难、压迫的第三世界国家，我们和塞尔维亚人民之间，是有共同感情的。== 塞尔维亚和我们的感情太久远了，甚至能够上溯到上世纪30年代。 那时候，塞尔维亚还叫“南斯拉夫”。 记得那首歌吗？“啊朋友再见，啊朋友再见吧再见吧，如果我在战斗中牺牲，你一定把我来埋葬，请把我埋在高高的山岗……” 这首歌是意大利游击队歌曲，但闻名于南斯拉夫电影《桥》，讲的是南斯拉夫人民的反法西斯斗争，那是一代人的记忆。 ==塞尔维亚、克罗地亚、黑山、斯洛文尼亚、波黑、马其顿……他们曾经都有一个祖国，叫做“南斯拉夫”——南斯拉夫社会主义联邦共和国。== ==曾经，他们是社会主义兄弟，他们还是欧洲唯一一个不靠苏联红军、不靠欧美盟军、而是靠自己的革命力量战胜纳粹，赢得民族解放的伟大国家。== 他们的革命史看起来很眼熟，在铁托同志的领导下，南斯拉夫的反法西斯斗争，跟我们的革命历程非常像，早先，他们也经历过莫斯科共产国际的遥控指挥，也走过很多弯路，但在铁托的带领下，逐渐走出了独立自主、符合南斯拉夫国情的斗争路线，他们身处整个欧洲战场的“敌后”，内外断绝，孤立无援，面临的是强大德军的扫荡和绞杀，只能靠着山地和群众基础艰苦奋斗……武器装备，只能靠缴获，南斯拉夫游击队有个外号，叫做“五发子弹的士兵”，可见他们斗争的艰苦卓绝。 ==他们甚至也有着自己的“长征”。== ==在前两次“围剿”铁托和游击队失败之后，德意法西斯与伪军又发起第三次“围剿”。来势十分凶猛，法西斯军队不仅占领革命根据地，而且大肆屠杀无辜百姓，制造广泛的“无人区”，隔绝游击队与人民的联系。南反法西斯斗争进入最困难的时期。南共中央决定突破敌人封锁线进行战略转移，这样就开始了堪称欧洲的“长征”。== 这场“长征”艰难困苦，法西斯围追堵截，对有可能为游击队提供补给的村落进行烧杀毁灭。游击队缺衣少食，不断减员，但他们不屈服、不舍弃，不少人赤着脚，抬着大批伤员，带着幼小的烈士遗孤，跋涉于白雪皑皑的山林，也不投降。大批共产党员为了掩护战友突围，毅然断后，和法西斯血战，弹尽粮绝英勇就义。 ==南斯拉夫长征甚至也有自己的“遵义会议”，在战斗最惨烈的苏杰斯卡战役后（苏捷斯卡战役很像“湘江血战”），游击队司令部在一个小磨坊召开会议，这就是南斯拉夫的遵义会议，会议上铁托决定向敌人力量薄弱的波斯尼亚地区转移，在那里建立新的根据地。== 实际上，南斯拉夫长征真的和我们有关系，因为当时中国的长征已经被当时欧美的左翼作家、同志们宣传到了全世界，早已成为了全世界无产阶级心目中的“神迹”，在南斯拉夫长征的队伍中，他们也两次印刷小册子宣传中国工农红军的长征，鼓舞同志们的士气。 我们中国的长征被称作革命的“播种机、宣传队”，南斯拉夫长征也是这样，长征中游击队不仅没有减少，反而不断增强，沿途不断解放新的城镇，扩大了南斯拉夫民族统一抗战的阵营，游击队得到很大发展，人数已超过15万人。最后游击队改编为南斯拉夫人民解放军……最终反攻贝尔格莱德，取得全国解放的胜利。 你不得不感慨，当年我们的事业并不孤单，在地球上另外一块遥远的地方，有着我们的同志，有着我们的同路人。 铁托同志是个真正意义上的硬汉，无论是革命战争时代，还是社会主义建设时代，他一直保持着南斯拉夫的独立性，没有向任何强权低头。 他用二十年时间，把南斯拉夫建成了一个工业高度发达，而工业增长率达到9.1%的工业国。他创造了“企业工人自治”制度，工人直接决定企业的生产和分配，大大激发了劳动积极性。南斯拉夫人均GDP不断增长，当时南斯拉夫人均GDP增速是6.5%，到了上世纪七十年代末，南斯拉夫的人均收入达到1500美元，这在当时来说是中等偏上国家。1976年，南斯拉夫的民众家庭中，有36%拥有轿车，56%的家庭有电视，而且冰箱的拥率也突破40%，所有的孩子都能接受免费基础教育，这样的生活水平，很多西方国家都达不到，这是一个经济奇迹。 因为铁托坚持“不结盟”政策，既不倒向苏联，也不倒向美国，这就导致了美苏双方对南斯拉夫都是既想打压又想拉拢，这就让南斯拉夫得到了能从美苏双方都获得经济科技支持的机会，因此南斯拉夫科技发达，也带动了军事发展。上世纪七十年代，南斯拉夫常备陆军有60多万，坦克有一千多辆，还有六百门反坦克火炮，1400辆装甲车及各式口径的火炮九千多门。海军达到1.1万，有80艘舰艇，空军有六百多架，有3.2万人。这放在整个欧洲，也是军事强国。铁托时代的南斯拉夫，被周边国家称为“巴尔干之虎”。 可惜的是，南斯拉夫是个多民族国家，并且没有一个强大的主体民族，克罗地亚、塞尔维亚、黑山、波黑、斯洛文尼亚、马其顿各地经济发展不均衡，再加上后来企业私有化导致的社会不公平加剧，以及西方的不断作梗和煽动，酝酿了尖锐的民族矛盾和地区冲突……. 铁托在世的时候，还能靠着铁腕和个人威望压制矛盾，让各民族拧成一股绳；铁托虽然出身于克罗地亚，但他对各个民族之间不偏不倚，保持公正。无论是经济上，还是政治上都一视同仁。各个民族的民众都拥有富裕的生活，也就没有分裂独立的必要。在共产主义理想还在的时候，人民爱的是南斯拉夫社会主义联邦共和国这个伟大祖国。 但在铁托去世后，刚好又遇到东欧剧变、苏联解体，南斯拉夫经济改革失败，增长停滞，导致各民族之间继续撕裂、矛盾激化；西方又加紧了对南斯拉夫的干涉，这种干涉包括好几个方面，一是采用经济制裁，让南斯拉夫的经济处于崩溃的状态中。二是培养反政府势力，特别是那些亲西方的反政府势力……这就加剧了南斯拉夫的分崩离析。 此后，就是血腥的南斯拉夫内战，当年的一切繁荣化为泡影，经济建设成果毁于一旦，铁托建立的伟大国家不复存在，本来的民族兄弟同室操戈血流成河，然后是美国和北约发动“科索沃战争”，悍然对南斯拉夫进行长达78天的狂轰滥炸……迫使了南斯拉夫进一步解体。 没有南斯拉夫了，只有塞尔维亚、克罗地亚、黑山、波黑、斯洛文尼亚……就连科索沃都分裂出去了。 1992年实行“多党制”、“私有化”，向西方积极靠拢的南斯拉夫，高呼自由民主人们甚至拆除、移走了铁托的雕像，但到了30年后，一片混乱衰败的土地上，人们又开始想念铁托同志了。 那个年代狂热的年轻人已经老了，他们反思着——“铁托的时代我还小，但清楚记得家中从未因日常生活而发过愁，每逢夏季全家都要到海边或是其他国家旅游度假，从来也不必担心，出外期间家中有可能被人抢劫或偷盗，但现在一切都变了，所以人们开始想他了…….”南斯拉夫各族人民都在怀念他。 但“巴尔干之虎”不复存在了，塞尔维亚如今最出色的，是体育人才，比如网球巨星德约科维奇，比如篮球巨星约基奇，比如足球豪强贝尔格莱德红星。 我最早关注他们，是因为篮球，巴尔干半岛是一个篮球天才辈出的神奇地方，当年他们有博迪洛加、彼得洛维奇、迪瓦茨、库科奇、斯托贾科维奇…..当他们全胜时期，可以击败苏联、美国，就算他们经历国家解体只剩下半壁江山时，依然可以在2002年再次打败美国队。 今天他们有约基奇、博格达诺维奇（塞尔维亚）、东契奇（斯洛文尼亚）、武切维奇（黑山）、努尔基奇（波黑）…….上面这些人，都是当今NBA的一线球星，约基奇、东契奇两位，如今还是整个NBA年轻一代的领军人物、超级巨星。如果把他们凑到一起，简直是一支梦之队。但“南斯拉夫内战”和“北约轰炸南联盟”彻底拆散了这个了不起的篮球大国。 ==南斯拉夫人民曾经也有一个统一、富强、独立的大国梦啊，只可惜，在内外敌人的联手破坏、绞杀下破灭了，国家被拆散，四分五裂，人民被轰炸被屠杀，民选的领导人被抓捕，被国际法庭审判，死得不明不白。== 1999年3月24日，以美国为首的北约在没有得到联合国安理会授权的情况下，不顾国际社会强烈反对，打着所谓“人道主义”的旗号，悍然对南联盟——一个主权国家发动了长达78天的狂轰滥炸，造成了超过3500人遇难、1.25万多人受伤、数十万难民背井离乡，制造了当时冷战结束后最大规模的人道主义灾难。 那一年5月7日深夜，美军三枚导弹击中了我国驻南联盟大使馆，造成正在使馆中工作的新华社记者邵云环、《光明日报》记者许杏虎、朱颖不幸牺牲，同时被炸伤数十人。 贝尔格莱德的中国大使馆遗址处，有一块黑色的纪念碑，这块纪念碑上用塞尔维亚文和中文写着：“谨此感谢中华人民共和国在塞尔维亚共和国人民最困难的时刻给予的支持和友谊，并谨此缅怀罹难烈士。” 塞尔维亚人民，贝尔格莱德人民应该是最能理解我们的。 “塞尔维亚人民心里永远记得中国当年的牺牲。在那个非常时期，中国和我们站在一起，你们的伤痛也是我们的伤痛。”——贝尔格莱德大学教授帕夫洛维奇。 有的人无法理解中国人的爱国情感，无法理解中国人对国家统一和领土完整的强烈追求，因为中国人经历过，见识过这个世界的真相。真相就是，分裂就是战争和灾难，就是国家的屈辱和衰退，民众的朝不保夕。 ==分裂的背后，往往都是国际强权的阴谋和阳谋。那些顶级的掠食者，不愿意另一个统一的、强大的挑战者出现，不愿意他们成长起来，所以，他们花钱策反，动用媒体和舆论、文化入侵，鼓动分裂和内斗，鼓吹独立和自由，甚至直接武装干涉，最终把潜在的对手一一肢解，然后掠夺他们的人才和资源。== ==所以，中国人民一直和塞尔维亚人民站在一起，我们都是站着、不肯跪的一群人。== 2022年，6架“鲲鹏”运-20战略运输机飞越土耳其上空，飞往塞尔维亚，给他们送去了FK3(红旗-22外贸版）防空导弹系统和察打一体无人机。 塞尔维亚作为欧洲唯一一个独立自主的国家，太需要自己的国防体系了，太需要防空导弹了，在欧洲局势越发动荡的局面下……塞尔维亚当然要早点做好准备。毕竟1999年到今天也才过去了20多年，南斯拉夫人民血与火的记忆还在。我们没忘记那笔血债，塞尔维亚人自然更不敢忘。 我们在各个领域帮助塞尔维亚，成立于1913年的斯梅戴雷沃钢厂是塞尔维亚唯一国有钢厂。由于市场及转型等原因，钢厂一度陷入困境，濒临倒闭。2003年，一家美国钢铁企业接手斯梅戴雷沃钢厂，却未能给钢厂带来生机。2012年，美方撤资，塞尔维亚政府以1美元的价格回购这座曾被誉为“塞尔维亚的骄傲”的钢厂。 2016年，中国河钢集团收购这座已连续亏损七年的钢厂，成立河钢塞尔维亚公司（河钢塞钢）。这是中国钢企收购的第一家境外实体企业。被河钢收购仅半年多，斯梅戴雷沃钢厂就成功扭亏为盈。2018年，钢厂年产177万吨钢，创下建厂105年来的最高纪录，当年实现收入10.5亿美元，一举成为塞尔维亚第一出口创汇大户。河钢塞钢成为中塞共建“一带一路”标志性项目。 我们和真正的朋友之间，是肝胆相照的。 有人说，国与国之间只谈利益，不讲感情的，说得对，即便从现实利益出发，塞尔维亚也注定应该是我们的友邦和兄弟。塞尔维亚目前是我国在欧洲最坚定的支持者、几乎是“唯一的朋友”，在整个西方污蔑我们的时候，塞尔维亚是唯一一个站出来支持我们的，在欧美制裁中国的时候，塞尔维亚也是欧洲少见的和我们站在一边的国家。 对于这样的朋友，怎能不尽力保护和援助？中华民族是一个善良、友爱、言必信、行必果的民族，我们说“人类命运共同体”，就是一定要实现的。 我们不打仗、不杀人、不争霸，但我们想要让整个世界都不打仗、不杀人、不争霸，不能光靠美好愿景，还要有让大家和和气气的手段和能力。 我们要守护我们的理想，帮助一切愿意独立自主、自尊自强的人民。塞尔维亚街头人们在谈论中国微博新知博主","link":"/2024/05/a3b4c41b6f1c.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 革命的困境之一 近代史上的中国面临着两到三次技术革命接连掉队的问题 第一次和第二次技术革命，中国都没有跟上步伐。到了近代史的末期，以核技术和计算机为代表的第三次技术革命也开始涌现了。 反复落后于技术革命并导致落后度不断叠加，这使得中国的自救之路变得相当艰辛，甚至是越来越危险。技术的不断发展甚至导致了，中国越革命越进步，与世界列强的差距，不减反增 ^18a87aae 被技术革命反复甩下还造成了另一个严重问题： 中国的经济和文化发展具有高度的不平衡性。 上海在20世纪上半叶已经是远东超级大都市，知识分子可以容易地接触到世界前沿思想文化，而全国绝大多数地方依然是文盲遍地的赤贫封闭农村。此种内部的严重不平衡极容易导致族群内部由于阶级，文化，经济模式等差异而被纵向撕裂。 这种撕裂既容易使占大部分人口的普罗大众对能接触到先进生产力和先进文化的少数精英感到不信任， 也容易使少数精英主动地甚至被迫地脱离普罗大众， 而真正想要扎根群众动员群众的精英则往往不得不在文化和政治理念上开历史倒车以保证自己能接地气。一个组织要想同时代表先进生产力，先进文化和最广大人民的利益是十分困难的。精英与群众的血肉联系亦是俊男的 ^3d824fd0 革命的困境之二 中国近代以来遭受到的外部挑战是全方位的文明冲击。 清朝人用了几十年时间逐步认识到，中国在军事、经济、科技、政治各个方向上全方位落后于西方。此种文明冲击是中国古代史上未曾面对过的，也使得中国没有办法依托丰富的治乱循环，王朝更替和同化少数族群的经验来处理此次外部文明挑战。 ^a60b86c7 革命的困境之三 中国革命面临十分复杂的国际政治格局。 近代史期间世界局势纷繁复杂，列强的命运也是跌宕起伏。尤其是从八国联军到朝鲜战争这五十年的博弈格局高度混沌。 ^ded80cf3 Content中国革命的近乎不可能之路（一）革命的困境（上） （注：原文发布于2021年） 中国近代以来的主要历史任务是中国人民的自救，自救的方式是革命。然而革命自救面临着巨大的困难和复杂的形势，中国革命的胜利实为走通了一条近乎不可能之路。在这里我们先分析一下中国革命自救运动的深刻困境，然后将解释中国革命之路的非同寻常之处。 ==革命的困境之一 近代史上的中国面临着两到三次技术革命接连掉队的问题== ==第一次和第二次技术革命，中国都没有跟上步伐。到了近代史的末期，以核技术和计算机为代表的第三次技术革命也开始涌现了。 反复落后于技术革命并导致落后度不断叠加，这使得中国的自救之路变得相当艰辛，甚至是越来越危险。== 随着技术革命的迭代升级，中国面对的主要列强的相对实力越来越恐怖，这是中国革命面临的残酷局面，也是中国的革命力度和组织能力不断升级却反复重挫的一个基本原因。开始的列强主要是英法，行为主要是占一些口岸，索要一些特权和赔款以及小规模杀戮。再后来的日本野心远超英法和大量吞并领土的沙俄，甚至想侵吞大部分中国并取得了很大进展。这里固然有地缘便利，但也离不开技术发展比如下文描述的军事技术升级。再往后，正如日本在对付中国时显示出远超英法的干涉力，美苏也较之往日的日本更加强大。 一个典型的代表就是军事能力的发展。从甲午战争前的清朝到北洋军阀，从北洋军阀到国民革命军，应该说中国的军事力量是发生过不止一次的实质性提升的。可是如果我们看一下外战的战绩情况就不容乐观了。19世纪末的时候，列强尚缺乏吞并绝大部分中国的能力（或者至少是缺乏决心，而这种决心的缺乏和他们对能力的判断也是有很大关系的）。而到了40年代初，列强中最多属于第三档次的日本已经具备了占领大部分中国人口聚居区， 控制占领区绝大多数城市并建立大量伪军的能力。 可见在中国军事能力取得至少两轮实质性进展的情况下，和世界军事的差距恐怕还越拉越大。 这就是被技术革命反复甩下的残酷性。更为残酷的是，40年代末美苏接连进入核武器与导弹时代，新一轮军事技术变革到来了。 不亚于军事压力的还有体量优势和技术革命带来的美苏两超史无前例的经济输出和经济体系建设能力。 这是曾经的英法和日本比不过的。这种力量在40年代末期的马歇尔计划，50年代开始的日本经济起飞，再往后的四小龙崛起，苏联东欧经互会的建立和相当一段时间内的稳定运行，苏联在50年代对共和国的体系性工业输出等等案例中都清楚体现了。这也意味着美苏可能都有力量军事经济双管齐下将一个或半个松散软弱的中国置于自身体系中并长期深度控制。 ==被技术革命反复甩下还造成了另一个严重问题： 中国的经济和文化发展具有高度的不平衡性。== ==上海在20世纪上半叶已经是远东超级大都市，知识分子可以容易地接触到世界前沿思想文化，而全国绝大多数地方依然是文盲遍地的赤贫封闭农村。此种内部的严重不平衡极容易导致族群内部由于阶级，文化，经济模式等差异而被纵向撕裂。 这种撕裂既容易使占大部分人口的普罗大众对能接触到先进生产力和先进文化的少数精英感到不信任， 也容易使少数精英主动地甚至被迫地脱离普罗大众， 而真正想要扎根群众动员群众的精英则往往不得不在文化和政治理念上开历史倒车以保证自己能接地气。一个组织要想同时代表先进生产力，先进文化和最广大人民的利益是十分困难的。== 很多发展中国家和后发工业化国家在近代之所以革命不彻底不成功甚至成功之后又国势重挫，就和这种内部发展不平衡带来的严重撕裂密不可分。这是世界性的技术革命条件下的转型难题，印度中东拉美等都解决不了。 ==革命的困境之二 中国近代以来遭受到的外部挑战是全方位的文明冲击。== ==清朝人用了几十年时间逐步认识到，中国在军事、经济、科技、政治各个方向上全方位落后于西方。此种文明冲击是中国古代史上未曾面对过的，也使得中国没有办法依托丰富的治乱循环，王朝更替和同化少数族群的经验来处理此次外部文明挑战。== 西方的全方位领先和不同种族性使得他们不存在被同化或者局部同化的可能。 更不用说19世纪到20世纪上半叶正是西方种族主义极为猖獗的时代，一旦中国持续虚弱下去西方对中国的侵略是没有底线的，印度的被全面殖民已经是一个很好的警告。 而印度的情况还只是反映了19世纪西方列强的进攻性， 到了20世纪纳粹已经发展到了有理论有计划有系统地全面工业化种族大屠杀的地步。 而在西方的强烈刺激下短期内自救成功的日本也爆发出了变本加厉的残暴， 全然没有因为与中国近文同种而手下留情。 在1905年日俄战争之后，很多中国知识分子还一度被黄种人的胜利所鼓舞， 但日本在侵占东北后十几年内的政策已经表明了，即使中国愿意将自身融入日本主导的黄种人东亚秩序， 中国的民众无论是精英还是普罗大众在日本治下的前景都将弱于过往的汉人在满清之下的前景。原因是很明显的，后发国身份和本土资源匮乏的现实使日本走上了利用民族主义深度动员本族基层进行扩张的道路， 此种民族主义深度动员使得日本人很难接受向中国让渡利益，而政治体制的落后所致的下克上风潮更是进一步严重限制了日本统治阶层统战中国的能力。 早在20世纪初， 中国的有识之士就已经陷入了全面丧失自信和慌乱的状态。著名的保国保教保种的讨论就深刻反映了他们的高度焦虑。在高度焦虑之下，各种稀奇古怪离经叛道的思路都涌现了出来， 即使像鲁迅这样优秀的知识分子也一度鼓吹要让汉字消亡。在高度焦虑之下，中国的精英阶层很容易出现两种严重的心理问题，要么完全陷入投机主义，要么走入另一极端而被刻上某种来自（广义的）西方的思想钢印。中国近代史上，投机主义者不断背叛革命，钢印族则多次令革命遭受无谓损失。中国人不仅被打垮了，而且被打懵了。 ==革命的困境之三 中国革命面临十分复杂的国际政治格局。== ==近代史期间世界局势纷繁复杂，列强的命运也是跌宕起伏。尤其是从八国联军到朝鲜战争这五十年的博弈格局高度混沌。== 参与八国联军的英法德奥俄意日美八国，在1945年后除了美苏（俄）两国之外其他六国的地位都遭受重创，甚至有的不复存在。而苏俄在期间也遭受了数次极为沉重的打击。 在这种高度混沌的国际环境之下，中国革命自救的道路始终弥漫在迷雾之中。 复杂国际局势的影响主要是两方面。 第一方面，由于列强很多很强，中国自救的历程势必包含着从国外借力，而从什么国家那里借力以及如何借力就变成了很难准确判断的事情。 一度能够大体协调好列强关系维护自身统治的慈禧政权在19世纪末20世纪初就把局势给搞崩溃了。后来多路军阀试图利用列强来为自己谋取利益和安全，玩失手的也非常多，从袁世凯到张作霖都是如此。孙中山从英美、日本各方向都试图获得助力，但一直没有获得成功。到了他晚年从苏俄获取助力的路看起来颇有前途，但很快就人亡政息。 以蒋介石为代表的派系长期依赖美国资源在国内进行他们认为正确的自救道路。但在熬成了二战胜利者之后也在迅速发展的美苏冷战格局中进退失据，最后不仅没有协调好和苏联的关键性关系，也出人意料地在关键时候没有得到美国的及时有力支援。中国共产党在借助外国力量的过程中，更是众所周知地遭受过严重的挫折。 看上去很有希望的苏维埃国很大程度上由于苏联势力错误干涉而遭受灭顶之灾。 另一方面，国际局势的混沌化也导致了中国如何学习以及学习何种外国经验变成一个令人头痛的问题。中国人民自救运动的一个突出特点就是深度使用外国思想资源，这从太平天国运动就开始了。在中国近代以来，学西欧，学日本，学苏联，学美国的思潮都各自拥有很多的支持者，甚至30年代还一度有想模仿纳粹的意愿。学习路线太多，本身就分散了中国革命组织和动员的力量，并容易造成反复的革命者内部自相残杀。 革命的困境之四 中国近代以来出现了生存资源严重稀缺的问题。 在清朝后期中国人口就已经突破4亿，这是历朝历代从未出现过的情况。到建国初人口已突破5亿。根据统计数据，中国大量关乎基本民生的核心物资产品的人均产量在建国初已经排在了全世界末尾。此种局面似乎也是历朝历代所未有。 事实上，组织力超强的共和国建立以后中国仍然常年面临粮食非常紧张的情况就已经很能说明问题。中国历朝历代一旦大一统政权实现国内统一和平往往便能快速进入国内经济和资源矛盾大为缓解的红利期，而且生活水平能够明显超出周边地区。但近代中国是不同的。历代政权能做到这一点，和战乱中人口大量减少，和平环境下可以大量开辟新的土地以及中国本来就是经济及技术高地等等有关系。但近代中国面临的情况是，即使在战乱状态下人口依然居高不下甚至慢速增长，而适宜开发地区基本被占据殆尽或者面临严重生态破坏和烈性高频度自然灾害。这就导致既存在大量人口预期寿命很低的悲惨状况，又依然面临着越来越严重的资源高度稀缺，甚至第一个问题的解决会加重第二个问题的负担。 在自身资源稀缺的情况下，早已成为世界范围内经济和技术低洼地区的中国难以抵御外国资源的诱惑。中国近代以来出现了深度依赖外国资源的问题，这也是中国历朝历代改朝换代之时未曾面临的局面。 首先是中国的武器严重依赖外国。中国缺乏制造哪怕比先进武器落后两代的武器的能力。这种至少三级的武器代差使得列强很容易下决心武装中国军队。在反复的内战中，谁能够先于对方拿到外国武器，谁就能在军备上获得具有代差的优势。第二是中国在财政上陷入了深度依赖外国资源的地步。这是从清朝末期就开始的。这在大大改善了晚清财政状态的情况下，也使得中国从此极难摆脱外国人对中国经济的深度介入。 蒋介石政权就是深度依赖外国资源的一个例子，这既是他的强处亦是他的软肋。另一方面， 最终获得胜利的共产党也没有办法摆脱前期对苏联资源的深度依赖以及之后的一定程度的依赖。 这些问题的并存导致了中国革命的深层矛盾。新兴力量即使能够在某一地区获得一段时间的相对稳定以从事建设积累实力， 也很难在短时间内解决生存资源和军事资源稀缺的问题，同时还要面临巨大外部军事压力。而一味地将军事问题摆在第一位也是非常危险的，仅仅是自身的维系都可能摇摇欲坠，蒋介石集团的后期命运即为明证。 想发育好自身再打出去是不行的，想靠扩张解决经济问题是不行的，想依赖外国经济资源则是后患无穷的。如何平衡协调建设与扩张，经济与军事，短期压力与长期压力，内部开发挖潜与寻求外部资源，这是对组织者能力的全面挑战。","link":"/2024/05/c1329d9ab4cd.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 速度： 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则(采用Selective Search方法)预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上(采用CNN)提取特征，进行判断。相较于传统算法,通过滑动窗口寻找,rcnn使用了selective search,再在可能的区域上进行CNN提取特征 RCNN算法分为4个步骤 候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法） 特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN） 类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类 位置精修： 使用回归器精细修正候选框位置 Selective Search 主要思想: 使用一种过分割手段，将图像分割成小区域 (1k~2k 个) 查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置 输出所有曾经存在过的区域，所谓候选区域 其中合并规则如下： 优先合并以下四种区域： 颜色（颜色直方图）相近的 纹理（梯度直方图）相近的 合并后总面积小的： 保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域 （例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -&gt; abcd-efgh -&gt; abcdefgh。 不好的合并方法是：ab-c-d-e-f-g-h -&gt;abcd-e-f-g-h -&gt;abcdef-gh -&gt; abcdefgh） 合并后，总面积在其BBOX中所占比例大的： 保证合并后形状规则。 上述四条规则只涉及区域的颜色直方图、梯度直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。 所谓的有监督预训练也可以把它称之为迁移学习。比如你已经有一大堆标注好的人脸年龄分类的图片数据，训练了一个CNN，用于人脸的年龄识别。然后当你遇到新的项目任务时：人脸性别识别，那么这个时候你可以利用已经训练好的年龄识别CNN模型，去掉最后一层，然后其它的网络层参数就直接复制过来，继续进行训练，让它输出性别。这就是所谓的迁移学习，说的简单一点就是把一个任务训练好的参数，拿到另外一个任务，作为神经网络的初始参数值,这样相比于你直接采用随机初始化的方法，精度可以有很大的提高。把一个类似的训练好的模型,去掉最后一个输出层,把网络层参数直接拿来用,修改修改,就可以变成另外一个模型例如从训练好的人脸年龄模型可以迁移训练成为人脸性别模型 对于bounding box的定位精度，有一个很重要的概念： 因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式：IOU。 它定义了两个bounding box的重叠度，如下图所示 就是矩形框A、B的重叠面积占A、B并集的面积比例。 非极大值抑制（NMS）顾名思义就是抑制不是极大值的元素，搜索局部的极大值。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。这里不讨论通用的NMS算法，而是用于在目标检测中用于提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。*对于从小到大排列的矩形框A,B,C,D,E,设定一个阈值LA,B对E的重叠度超过了L,可以认为A,B在E的邻域内.C,D对F的重叠度小于L,可以认为C,D不在E的邻域内 对于某个矩形框alpha进行NMS,意味着所有超出阈值的矩形框都要比较大小,仅仅保留最大的小于阈值的矩形框暂时保留,因为它们不在alpha的邻域中 NMS意味着,每个矩形框邻域内,仅仅保留最大的矩形框* 首先对每一个输入的图片产生近2000个不分种类的候选区域（region proposals），然后使用CNNs从每个候选框中提取一个固定长度的特征向量（4096维度），接着对每个取出的特征向量使用特定种类的线性SVM进行分类。也就是总个过程分为三个程序：a、找出候选框；b、利用CNN提取特征向量；c、利用SVM进行特征向量分类。 为什么是固定长度的特征向量4096维度 Content前面一直在写传统机器学习。从本篇开始写一写 深度学习的内容。 可能需要一定的神经网络基础（可以参考 Neural networks and deep learning 日后可能会在专栏发布自己的中文版笔记）。 RCNN (论文：Rich feature hierarchies for accurate object detection and semantic segmentation) 是将CNN方法引入目标检测领域， 大大提高了目标检测效果，可以说改变了目标检测领域的主要研究思路， 紧随其后的系列文章：（ RCNN）,Fast RCNN, Faster RCNN 代表该领域当前最高水准。 【论文主要特点】（相对传统方法的改进） ==速度： 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则(采用Selective Search方法)预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上(采用CNN)提取特征，进行判断。== 训练集： 经典的目标检测算法在区域中提取人工设定的特征。本文则采用深度网络进行特征提取。使用两个数据库： 一个较大的识别库（ImageNet ILSVC 2012）：标定每张图片中物体的类别。一千万图像，1000类。 一个较小的检测库（PASCAL VOC 2007）：标定每张图片中，物体的类别和位置，一万图像，20类。 本文使用识别库进行预训练得到CNN（有监督预训练），而后用检测库调优参数，最后在检测库上评测。 看到这里也许你已经对很多名词很困惑，下面会解释。先来看看它的基本流程： 【基本流程 ===================================】 ==RCNN算法分为4个步骤== ==候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法）== ==特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN）== ==类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类== ==位置精修： 使用回归器精细修正候选框位置== 【基础知识 ===================================】 ==Selective Search== ==主要思想:== ==使用一种过分割手段，将图像分割成小区域 (1k~2k 个)== ==查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置== ==输出所有曾经存在过的区域，所谓候选区域== ==其中合并规则如下： 优先合并以下四种区域：== ==颜色（颜色直方图）相近的== ==纹理（梯度直方图）相近的== ==合并后总面积小的： 保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域 （例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -====&gt;== ==abcd-efgh -====&gt;== ==abcdefgh。 不好的合并方法是：ab-c-d-e-f-g-h -====&gt;====abcd-e-f-g-h -====&gt;====abcdef-gh -====&gt;== ==abcdefgh）== ==合并后，总面积在其BBOX中所占比例大的： 保证合并后形状规则。== ==上述四条规则只涉及区域的颜色直方图、梯度直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。== 有监督预训练与无监督预训练: (1)无监督预训练(Unsupervised pre-training) 预训练阶段的样本不需要人工标注数据，所以就叫做无监督预训练。 (2)有监督预训练(Supervised pre-training) ==所谓的有监督预训练也可以把它称之为迁移学习。比如你已经有一大堆标注好的人脸年龄分类的图片数据，训练了一个CNN，用于人脸的年龄识别。然后当你遇到新的项目任务时：人脸性别识别，那么这个时候你可以利用已经训练好的年龄识别CNN模型，去掉最后一层，然后其它的网络层参数就直接复制过来，继续进行训练，让它输出性别。这就是所谓的迁移学习，说的简单一点就是把一个任务训练好的参数，拿到另外一个任务，作为神经网络的初始参数值,这样相比于你直接采用随机初始化的方法，精度可以有很大的提高。== 对于目标检测问题： 图片分类标注好的训练数据非常多，但是物体检测的标注数据却很少，如何用少量的标注数据，训练高质量的模型，这就是文献最大的特点，这篇论文采用了迁移学习的思想： 先用了ILSVRC2012这个训练数据库（这是一个图片分类训练数据库），先进行网络图片分类训练。这个数据库有大量的标注数据，共包含了1000种类别物体，因此预训练阶段CNN模型的输出是1000个神经元（当然也直接可以采用Alexnet训练好的模型参数）。 重叠度（IOU）: 物体检测需要定位出物体的bounding box，就像下面的图片一样，我们不仅要定位出车辆的bounding box 我们还要识别出bounding box 里面的物体就是车辆。 ==对于bounding box的定位精度，有一个很重要的概念： 因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式：IOU。 它定义了两个bounding box的重叠度，如下图所示== ==就是矩形框A、B的重叠面积占A、B并集的面积比例。== 非极大值抑制（NMS）： RCNN会从一张图片中找出n个可能是物体的矩形框，然后为每个矩形框为做类别分类概率： 就像上面的图片一样，定位一个车辆，最后算法就找出了一堆的方框，我们需要判别哪些矩形框是没用的。非极大值抑制的方法是：先假设有6个矩形框，根据分类器的类别分类概率做排序，假设从小到大属于车辆的概率 分别为A、B、C、D、E、F。 (1)从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值; (2)假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。 (3)从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。 就这样一直重复，找到所有被保留下来的矩形框。 ==非极大值抑制（NMS）顾名思义就是抑制不是极大值的元素，搜索局部的极大值。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。这里不讨论通用的NMS算法，而是用于在目标检测中用于提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。== VOC物体检测任务: 相当于一个竞赛，里面包含了20个物体类别：PASCAL VOC2011 Example Images 还有一个背景，总共就相当于21个类别，因此一会设计fine-tuning CNN的时候，我们softmax分类输出层为21个神经元。 【各个阶段详解 ===================================】 总体思路再回顾： ==首先对每一个输入的图片产生近2000个不分种类的候选区域（region proposals），然后使用CNNs从每个候选框中提取一个固定长度的特征向量（4096维度），接着对每个取出的特征向量使用特定种类的线性SVM进行分类。也就是总个过程分为三个程序：a、找出候选框；b、利用CNN提取特征向量；c、利用SVM进行特征向量分类。== 候选框搜索阶段： 当我们输入一张图片时，我们要搜索出所有可能是物体的区域，这里采用的就是前面提到的Selective Search方法，通过这个算法我们搜索出2000个候选框。然后从上面的总流程图中可以看到，搜出的候选框是矩形的，而且是大小各不相同。然而CNN对输入图片的大小是有固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。因此对于每个输入的候选框都需要缩放到固定的大小。下面我们讲解要怎么进行缩放处理，为了简单起见我们假设下一阶段CNN所需要的输入图片大小是个正方形图片227*227。因为我们经过selective search 得到的是矩形框，paper试验了两种不同的处理方法： (1)各向异性缩放 这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示； (2)各向同性缩放 因为图片扭曲后，估计会对后续CNN的训练精度有影响，于是作者也测试了“各向同性缩放”方案。有两种办法 A、先扩充后裁剪： 直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如上图(B)所示; B、先裁剪后扩充：先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如上图(C)所示; 对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0,第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。 （备注：候选框的搜索策略作者也考虑过使用一个滑动窗口的方法，然而由于更深的网络，更大的输入图片和滑动步长，使得使用滑动窗口来定位的方法充满了挑战。） CNN特征提取阶段： 1、算法实现 a、网络结构设计阶段 网络架构两个可选方案：第一选择经典的Alexnet；第二选择VGG16。经过测试Alexnet精度为58.5%，VGG16精度为66%。VGG这个模型的特点是选择比较小的卷积核、选择较小的跨步，这个网络的精度高，不过计算量是Alexnet的7倍。后面为了简单起见，我们就直接选用Alexnet，并进行讲解；Alexnet特征提取部分包含了5个卷积层、2个全连接层，在Alexnet中p5层神经元个数为9216、 f6、f7的神经元个数都是4096，通过这个网络训练完毕后，最后提取特征每个输入候选框图片都能得到一个4096维的特征向量。 b、网络有监督预训练阶段 （图片数据库：ImageNet ILSVC ） 参数初始化部分：物体检测的一个难点在于，物体标签训练数据少，如果要直接采用随机初始化CNN参数的方法，那么目前的训练数据量是远远不够的。这种情况下，最好的是采用某些方法，把参数初始化了，然后在进行有监督的参数微调，这里文献采用的是有监督的预训练。所以paper在设计网络结构的时候，是直接用Alexnet的网络，然后连参数也是直接采用它的参数，作为初始的参数值，然后再fine-tuning训练。网络优化求解时采用随机梯度下降法，学习率大小为0.001； C、fine-tuning阶段 （图片数据库： PASCAL VOC） 我们接着采用 selective search 搜索出来的候选框 （PASCAL VOC 数据库中的图片） 继续对上面预训练的CNN模型进行fine-tuning训练。假设要检测的物体类别有N类，那么我们就需要把上面预训练阶段的CNN模型的最后一层给替换掉，替换成N+1个输出的神经元(加1，表示还有一个背景) (20 + 1bg = 21)，然后这一层直接采用参数随机初始化的方法，其它网络层的参数不变；接着就可以开始继续SGD训练了。开始的时候，SGD学习率选择0.001，在每次训练的时候，我们batch size大小选择128，其中32个事正样本、96个事负样本。 关于正负样本问题： 一张照片我们得到了2000个候选框。然而人工标注的数据一张图片中就只标注了正确的bounding box，我们搜索出来的2000个矩形框也不可能会出现一个与人工标注完全匹配的候选框。因此在CNN阶段我们需要用IOU为2000个bounding box打标签。如果用selective search挑选出来的候选框与物体的人工标注矩形框（PASCAL VOC的图片都有人工标注）的重叠区域IoU大于0.5，那么我们就把这个候选框标注成物体类别（正样本），否则我们就把它当做背景类别（负样本）。 （备注： 如果不针对特定任务进行fine-tuning，而是把CNN当做特征提取器，卷积层所学到的特征其实就是基础的共享特征提取层，就类似于SIFT算法一样，可以用于提取各种图片的特征，而f6、f7所学习到的特征是用于针对特定任务的特征。打个比方：对于人脸性别识别来说，一个CNN模型前面的卷积层所学习到的特征就类似于学习人脸共性特征，然后全连接层所学习的特征就是针对性别分类的特征了） 2. 疑惑点： CNN训练的时候，本来就是对bounding box的物体进行识别分类训练，在训练的时候最后一层softmax就是分类层。那么为什么作者闲着没事干要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练svm分类器？ 这个是因为svm训练和cnn训练过程的正负样本定义方式各有不同，导致最后采用CNN softmax输出比采用svm精度还低。事情是这样的，cnn在训练的时候，对训练数据做了比较宽松的标注，比如一个bounding box可能只包含物体的一部分，那么我也把它标注为正样本，用于训练cnn；采用这个方法的主要原因在于因为CNN容易过拟合，所以需要大量的训练数据，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松(IOU只要大于0.5都被标注为正样本了)；然而svm训练的时候，因为svm适用于少样本训练，所以对于训练样本数据的IOU要求比较严格，我们只有当bounding box把整个物体都包含进去了，我们才把它标注为物体类别，然后训练svm，具体请看下文。 SVM训练、测试阶段 训练阶段： 这是一个二分类问题，我么假设我们要检测车辆。我们知道只有当bounding box把整量车都包含在内，那才叫正样本；如果bounding box 没有包含到车辆，那么我们就可以把它当做负样本。但问题是当我们的检测窗口只有部分包含物体，那该怎么定义正负样本呢？作者测试了IOU阈值各种方案数值0,0.1,0.2,0.3,0.4,0.5。最后通过训练发现，如果选择IOU阈值为0.3效果最好（选择为0精度下降了4个百分点，选择0.5精度下降了5个百分点）,即当重叠度小于0.3的时候，我们就把它标注为负样本。一旦CNN f7层特征被提取出来，那么我们将为每个物体类训练一个svm分类器。当我们用CNN提取2000个候选框，可以得到2000*4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096*N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，就可以得到结果了。 得到的特征输入到SVM进行分类看看这个feature vector所对应的region proposal是需要的物体还是无关的实物(background) 。 排序，canny边界检测之后就得到了我们需要的bounding-box。 再回顾总结一下：整个系统分为三个部分：1.产生不依赖与特定类别的region proposals，这些region proposals定义了一个整个检测器可以获得的候选目标2.一个大的卷积神经网络，对每个region产生一个固定长度的特征向量3.一系列特定类别的线性SVM分类器。 位置精修： 目标检测问题的衡量标准是重叠面积：许多看似准确的检测结果，往往因为候选框不够准确，重叠面积很小。故需要一个位置精修步骤。 回归器：对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。 输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。 训练样本：判定为本类的候选框中和真值重叠面积大于0.6的候选框。 测试阶段： 使用selective search的方法在测试图片上提取2000个region propasals ，将每个region proposals归一化到227x227，然后再CNN中正向传播，将最后一层得到的特征提取出来。然后对于每一个类别，使用为这一类训练的SVM分类器对提取的特征向量进行打分，得到测试图片中对于所有region proposals的对于这一类的分数，再使用贪心的非极大值抑制（NMS）去除相交的多余的框。再对这些框进行canny边缘检测，就可以得到bounding-box(then B-BoxRegression)。 （非极大值抑制（NMS）先计算出每一个bounding box的面积，然后根据score进行排序，把score最大的bounding box作为选定的框，计算其余bounding box与当前最大score与box的IoU，去除IoU大于设定的阈值的bounding box。然后重复上面的过程，直至候选bounding box为空，然后再将score小于一定阈值的选定框删除得到这一类的结果（然后继续进行下一个分类）。作者提到花费在region propasals和提取特征的时间是13s/张-GPU和53s/张-CPU，可以看出时间还是很长的，不能够达到及时性。 完。 本文主要整理自以下文章： RCNN学习笔记(0):rcnn简介 RCNN学习笔记(1):Rich feature hierarchies for accurate object detection and semantic segmentation RCNN学习笔记(2):Rich feature hierarchies for accurate object detection and semantic segmentation 《Rich feature hierarchies for Accurate Object Detection and Segmentation》 《Spatial 《Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》","link":"/2024/05/50e3f72dd70c.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 工业化本身就是极大偶然，资本主义是后世追加的，如果没有工业化也不存在资本主义一说，只有封建主义，工业化不是人类发展的必然方向，只是一个偶发事件。 ^a0732981 这个世界不可能全部进入工业化，只有部分国家可以工业化，因为工业化需要市场，资源供给和技术，而资本的利润需要收割，工业化国家的矛盾需要外部化，这个不是制度、意识形态或者道德问题，这个是工业化的本质问题，扩大生产必然带来市场扩张需求，压低资源价格需求和技术升级需求，最后只能走入帝国争霸，大多数人口和国家只能是其它工业化片区的外围。残酷的世界真相 ^21631b40 新自由主义后形成的后发国家港口型工业区，那不是这些后发国家的，这个道理这么难懂吗？搞工业和搞工业化不是一个概念，工业化是社会革命为前提，工业谁都能搞，两码事，这些外资控制的工业他的脐带在工业化国家，不在这些后发国家 ^1cafc216 当然先发展的工业化国家倒是有掉沟里的风险的，一旦几项要素不匹配了，或者缺了，那就没办法继续玩了，工业化没有真正的完成时，只有进行时，一旦滚不起来，停了就死。只有死亡才会落地的鸟 ^e52e2cf8 Content简单说吧，还是有朋友纠结后发国家的工业化问题或者叫追赶问题第一，==工业化本身就是极大偶然，资本主义是后世追加的，如果没有工业化也不存在资本主义一说，只有封建主义，工业化不是人类发展的必然方向，只是一个偶发事件。==第二，==这个世界不可能全部进入工业化，只有部分国家可以工业化，因为工业化需要市场，资源供给和技术，而资本的利润需要收割，工业化国家的矛盾需要外部化，这个不是制度、意识形态或者道德问题，这个是工业化的本质问题，扩大生产必然带来市场扩张需求，压低资源价格需求和技术升级需求，最后只能走入帝国争霸，大多数人口和国家只能是其它工业化片区的外围。==第三，==新自由主义后形成的后发国家港口型工业区，那不是这些后发国家的，这个道理这么难懂吗？搞工业和搞工业化不是一个概念，工业化是社会革命为前提，工业谁都能搞，两码事，这些外资控制的工业他的脐带在工业化国家，不在这些后发国家==，严格意义上说，只有中国透过地缘博弈和高维组织度完成了自主工业化，韩国算半个，即使如此我们在过去某两段时间内也有很强的外资控制属性，当然因为本身工业体系和主权的完整有惊无险的走过去了。第四，==当然先发展的工业化国家倒是有掉沟里的风险的，一旦几项要素不匹配了，或者缺了，那就没办法继续玩了，工业化没有真正的完成时，只有进行时，一旦滚不起来，停了就死。==","link":"/2024/05/bf8c6411fb14.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 因此，整个demo的核心实际上是VisualizationDemo。 模型处理输入得到输出predictions=self.predictor(image)，predictions就是模型(刚刚的self.predictor)输出的结果。阅读机器学习、深度学习代码最重要的就是追踪这类模型处理数据的代码，因为这类代码是理解整体计算模型的关键。 在predictor.py9-12行的import部分，我们可以学习到很多架构深度学习项目的规范、设计方法，在不同的文件夹中，我们往往会通过功能将不同的模块分开包装。例如在predictor.py中体现的： .data：处理数据相关的类和方法 .engine：对训练、预测逻辑的整体包装，类似于对整体Pipeline的定义，常见于大型项目 .utils：应该是utilities的简写，一般用来放置常用的工具模块，例如在这里体现出来的可视化部分 总之，对于越大型的项目来说，合理的分区、包装就越有必要，因为这可以从软件工程角度节省大量用来理解、开发、查错(Debug)的成本。在自己的很多小项目中，合理地使用类似的方法也能有效地提升项目质量。 训练代码是tools/train_net.py if __name__ == '__main__'的部分(这里是代码运行的接口)，可以看到detectron2的结构是利用launch运行了main函数中的内容。如果我们不关心分布式训练的部分(即在distributed的作用域的部分)，那么main函数的逻辑相当简单：得到模型和运行的参数(在参数cfg中)。利用定义好的类Trainer，通过传入cfg参数可以定义出模型，后面的部分均通过Trainer里面的方法都可以实现，例如train()顾名思义就是做训练的，test()就是测试的，build_model()就是创建模型的。很有意思的是,过去的detectron2没有封装invoke_main.不知道为什么要封装这么个东西 在Trainer的定义中我们发现它是一个继承自engine.DefaultTrainer的子类，而我们通过上面对main函数的分析发现Trainer的主要功能其实都来自于DefaultTrainertrainer看engine.DefaultTrianer就行 查看文件名字和每个文件上面__all__的部分可以大致猜测出它们之间相互引用的关系和每个文件主要负责的部分 defaults.py包含了我们在train_net.py中见到的DefaultTrainer，也大多是在import别人 launch.py中的launch顾名思义是让算法开始运行的代码，我们浏览一下它最主要的函数launch，根据它的参数num_machines、machine_rank可得知它是负责分布式训练的代码，又有参数中main_func，可以知道launch不涉及detectron2的实际功能分布式训练,不用管 我们清晰了engine部分的层次关系。具体而言，我们按照如下的顺序阅读代码 train_loop.py hook.py defaults.py HookBase是Hook的基类，其中实现了方法before_step、before_train和after_step、after_train，其主要的作用是在真正做训练之前，做好每一步的准备工作。针对不同的Trainer可以使用不同的Hook。Hook翻译过来叫做“钩子”，所以我们可以形象地理解成Hook像在训练首尾的两个钩子一样挂着负责训练的Trainer。 在TrainerBase中定义了多个Hook，并且在Trainer的before_step、after_step等函数中可以看到需要执行每一个Hook在训练之前的准备动作HookBase.before_step、训练之后的收尾动作HookBase.after_step。具体的训练过程非常正常，就是按照iteration的数量运行before_step、run_step、after_step三个函数。在 Python 中，hook通常是指在特定时刻自动执行的函数。 在SimpleTrainer中作者实现了一种最基本的训练神经网络的流程，它是作为上一段中TrainerBase的子类出现的。它最主要的工作就是将TrainerBase中没有实现的run_step方法实现。事实上，在SimpleTrainer中实现的过程也是最通用的训练过程： iter(dataloader)读取数据 loss_dict = self.model(data)计算每个batch的loss self.optimizer.zero_grad、losses.backward()、self.optimizer.step()实现训练的过程 通过统一的结构_write_metrics记录、打印计算的指标。 继承HookBase定义在训练前的准备工作、训练后的收尾工作要怎么做 继承SimpleTrainer或者TrainerBase定义自己的训练逻辑继承自HookBase,负责before_step、after_step继承自SimpleTrainer,负责run_step hook.py的主要内容就是针对深度学习训练、测试过程中的不同需求，定义了很多个不同的Hook，用来处理训练之前、之后需要准备、收尾的工作。 Hook的实现也都和自己的具体功能有关，会涉及到一些细节，在后面需要考虑这些细节的时候我们自然会涉及到它们。但是这些Hook的实现都遵循着统一的设计逻辑——回顾HookBase，它包含四种方法before_step、after_step、before_train、after_train，只要我们想要的Hook需要在其中某一个部分做工作，那么只需要定义一个函数的实现即可。统一的设计原则 在深度学习的任务中，如何清晰简洁地定义每一步训练之前、之后的上下文和额外操作是一件非常重要但是麻烦的事情。在detectron2的hook设计中，它通过简单统一的一个接口就将这一切统一到了一起，是一个非常有创意、管用的设计。 DefaultTrainer继承自SimpleTrainer，它在之前的基础上增加了一些常见的特性，使得DefaultTrainer几乎是一个完整的能用来训练神经网络的框架了。 它主要增加了如下的几个部分： 通过参数构建模型(model)、加载训练数据(DataLoader)、优化器(Optimizer)、学习率的变化规则(Scheduler)。 创建常见的Hook(在上一部分我们已经分析了Hook是什么，它们可以处理每次训练前后的准备、收尾工作)。 加载、存储网络中间参数，也就是CheckPoint功能。 训练完全继承自SimpleTrainer，可见super().train() DefaultTrainer和SimpleTrainer不同的部分在于它构建模型、数据集等的部分，可以看到DefaultTrainer都是调用已有的build_xxx函数实现的。其次看创建Hook的部分，在__init__里面它是通过self.register_hooks(self.build_hooks())实现的。在self.build_hooks()里面它构建了在hook.py中已经实现的三种最常见的Hook，包括计算时间的、调整学习率的和计算BatchNorm的统计量的。 Content我自己阅读detectron2主要是出于下面两点原因： 最近一年的经历越发让我意识到工程能力——特别是在复杂的需求下可以做好的系统设计，在每个模块能写出清晰简洁代码的软件工程能力的重要性。所以我选择把detectron2作为一个绝好的学习范本。 Object Detection(物体检测)是计算机视觉中非常基础重要的一个任务，所以我有必要通过学习detectron2的代码弄清楚这个任务一些重要的实现细节。 但是当我写作阅读笔记的时候，我产生了新的动机，因为写出来到知乎这个平台上的文字和写给我自己的文字终究是不同的。我的新动机就是： 帮助一位深度学习初学者学会如何阅读一个开源深度学习项目、一个Pytorch项目。 帮助自己和任意的一位初学者思考项目中一些独特的设计在软件工程上究竟有怎样的好处，这样来帮助自己写出更好的项目。 不过在真正阅读这篇文章之前，还是需要具备一些基本知识的： Python的基本使用和Pytorch的基础用法。 神经网络训练的基本技巧，或者看过相关博客文章了解相关概念。 Object Detection的基本算法RCNN、Fast-RCNN、Faster-RCNN，或者看过相关文章，了解相关概念。 如果你已经做好了一切准备，就让我们一起踏上这段探索的旅程吧哈哈哈！ 庞子奇：Detectron2 代码学习 1 — 整体结构 (本篇) 2. 庞子奇：Detectron2代码学习2 — 检测模型实现 3.庞子奇：Detectron2代码学习3 — 数据加载 4. (计划中) 模型实现细节与其它设计 1. 整体结构1.1 Demo想要高效地阅读代码需要摸准它的主体结构，而找到代码的主体结构就得从它的使用方式看起。所以我们首先关注Detectron2的demo部分。在demo中主要包括两个文件，其中demo.py是代码的主要运行部分。demo.py的运行过程依靠predictor.py中的VisualizationDemo，其主要功能是提供了在输入图片/视频上运行Detectron2模型的接口，例如run_on_image在图片上运行，run_on_video在视频上运行。 12341. 根据参数和config文件创建模型、输入2. 利用VisualizationDemo的run_on_image、run_on_video接口处理输入图片/视频3. 利用opencv-python的专用函数，记录或者显示detectron处理后的图片/视频 ==因此，整个====demo====的核心实际上是====VisualizationDemo====。== VisualizationDemo的逻辑也很清楚，我们首先关注__init__部分，这里是整个类的初始化部分，在这里self.predictor顾名思义：它是根据输入图片得到预测结果的模块。在self.run_on_image中展示了用model在给定图片(image参数)上做预测的逻辑。 ==模型处理输入得到输出====predictions=====self.predictor(image)====，====predictions====就是模型(刚刚的====self====.predictor====)输出的结果。阅读机器学习、深度学习代码最重要的就是追踪这类====模型处理数据====的代码，因为这类代码是理解整体====计算模型====的关键。== 在visualizer中作者可以根据不同的输出模式(比如panoptic_seg、sem_seg)对图片做不同方式的可视化，其中的细节我们暂时先不追究。 在run_on_video和AsyncPredictor中detectron2针对视频和多线程的情况进行了实现，因为我们的重点在于学习整个detectron2的写法，所以暂时不对这些细节进行讨论，感兴趣/对这类情况有需要可以自行学习。 ==在====predictor====.py====9-12行的====import====部分，我们可以学习到很多架构深度学习项目的规范、设计方法，在不同的文件夹中，我们往往会通过功能将不同的模块分开包装。例如在====predictor====.py====中体现的：== ==.====data====：处理数据相关的类和方法== ==.engine====：对训练、预测逻辑的整体包装，类似于对整体Pipeline的定义，常见于大型项目== ==.utils====：应该是====utilities====的简写，一般用来放置常用的工具模块，例如在这里体现出来的可视化部分== ==总之，对于越大型的项目来说，合理的分区、包装就越有必要，因为这可以从软件工程角度节省大量用来理解、开发、查错(Debug)的成本。在自己的很多小项目中，合理地使用类似的方法也能有效地提升项目质量。== 1.2 训练概览 train_net.py在demo中我们看到了在图片上做infer是怎样的结构，那么训练要怎么做呢？通过阅读说明文档可以发现==训练代码是====tools/train_net.====py==，所以我们下一步就是分析train_net.py是如何实现的。 train_net.py在文件开始的部分import了一堆东西，因为我们是自顶向下(Top-Down)地对项目进行阅读和理解，所以可以暂时不管这部分的代码具体在做什么。在整个文件中，我们直接跳转到==if== ==__name__== ==== '====__main__===='====的部分(这里是代码运行的接口)，可以看到====detectro====n2====的结构是利用====launch====运行了====main====函数中的内容。如果我们不关心分布式训练的部分(即在distributed的作用域的部分)，那么====main====函数的逻辑相当简单：得到模型和运行的参数(在参数cfg中)。利用定义好的类====Trainer====，通过传入====cfg====参数可以定义出模型，后面的部分均通过====Trainer====里面的方法都可以实现，例如====train====()====顾名思义就是做训练的，====test====()====就是测试的，====build_model====()====就是创建模型的。== ==在====Trainer====的定义中我们发现它是一个继承自====engine====.DefaultTrainer====的子类，而我们通过上面对====main====函数的分析发现====Trainer====的主要功能其实都来自于====DefaultTrainer==，因此我们的主要任务就是在engine中弄清楚负责训练的模块是如何构建与运行的。 1.3 Engine在engine中，detectron2定义了训练、测试的Pipeline。在demo中我们也看到了来自engine的predictor能够在给定的图片上用模型做预测。对于一个机器学习/深度学习的项目来说，他必须要完成、也是主要完成的事情，就是针对给定的模型进行训练与测试。因此，按照自顶向下的原则认识detectron2就需要首先研究engine中是怎样实现的。 在engine中有多个py文件，==查看文件名字和每个文件上面====__all__====的部分可以大致猜测出它们之间相互引用的关系和每个文件主要负责的部分==。==defaults====.py====包含了我们在====train_net====.py====中见到的====DefaultTrainer====，也大多是在import别人==，==launch====.py====中的====launch====顾名思义是让算法开始运行的代码，我们浏览一下它最主要的函数====launch====，根据它的参数====num_machines====、====machine_rank====可得知它是负责分布式训练的代码，又有参数中====main_func====，可以知道====launch====不涉及====detectro====n2====的实际功能==，所以我们跳过launch.py。进一步考察，我们发现hook.py引用了train_loop.py中的内容，因此==我们清晰了====engine====部分的层次关系。具体而言，我们按照如下的顺序阅读代码== ==train_loop====.py== ==hook====.py== ==defaults====.py== 1.3.1 train_loop.pytrain_loop中作者实现了从简单到复杂的三个类，分别在不同的层次上抽象了对训练过程的需要和实现，包括HookBase、TrainBase、SimpleTrainer。通过名字上的Base和Simple可以这些只是实际被使用的类的基类，但是我们还是要首先针对这三个类进行分析。 这三个模块的注释都非常详尽，阅读之后可以对模块的构成、作用有初步的了解，在这里仅做简要的解释。==HookBase====是====Hook====的基类，其中实现了方法====before_step====、====before_train====和====after_step====、====after_train====，其主要的作用是在真正做训练之前，做好每一步的准备工作。针对不同的====Trainer====可以使用不同的====Hook====。Hook翻译过来叫做“钩子”，所以我们可以形象地理解成Hook像在训练首尾的两个钩子一样挂着负责训练的====Trainer====。== ==在====TrainerBase====中定义了多个====Hook====，并且在====Trainer====的====before_step====、====after_step====等函数中可以看到需要执行每一个====Hook====在训练之前的准备动作====HookBase====.====before_step====、训练之后的收尾动作====HookBase====.====after_step====。具体的训练过程非常正常，就是按照iteration的数量运行====before_step====、====run_step====、====after_step====三个函数。== ==在====SimpleTrainer====中作者实现了一种最基本的训练神经网络的流程，它是作为上一段中====TrainerBase====的子类出现的。它最主要的工作就是将====TrainerBase====中没有实现的====run_step====方法实现。事实上，在====SimpleTrainer====中实现的过程也是最通用的训练过程：== ==iter====(dataloader)====读取数据== ==loss_dict== === self.model(====data====)====计算每个batch的loss== ==self====.optimizer====.zero_grad====、====losses====.backward====()====、====self====.optimizer====.step====()====实现训练的过程== ==通过统一的结构====_write_metrics====记录、打印计算的指标。== 综上，我们了解了detectron2中engine的框架，和我们使用时需要注意的层次： ==继承====HookBase====定义在训练前的准备工作、训练后的收尾工作要怎么做== ==继承====SimpleTrainer====或者====TrainerBase====定义自己的训练逻辑== 1.3.2 hook.py==hook====.py====的主要内容就是针对深度学习训练、测试过程中的不同需求，定义了很多个不同的====Hook====，用来处理训练之前、之后需要准备、收尾的工作。==其中包括了计算时间的IterationTimer、按一定周期输出结果的PeriodicWriter、调整学习率的LRScheduler等。 其它的==Hook====的实现也都和自己的具体功能有关，会涉及到一些细节，在后面需要考虑这些细节的时候我们自然会涉及到它们。但是这些====Hook====的实现都遵循着统一的设计逻辑——回顾====HookBase====，它包含四种方法====before_step====、====after_step====、====before_train====、====after_train====，只要我们想要的====Hook====需要在其中某一个部分做工作，那么只需要定义一个函数的实现即可。== ==在深度学习的任务中，如何清晰简洁地定义每一步训练之前、之后的上下文和额外操作是一件非常重要但是麻烦的事情。在====detectro====n2====的====hook====设计中，它通过简单统一的一个接口就将这一切统一到了一起，是一个非常有创意、管用的设计。== 1.3.3 defaults.py有了train_loop.py中的基本理解，我们就可以深入到defaults.py了，在这里定义了在train_net.py中使用的基本模块DefaultTrainer。 ==DefaultTrainer====继承自====SimpleTrainer====，它在之前的基础上增加了一些常见的特性，使得====DefaultTrainer====几乎是一个完整的能用来训练神经网络的框架了。==它主要增加了如下的几个部分： ==通过参数构建模型(model)、加载训练数据(DataLoader)、优化器(Optimizer)、学习率的变化规则(Scheduler)。== ==创建常见的Hook(在上一部分我们已经分析了Hook是什么，它们可以处理每次训练前后的准备、收尾工作)。== ==加载、存储网络中间参数，也就是CheckPoint功能。== ==训练完全继承自====SimpleTrainer====，可见====super====()====.train()== ==DefaultTrainer====和====SimpleTrainer====不同的部分在于它构建模型、数据集等的部分，可以看到====DefaultTrainer====都是调用已有的====build_xxx====函数实现的。其次看创建Hook的部分，在====__init__====里面它是通过====self.register====_hooks(====self====.====build_hooks====()====)====实现的。在====self====.build_hooks()====里面它构建了在====hook====.py====中已经实现的三种最常见的Hook，包括计算时间的、调整学习率的和计算BatchNorm的统计量的。== 1.4 小结综上，我们已经清晰了detectron2的整体架构与逻辑，特别是它如何为训练过程的组件和函数构建了统一的接口Trainer、Hook。但是我们在这个过程中也没有深究一些细节，比如说如何构建数据集、如何构建模型、如何构建优化器等等，在后面我们将对它们进行详细分析。","link":"/2024/06/dfcd5569ee2e.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 首先介绍detectron2中使用的registry机制 Trainer中初始化模型调用的接口是build_model函数，通过modeling/__init__.py可以知道它是在modeling/meta_arch/build.py中定义的。但是在阅读build.py的过程中，我们发现它使用了一个叫做Registry的东西——那么什么是Registry呢？ Registry机制来自于FaceBook计算机视觉研究组的常用函数库fvcore，其中Registry的源代码和解读可见registry。它的主要作用是提供了用字符串调用类方法的接口，具体的函数是registry中的get方法。个人感觉registry.get()非常像一个getattr方法，它能够通过字符串访问类的方法。 例如我们有一个具体的网络结构，定义在modeling/meta_arch/rcnn.py中的GeneralizedRCNN。注意在它的定义上方有一个修饰器@META_ARCH_REGISTRY.register()，意思就是把GeneralizedRCNN注册到META_ARCH_REGISTRY中。那么在modeling/meta_arch/build.py中的model = META_ARCH_REGISTRY.get(meta_arch)(cfg)中，只要我们设置meta_arch为GeneralizedRCNN，那么META_ARCH_REGISTRY.get(meta_arch)就调用了GeneralizedRCNN方法，也就因此初始化了模型。 指定名字来调用模型用@ 修饰器在META_ARCH_REGISTRY中注册再在参数中写入名称即可实现初始化* registry的几个要点 创建一个registry，设置可能的调用的类的名字 对于想加入到registry中的类，在定义的时候通过修饰器指定 调用类方法的时候通过get(name) 通过fvcore中的源代码，我们可以知道如何写python修饰器。 Faster-RCNN的结构主要包含如下几个部分，而这几个部分也是GeneralizedRCNN在初始化部分的输入： backbone：从图片提取特征表示的卷积神经网络结构，比如说ResNet。 proposal_generator：从图片的特征预测“哪里可能有物体” roi_head：以proposal_generator部分预测的有物体区域为基础，预测物体的类别和检测框坐标 与__init__功能相似的是from_config函数，它用config文件初始化模型，通过这个函数我们知道了实际构造backbone、proposal_generator和roi_head的函数分别都是来自对应文件夹的build_xxx函数。 RCNN模型处理函数的过程，我们主要关注forward函数，主要包括如下步骤： 利用preprocess_image对输入的图片做初始化，特别是其中会对图片做归一化(normalization)，并将图片放到指定的设备(device，也就是gpu)上。 在self.backbone(images.tensor)一句，我们可以得到这个图片经过卷积神经网络处理得到的feature。 如果我们没有告诉rcnn已经被发现的物体有哪些(detected_instances is None)，它就需要自己寻找哪些位置可能有物体出现，并通过self.proposal_generator(images, features)得到可能出现物体的位置proposals。 得到了可能出现物体的区域，我们就用self.roi_heads(images, features, proposals)，结合feature的信息对roi区域进行处理，得到每个区域的结果。值得注意的是，如果我们提供了目标结果(gt_instances)，那么roi_head计算的就是Loss了。 Content合集目录： 庞子奇：Detectron2 代码学习 1 — 整体结构 2. Detectron2 代码学习 2 — 检测模型实现 (本篇) 3. 庞子奇：Detectron2代码学习3 — 数据加载 4. (计划中) 模型实现细节与其它设计 在这部分中我们将沿着刚才分析的训练结构，尝试分析如何构建detectron2的模型。为了实现这一点，我们会==首先介绍====detectro====n2====中使用的====registry====机制==，之后进一步分析 2.1 Registry机制与build_model==Trainer====中初始化模型调用的接口是====build_model====函数，通过====modeling/====__init__====.====py====可以知道它是在====modeling/met====a_arch====/build.py====中定义的。但是在阅读====build====.py====的过程中，我们发现它使用了一个叫做====Registry====的东西——那么什么是====Registry====呢？== ==Registry====机制来自于FaceBook计算机视觉研究组的常用函数库====fvcore====，其中====Registry====的源代码和解读可见====registry====。它的主要作用是提供了用字符串调用类方法的接口，具体的函数是====registry====中的====get====方法。个人感觉====registry.====get====()====非常像一个====getattr====方法，它能够通过字符串访问类的方法。== 接下来我们通过build_model的具体的用例来体会一下Registry机制的使用。==例如我们有一个具体的网络结构，定义在====modeling/met====a_arch====/rcnn.py====中的====GeneralizedRCNN====。注意在它的定义上方有一个修饰器====@====META_ARCH_REGISTRY====.====register====()====，意思就是把====GeneralizedRCNN====注册到====MET====A_ARCH====_REGISTRY====中。那么在====modeling/met====a_arch====/build.py====中的====model = MET====A_ARCH====_REGISTRY.get(met====a_arch====)(cfg)====中，只要我们设置====met====a_arch====为====GeneralizedRCNN====，那么====MET====A_ARCH====_REGISTRY.get(met====a_arch====)====就调用了====GeneralizedRCNN====方法，也就因此初始化了模型。== 最后我们回顾和总结一下==registry====的几个要点== ==创建一个====registry====，设置可能的调用的类的名字== ==对于想加入到====registry====中的类，在定义的时候通过修饰器指定== ==调用类方法的时候通过====get====(name)== ==通过====fvcore====中的源代码，我们可以知道如何写====python====修饰器。== 由此，我们弄清楚了build_model的实现和registry的机制。 2.2 RCNN结构模型在分析模型建构的过程中，我们主要看经典模型Faster-RCNN，在modeling/meta_arch/rcnn.py。==Faster-RCNN====的结构主要包含如下几个部分，而这几个部分也是====GeneralizedRCNN====在初始化部分的输入：== ==backbone====：从图片提取特征表示的卷积神经网络结构，比如说ResNet。== ==proposal_generator====：从图片的特征预测“哪里可能有物体”== ==roi_head====：以====proposal_generator====部分预测的有物体区域为基础，预测物体的类别和检测框坐标== ==与====__init__====功能相似的是====from_config====函数，它用config文件初始化模型，通过这个函数我们知道了实际构造backbone、proposal_generator和roi_head的函数分别都是来自对应文件夹的====build_xxx====函数。== 在这之后我们继续考察==RCNN====模型处理函数的过程，我们主要关注====forward====函数，主要包括如下步骤：== ==利用====preprocess_image====对输入的图片做初始化，特别是其中会对图片做归一化(normalization)，并将图片放到指定的设备(device，也就是gpu)上。== ==在====self====.backbone====(====images====.tensor====)====一句，我们可以得到这个图片经过卷积神经网络处理得到的====feature====。== ==如果我们没有告诉====rcnn====已经被发现的物体有哪些(====detected_instances== ==is== ==None====)，它就需要自己寻找哪些位置可能有物体出现，并通过====self.proposal====_generator(====images====,== ==features====)====得到可能出现物体的位置====proposals====。== ==得到了可能出现物体的区域，我们就用====self.roi====_heads(====images====,== ==features====,== ==proposals====)====，结合feature的信息对roi区域进行处理，得到每个区域的结果。值得注意的是，如果我们提供了目标结果(====gt_instances====)，那么====roi_head====计算的就是====Loss====了。== 综上，我们知道了RCNN的架构和运行方式，接下来我们会针对它的组件，backbone、proposal_generator和roi_head分别进行研究。 2.3 backbonebackbone的类仍然是采用registry的模式，这样方便后继的人对于库进行修改。对于backbone的分析其实不用非常具体，因为BackBone就是最普通的卷积神经网络。但是在detectron2的具体实现中，有下面几点可以简单提一下： detectron2的backbone均基于modeling/backbone/backbone.py中的Backbone基类，它在nn.Module上做了简单的包装，主要是针对物体检测和实例分割的特殊需求，比如说： size_divisibility：因为卷积神经网络涉及到降采样，所以会对输入数据产生要求。例如降采样8倍的网络，其输入的长宽也必须是8的倍数。 output_shape：返回输出的Feature Map的形状是怎样的，方便后续的proposal_generator和roi_head进行处理。 以ResNet的实现为例，它的实现方法和torchvision中对ResNet的实现方式非常像(或者说基本是一样的)，只是在build_resnet中制作了生成resnet模型的统一接口。 2.4 proposal_generator与backbone相同，proposal_generator也是通过build_proposal_generator的接口创建“从图片的特征图提出可能产生物体的区域”的网络。暂时detectron2实现了两种proposal_generator，一种是Region Proposal Generator，也就是代码库中的rpn；另一种是Rotated Region Proposal Network，也就是rrpn。在下面，我们主要分析RPN的实现。 2.4.1 RPN HeadRPN作为proposal_generator的一种并不是最细分的抽象层次，最细分的抽象层次是RPN Head，也就是RPN用怎样的结构处理输入的特征图。这也就是在modeling/proposal_generator/rpn.py中RPN_HEAD_REGISTRY的由来。 在这里，detectron2为我们实现了一个典型的RPN Head——StandardRPNHead。它首先用一个3x3的卷积处理输入的特征图，之后分别用两个1x1的卷积处理得到：objectness_logits，有多大可能是一个物体；anchor_deltas：如何生成一个合理的锚定框(Anchor Box)。在它的输出中，objectness_logits是一个的张量，其中是每个Batch的图片个数，是在每个空间位置上设定的锚定框个数；anchor_deltas和objectness_logits是一一对应的，只不过它的输出变成了，增加了对锚定框位置的描述。 2.4.2 RPN的forward过程尽管在上一段中我们清楚了RPN Head是如何构成的、它的工作原理是怎样的，但是我们对于RPN最关键的部分：它是如何预测锚定框的、它又是如何训练的仍然一无所知。为了实现这个目的，我们需要仔细研究RPN的实现，最主要的就是它forward的过程。 RPN的输入是图片的特征，它通过如下步骤进行处理： 首先用anchor_generator生成了anchor的所有可能位置。我们会在稍后详细分析anchor_generator的实现，在这里我们可以把它的输出暂时理解为“一个列表，列表包含了几何意义上的所有可能锚定框”。 其次通过刚刚分析过的rpn_head为每个anchor的位置预测了存在物体的可能性和框的可能位置。 如果在输入中提供了真实的锚定框信息，也就是gt_instances不是None，那么会通过self.label_and_sample_anchors制作属于“锚定框”的数据集，并由self.losses计算RPN部分的损失函数，以训练RPN Head。 通过self.predict_proposals可以通过之前得到的每个位置的：是否有物体、回归的框位置，得到可能存在物体的区域，也就是proposals，至此，实现了RPN处理图片的forward过程。 接下来，我们关注下面几个部分的实现，分别是self.label_and_sample_anchors、self.losses和self.predict_proposals。 2.4.3 label_and_sample_anchors：处理真实框信息RPN Head的目标是对anchor_generator中提出的粗糙的锚定框进行分类，选取出真正可能存在物体的框，放弃不存在物体的框。那么为了训练RPN Head实现这一功能，我们就需要通过已知的物体框信息训练RPN Head对粗糙框进行分类：哪些是正样本(包含物体)、哪些是负样本(不包含物体)等等。而label_and_sample_anchors函数的目的就是制作一个训练RPN Head处理这类问题的数据集。 算法的主体思路是通过我们提出的框和实际框之间的IOU判定是正样本还是负样本。因此： 首先计算每个提出框与真实框之间的IOU，存储到match_quality_matrix。 其次，通过modeling/matcher.py/Matcher为这些框之间打Label。这部分的操作就是，如果IOU低于某个阈值(例如0.3)，那么Label为0，代表负样本；超过某个阈值(例如0.7)，那么Label为1，代表正样本；在两个阈值之间是难以判断的情况，为了避免对训练造成混淆，设置Label为-1，代表训练时可以忽略的样本。 根据每张图片中正样本的比例选取一部分正样本、负样本参与训练。其中正样本不应超过一个预设的比例(positive_fraction)，剩余的样本数量用负样本补齐。 返回的结果有两部分，第一部分是对应每个提出的锚定框的真实框坐标值，第二部分是这组对应关系的标签(Label)是怎样的。 这样，我们就得到了可以训练RPN Head的数据。 2.4.4 losses：计算损失函数通过观察losses的参数列表，我们就可以对它的逻辑略知一二。它的主要思路应该是通过objectness_logits和gt_label(回忆一下，在2.4.3中我们介绍了gt_label的含义)使得网络可以分辨哪片区域是有物体的，通过deltas和真实物体的框gt_bboxes使得网络能够得到物体的详细位置。 在实际的实现中也基本是按照这两部分进行的。“是否有物体”的判定这明显是一个二分类问题，所以通过binary_cross_entropy就可以训练。 针对回归物体位置的部分，在losses中提供了两种选择： 第一种是采用smooth_l1_loss，它的直观就是直接求预测值和实际值之间的差别作为Loss，它的做法就是直接求预测的框位置的Delta和真实框的Delta之间的差别。 第二种方式是采用Giou Loss，它的做法和第一种做法，即计算delta的差距，是相反的。它的直观是预测的Delta产生的框效果是怎样的，所以它会首先把预测的Delta转化成具体框的位置，之后与真正的框位置计算iou，那么iou越大说明预测的位置越准确。 综上，我们了解了在RPN部分的Loss计算。 2.4.5 predict_proposal：提取Proposal在这部分中，我们将来到RPN的最后一步，即如何得到物体的Proposal，利用用之前预测的objectness——是否有物体，和deltas——物体的位置？在这里我们重申一下得到Proposal的目的：为了细致地判断框内物体的类别和位置。 在predict_proposal中实现了提取proposal的全过程，主要包含如下步骤： 通过_decode_proposal将预测的deltas转化为实际的框位置 通过find_top_rpn_proposals找到其中最合适的预测结果 在这里，我们只对find_top_rpn_proposals进行讨论，它的实现在modeling/proposal_generator/proposal_utils.py。这个算法实际上就是实现了一个简单的筛选过程。它首先按照objectness抽取出分数最高的部分Proposal，值得注意的是，这部分的Proposal是足够多的，用机器学习的术语来解释就是“有很高的Recall”。那么这些Proposal中又如何进一步筛选呢？ 在筛选的过程中，最重要的就是NMS操作。在之前的Proposal中，存在很多框严重重叠的现象，这是因为在最开始提出Proposal的过程中，在同一个位置会有多个候选框出现，而这些候选框实际上代表的都是同一个物体。因此NMS操作应运而生，它的目的就是通过计算框之间的iou值，筛选掉这些实际上代表了同一物体的候选框。这部分的具体实现在layers/nms.py。在后面我们会对它进行具体分析。 经过上面的操作，我们就可以预测合理的Proposal，也就因此实现了对于proposal_generator模块的理解。 2.4.6 小结与讨论在这部分中我们不关心detectron2实现的具体细节，而是针对它的设计思想、设计逻辑进行一些总结和讨论。在detectron2的实现中，它首先将RPN本身的输入输出要弄清楚：输入是来自Backbone的特征表示，输出是哪些地点存在物体的Proposal。 其次，它将RPN按照功能分拆成如下多个部分，按照“从粗糙到细致”的顺序逐步完成了对Proposal的提取，从最开始的只要是一个位置就看做一个Proposal，到最终利用分数和IOU筛选出合理的Proposal。跳出RPN本身的实现，如果我们不考虑后面逐步筛选的步骤，那么只要我们有足够多的计算资源，其实是不会影响后面的训练效果的——因为我们完全可以把那些不包含物体的框设置成负样本不予考虑。这样的角度给我们的启示就是，其实我们完全可以重新对RPN的操作进行设计，增加或者减少对于Proposal的筛选，当然也可以改变筛选的方式，比如NMS的做法。不过无论我们怎么修改，其实都是在按照detectron2一种“链式筛选”的结构在做。 最后，毫无疑问，detectron2对于RPN在这样的实现方式给予了编程人员很大的修改自由度和简洁的抽象层次。尽管我们可能只有完整地了解了RPN的流程才会想到这样的实现方法，但是我们可以在未来设计算法的时候抓住“链式筛选”这样“由粗糙到细致”的算法模式，设计自己的接口和实现方式。 2.5 roi_heads2.5.1 结构简介回顾rcnn的结构，对roi_heads的调用出现的形式是results, _ = self.roi_heads(images, features, proposals, None)，也就是roi_heads处理Proposal，得到最终检测的结果；如果我们已经知道了proposal是怎样的，那么通过roi_heads_forward_with_given_boxes也可以实现检测。在了解了roi_heads的功能之后，我们来看它的实现，基本都是在modeling/roi_heads/里面。 在roi_head的__init__.py中可以看到detectron2提供了对多种任务的roi_head支持，例如box、mask和key_point，分别针对物体检测、实例分割和人体姿态估计。在我们的分析中，仅以物体检测的Box_head为例进行分析。构建roi_head的函数是在modeling/roi_heads/roi_heads.py的build_roi_heads。通过实现可以看到它也是通过REGISTRY方式进行构建。通过查阅config/defaults.py文件，我们知道了对于默认的Faster-RCNN使用的是Res5ROIHeads，所以我们重点研究它的实现。 2.5.2 ROIHeads基类：如何提供对ROI的训练数据在注释中作者解释了ROIHeads共有的逻辑： 在训练部分，在Proposal和实际框之间进行匹配，同时对Proposal进行采样 对Proposal的一片区域进行处理，得到该区域的特征 利用Feature针对我们的任务(检测/分割/…)进行预测 在ROIHeads基类中并没有对forward的逻辑进行实现，因为它与具体的任务相关，在BoxHead、MaskHead等模块内部自己实现。在基类中具体实现的是如何通过Ground Truth的样本和Proposal样本的列表创造对ROIHead的训练数据。通过对Res5ROIHeads的阅读可以发现实际得到使用的函数是label_and_sample_proposals。 首先，通过add_ground_truth_to_proposals可以提升Proposal的效果，特别是在训练刚刚开始的时候，RPN提供的Proposal可能质量很差，那么利用Ground Truth的数据可以保证正样本的存在。 其次，我们将Proposal和实际的框之间进行匹配，利用的函数是我们在RPN的label_and_sample_anchors中介绍的一样的方法。我们会计算每个Proposal与真实的框之间的IOU矩阵，通过proposal_matcher得到两两之间匹配的结果。进一步地，通过sample_proposals我们从所有的Proposal中提取出参与训练的Proposal。至此就基本实现了获取训练ROI的Proposal的步骤。 最后我们需要看一下sample_proposals的实现中需要注意的一个点。它利用subsample_labels从proposals中提出一定数量的样本训练，其中正样本不能超过一定的比例。关于负样本究竟具体会对训练结果产生怎样的影响，可以参考RCNN实验里的讨论。 2.5.3 Res5ROIHeadsRes5ROIHeads是默认使用的ROIHead，在它的forward函数中实现了对Proposal进行框预测和类别预测的过程。它(训练的)的主要流程是先通过对Proposal的采样制造训练数据。其次通过shared_roi_transform提取每个Proposal框中的特征表示。最后通过box_predictor得到每个Proposal内物体的类别和具体的框坐标。 其中，我们之前已经分析了如何在Proposal中采样得到训练样本，因此不再讨论。shared_roi_transform中主要用到了Roi_Align、Roi_Pool等操作，它们的重点在于这些模块的实现，因此我们在后面再进行讨论。在这里我们只需要知道ROIPool的功能就是：对于给定区域内的图片特征(Feature Map)，我们将其变成形状一定的这个Proposal的特征表示(Feature Vector)。在最后一步中，detectron2通过box_predictor利用每个Proposal内的特征表示预测物体的类别和准确的框坐标。在下面，我们简要分析box_predictor的工作过程。 box_predictor的主要流程是现在modeling/roi_heads/fast_rcnn.py/FastRCNNOutputLayers中。通过对__init__.py的阅读，我们可以发现box_predictor的核心在于两个线性层：cls_score、box_pred，分别负责预测物体的类别和回归框的坐标。它的工作流程在forward函数中其实相当简单，只需要把特征表示分别送入到cls_score和box_pred中，两个线性层就会分别把Logits和预测的框的Deltas输出出来。 综上，我们也基本了解了roi_heads的工作过程。 3. 成库","link":"/2024/05/1bfe150236ba.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 首先介绍detectron2中使用的registry机制 Trainer中初始化模型调用的接口是build_model函数，通过modeling/__init__.py可以知道它是在modeling/meta_arch/build.py中定义的。但是在阅读build.py的过程中，我们发现它使用了一个叫做Registry的东西——那么什么是Registry呢？ Registry机制来自于FaceBook计算机视觉研究组的常用函数库fvcore，其中Registry的源代码和解读可见registry。它的主要作用是提供了用字符串调用类方法的接口，具体的函数是registry中的get方法。个人感觉registry.get()非常像一个getattr方法，它能够通过字符串访问类的方法。 例如我们有一个具体的网络结构，定义在modeling/meta_arch/rcnn.py中的GeneralizedRCNN。注意在它的定义上方有一个修饰器@META_ARCH_REGISTRY.register()，意思就是把GeneralizedRCNN注册到META_ARCH_REGISTRY中。那么在modeling/meta_arch/build.py中的model = META_ARCH_REGISTRY.get(meta_arch)(cfg)中，只要我们设置meta_arch为GeneralizedRCNN，那么META_ARCH_REGISTRY.get(meta_arch)就调用了GeneralizedRCNN方法，也就因此初始化了模型。 指定名字来调用模型用@ 修饰器在META_ARCH_REGISTRY中注册再在参数中写入名称即可实现初始化* registry的几个要点 创建一个registry，设置可能的调用的类的名字 对于想加入到registry中的类，在定义的时候通过修饰器指定 调用类方法的时候通过get(name) 通过fvcore中的源代码，我们可以知道如何写python修饰器。 Faster-RCNN的结构主要包含如下几个部分，而这几个部分也是GeneralizedRCNN在初始化部分的输入： backbone：从图片提取特征表示的卷积神经网络结构，比如说ResNet。 proposal_generator：从图片的特征预测“哪里可能有物体” roi_head：以proposal_generator部分预测的有物体区域为基础，预测物体的类别和检测框坐标 与__init__功能相似的是from_config函数，它用config文件初始化模型，通过这个函数我们知道了实际构造backbone、proposal_generator和roi_head的函数分别都是来自对应文件夹的build_xxx函数。 RCNN模型处理函数的过程，我们主要关注forward函数，主要包括如下步骤： 利用preprocess_image对输入的图片做初始化，特别是其中会对图片做归一化(normalization)，并将图片放到指定的设备(device，也就是gpu)上。 在self.backbone(images.tensor)一句，我们可以得到这个图片经过卷积神经网络处理得到的feature。 如果我们没有告诉rcnn已经被发现的物体有哪些(detected_instances is None)，它就需要自己寻找哪些位置可能有物体出现，并通过self.proposal_generator(images, features)得到可能出现物体的位置proposals。 得到了可能出现物体的区域，我们就用self.roi_heads(images, features, proposals)，结合feature的信息对roi区域进行处理，得到每个区域的结果。值得注意的是，如果我们提供了目标结果(gt_instances)，那么roi_head计算的就是Loss了。 Content合集目录： 庞子奇：Detectron2 代码学习 1 — 整体结构 2. Detectron2 代码学习 2 — 检测模型实现 (本篇) 3. 庞子奇：Detectron2代码学习3 — 数据加载 4. (计划中) 模型实现细节与其它设计 2. Detectron2的Model部分在这部分中我们将沿着刚才分析的训练结构，尝试分析如何构建detectron2的模型。为了实现这一点，我们会==首先介绍====detectro====n2====中使用的====registry====机制==，之后进一步分析 2.1 Registry机制与build_model==Trainer====中初始化模型调用的接口是====build_model====函数，通过====modeling/====__init__====.====py====可以知道它是在====modeling/met====a_arch====/build.py====中定义的。但是在阅读====build====.py====的过程中，我们发现它使用了一个叫做====Registry====的东西——那么什么是====Registry====呢？== ==Registry====机制来自于FaceBook计算机视觉研究组的常用函数库====fvcore====，其中====Registry====的源代码和解读可见====registry====。它的主要作用是提供了用字符串调用类方法的接口，具体的函数是====registry====中的====get====方法。个人感觉====registry.====get====()====非常像一个====getattr====方法，它能够通过字符串访问类的方法。== 接下来我们通过build_model的具体的用例来体会一下Registry机制的使用。==例如我们有一个具体的网络结构，定义在====modeling/met====a_arch====/rcnn.py====中的====GeneralizedRCNN====。注意在它的定义上方有一个修饰器====@====META_ARCH_REGISTRY====.====register====()====，意思就是把====GeneralizedRCNN====注册到====MET====A_ARCH====_REGISTRY====中。那么在====modeling/met====a_arch====/build.py====中的====model = MET====A_ARCH====_REGISTRY.get(met====a_arch====)(cfg)====中，只要我们设置====met====a_arch====为====GeneralizedRCNN====，那么====MET====A_ARCH====_REGISTRY.get(met====a_arch====)====就调用了====GeneralizedRCNN====方法，也就因此初始化了模型。== 最后我们回顾和总结一下==registry====的几个要点== ==创建一个====registry====，设置可能的调用的类的名字== ==对于想加入到====registry====中的类，在定义的时候通过修饰器指定== ==调用类方法的时候通过====get====(name)== ==通过====fvcore====中的源代码，我们可以知道如何写====python====修饰器。== 由此，我们弄清楚了build_model的实现和registry的机制。 2.2 RCNN结构模型在分析模型建构的过程中，我们主要看经典模型Faster-RCNN，在modeling/meta_arch/rcnn.py。==Faster-RCNN====的结构主要包含如下几个部分，而这几个部分也是====GeneralizedRCNN====在初始化部分的输入：== ==backbone====：从图片提取特征表示的卷积神经网络结构，比如说ResNet。== ==proposal_generator====：从图片的特征预测“哪里可能有物体”== ==roi_head====：以====proposal_generator====部分预测的有物体区域为基础，预测物体的类别和检测框坐标== ==与====__init__====功能相似的是====from_config====函数，它用config文件初始化模型，通过这个函数我们知道了实际构造backbone、proposal_generator和roi_head的函数分别都是来自对应文件夹的====build_xxx====函数。== 在这之后我们继续考察==RCNN====模型处理函数的过程，我们主要关注====forward====函数，主要包括如下步骤：== ==利用====preprocess_image====对输入的图片做初始化，特别是其中会对图片做归一化(normalization)，并将图片放到指定的设备(device，也就是gpu)上。== ==在====self====.backbone====(====images====.tensor====)====一句，我们可以得到这个图片经过卷积神经网络处理得到的====feature====。== ==如果我们没有告诉====rcnn====已经被发现的物体有哪些(====detected_instances== ==is== ==None====)，它就需要自己寻找哪些位置可能有物体出现，并通过====self.proposal====_generator(====images====,== ==features====)====得到可能出现物体的位置====proposals====。== ==得到了可能出现物体的区域，我们就用====self.roi====_heads(====images====,== ==features====,== ==proposals====)====，结合feature的信息对roi区域进行处理，得到每个区域的结果。值得注意的是，如果我们提供了目标结果(====gt_instances====)，那么====roi_head====计算的就是====Loss====了。== 综上，我们知道了RCNN的架构和运行方式，接下来我们会针对它的组件，backbone、proposal_generator和roi_head分别进行研究。 2.3 backbonebackbone的类仍然是采用registry的模式，这样方便后继的人对于库进行修改。对于backbone的分析其实不用非常具体，因为BackBone就是最普通的卷积神经网络。但是在detectron2的具体实现中，有下面几点可以简单提一下： detectron2的backbone均基于modeling/backbone/backbone.py中的Backbone基类，它在nn.Module上做了简单的包装，主要是针对物体检测和实例分割的特殊需求，比如说： size_divisibility：因为卷积神经网络涉及到降采样，所以会对输入数据产生要求。例如降采样8倍的网络，其输入的长宽也必须是8的倍数。 output_shape：返回输出的Feature Map的形状是怎样的，方便后续的proposal_generator和roi_head进行处理。 以ResNet的实现为例，它的实现方法和torchvision中对ResNet的实现方式非常像(或者说基本是一样的)，只是在build_resnet中制作了生成resnet模型的统一接口。 2.4 proposal_generator与backbone相同，proposal_generator也是通过build_proposal_generator的接口创建“从图片的特征图提出可能产生物体的区域”的网络。暂时detectron2实现了两种proposal_generator，一种是Region Proposal Generator，也就是代码库中的rpn；另一种是Rotated Region Proposal Network，也就是rrpn。在下面，我们主要分析RPN的实现。 2.4.1 RPN HeadRPN作为proposal_generator的一种并不是最细分的抽象层次，最细分的抽象层次是RPN Head，也就是RPN用怎样的结构处理输入的特征图。这也就是在modeling/proposal_generator/rpn.py中RPN_HEAD_REGISTRY的由来。 在这里，detectron2为我们实现了一个典型的RPN Head——StandardRPNHead。它首先用一个3x3的卷积处理输入的特征图，之后分别用两个1x1的卷积处理得到：objectness_logits，有多大可能是一个物体；anchor_deltas：如何生成一个合理的锚定框(Anchor Box)。在它的输出中，objectness_logits是一个的张量，其中是每个Batch的图片个数，是在每个空间位置上设定的锚定框个数；anchor_deltas和objectness_logits是一一对应的，只不过它的输出变成了，增加了对锚定框位置的描述。 2.4.2 RPN的forward过程尽管在上一段中我们清楚了RPN Head是如何构成的、它的工作原理是怎样的，但是我们对于RPN最关键的部分：它是如何预测锚定框的、它又是如何训练的仍然一无所知。为了实现这个目的，我们需要仔细研究RPN的实现，最主要的就是它forward的过程。 RPN的输入是图片的特征，它通过如下步骤进行处理： 首先用anchor_generator生成了anchor的所有可能位置。我们会在稍后详细分析anchor_generator的实现，在这里我们可以把它的输出暂时理解为“一个列表，列表包含了几何意义上的所有可能锚定框”。 其次通过刚刚分析过的rpn_head为每个anchor的位置预测了存在物体的可能性和框的可能位置。 如果在输入中提供了真实的锚定框信息，也就是gt_instances不是None，那么会通过self.label_and_sample_anchors制作属于“锚定框”的数据集，并由self.losses计算RPN部分的损失函数，以训练RPN Head。 通过self.predict_proposals可以通过之前得到的每个位置的：是否有物体、回归的框位置，得到可能存在物体的区域，也就是proposals，至此，实现了RPN处理图片的forward过程。 接下来，我们关注下面几个部分的实现，分别是self.label_and_sample_anchors、self.losses和self.predict_proposals。 2.4.3 label_and_sample_anchors：处理真实框信息RPN Head的目标是对anchor_generator中提出的粗糙的锚定框进行分类，选取出真正可能存在物体的框，放弃不存在物体的框。那么为了训练RPN Head实现这一功能，我们就需要通过已知的物体框信息训练RPN Head对粗糙框进行分类：哪些是正样本(包含物体)、哪些是负样本(不包含物体)等等。而label_and_sample_anchors函数的目的就是制作一个训练RPN Head处理这类问题的数据集。 算法的主体思路是通过我们提出的框和实际框之间的IOU判定是正样本还是负样本。因此： 首先计算每个提出框与真实框之间的IOU，存储到match_quality_matrix。 其次，通过modeling/matcher.py/Matcher为这些框之间打Label。这部分的操作就是，如果IOU低于某个阈值(例如0.3)，那么Label为0，代表负样本；超过某个阈值(例如0.7)，那么Label为1，代表正样本；在两个阈值之间是难以判断的情况，为了避免对训练造成混淆，设置Label为-1，代表训练时可以忽略的样本。 根据每张图片中正样本的比例选取一部分正样本、负样本参与训练。其中正样本不应超过一个预设的比例(positive_fraction)，剩余的样本数量用负样本补齐。 返回的结果有两部分，第一部分是对应每个提出的锚定框的真实框坐标值，第二部分是这组对应关系的标签(Label)是怎样的。 这样，我们就得到了可以训练RPN Head的数据。 2.4.4 losses：计算损失函数通过观察losses的参数列表，我们就可以对它的逻辑略知一二。它的主要思路应该是通过objectness_logits和gt_label(回忆一下，在2.4.3中我们介绍了gt_label的含义)使得网络可以分辨哪片区域是有物体的，通过deltas和真实物体的框gt_bboxes使得网络能够得到物体的详细位置。 在实际的实现中也基本是按照这两部分进行的。“是否有物体”的判定这明显是一个二分类问题，所以通过binary_cross_entropy就可以训练。 针对回归物体位置的部分，在losses中提供了两种选择： 第一种是采用smooth_l1_loss，它的直观就是直接求预测值和实际值之间的差别作为Loss，它的做法就是直接求预测的框位置的Delta和真实框的Delta之间的差别。 第二种方式是采用Giou Loss，它的做法和第一种做法，即计算delta的差距，是相反的。它的直观是预测的Delta产生的框效果是怎样的，所以它会首先把预测的Delta转化成具体框的位置，之后与真正的框位置计算iou，那么iou越大说明预测的位置越准确。 综上，我们了解了在RPN部分的Loss计算。 2.4.5 predict_proposal：提取Proposal在这部分中，我们将来到RPN的最后一步，即如何得到物体的Proposal，利用用之前预测的objectness——是否有物体，和deltas——物体的位置？在这里我们重申一下得到Proposal的目的：为了细致地判断框内物体的类别和位置。 在predict_proposal中实现了提取proposal的全过程，主要包含如下步骤： 通过_decode_proposal将预测的deltas转化为实际的框位置 通过find_top_rpn_proposals找到其中最合适的预测结果 在这里，我们只对find_top_rpn_proposals进行讨论，它的实现在modeling/proposal_generator/proposal_utils.py。这个算法实际上就是实现了一个简单的筛选过程。它首先按照objectness抽取出分数最高的部分Proposal，值得注意的是，这部分的Proposal是足够多的，用机器学习的术语来解释就是“有很高的Recall”。那么这些Proposal中又如何进一步筛选呢？ 在筛选的过程中，最重要的就是NMS操作。在之前的Proposal中，存在很多框严重重叠的现象，这是因为在最开始提出Proposal的过程中，在同一个位置会有多个候选框出现，而这些候选框实际上代表的都是同一个物体。因此NMS操作应运而生，它的目的就是通过计算框之间的iou值，筛选掉这些实际上代表了同一物体的候选框。这部分的具体实现在layers/nms.py。在后面我们会对它进行具体分析。 经过上面的操作，我们就可以预测合理的Proposal，也就因此实现了对于proposal_generator模块的理解。 2.4.6 小结与讨论在这部分中我们不关心detectron2实现的具体细节，而是针对它的设计思想、设计逻辑进行一些总结和讨论。在detectron2的实现中，它首先将RPN本身的输入输出要弄清楚：输入是来自Backbone的特征表示，输出是哪些地点存在物体的Proposal。 其次，它将RPN按照功能分拆成如下多个部分，按照“从粗糙到细致”的顺序逐步完成了对Proposal的提取，从最开始的只要是一个位置就看做一个Proposal，到最终利用分数和IOU筛选出合理的Proposal。跳出RPN本身的实现，如果我们不考虑后面逐步筛选的步骤，那么只要我们有足够多的计算资源，其实是不会影响后面的训练效果的——因为我们完全可以把那些不包含物体的框设置成负样本不予考虑。这样的角度给我们的启示就是，其实我们完全可以重新对RPN的操作进行设计，增加或者减少对于Proposal的筛选，当然也可以改变筛选的方式，比如NMS的做法。不过无论我们怎么修改，其实都是在按照detectron2一种“链式筛选”的结构在做。 最后，毫无疑问，detectron2对于RPN在这样的实现方式给予了编程人员很大的修改自由度和简洁的抽象层次。尽管我们可能只有完整地了解了RPN的流程才会想到这样的实现方法，但是我们可以在未来设计算法的时候抓住“链式筛选”这样“由粗糙到细致”的算法模式，设计自己的接口和实现方式。 2.5 roi_heads2.5.1 结构简介回顾rcnn的结构，对roi_heads的调用出现的形式是results, _ = self.roi_heads(images, features, proposals, None)，也就是roi_heads处理Proposal，得到最终检测的结果；如果我们已经知道了proposal是怎样的，那么通过roi_heads_forward_with_given_boxes也可以实现检测。在了解了roi_heads的功能之后，我们来看它的实现，基本都是在modeling/roi_heads/里面。 在roi_head的__init__.py中可以看到detectron2提供了对多种任务的roi_head支持，例如box、mask和key_point，分别针对物体检测、实例分割和人体姿态估计。在我们的分析中，仅以物体检测的Box_head为例进行分析。构建roi_head的函数是在modeling/roi_heads/roi_heads.py的build_roi_heads。通过实现可以看到它也是通过REGISTRY方式进行构建。通过查阅config/defaults.py文件，我们知道了对于默认的Faster-RCNN使用的是Res5ROIHeads，所以我们重点研究它的实现。 2.5.2 ROIHeads基类：如何提供对ROI的训练数据在注释中作者解释了ROIHeads共有的逻辑： 在训练部分，在Proposal和实际框之间进行匹配，同时对Proposal进行采样 对Proposal的一片区域进行处理，得到该区域的特征 利用Feature针对我们的任务(检测/分割/…)进行预测 在ROIHeads基类中并没有对forward的逻辑进行实现，因为它与具体的任务相关，在BoxHead、MaskHead等模块内部自己实现。在基类中具体实现的是如何通过Ground Truth的样本和Proposal样本的列表创造对ROIHead的训练数据。通过对Res5ROIHeads的阅读可以发现实际得到使用的函数是label_and_sample_proposals。 首先，通过add_ground_truth_to_proposals可以提升Proposal的效果，特别是在训练刚刚开始的时候，RPN提供的Proposal可能质量很差，那么利用Ground Truth的数据可以保证正样本的存在。 其次，我们将Proposal和实际的框之间进行匹配，利用的函数是我们在RPN的label_and_sample_anchors中介绍的一样的方法。我们会计算每个Proposal与真实的框之间的IOU矩阵，通过proposal_matcher得到两两之间匹配的结果。进一步地，通过sample_proposals我们从所有的Proposal中提取出参与训练的Proposal。至此就基本实现了获取训练ROI的Proposal的步骤。 最后我们需要看一下sample_proposals的实现中需要注意的一个点。它利用subsample_labels从proposals中提出一定数量的样本训练，其中正样本不能超过一定的比例。关于负样本究竟具体会对训练结果产生怎样的影响，可以参考RCNN实验里的讨论。 2.5.3 Res5ROIHeadsRes5ROIHeads是默认使用的ROIHead，在它的forward函数中实现了对Proposal进行框预测和类别预测的过程。它(训练的)的主要流程是先通过对Proposal的采样制造训练数据。其次通过shared_roi_transform提取每个Proposal框中的特征表示。最后通过box_predictor得到每个Proposal内物体的类别和具体的框坐标。 其中，我们之前已经分析了如何在Proposal中采样得到训练样本，因此不再讨论。shared_roi_transform中主要用到了Roi_Align、Roi_Pool等操作，它们的重点在于这些模块的实现，因此我们在后面再进行讨论。在这里我们只需要知道ROIPool的功能就是：对于给定区域内的图片特征(Feature Map)，我们将其变成形状一定的这个Proposal的特征表示(Feature Vector)。在最后一步中，detectron2通过box_predictor利用每个Proposal内的特征表示预测物体的类别和准确的框坐标。在下面，我们简要分析box_predictor的工作过程。 box_predictor的主要流程是现在modeling/roi_heads/fast_rcnn.py/FastRCNNOutputLayers中。通过对__init__.py的阅读，我们可以发现box_predictor的核心在于两个线性层：cls_score、box_pred，分别负责预测物体的类别和回归框的坐标。它的工作流程在forward函数中其实相当简单，只需要把特征表示分别送入到cls_score和box_pred中，两个线性层就会分别把Logits和预测的框的Deltas输出出来。 综上，我们也基本了解了roi_heads的工作过程。 3. 成库","link":"/2024/06/0eb0bfce10fa.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 斯拉夫人，在宗教进入他们文明史之前，他们记录的东西很少，俄罗斯人的历史是以《往年纪事》为开端的，这本书诞生于1377年，记录的事情的起点是在859年，而859年都是唐宣宗时代了，属于唐末民变的时代的开端。 ^abefa6cf 类似的故事不光是在俄罗斯，波兰也有，过去波兰不是搞过一个动画片么？下面这个。 所以为什么西方人注重宗教，中国人看都不看、简单：宗教对于西方人来说，是其历史，文明史的开端，无比的重要。对于中国来说，那尽想到什么鸦片战争，八国联军…… ^5e22f16a Content为什么要辩经？因为咱们这是过渡期，必须知道经文，解构经文。当然最大的原因还是：好玩。 对于欧洲来说，很多国家的文明史就是宗教史，举个例子。 ==斯拉夫人，在宗教进入他们文明史之前，他们记录的东西很少，俄罗斯人的历史是以《往年纪事》为开端的，这本书诞生于1377年，记录的事情的起点是在859年，而859年都是唐宣宗时代了，属于唐末民变的时代的开端。== 而这本书里面有一大坨的宗教概念，什么诺亚的故事，诺亚儿子的故事等等。 俄罗斯的历史，罗斯人和拜占庭的战役，当时的拜占庭的皇帝是米海尔三世。情况是这样的：860年6月18日，200艘罗斯船停在博斯普鲁斯海峡沿岸，罗斯人打不进君士坦丁堡，但是可以抢劫郊区。 当时君堡也是倒霉催的，正在和阿拉伯人打的不可开交，没什么防御，罗斯人大赚特赚。 此后君堡又采取日常对付蛮族的办法：派人和罗斯人达成协议，派了主教前往罗斯，罗斯人受洗。而这个就被俄罗斯人认为是俄罗斯历史的开端。 ==类似的故事不光是在俄罗斯，波兰也有，过去波兰不是搞过一个动画片么？====下面这个。== ==所以为什么西方人注重宗教，中国人看都不看、====简单：宗教对于西方人来说，是其历史，文明史的开端，无比的重要。====对于中国来说，那尽想到什么鸦片战争，八国联军……== 微博新知网页链接","link":"/2024/05/7acae0827b9d.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 因此，整个demo的核心实际上是VisualizationDemo。 模型处理输入得到输出predictions=self.predictor(image)，predictions就是模型(刚刚的self.predictor)输出的结果。阅读机器学习、深度学习代码最重要的就是追踪这类模型处理数据的代码，因为这类代码是理解整体计算模型的关键。 在predictor.py9-12行的import部分，我们可以学习到很多架构深度学习项目的规范、设计方法，在不同的文件夹中，我们往往会通过功能将不同的模块分开包装。例如在predictor.py中体现的： .data：处理数据相关的类和方法 .engine：对训练、预测逻辑的整体包装，类似于对整体Pipeline的定义，常见于大型项目 .utils：应该是utilities的简写，一般用来放置常用的工具模块，例如在这里体现出来的可视化部分 总之，对于越大型的项目来说，合理的分区、包装就越有必要，因为这可以从软件工程角度节省大量用来理解、开发、查错(Debug)的成本。在自己的很多小项目中，合理地使用类似的方法也能有效地提升项目质量。 训练代码是tools/train_net.py if __name__ == '__main__'的部分(这里是代码运行的接口)，可以看到detectron2的结构是利用launch运行了main函数中的内容。如果我们不关心分布式训练的部分(即在distributed的作用域的部分)，那么main函数的逻辑相当简单：得到模型和运行的参数(在参数cfg中)。利用定义好的类Trainer，通过传入cfg参数可以定义出模型，后面的部分均通过Trainer里面的方法都可以实现，例如train()顾名思义就是做训练的，test()就是测试的，build_model()就是创建模型的。很有意思的是,过去的detectron2没有封装invoke_main.不知道为什么要封装这么个东西 在Trainer的定义中我们发现它是一个继承自engine.DefaultTrainer的子类，而我们通过上面对main函数的分析发现Trainer的主要功能其实都来自于DefaultTrainertrainer看engine.DefaultTrianer就行 查看文件名字和每个文件上面__all__的部分可以大致猜测出它们之间相互引用的关系和每个文件主要负责的部分 defaults.py包含了我们在train_net.py中见到的DefaultTrainer，也大多是在import别人 launch.py中的launch顾名思义是让算法开始运行的代码，我们浏览一下它最主要的函数launch，根据它的参数num_machines、machine_rank可得知它是负责分布式训练的代码，又有参数中main_func，可以知道launch不涉及detectron2的实际功能分布式训练,不用管 我们清晰了engine部分的层次关系。具体而言，我们按照如下的顺序阅读代码 train_loop.py hook.py defaults.py HookBase是Hook的基类，其中实现了方法before_step、before_train和after_step、after_train，其主要的作用是在真正做训练之前，做好每一步的准备工作。针对不同的Trainer可以使用不同的Hook。Hook翻译过来叫做“钩子”，所以我们可以形象地理解成Hook像在训练首尾的两个钩子一样挂着负责训练的Trainer。 在TrainerBase中定义了多个Hook，并且在Trainer的before_step、after_step等函数中可以看到需要执行每一个Hook在训练之前的准备动作HookBase.before_step、训练之后的收尾动作HookBase.after_step。具体的训练过程非常正常，就是按照iteration的数量运行before_step、run_step、after_step三个函数。在 Python 中，hook通常是指在特定时刻自动执行的函数。 在SimpleTrainer中作者实现了一种最基本的训练神经网络的流程，它是作为上一段中TrainerBase的子类出现的。它最主要的工作就是将TrainerBase中没有实现的run_step方法实现。事实上，在SimpleTrainer中实现的过程也是最通用的训练过程： iter(dataloader)读取数据 loss_dict = self.model(data)计算每个batch的loss self.optimizer.zero_grad、losses.backward()、self.optimizer.step()实现训练的过程 通过统一的结构_write_metrics记录、打印计算的指标。 继承HookBase定义在训练前的准备工作、训练后的收尾工作要怎么做 继承SimpleTrainer或者TrainerBase定义自己的训练逻辑继承自HookBase,负责before_step、after_step继承自SimpleTrainer,负责run_step hook.py的主要内容就是针对深度学习训练、测试过程中的不同需求，定义了很多个不同的Hook，用来处理训练之前、之后需要准备、收尾的工作。 Hook的实现也都和自己的具体功能有关，会涉及到一些细节，在后面需要考虑这些细节的时候我们自然会涉及到它们。但是这些Hook的实现都遵循着统一的设计逻辑——回顾HookBase，它包含四种方法before_step、after_step、before_train、after_train，只要我们想要的Hook需要在其中某一个部分做工作，那么只需要定义一个函数的实现即可。统一的设计原则 在深度学习的任务中，如何清晰简洁地定义每一步训练之前、之后的上下文和额外操作是一件非常重要但是麻烦的事情。在detectron2的hook设计中，它通过简单统一的一个接口就将这一切统一到了一起，是一个非常有创意、管用的设计。 DefaultTrainer继承自SimpleTrainer，它在之前的基础上增加了一些常见的特性，使得DefaultTrainer几乎是一个完整的能用来训练神经网络的框架了。 它主要增加了如下的几个部分： 通过参数构建模型(model)、加载训练数据(DataLoader)、优化器(Optimizer)、学习率的变化规则(Scheduler)。 创建常见的Hook(在上一部分我们已经分析了Hook是什么，它们可以处理每次训练前后的准备、收尾工作)。 加载、存储网络中间参数，也就是CheckPoint功能。 训练完全继承自SimpleTrainer，可见super().train() DefaultTrainer和SimpleTrainer不同的部分在于它构建模型、数据集等的部分，可以看到DefaultTrainer都是调用已有的build_xxx函数实现的。其次看创建Hook的部分，在__init__里面它是通过self.register_hooks(self.build_hooks())实现的。在self.build_hooks()里面它构建了在hook.py中已经实现的三种最常见的Hook，包括计算时间的、调整学习率的和计算BatchNorm的统计量的。 Content我自己阅读detectron2主要是出于下面两点原因： 最近一年的经历越发让我意识到工程能力——特别是在复杂的需求下可以做好的系统设计，在每个模块能写出清晰简洁代码的软件工程能力的重要性。所以我选择把detectron2作为一个绝好的学习范本。 Object Detection(物体检测)是计算机视觉中非常基础重要的一个任务，所以我有必要通过学习detectron2的代码弄清楚这个任务一些重要的实现细节。 但是当我写作阅读笔记的时候，我产生了新的动机，因为写出来到知乎这个平台上的文字和写给我自己的文字终究是不同的。我的新动机就是： 帮助一位深度学习初学者学会如何阅读一个开源深度学习项目、一个Pytorch项目。 帮助自己和任意的一位初学者思考项目中一些独特的设计在软件工程上究竟有怎样的好处，这样来帮助自己写出更好的项目。 不过在真正阅读这篇文章之前，还是需要具备一些基本知识的： Python的基本使用和Pytorch的基础用法。 神经网络训练的基本技巧，或者看过相关博客文章了解相关概念。 Object Detection的基本算法RCNN、Fast-RCNN、Faster-RCNN，或者看过相关文章，了解相关概念。 如果你已经做好了一切准备，就让我们一起踏上这段探索的旅程吧哈哈哈！ 庞子奇：Detectron2 代码学习 1 — 整体结构 (本篇) 2. 庞子奇：Detectron2代码学习2 — 检测模型实现 3.庞子奇：Detectron2代码学习3 — 数据加载 4. (计划中) 模型实现细节与其它设计 1. 整体结构1.1 Demo想要高效地阅读代码需要摸准它的主体结构，而找到代码的主体结构就得从它的使用方式看起。所以我们首先关注Detectron2的demo部分。在demo中主要包括两个文件，其中demo.py是代码的主要运行部分。demo.py的运行过程依靠predictor.py中的VisualizationDemo，其主要功能是提供了在输入图片/视频上运行Detectron2模型的接口，例如run_on_image在图片上运行，run_on_video在视频上运行。 1231. 根据参数和config文件创建模型、输入2. 利用VisualizationDemo的run_on_image、run_on_video接口处理输入图片/视频3. 利用opencv-python的专用函数，记录或者显示detectron处理后的图片/视频 ==因此，整个====demo====的核心实际上是====VisualizationDemo====。== VisualizationDemo的逻辑也很清楚，我们首先关注__init__部分，这里是整个类的初始化部分，在这里self.predictor顾名思义：它是根据输入图片得到预测结果的模块。在self.run_on_image中展示了用model在给定图片(image参数)上做预测的逻辑。 ==模型处理输入得到输出====predictions=====self.predictor(image)====，====predictions====就是模型(刚刚的====self====.predictor====)输出的结果。阅读机器学习、深度学习代码最重要的就是追踪这类====模型处理数据====的代码，因为这类代码是理解整体====计算模型====的关键。== 在visualizer中作者可以根据不同的输出模式(比如panoptic_seg、sem_seg)对图片做不同方式的可视化，其中的细节我们暂时先不追究。 在run_on_video和AsyncPredictor中detectron2针对视频和多线程的情况进行了实现，因为我们的重点在于学习整个detectron2的写法，所以暂时不对这些细节进行讨论，感兴趣/对这类情况有需要可以自行学习。 ==在====predictor====.py====9-12行的====import====部分，我们可以学习到很多架构深度学习项目的规范、设计方法，在不同的文件夹中，我们往往会通过功能将不同的模块分开包装。例如在====predictor====.py====中体现的：== ==.====data====：处理数据相关的类和方法== ==.engine====：对训练、预测逻辑的整体包装，类似于对整体Pipeline的定义，常见于大型项目== ==.utils====：应该是====utilities====的简写，一般用来放置常用的工具模块，例如在这里体现出来的可视化部分== ==总之，对于越大型的项目来说，合理的分区、包装就越有必要，因为这可以从软件工程角度节省大量用来理解、开发、查错(Debug)的成本。在自己的很多小项目中，合理地使用类似的方法也能有效地提升项目质量。== 1.2 训练概览 train_net.py在demo中我们看到了在图片上做infer是怎样的结构，那么训练要怎么做呢？通过阅读说明文档可以发现==训练代码是====tools/train_net.====py==，所以我们下一步就是分析train_net.py是如何实现的。 train_net.py在文件开始的部分import了一堆东西，因为我们是自顶向下(Top-Down)地对项目进行阅读和理解，所以可以暂时不管这部分的代码具体在做什么。在整个文件中，我们直接跳转到==if== ==__name__== ==== '====__main__===='====的部分(这里是代码运行的接口)，可以看到====detectro====n2====的结构是利用====launch====运行了====main====函数中的内容。如果我们不关心分布式训练的部分(即在distributed的作用域的部分)，那么====main====函数的逻辑相当简单：得到模型和运行的参数(在参数cfg中)。利用定义好的类====Trainer====，通过传入====cfg====参数可以定义出模型，后面的部分均通过====Trainer====里面的方法都可以实现，例如====train====()====顾名思义就是做训练的，====test====()====就是测试的，====build_model====()====就是创建模型的。== ==在====Trainer====的定义中我们发现它是一个继承自====engine====.DefaultTrainer====的子类，而我们通过上面对====main====函数的分析发现====Trainer====的主要功能其实都来自于====DefaultTrainer==，因此我们的主要任务就是在engine中弄清楚负责训练的模块是如何构建与运行的。 1.3 Engine在engine中，detectron2定义了训练、测试的Pipeline。在demo中我们也看到了来自engine的predictor能够在给定的图片上用模型做预测。对于一个机器学习/深度学习的项目来说，他必须要完成、也是主要完成的事情，就是针对给定的模型进行训练与测试。因此，按照自顶向下的原则认识detectron2就需要首先研究engine中是怎样实现的。 在engine中有多个py文件，==查看文件名字和每个文件上面====__all__====的部分可以大致猜测出它们之间相互引用的关系和每个文件主要负责的部分==。==defaults====.py====包含了我们在====train_net====.py====中见到的====DefaultTrainer====，也大多是在import别人==，==launch====.py====中的====launch====顾名思义是让算法开始运行的代码，我们浏览一下它最主要的函数====launch====，根据它的参数====num_machines====、====machine_rank====可得知它是负责分布式训练的代码，又有参数中====main_func====，可以知道====launch====不涉及====detectro====n2====的实际功能==，所以我们跳过launch.py。进一步考察，我们发现hook.py引用了train_loop.py中的内容，因此==我们清晰了====engine====部分的层次关系。具体而言，我们按照如下的顺序阅读代码== ==train_loop====.py== ==hook====.py== ==defaults====.py== 1.3.1 train_loop.pytrain_loop中作者实现了从简单到复杂的三个类，分别在不同的层次上抽象了对训练过程的需要和实现，包括HookBase、TrainBase、SimpleTrainer。通过名字上的Base和Simple可以这些只是实际被使用的类的基类，但是我们还是要首先针对这三个类进行分析。 这三个模块的注释都非常详尽，阅读之后可以对模块的构成、作用有初步的了解，在这里仅做简要的解释。==HookBase====是====Hook====的基类，其中实现了方法====before_step====、====before_train====和====after_step====、====after_train====，其主要的作用是在真正做训练之前，做好每一步的准备工作。针对不同的====Trainer====可以使用不同的====Hook====。Hook翻译过来叫做“钩子”，所以我们可以形象地理解成Hook像在训练首尾的两个钩子一样挂着负责训练的====Trainer====。== ==在====TrainerBase====中定义了多个====Hook====，并且在====Trainer====的====before_step====、====after_step====等函数中可以看到需要执行每一个====Hook====在训练之前的准备动作====HookBase====.====before_step====、训练之后的收尾动作====HookBase====.====after_step====。具体的训练过程非常正常，就是按照iteration的数量运行====before_step====、====run_step====、====after_step====三个函数。== ==在====SimpleTrainer====中作者实现了一种最基本的训练神经网络的流程，它是作为上一段中====TrainerBase====的子类出现的。它最主要的工作就是将====TrainerBase====中没有实现的====run_step====方法实现。事实上，在====SimpleTrainer====中实现的过程也是最通用的训练过程：== ==iter====(dataloader)====读取数据== ==loss_dict== === self.model(====data====)====计算每个batch的loss== ==self====.optimizer====.zero_grad====、====losses====.backward====()====、====self====.optimizer====.step====()====实现训练的过程== ==通过统一的结构====_write_metrics====记录、打印计算的指标。== 综上，我们了解了detectron2中engine的框架，和我们使用时需要注意的层次： ==继承====HookBase====定义在训练前的准备工作、训练后的收尾工作要怎么做== ==继承====SimpleTrainer====或者====TrainerBase====定义自己的训练逻辑== 1.3.2 hook.py==hook====.py====的主要内容就是针对深度学习训练、测试过程中的不同需求，定义了很多个不同的====Hook====，用来处理训练之前、之后需要准备、收尾的工作。==其中包括了计算时间的IterationTimer、按一定周期输出结果的PeriodicWriter、调整学习率的LRScheduler等。 其它的==Hook====的实现也都和自己的具体功能有关，会涉及到一些细节，在后面需要考虑这些细节的时候我们自然会涉及到它们。但是这些====Hook====的实现都遵循着统一的设计逻辑——回顾====HookBase====，它包含四种方法====before_step====、====after_step====、====before_train====、====after_train====，只要我们想要的====Hook====需要在其中某一个部分做工作，那么只需要定义一个函数的实现即可。== ==在深度学习的任务中，如何清晰简洁地定义每一步训练之前、之后的上下文和额外操作是一件非常重要但是麻烦的事情。在====detectro====n2====的====hook====设计中，它通过简单统一的一个接口就将这一切统一到了一起，是一个非常有创意、管用的设计。== 1.3.3 defaults.py有了train_loop.py中的基本理解，我们就可以深入到defaults.py了，在这里定义了在train_net.py中使用的基本模块DefaultTrainer。 ==DefaultTrainer====继承自====SimpleTrainer====，它在之前的基础上增加了一些常见的特性，使得====DefaultTrainer====几乎是一个完整的能用来训练神经网络的框架了。==它主要增加了如下的几个部分： ==通过参数构建模型(model)、加载训练数据(DataLoader)、优化器(Optimizer)、学习率的变化规则(Scheduler)。== ==创建常见的Hook(在上一部分我们已经分析了Hook是什么，它们可以处理每次训练前后的准备、收尾工作)。== ==加载、存储网络中间参数，也就是CheckPoint功能。== ==训练完全继承自====SimpleTrainer====，可见====super====()====.train()== ==DefaultTrainer====和====SimpleTrainer====不同的部分在于它构建模型、数据集等的部分，可以看到====DefaultTrainer====都是调用已有的====build_xxx====函数实现的。其次看创建Hook的部分，在====__init__====里面它是通过====self.register====_hooks(====self====.====build_hooks====()====)====实现的。在====self====.build_hooks()====里面它构建了在====hook====.py====中已经实现的三种最常见的Hook，包括计算时间的、调整学习率的和计算BatchNorm的统计量的。== 1.4 小结综上，我们已经清晰了detectron2的整体架构与逻辑，特别是它如何为训练过程的组件和函数构建了统一的接口Trainer、Hook。但是我们在这个过程中也没有深究一些细节，比如说如何构建数据集、如何构建模型、如何构建优化器等等，在后面我们将对它们进行详细分析。","link":"/2024/05/389041a5d7c3.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 流畅记忆的价值并不仅仅在于记住一些事实。许多实验并非用鹦鹉学舌式的记忆问题来测试学生，而是要求他们进行推理，绘制概念图[4]，或回答开放式的问题。在这些研究中，记忆力的提高能够转化为一般理解能力，及解决问题能力的提高。好的卡片不是死记硬背,而是要求去推理，绘制概念图，或回答开放式 提取（Retrieval）是 SRS 有别于传统学习模式的关键。仅仅简单回顾材料（如多读几遍）既没有加强记忆，更不能增进问题解决能力，而「提取」往往可以。这种通过「提取以掌握」的现象也被称为「测试效应」，因为往往发生在做自我测试时，故此得名。它形似学校考试，目的上又有所相反：「提取练习」是为了从测试中进行学习，而非「评估」学习成果。提取或者说是测试,目的是进行学习,而不是评估学习的成果 卡片的焦点应明确（Focused）：细节太多的问答不会让你专注，回答时的「提取效应」无法完整地刺激记忆、点亮全部的「思维灯泡」。不够聚焦的问题，还让你更难判断回答是否全面、差异在哪里。因此，最佳做法一般是：一次问答只聚焦一个细节。尽量聚焦少的细节,太多的细节会让我不够专注地回忆,无法点亮所有的思维灯泡 卡面应能诱导出一致的回答（Consistent），让每次任务都点亮相同的「思维灯泡」：否则，你可能遭遇「提取引发遗忘」（retrieval-induced forgetting）[7]—— 这是一种干扰现象，即已记住的会更牢，没记住的更易遗忘。（后文将讨论一种新的卡片，每次重复时都要求一个新答案，但它产生改变的效应不是「提取练习」）同个任务只能点亮相同的思维灯泡.也就是说,同一个卡片,不会让你回忆出不同的答案 卡片应让提取费工夫（effortful）：卡片练习的重点，是让你从记忆中提取答案， 而不应让你简单地从卡面「推测」答案（此外，「线索」很重要，我们稍后讨论）。实际上，提取练习的努力程度与效果正相关。这点正是强调复习和复习之间要有间隔的动机之一：如果回忆答案太容易，那提取练习效果不大[9]。提取难度与效果正相关.但过难会降低积极性.要有适当的提示,不能太简单也不能太难 我们会穷尽式地处理这份阅读材料，以最详尽地展示这些通用的制卡原则。请注意，实践中你通常不会也不必这么系统地学习。你一般只会关注文章中你认为最有价值的部分，然后在非常有必要的时候跳回原始材料，寻找与你理解最相关的信息并做成卡片 —— 这值得一赞！完美主义会过度消耗你的动力，穷尽式处理只是表面正确，实际上是浪费你的注意力，它们本应该放到更有价值的地方。这类问题会在后面更深入地讨论。穷尽式地处理并不是很好的选择.战术上努力,战略上懒惰.在必要时跳回原始材料就行 我们假如直接这么写卡：「制作鸡肉高汤需要什么？」，那么在回答的时候因为数量或者原料名称未作要求，所以很难作答。这样的卡片不够准确，也不够聚焦 ：同时要求提取的细节太多，所以想要加强的记忆不会全部被强力激活；并且因为它要的答案太多，因此的一致性、可控性也不好：每次回答，你会记起一些，又忘掉另一些。因此激活不够一致，容易导致记忆受到侵蚀。像我写的高数卡片… 在谈及事实时，我们自然会想添加一些解释。我个人会在细节不容易想到，或者事实背后的解释比较有意思的时候，添加一张「解释卡」对有趣事实进行解释是很有意思的事情 问：为什么我们做鸡肉高汤要用骨头？答：它们富含明胶（吉利丁，gelatin），可以产生浓郁的口感。*很好的解释卡,但仍有不足,像骨头比较便宜这个答案也是有可能出现的.这样就显得一致性,可控性不够好.还有改进空间 问：骨头如何产生鸡肉高汤的浓郁口感？答：它们富含吉利丁。更好,排除了骨头便宜的干扰,更加精准* 解释卡能强化「事实性」提问中的知识，而「解释」本身也让事实富有意义—— 这点也许更重要。此类卡片像钩子一样，将烹饪生涯中的想法与学到的「事实」相互关联起来。比如你学完这张卡的第二天，如果正好吃到「果冻鸡爪」，就可能考虑拿鸡爪作高汤材料（因为这是鸡身上明胶最丰富的部分），因为今天这张卡让你知道明胶能提升口感。通过解释,将解释卡与事实卡联系起来. 问：鸡肉高汤中使用的典型香料是什么？答：洋葱、胡萝卜、芹菜、大蒜和香菜 但是，除非你有一定经验，否则这个卡片对你来说可能并不可控，或是每次记的原料不一致。这样的无序列表要转化为好卡片，颇具难度。 对此，一个好策略是创建一组问题，并对选项分别挖空，并要求你逐一填空（下面用？？？指挖的孔）： 问：典型的鸡肉高汤香料：- ？？？- 胡萝卜- 芹菜- 大蒜- 香菜 答：洋葱 问：典型的鸡肉高汤香料：- 洋葱- ？？？- 芹菜- 大蒜- 香菜 答：胡萝卜 …以此类推。这里注意到选项列表顺序没有变动，这样你在重复回忆时，最终一定程度上会形成视觉形状上的记忆。cloze形式的anki卡片在这里就很实用,一次仅仅聚焦一个思维灯泡,并且形成视觉上的记忆 但对于复杂的内容，你可能得在彻底记住单选结果之后，还要添加一些综合性的卡片对清单类型的每个知识点进行小检测后,还要有综合检测 另一个帮自己理解「清单」的方法是为每个成分写一些解释卡——为什么胡萝卜是鸡肉高汤的好佐料？（注：胡萝卜提供植物糖，同盐一样能提亮其他味道）如果你知道原料的对应解释，也许不需要「填空」也能记住全部了。如前面所提，解释让「事实」更好被理解。本案的菜谱中，没有说为什么要这些香料，所以你需要自己去寻求解释*。（*译注：血泪提醒：「别做完美主义」）解释卡帮助理解清单类也有很大的作用 如果你对这些问题感到挣扎，那么可以添加一个「线索（cue）」： 问：典型的鸡肉高汤香料：- 洋葱- 胡萝卜- 芹菜- 大蒜- ？？？（一种味重的香料）线索联系答案的形式,也能够提高retrieval的效果 问：典型的鸡肉高汤香料：- 洋葱- ？？？- 芹菜- 大蒜- 香菜 答：胡萝卜（英文 carrots 与「鹦鹉 parrots」押韵：想象一群鹦鹉叼着胡萝卜飞行，把它们丢进一锅汤里） 这类线索涉及另外一种记忆现象，也是认知科学家的实验对象 ——「*精细编码 （elaborative encoding）」[11]：将信息与其他记忆相关联，它会变得更好回忆 。当然，原料清单这种，不容易搭配出有意义联想，但这种情况下，你仍可自己编造一个助记词来利用「精细编码」。生动的联想效果会更好，因此尽量从多个方面寻找联系。比如从视觉、有意义的个人经历、情绪（幽默、厌恶等）等方面。（*译注：1.「elaborative」一词包含了「协作」的意思，所以不需要懵逼地去想「哪儿精细了」；2. 友情提示：助记词写在卡背，线索写在卡面）更加狂野的联想,精细化编码,使答案更好回忆 当然了，做「线索」和「精细编码」会增加制卡负担。因此没必要见一张做一张，不然容易精疲力尽。 写好卡片往往涉及对原文的解读（「再解释」） ，这是让理解超脱文章本身局限的第一步。对原文进行属于自己的解释,倒是和卡片阅读的部分内容很相似 注意到，为了保证聚焦而精确，这里将原料表分解成很多个问答。新手常常有节约用卡的强迫症，多写一张就跟多掏钱一样，倾向于把卡片的「数量」写得少少的、把「范围」写得泛泛的 —— 但这适得其反，因为你要掌握的「知识量」不会随着你的卡片数量而减少（除非特意排除某些内容）*，把卡片数量减少、内容变糙，并没有让必学的知识减量，反而让材料更难做重复练习，容易「齁」。（*译注：薄的高数书只会更难。吾愿称之为 知 识 守 恒 律 ）没必要一张卡片写过多的内容.赛博卡片仅仅占一点点磁盘,完全不要钱.宁多毋少,超量制卡 卡片不贵，但也绝非免费 —— 会有情绪上的开销：数量爆炸的低难度卡片容易让你崩溃，因为没人愿意花时间复习一堆闭眼都会的材料。 因此，如果材料讨论的东西已经相当熟悉，卡片应该写少一点 —— 并非说熟悉的领域可以写得含糊，而是因为边际效应，你要捕获的知识量本身就少。即使卡片不要钱,也不要过多低难度卡片.既然已经非常熟悉答案,再去记忆,由于边际效益,收益很低 还有一点与此相关，一张卡片「聚焦」在何种尺度上，取决于你已了然于心的概念规模。本例中的香料对我来说太熟了，我将其作为一个原子单位去记 （“意式香料”） 而不是拆开。对于细节尺度的把控.对于我个人来说,不会将葱姜蒜三件套拆开来记忆,而是作为模块处理.菜谱中直接写香料,而不是拆开写葱姜蒜 复杂的概念会随着融会贯通（「流畅性」的建立），逐渐组块化为新的基本单元，这样一来，你在对复杂概念写卡时，既不会丢失细节，又足够聚焦。实际上，一个专家的重要特征，可能就是基于越来越复杂的「组块」思考[12]。从这个角度看，各种助记系统扮演了一个「组块催化剂」的角色，它促进了你对某个方面组块的「有效大小」的增长*（*译注：Andy 不方便说得太绝对，但不妨碍我加料：因此，硬记忆通过组块化提升理解能力）*记忆的最终目的之一,就是能够模块化理解复杂事务.例如深度学习被拆成了 training evaluate 优化等模块* 「程序性」知识 现在我们已经写好了关于原料的卡片，接下来烹饪的步骤更多是「程序性」知识，也就是用来执行特定任务的知识，对于「程序」，我们更多地是要知道“HOW”而不是“WHAT”. 解释卡 对「程序」学习有特殊价值：它避免你死记硬背，并帮你深入建立理解 卡片写作有助于揭露我们理解上的缺失。追随你敏感的大脑去查谷歌、去查文献，不要拘泥于原文。即使你不打算立刻「补缺」，光是写下这些卡，也能让自己敏于「查漏」、保持好奇。这有益于在未来的探索。 Content如何写出好卡片：利用间隔重复创造理解发布于 2021-11-16 21:40・IP 属地广东 ，编辑于 2023-09-06 10:21・IP 属地广东 如何制作和储存鸡肉高汤：「事实性」和「程序性」知识 「启明卡」和「Baader-Meinhof 现象」 译序：考试里有学习的奥秘？！前苹果系统工程师手把手教学 注：正文中的[数字]表示的是注释，可以善用 Ctrl+F 进行页面内搜索。本文有两万五千多字，可以在你做卡片时作为参考。 小时候，我时常做这样的白日梦，只要像打游戏那样敲对作弊代码，电脑就「哔哔」两声，自动给我打开神奇的世界，让我拥有和游戏主角一样超凡的力量，摆脱这单调乏味的生活。 以上幻想多半是游戏玩太多的缘故，但那神奇的感觉正与我后来使用「间隔重复系统」（Spaced Repetition Systems , 下称「SRS」或「SR系统」）的体验别无二致。如果使用得当，能产生魔法般的效果，让你掌控记忆的主动权，而不是听天由命。[1] 它可以提高学习效率、催化创意工作，或者带来更多[1]令人兴奋的事情。当然，它也要像童年幻想那样，先要「按对作弊代码」，奇迹才会显现 —— 换句话说，设法写出好卡片，才能芝麻开门。（即实践时，你在卡片上整理的问答） 一个 SR 系统的优劣，完全取决你能给出的卡片。新手阶段，因为你不知道什么样的卡片是好的，所以可能写出很差的卡片也无从改进。在我的早期阶段，对 SR 系统的实验一如我童年乱按作弊码：把它当做阿拉丁神灯那样去拨弄、琢磨，希望能无意中唤醒它的魔力。 幸运的是，卡片撰写从来不是玄学，而是体系完整的知识可以帮你分辨卡片的有效性、理解制卡的方法论。这类内容网上数不甚数，而本指南的重点，是帮助你从制卡资料（演讲、文章等）的语境中，创造并总结一种理解 —— 我一向认为，卡片不仅要帮助消化吸收作者表达的知识，也要从中衍生为你生活和创新工作所用理解。 对于不熟悉「间隔重复」的读者，本文会帮你克服那些常见的、让你从入门到放弃的阻碍；对于有经验的读者，后续章节会涵盖不常见的一些编卡理念，以加深你的 SRS 实践[2]。我们讨论的东西概括性较强，主要集中在制卡的纲领层面，因此无论你用什么 具体的 SR 系统，相信都有所受益。 「提取练习」—— SRS的核心卡片的具体应用有很多，但编写卡片时最好记住，不管表面如何，你正在给未来的自己编制任务，一个重复再重复的任务。因此请牢牢记住，「设计卡片」即「设计任务」。 如果某张卡片「见效」了，那不是碰巧，而是因为你对该任务的执行，用某种有用的方式「改变」了自己。根据这点，我们值得花一点时间去了解这些「改变」背后的机制。这样就能有针对性地编制任务，并设计你想产生的改变了。 SR 任务对你产生「改变」的最核心、最常见的机制，被称为「提取练习」（retrieval practice） 。简而言之：你的回忆即对记忆的提取，提取行为往往会强化记忆[3]，并且这个效应会减缓遗忘。因此，有策略地规划每次提取之间的间隔，可以有效阻止遗忘。尽管它物理层面的机制尚不明确，但数百名认知科学家对此已做过大量的实验探索，涉及不同学科、不同知识类型（事实、概念、程序、运动）乃至不同测试方式（选择、简答、口答），都复现出同样的结论。 ==流畅记忆的价值并不仅仅在于记住一些事实。许多实验并非用鹦鹉学舌式的记忆问题来测试学生，而是要求他们进行推理，绘制概念图[4]，或回答开放式的问题。在这些研究中，记忆力的提高能够转化为一般理解能力，及解决问题能力的提高。== ==提取（Retrieval）====是 SRS 有别于传统学习模式的关键。仅仅简单回顾材料（如多读几遍）既没有加强记忆，更不能增进问题解决能力，而「提取」往往可以。这种通过「提取以掌握」的现象也被称为「测试效应」，因为往往发生在做自我测试时，故此得名。它形似学校考试，目的上又有所相反：「提取练习」是为了从测试中====进行====学习，而非「评估」学习成果。== SRS 的设计目的便是实现测试效应。如果想用它强化某方面的理解，那你必须学会卡片化相关的全部细节，一个不漏地做提取。 受限于资料，可查的文献远不够作出最准确的指导，因此有必要走出故纸堆去理解卡片制作。我将提炼自己数千张的制卡经验，在本指南中提供建议，并尽可能利用实验证据提供支持。 本指南本身，是一个关于所谓助记媒介[5]（我和 Michael Nielsen 所命名）的例子。文中嵌入了一系列 SR 卡片[Jarrett 1]，来例证自己的建议。 所用用卡片系统是 Orbit ，原理与你[6]自用的 SR 软件差不多，但还有更深一层愿景：通过在阅读中嵌入一系列专家认证的卡片，使读者在内化文章意图时事半功倍 —— 如果你也用Orbit，本指南不仅会帮助你如何写出好的卡片，也对写要发布的稿件有益。当然，你也可以仅阅读而不回答这些内嵌的红色卡片，不过希望您能试试。（*译注：原网页中是交互的红色卡片，我将其截图搬运而来，手机端狂喜） 2022-03-19 update：目前将本文制作成带交互卡片的助记媒介，访问地址如下https://l-m-sherlock.github.io/thoughts-memo/post/how-to-write-good-prompts/ 此外，第一个「助记媒介」的实验是一篇量子计算的入门读物《量子国度》，但它比较硬核 —— 定义，符号，定律那些 …… 你懂的。相比之下，本指南更侧重于展示制卡中应有的意识（heuristic）*、思维模型，并提供一些指导建议。 —— 本文是一项实验，你可以告诉我自己的体验。（*译注：原文「heuristic」，指人处理事务时，不通过逻辑思考，而是下意识就知道怎么决策的认知，故此处翻译为「制卡意识」。在这满是 CSer 的世界，它还有个黑话叫「启发式」） 局限性注意！本指南的出发点，是在材料已经明确表达的内容的基础上，教你写出带个人理解的卡片。但 Orbit用户目前还不能对已经自带作者版卡片的材料添卡（比如本文）。未来会向这个方向前进。 有效的「提取练习」—— 卡片应有什么样的属性「写出优质卡片」与翻译文章惊人地相似：翻译时，你会不断问自己「选哪些词，会让读者阅读时有如体验原著」，并且在脑海中「点亮相同的”思维灯泡”？」 这种翻译不可能是一板一眼的，因为文章往往涉及典故/ 隐喻/ 幽默，为了让文化背景不同的读者也能身临其境，遣词造句必须考究。 SR 卡片的制作与文章翻译颇为相似。当知识的细节「完全载入」你的脑海中后，它们会点亮一个个的「思维灯泡」。而为了对这些细节触发「提取练习」，你会问自己：哪些任务（即卡片）一起执行时，需要答题的你点亮同样这么一组「思维灯泡」？ 这样的「有效卡片」会拥有怎样的主要属性，其实就隐含在提取练习本身的机制里。我们将在这里简要回顾，并在后文详尽示例以继续深入。 这些属性不是自然法则，而类似「语法」那种「规则」 —— 你可以学到手，也能（也应该！）像优秀的作家打破语法那样，在合适的时候有所突破，激发最应景的效果。（当然这要有丰富的制卡经验支撑，需要理解什么时候可以任性一把） 「有效卡片」应该拥有的属性： ==卡片的====焦点====应明确（Focused）：细节太多的问答不会让你专注，回答时的「提取效应」无法完整地刺激记忆、点亮全部的「思维灯泡」。不够聚焦的问题，还让你更难判断回答是否全面、差异在哪里。因此，最佳做法一般是：一次问答只聚焦一个细节。== 卡片应能精确引导答案 （Precision） ：模糊的问题只会引出模糊答案，不能可靠地点亮你要的「思维灯泡」。 ==卡面应能诱导出====一致的====回答（Consistent），让每次任务都点亮相同的「思维灯泡」：否则，你可能遭遇「提取引发遗忘」（retrieval-induced forgetting）[7]—— 这是一种干扰现象，即已记住的会更牢，没记住的更易遗忘。（后文将讨论一种新的卡片，每次重复时都要求一个新答案，但它产生改变的效应不是「提取练习」）== 卡片问答应该可控（tractable）：为了避免复习时，因为干扰过强而混乱、烦恼，你应用心写出自己几乎不会错答的卡片*（ almost always answer correctly）。这通常依赖任务分解，或者添加线索[8]。（*译注：此处应指不容易答偏，SR 的核心效应是「提取」，「可控（tractable）」和费工夫不冲突） ==卡片应让提取====费工夫====（effortful）：卡片练习的重点，是让你从记忆中提取答案， 而不应让你简单地从卡面「推测」答案（此外，「线索」很重要，我们稍后讨论）。实际上，提取练习的努力程度与效果正相关。这点正是强调复习和复习之间要有间隔的动机之一：如果回忆答案太容易，那提取练习效果不大[9]。== 组织这样一张卡片，要点是让题目的考察范围充分狭窄，否则回答时或是「提取」不够聚焦、或是答案难以一致/ 精准、或是问题不好驾驭。但要写一个足够紧确的题目，难度超乎常人想象，你得把知识一点点掰开揉碎，才可重新组合成题目。对了，知识点一旦揉碎，复习会变得更精耕细作 —— SR 软件的复习规划器，可以差别处理难易不同的知识点，让你更多地回顾难点。 现在，请想象我们正在读一篇长文，是你没见过的主题。然后问自己能否清晰地解释给别人，并思考自己能回答哪些问题，才肯定自己「学会」了这篇文章？还是用翻译做比喻：如果「知识」是一门语言，那你需要将它从内容中「翻译」出来。为此你首先要会「读」，明白它是怎么被「书写」的 —— 识别得出「知识」的词性，句子结构、叙事节奏 —— 才能给出合适的翻译。其中有些细节是无关紧要，有些是核心中的核心。更进一步，好的「翻译者」不能只停留于纸面，还得留心其中的内涵，以及概念之间的联系。 因此，去编制有效的练习卡，我们需要两个技能：1，首先，如何精准地刻画你要强化的知识？ 2，其次，如何有效提问? 菜谱「鸡肉高汤」——目前我们的讨论太过抽象，不如从稍后一个菜谱《鸡肉高汤》继续。 某种意义上，你可能觉得菜谱是微不足道的编卡对象，但它其实也是个简短、自成体系的领域。我有数百个卡片记录菜谱和厨房心得，在此将简述我的经历 。（留意卡片能用到哪些不寻常的领域，本身就是一项编卡必备技能） 这些卡片是我三年前开始编写的。而在此之前，我已经相当认真地做了十年饭。尽管对很多技术要点、配比、搭配了然于心，然而一旦做起复杂的菜品，我依然得停停歇歇地查菜谱，这让我步履维艰。要说那种体验，非常像我学编程的头几年 —— 几乎感觉不到什么「心流」。我最终是在全职工作了几年后才内化了编程的必备知识的。因此，我如今确信下厨也是这个路子，只不过我不是专业的，所以这个过程可能还需几十年的时间。 SRS 则从本质上改变了我的厨房生活。卡片催生了我选菜的能力：菜市场上一旦看中某个原料，我都能毫不费力地用它搭配出复杂的菜品。这能力极让我满意，我知道要买哪些东西去配菜 —— 如果看中那个洋姜，那我就再买点刚才路过的芥菜，它们是很好的搭档。于是，在回家之前，我就知道这一餐该怎么做了。 我对烹饪感到得心应手，在厨房杂事中来去自如。就事论事，尽管本文的长篇大论让你觉得我有点那啥，但这些卡片的用时并没想象中大。我会把一些有意思的事情稍微花几分钟做成卡片，一两周一次就已经足够影响深远了。 （译者提醒：下面的菜谱建议另开一个网页对照阅读，不然回读挺麻烦的。PS：本文献的原网页，菜谱是全程悬浮在右侧的） 《鸡肉高汤》介绍一家像样的餐馆里，即使最常见的菜肴，也往往比家里做的好吃。蔬菜浓郁，谷物更香，酱汁甘美。其秘诀之一是「高汤」，一种味道鲜美的汤式「积木」，平日在家直接加水的步骤，餐馆经常换用高汤，比如炒蔬菜、化果酱、炖全麦等。 高汤也是许多酱汁、汤和炖菜的基础。用滋味比较丰厚的原料，可以炖出不同种类的高汤：鸡肉高汤、蔬菜高汤、蘑菇高汤、猪肉高汤…等等。但不同于典型的「肉」汤，高汤用肉，不是为了突出肉味，而是给菜肴打下多样化的味道基础。 其中鸡肉高汤是最常用的高汤之一。加进素菜里不是为了让它们吃起来像鸡肉，而是让味道更完满、可口。这种高汤富含来自鸡骨的吉利丁（*译注：明胶），因此尝起来口感更浓郁。制作鸡肉高汤只需几分钟，材料一般可以直接在家里中获得，因为它用的主料是鸡骨。所以常吃鸡的话，你可以在煮鸡肉时顺手把骨头留下，冰冻起来。 《鸡肉高汤》- 菜谱 2 磅（~ 1 千克）鸡骨 2 夸脱（~ 2 升）水 1 个洋葱，切块 2 个胡萝卜，切块 2 根芹菜，切块 4 瓣大蒜，捣碎 半束新鲜的香菜 把所有原料一起放进大锅里。 小火炖到沸腾（约1小时）。用小火的话，味道就能明亮、干净；如果温度较高，汤的色、味就比较暗淡。 降低火候，小火慢炖一个半小时。 过滤，等其冷却后转移到容器里储藏。 鸡肉高汤放在冷藏层可以存一周，放在冷冻层可以无限期保存。使用前，需要撇去高汤上的一层脂肪，这些脂肪可以在其他要提味的地方，用来代替植物油或者黄油。 用量上，则可以根据你鸡骨的数量等比例缩放。骨头和水的比例是 1:1（磅/夸脱），蔬菜的种类和比例可以随性调整。 《鸡肉高汤》- 菜谱变体如想尝尝偏法式的鸡肉高汤，可以用韭菜代替芹菜，再加入月桂叶、黑胡椒和百里香。如果想要更浓的鸡肉高汤，可以预先烤一下鸡骨和蔬菜，这样便是做成所谓的「棕色鸡肉高汤」。（之前的菜谱相对是「白色鸡肉高汤」，味道不强烈，但更细腻、万能） 《鸡肉高汤》—— 如何使用鸡肉高汤下面是一些鸡肉高汤的使用建议： 煮「大麦」、「法罗」、「蒸粗麦粉」和其他谷物。 与烤蔬菜泥一起做汤。 将「甘蓝」、「甜菜」或「散叶甘蓝」等蔬菜放入油中，然后加入少许高汤，闷透。 （在平底锅烤肉或煎肉之后），将高汤倒在滚烫的平底锅底上，做成速成酱汁用于餐中。 为了组织我们的阅读成果，我们可以问：具体要知道哪些东西，才意味着你「学会」这些材料？我认为，「学会」这段材料的人应该： 知道如何「制作」和「储存」鸡肉高汤； 知道什么是鸡肉高汤，并（至少是浅显地）理解它为什么、什么时候很重要； 知道鸡肉高汤的具体作用和意义； 知道使用鸡肉高汤的一些方法，包括一些具体的例子； 知道一些常见变体以及何时可以使用它们； 这些内容中，有些知识是「事实性」的，有些是「过程性」的，还有些是「概念性」的。与之对应的制卡策略，将在后文一一陈述。 但「理解」是很个人的事。真要既「知」且「道」某件事情，往往必须超越内容本身，将其与你生活之方式、探索之想法，以及其他心目中有意义的活动联系起来。如何编写这种卡片，我们也会同样探索。 本指南会假设读者对家庭烹饪有兴趣，且从未做过高汤，因此不具备例子中所需要的各项技能。请试着思考在这种人设下[10]，「我」该如何去内化材料的内核。 ==我们会穷尽式地处理这份阅读材料，以最详尽地展示这些通用的制卡原则。请注意，实践中你通常不会也不必这么系统地学习。你一般只会关注文章中你认为最有价值的部分，然后在非常有必要的时候跳回原始材料，寻找与你理解最相关的信息并做成卡片 —— 这值得一赞！完美主义会过度消耗你的动力，穷尽式处理只是表面正确，实际上是浪费你的注意力，它们本应该放到更有价值的地方。这类问题会在后面更深入地讨论。== 如何制作和储存鸡肉高汤：「事实性」和「程序性」知识《鸡肉高汤》开头段落，更偏向概念性知识，因此我们直接从「菜谱」段开始，它具体描述了如何制作和存储鸡肉高汤。「菜谱」作为一类清单，包含的知识结构比「散文」形式更为明确，这给我们写卡初の体验提供了一些辅助。 我们先谈一谈「知道制作鸡肉高汤的必要原料」，此类知识主是「事实类」，「概念类」或「概念之间的关联」的成分比较少，其中主要包含了是无需加工的原始信息，给你打下学习下一层知识的基础。 「简单事实」类知识（Simple fact）==我们假如直接这么写卡：「制作鸡肉高汤需要什么？」，那么在回答的时候因为数量或者原料名称未作要求，所以很难作答。这样的卡片不够====准确====，也不够====聚焦== ==：同时要求提取的细节太多，所以想要加强的记忆不会全部被强力激活；并且因为它要的答案太多，因此的====一致性====、====可控性====也不好：每次回答，你会记起一些，又忘掉另一些。因此激活不够一致，容易导致记忆受到侵蚀。== 所以，得把答案中的原料表分解为实际会学到的要素。如果你从未听说过高汤的话，你可以像下面第一问一样，先简单地澄清取用部位： 问：取鸡身上哪个「类型」的部位做高汤原料？答：骨头。（Bones） 这个问题仅聚焦一处文章细节，想要的答案也毫不含糊（「哪个 “部位” 」），而「骨头」在每次回答中也都是一致的。这样的卡回答容易控制，但要对记忆做的「提取」仍不失努力。 ==在谈及事实时，我们自然会想添加一些解释。我个人会在细节不容易想到，或者事实背后的解释比较有意思的时候，添加一张「====解释====卡」==，相必你也有同样的冲动。因为即使身为大厨，不在乎上面那张卡，但依然可能受益于这张： ==问：为什么我们做鸡肉高汤要用骨头？====答：它们富含明胶（吉利丁，gelatin），可以产生浓郁的口感。== ==解释卡能强化「事实性」提问中的知识，而「解释」本身也让事实富有意义—— 这点也许更重要。此类卡片像钩子一样，将烹饪生涯中的想法与学到的「事实」相互关联起来。比如你学完这张卡的第二天，如果正好吃到「果冻鸡爪」，就可能考虑拿鸡爪作高汤材料（因为这是鸡身上明胶最丰富的部分），因为今天这张卡让你知道明胶能提升口感。==（*译者的经历：今天吃饭的时候我盯着甲鱼浮想联翩，因为它的裙边和 jio 富含明胶） 还想说一点，知识点并非集中于文章中一块儿。像上面这两张卡，它们的答案汇集自文章各处！写卡如拼图，你需要去文中各处翻找知识碎片。 这张「为什么」是一个不错的初の尝试，但仍可以更精确。因为像「骨头很便宜」也属于一种回答（尽管在设计之外）。如果你希望对信息的提取得毫无歧义，那下面这张会更好。 问：骨头如何产生鸡肉高汤的浓郁口感？答：它们富含吉利丁。 （你是否留意到红色的复习卡中仍有一张不符合「一致性」的原则？它并非为了提取练习，而是一个小实验，稍后讨论） 「清单」类知识回到原料表中的内容，「鸡肉高汤」从定义上显然就该包含水和鸡肉（稍后会处理分析），但剩下的香料都是变量，取决于应用场合。 因此，我们不如先从功能组别上去理解原料，会更好地帮我们内化菜谱结构： 问：鸡肉高汤是用鸡肉、水和其他什么类别的原料制成的？答：香料。 分组后，我们可以提子问题： ==问：鸡肉高汤中使用的典型香料是什么？====答：洋葱、胡萝卜、芹菜、大蒜和香菜== ==但是，除非你有一定经验，否则这个卡片对你来说可能并不可控，或是每次记的原料不一致。这样的无序列表要转化为好卡片，颇具难度。== ==对此，一个好策略是创建一组问题，并对选项分别挖空，并要求你逐一填空（下面用====？？？====指挖的孔）：== ==问：典型的鸡肉高汤香料：====- ？？？====- 胡萝卜====- 芹菜====- 大蒜====- 香菜== ==答：洋葱== ==问：典型的鸡肉高汤香料：====- 洋葱====- ？？？====- 芹菜====- 大蒜====- 香菜== ==答：胡萝卜== ==…以此类推。这里注意到选项列表顺序没有变动，这样你在重复回忆时，最终一定程度上会形成视觉====形状====上的记忆。== 大多数 SR 软件都有快速生成这样一组套卡的功能，卡片之间互为变体。即所谓「完形填空/ 填空题/ 挖空题」（cloze deletions），一次复习，只推送一个版本的问题要你填空。这很重要，因为只答一种版本，容易遗忘其余的选项。 当然，如果能在需要时回想起全部选项是最好的。尽管单选填空已足够应付大多数的做卡材料，==但对于复杂的内容，你可能得在彻底记住单选结果之后，还要添加一些综合性的卡片==（不同类别的「综合性」定义不同）。例如对于「清单」，可能要求你随着复习逐渐多选——我不知道是否有这样的 SR 软件，但似乎值得一试。 ==另一个帮自己理解「清单」的方法是为每个成分写一些解释卡——====为什么====胡萝卜是鸡肉高汤的好佐料？（注：胡萝卜提供植物糖，同盐一样能提亮其他味道）如果你知道原料的对应解释，也许不需要「填空」也能记住全部了。如前面所提，解释让「事实」更好被理解。本案的菜谱中，没有说为什么要这些香料，所以你需要自己去寻求解释。（译注：血泪提醒：「别做完美主义」）== 「线索」和「精细编码」==如果你对这些问题感到挣扎，那么可以添加一个「线索（cue）」：== ==问：典型的鸡肉高汤香料：====- 洋葱====- 胡萝卜====- 芹菜====- 大蒜====- ？？？（一种味重的香料）== 答：香菜 但要确保你的线索不会让卡片失去灵魂，努力地记忆中提取答案，是重中之重。 这样子就很拉胯： 问：典型的鸡肉高汤香料：- 洋葱- ？？？（英文与「parrots」押韵）- 芹菜- 大蒜- 香菜 答：胡萝卜 这种卡片实质上是要你猜一个谐音梗，而无需对所问的知识做「硬提取」—— parrots 只和 carrot 押韵，所以不看问题也能作答，压根就不存在对菜谱的知识做提取。总之，不能影响卡片的「提取」是写「线索」的基本要求。相比之下，上一版的线索「味重的香料」仍考验你的硬回忆。毕竟「香料」有很多种，范围虽然有所缩小，却仍要你记住菜谱指定的那个。 ==问：典型的鸡肉高汤香料：====- 洋葱====- ？？？====- 芹菜====- 大蒜====- 香菜== ==答：胡萝卜（英文 carrots 与「鹦鹉 parrots」押韵：想象一群鹦鹉叼着胡萝卜飞行，把它们丢进一锅汤里）== ==这类线索涉及另外一种记忆现象，也是认知科学家的实验对象 ——「精细编码 （elaborative encoding）」[11]：将信息与其他记忆相关联，它会变得更好回忆 。当然，原料清单这种，不容易搭配出有意义联想，但这种情况下，你仍可自己编造一个助记词来利用「精细编码」。生动的联想效果会更好，因此尽量从多个方面寻找联系。比如从视觉、有意义的个人经历、情绪（幽默、厌恶等）等方面。（译注：1.「elaborative」一词包含了「协作」的意思，所以不需要懵逼地去想「哪儿精细了」；2. 友情提示：助记词写在卡背，线索写在卡面）== 这里有个通用的技巧：万物皆可制卡，助记词也是如此。如果你要记的信息比较随意或零散，直接把助记词括起来放在答案栏里就行。要还是很难回答，就专门把助记词提成一张卡： 问：鸡肉高汤中「胡萝卜」的助记词？答：英文 carrots 与「鹦鹉 parrots」押韵：想象一群鹦鹉叼着胡萝卜飞行，把它们丢进一锅汤里 此外，图像也能触发「精细编码」，也很适合挖掉做「填空题」，你可能会发现这张卡片比文字更有记忆点： 问：鸡肉高汤的香料： 答：胡萝卜 ==当然了，做「线索」和「精细编码」会增加制卡负担。因此没必要见一张做一张，不然容易精疲力尽。==但如果你估摸着某张卡可能比较难记，它仍然是个有用的技术。 「再解释」以及经验法则「超量制卡」现在，高汤用什么原料已经解决了，数量上如何做卡？ 唔，你可以尝试这样问：「一份鸡肉高汤里有多少鸡骨？」，其中「一份」是什么，仍然不够精确。对此我们可以将问题和指定清单绑定起来，如「Andy版的鸡肉高汤配方里有多少鸡骨？」。不过这仍然不是我们实际想知道的 —— 鸡肉高汤的菜谱明确指出，量要随机应变。==写好卡片往往涉及对原文的解读（「再解释」） ，这是让理解超脱文章本身局限的第一步。==就像下面这样。 问：鸡肉高汤中鸡骨和水的比例是多少？答：每磅骨头一夸脱水 问：一磅鸡骨在鸡肉高汤中应使用多少洋葱？答：半颗洋葱 问：一磅鸡骨的鸡肉高汤中要用多少胡萝卜/ 芹菜？答：1 根胡萝卜/芹菜 问：一磅鸡骨的鸡肉高汤中要用多少大蒜？答：2 个捣碎的大蒜 其中没提香菜，这是另一例「再解释」：原文的「一束」无论如何也不是一个确切的单位，所以我才不管到底多少，反正我只抓一把。 ==注意到，为了保证聚焦而精确，这里将原料表分解成很多个问答。新手常常有节约用卡的强迫症，多写一张就跟多掏钱一样，倾向于把卡片的「数量」写得少少的、把「范围」写得泛泛的 —— 但这适得其反，因为你要掌握的「知识量」不会随着你的卡片数量而减少（除非特意排除某些内容），把卡片数量减少、内容变糙，并没有让必学的知识减量，反而让材料更难做重复练习，容易「齁」。（译注：薄的高数书只会更难。吾愿称之为 知 识 守 恒 律 ）== 卡片的复习用时比你想象中要少 —— 第一年里，一张低难度的卡片每次会花费10-30 秒，然后逐年剧减。如果你暂时没法把握时间开销，那么试着接受这个经验法则：永远比舒适量多写几张* （write more prompts than feels natural.）（*译注：我愿称之为 过 饱 和 写 卡，张数再多些、复习难度再低些 —— 有的（其实是全部）译注就是废话，当助记词吧） ==卡片不贵，但也绝非免费 —— 会有情绪上的开销：数量爆炸的低难度卡片容易让你崩溃，因为没人愿意花时间复习一堆闭眼都会的材料。 因此，如果材料讨论的东西已经相当熟悉，卡片应该写少一点 —— 并非说熟悉的领域可以写得含糊，而是因为边际效应，你要捕获的知识量本身就少。== 例如，我自己的卡组中，没有包括本例的原材料预处理，这对我没必要—— 蔬菜要小切、大蒜要捣碎，对于一个厨师，如果不粗心的话一般是自然而然的处理。不过你觉得有用的话就还是写一下吧。 ==还有一点与此相关，一张卡片「聚焦」在何种尺度上，取决于你已了然于心的概念规模。本例中的香料对我来说太熟了，我将其作为一个原子单位去记 （“意式香料”） 而不是拆开。== ==复杂的概念会随着融会贯通（「流畅性」的建立），逐渐组块化为新的基本单元，这样一来，你在对复杂概念写卡时，既不会丢失细节，又足够聚焦。实际上，一个专家的重要特征，可能就是基于越来越复杂的「组块」思考[12]。从这个角度看，各种助记系统扮演了一个「组块催化剂」的角色，它促进了你对某个方面组块的「有效大小」的增长（译注：Andy 不方便说得太绝对，但不妨碍我加料：因此，硬记忆通过组块化提升理解能力）== ==「程序性」知识====现在我们已经写好了关于原料的卡片，接下来烹饪的步骤更多是「程序性」知识，也就是用来执行特定任务的知识，对于「程序」，我们更多地是要知道“HOW”而不是“WHAT”.== 制卡方式一程序如果列好步骤，依然是某种意义上的「清单」，所以我们可以用「挖空」去做，例如第一个步骤： 问:1. ？？？2. 用小火炖到沸腾（约1h）。我们要用小火让其产生明亮、干净的味道，如果用温度较高的火，汤的味道和颜色都比较黯淡。3. 降低火候，保持一个半小时的沸腾。4. 过滤，等其冷却后转移到储存容器中。 答：在一个大锅中混合所有的食材。 （其余四个步骤以此类推）。 不过这张卡片完全谈不上聚焦。它糅杂了太多次要细节，掩蔽了你真正想提取的知识。个人而言，我会被这种卡片分散注意力，让回答含混不清、心不在焉。 我们可以简单删减文字来改进，细枝末节则移到新的卡片上去（如有必要）。下面这样就比上面好： 问：1. ？？？2. 小火慢沸3. 保持90分钟咕嘟咕嘟*4. 滤出，冷却后储存。 答：混合所有食材 *译者注： 原文「bare simmer」描述一种极轻微的沸腾程度。 制卡方式二如果从整个流程的角度，我们重新编辑这个程序，可以更好地观察过程中的知识。首先我们有如下观察：几个关键词/词组承载了核心细节：小火慢沸，微沸 90 分钟，而其他的词句只是程序的框架。由此得到第二个观察：第一和第四步不值得写卡 —— 因为有初步了解之后，你当然知道自己是用「锅」熬食材，当然知道炖完以后要「过滤保存」，这是常识。 以这种方式强调关键词后，写卡就像是在玩《危险边缘》，「现在你有xxx秒内回答如下问题」: 问：你应该以什么速度加热一锅鸡肉高汤的原料？答：慢慢地。 问：在制作鸡肉高汤时，你应该在什么时候降低火候？答：在锅里沸腾后。 问：在制作鸡肉高汤时，在锅内达到沸腾后，你应该做什么？答：将温度降至轻微沸腾。 问：鸡肉高汤必须炖多长时间？答：90 分钟。 这里是用「列关键词」的方式制的卡，在「列清单」的方式上进行了修订。反映了我对这个程序个性化的理解。 一个程序往往可以被分解为几个关键词：重要动词是什么；何时转移到下一个动作；哪些是关键形容词、副词，以及关键的主语、宾语。我们的高汤配方中，动词不是关键：「降温」、「过滤」——你煮东西的动作都很显而易见。但在动作之间跳转的条件和启发式很重要：水「降温」之前，不仅要沸腾，还要轻沸 90 分钟。同时对于「缓慢地加热」而言，副词「缓慢地」要比「加热」更重要。 鸡肉高汤中的程序相当线性，而更复杂的程序可能会有分支，包括特殊情况下的备选项。这样的谓词结构*（Predicate structure） 往往值得写卡。如果分支实在太多，你可以考虑画一个流程图。（*译注：「谓词 （Predicate）」—— 简单地讲， if (A&gt;B) {…}，中的 A&gt;B就是一个谓词，它决定了你走入下面哪一步。这里特别提出来是因为我想秀） 那么，「列关键词」的方式是不是比「列清单」更好呢？这取决于你的需求，如果文中离散的信息对你比较重要性、不够直观，那选择前者。它侧重于强调组成知识的 “零件”，可以精确表达知识（而且，回答聚焦的问题总是比较愉悦）。如果你只是想要概括性的大纲，那么列个清单可能更简单。 上文卡组中，一些有用的细节没被包含。现在我们单独添进卡里： 问：加热一批鸡肉高汤（含 2 磅骨头）需要多长时间？答：大约一个小时 这类「当心！」型信息看似不起眼，却往往藏着程序中的有用信息。比如你知道要加热多久，便在实操时有了对照：锅热了这么久还没有反应，是不是可以停了？汤这么快就开，是不是得赶紧停下？*（*译注：菜谱无法教你如何对所有可能性做处理，但条件约束上可以推断出好多东西。） ==解释卡== ==对「程序」学习有特殊价值：它避免你死记硬背，并帮你深入建立理解== —— 问：为什么 Andy 的菜谱声称我们应该用小火准备鸡肉高汤？答：「更明亮、更干净」的味道。 请注意，这次的例子中我们只深入了一层「为什么」—— 为什么要小火？菜谱只说能让味道更干净，至于为什么能更干净则没提到。于此同时，你也自然想知道什么味道算是更「亮」或「干净」，于是卡片写完，理解上的缺漏也一起暴露，这简直不能更棒。这里要注明的是，这些答案虽然不够刨根问底，但我们暂时选择继续前进。你无需为此特别标注，只要在制作卡片时写成例子中这样，明确体现出此答案是依赖于某种外部要求而暂定的即可。 每当处理主观、暂时、或不全面的信息时，最好都体现出它的这种性质。因为大部分卡片给出的内容，或多或少都有暂时性（比如换个菜谱可能用不同方式处理相同步骤），因此理论上我们可以把一切卡片都表述得不那么绝对，然而这弊大于利，因为太容易让人分心。平衡这个矛盾的一个办法是，我们简单记录信息来源（SRS 系统一般都有元数据项可以链接到原始菜谱），这在一般情况下已经足够了。 练习：如何储存鸡肉高汤？我们已经写了关于如何制作鸡肉高汤的卡片，现在轮到你了。请利用我们到目前为止所学的知识，在笔记上写出带上你自己理解的卡片： 「这将产生大约 1.5 夸脱鸡肉高汤，可以冷藏一周，也可以在冷冻里无限期保存。使用前，需要脱去高汤上的一层脂肪，这些脂肪可以在别的要增味的地方代替植物油或者黄油。」 ​ 给 你 一 炷 香 的 时 间 以下是我的卡片： 问：2 磅鸡骨大约能产出多少汤？答：1.5 夸脱 问：？？？磅鸡骨大约可以得到 1.5 夸脱的汤汁？答：2 磅 问：鸡肉高汤在冷藏区里能保存多长时间？答：一个星期 问：鸡肉高汤在冷冻区里能保存多长时间？答：无限期 问：冷却后，在使用新的一批鸡肉高汤之前，我应该做什么？答：刮除表层的脂肪 问：我应该如何处理从鸡肉高汤中刮除的脂肪？答：保留并作为咸味烹饪油脂使用。 看完后思考以下问题：这些卡片与你的卡片相比如何？这些卡片是否包括了你没有涉及的细节？你是否涵盖了这些卡片遗漏的任何细节？这些差异对你有什么影响？你的卡片覆盖的知识/问题范围与这些相比如何？ 何为高汤？为何重要：「概念性」知识一个能自己转动而不能带动任何东西转动的轮子，就不是机器的一部分 —— Ludwig Wittgenstein，《哲学研究》。 现在我们回头看菜谱最开始的段落，它介绍了鸡肉高汤的。「定义」看起来像是最简单的卡片内容了：学校里那种类型的 “闪卡” 就最爱这么干（白眼）。 例如，这样考察定义怎么样？： 问：什么是高汤？答：鲜美的的液体烹饪积木（liquid building block）。 问：描述鲜美的液体烹饪积木的烹饪术语？答：高汤。 先不提卡片的「聚焦性」、「精确性」、「一致性」。我们完全可以逐字逐句记住第一个问题中的答案，名称放在正面也可以帮你记住术语，但只能复述答案完全不等于明白高汤是何物。 「高汤」是一种概念。知道一个「概念」所指何物，与高中闪卡式的知识（例如「意大利语 “correre” 等于 “跑步” 」）不同。想要内化它，你需要了解组成概念的元素以及元素之间形成的结构。因此对于这类知识，你的目标是设计一套卡片，联合起来，一起框定「高汤」这个概念*。（*译注：学CS 的同学可以用「数据结构」去理解这段话） 现在我将介绍一些视角，用来帮助理解「概念」。它们可以看作一组工具套件，从知识中帮你提取需要的部分。它们附带的示例比较适合新手厨师，老道的厨师通常知道高汤是什么概念（尽管不一定会做）。 视角一：特性和倾向*：什么让高汤之所以为「高汤」？对于高汤来说，哪些断言或描述「永远」/「有时」/ 「永不」为真？（*译注：原文「 Attributes」，显然又是个 CS 黑话） 问：高汤通常是如何制作的？答：在水中炖煮具有丰厚滋味的原料。 问：为什么高汤通常没有突出的味道？答：为了使它们更广泛地兼容多种菜肴。 视角二：辨析异同：要知道什么是高汤，就要知道它与其他近似概念的关系和区别。 问：高汤与广义上的「汤」有什么不同？答：普通的汤本身味道更完整；而高汤往往作为辅料。 视角三：部分和整体：有哪些高汤的具体例子？高汤是否有重要的「次级概念」？「高汤」是否是某类更广概念的次级概念？请想象一个概念和概念之间的韦恩图，虽然没有非常明确的边界。 问：至少说出三个高汤的例子。答：如鸡肉高汤、蔬菜高汤、蘑菇高汤、猪肉高汤。 问：高汤很少直接食用，它最好被认为是一种? （用乐高比喻）答：积木。 视角四：因果关系：高汤是「做什么」的？什么让它「实现那个效果」？它没有「做到什么」？「什么时候」用它？ 问：为什么餐馆使用高汤而不是水作为烹饪介质？（请说出两个原因）答：增加味道，改善口感。 问：高汤是___的常见基础（至少说出两个）答：e.g. 酱汁、汤、炖菜。 问：餐馆经常使用高汤作为烹饪媒介，而家庭厨师可能使用？？？。答：水 视角五：意义和影响：「为什么」高汤很重要？它表示了什么？注意：请让这个概念对你有个人意义。 问：哪种液体积木可以解释为什么简单的餐厅菜肴往往比家里的菜肴更美味？答：高汤。 问：如果我注意到我在做料理时使用了水，我应该问自己什么？答：「我应该用高汤代替吗？」 最后这张卡并非取自原文，只是示范一种个人理解。同时也要注意，它更多试图对「行为」做改变，而不是「智识」方面。在鸡肉高汤的应用章节中，我们将详述如何使用卡片来改变行为。 练习：何为鸡肉高汤，为何有意义？下面一段介绍了鸡肉高汤在烹饪中扮演的角色，为了练习对「概念」性知识的建模，请尝试对自己的理解编制卡片： 「鸡肉高汤是最普遍、最有用的高汤之一，并非为了让一切菜肴染上鸡肉味，而像是为菜肴加入“和弦”，协调其主味。例如在做素菜时加入它，会让菜肴的味道更加完满。而其中来自鸡骨的明胶成分，也让口感也更丰厚。至于成本，这种高汤既不占用时间，也无额外开销。它的原料来自鸡骨，如果你经常用鸡肉做饭，可以在冰箱里顺手存上很多」 [ 给你一炷香的时间X2 ] 我可能写出如下的卡片： 问：鸡肉高汤不会使素菜吃起来像鸡肉，而是使它们吃起来更??? （根据安迪的菜谱）答：味道完满 问：鸡肉高汤使素菜的味道「更完满」，因为它加入了？？？，从而像为主味加入？？？（音乐比喻）。答：支持性（supporting）的声音；和弦 问：除了改善味道，鸡肉高汤给菜肴增加了丰厚的？？？。答：口感 问：撇开味道和饮食偏好，为什么用鸡肉高汤而不是蔬菜或蘑菇高汤？答：鸡肉高汤中含有明胶，创造丰厚口感 问：为什么鸡肉高汤很经济？答：它的主料（骨头）可以免费积累，如果用鸡肉做饭的话。 问：我应该如何处理烤鸡的边角料？答：冻起来，做鸡肉高汤 我发现还有一张我自己很想写的卡片，但光靠原文没办法写出来： 问：什么时候使用「鸡肉高汤」而非其他肉类做的高汤？答：？？？ ==卡片写作有助于揭露我们理解上的缺失。追随你敏感的大脑去查谷歌、去查文献，不要拘泥于原文。即使你不打算立刻「补缺」，光是写下这些卡，也能让自己敏于「查漏」、保持好奇。这有益于在未来的探索。== 请考虑下面问题：这些卡片与你自己卡片相比如何？我是否包括了你没有涉及的任何细节？你是否涵盖了我遗漏的任何细节？这些差异对你有什么影响？你的卡片范围与这些相比如何？ 你会注意到，我并不一定会用上之前介绍的所有「视角」。例如「部分/整体」和「核心特征」视角——我不觉得鸡肉高汤有什么部分和整体结构，也不觉得鸡肉高汤的核心特征（用鸡制作）不傻。 使用鸡肉高汤：「开放式清单」和「启明卡」高汤光看不用没有意义，所以菜谱里还给了建议用法列出了清单，此类型的知识又该如何建立理解呢？ 「开放式清单」「清单」类知识的处理技术我们已经学习，试试此处是否也适用？： 问：可以用鸡肉高汤做什么：- ？？？- 将丰盛的绿蔬打蔫并蒸熟- 做西式浓汤- 在平底锅上「刺啦」一下 答：用它烹饪谷物 这卡片显然毫无帮助，因为第一个空里看起来填什么都合理。你也许已经发现，这个列表的「任意性」要大于之前部分的原料清单，问题没有固定的答案。此类便是「开放式 清单（Open list）」类的知识，相对应地，原料表则是封闭式清单（closed list)，它的成员固定。开放式清单无需记住所有内容，不过可以按需记一些 —— 但如果你会一直下厨，不要这么做，不然会越记越多，然后把一辈子都搭在这个清单上。 我个人把封闭式清单看做一种复合后的「事实类」知识，它们几乎是个静态的等式： 地球的半径 = 6,371 km 鸡肉高汤的原料 = 洋葱、胡萝卜、芹菜、大蒜、香菜。 而开放性清单我喜欢看做标签 （tags），就像你可能在数字书签系统中用的那种。本案例中可以这么认为：我头脑档案柜中有一种 tag 叫做「鸡肉高汤的用法」，我把它贴在关于浓汤制作*的笔记上[13] 。（*译者注：「 purée soups」 是用蔬菜泥，土豆泥，水果泥，起司等做的糊糊，典型用法是蘸烤法棍片当餐点主食。此处指给所有糊糊的做法都贴上这个 tag） 我发现有三类卡片可以帮助「开放式清单」的编码：首先是我打好 tag 的普通提取卡，它将卡片实例和 tag 关联起来；之后若注意到 tag 中蕴藏的模式（pattern）*，我可能将 tag 提成单独一张卡；最后我还常写一个举例卡，要我围绕 tag 举例，以此将 tag 和其实例松散地产生联系。（*译者注：实例是一个抽象物的实体，比如世界上有个名叫「特斯拉」的猫，那么它就是「猫」的一个实例。模式（pattern）指实例中存在的相似结构，比如做浓汤时总是要加水） 例如，下面这张卡将一个实例关联到 tag 上： 问：做蔬菜浓汤时，怎样才能既不增加油脂，又产生更丰富的味道？答：用鸡肉高汤而不是水稀释蔬菜泥。 写了几张之后，假设察觉到 tag 的共同模式（都是用水做汤），因此将这个模式提为卡片： 问：如果我注意到我在用水做咸口的菜，我应该问自己什么？答：「我应该用高汤代替吗？」 我希望必要时能回想起具体实例，因此我们另起一张卡片，将 tag 松散地链接到实例： 问：说出两种使用鸡肉高汤的用法。答：如：烹调谷物、蒸煮蔬菜、做清汤、「刺啦」撒在烤盘上 最后这类卡不怎么费脑子，因此易被滥用。这类卡极度依赖其他卡片。否则，你可能会忘记其他项，而总用固定的一两个案例作答。即使每次答案确实 轮换了不同的实例，但卡片也不再满足我们说的「一致性」，并且干扰效应可能让记忆变得不可靠。 如果你刚刚习得的概念高度开放，可用范围极广阔，那么你可以将「案例生成卡」转变为如下的「创意卡」： 问：请说出你可能尝试用鸡肉高汤制作的蔬菜浓汤（不允许和以前的答案重复）答：e.g. 土豆、防风草、芹菜、苏子、莎草、南瓜、胡萝卜、胡椒、扁豆…… 「不允许和以前的答案重复」这是个很有意思的小把戏，尽管过一两年可能还是会重复（这可以接受）。我要说的重点在于，一开始就概括了应用场景的问题很难写。换句话说，你得写卡前就知道高汤怎么用，这是要一定烹饪经验的。 「创意卡」更类似教科书上的习题，它引导你创造性使用知识点。与「提取卡」相反，它极力避免 从记忆中提取固定答案，而是要求你创造性地思考片刻。由于你想到的答案次次不同，就不会强化某个固定答案的记忆，而是强化在生成 各种结果时，你大脑里一致依赖的知识。同时，你的创新也可能勾起有意义的联系，并触发「精细编码」强化记忆。这些联系因为是你自己生成，所以会格外牢靠 —— 即所谓「生成效应」。[14] 严谨地说，目的对「创意卡」的内蕴机制理解有限，远不如对「提取卡」的。一些课题仍待研究[15]：在我们的记忆和理解中，这些任务产生哪些特殊效应（如果有的话）？通过什么机制？要设计何种适用环境、使用原则？适用何种间隔重复计划？ 「启明卡」和「Baader-Meinhof 现象」我们讨论的很多卡片除了影响记忆和理解外，还有另一个重要功效：保持你对 idea 的长期思考（keep you in contact with an idea over time）。 你是否有过这样的经历，明明是第一次了解某个事物，却突然发现你到处都能见着它？比方说学习了一个类似「mellifluous」的罕见词，之后几天能看到它好几次。这个现象被称作Baader-Meinhof 现象（*译注：也称频率错觉）。因 1994 年某网友投稿说自己一天里注意到两次该冷门恐怖组织而得名。斯坦福大学语言学教授 Arnold Zwicky 认为，这种效应本质是是一种「选择性注意」：新的 idea 在意识里总是更靠前（「凸显性/ 显著性」），所以对应的信息更引人注意，而客观上，出现频率并没有变化。正所谓「塞给你一个锤子，看什么都像钉子」。 但对于某个idea来说，这种效应并非总是正面的，因为新的「锤子」不一定适用所有「钉子」*。要真正内化它，你需要自己生活中有所代入、赋予其意义。特别是学习一个新技能时，除非多实践几次，否则可能只是浅薄理解而不自知。（*译注：避免新学一个概念后滥用和过度泛化） 如果不快点把 idea 和有实义的东西联系起来，它的「凸显性」会消退，你也逐渐停下对周边机会的觉察。但这种凸显性的消退不正如知识的遗忘吗？因此始终在脑中 “置顶” 你的 idea，也是 SR 卡的价值所在。Gwern Branwen 认为[*]此类卡片实际是对控制、扩展 Baader-Meinhof 现象的有效尝试。 我们关于「凸显性」写了一些卡： 问：如果我注意到我在咸口的烹饪中使用了水，我应该问自己什么？答： 「我应该用高汤代替吗？」 问：我应该如何处理烤鸡骨头？答：冻起来，做鸡肉高汤。 问：请说出你可能尝试用鸡肉高汤制作的蔬菜浓汤（不允许和以前的答案重复）答：e.g. 土豆、防风草、芹菜、苏子、莎草、南瓜、胡萝卜、胡椒、扁豆…… 这些卡片旨在「提示」而非对答案的「传授」，从而尝试激发新的灵感或者创造新的行为。从这个角度看，SR 卡让这些 idea 长久保持了「凸显」，让人对相关内容保持敏感，直到遇到机会，将自己生活中有意义的事物与其联系起来。就像经济学家布拉德-德隆（Brad DeLong）认为的那样，SR 卡在复习环节和世俗版的「教理问答*」惊人地相似（*译注：教理问答 —— 一种宗教教育的教材，形式上也是问答体。通过问答来潜移默化地记住、思考、理解。） 本指南中的许多 Orbit 卡片（*译注：红卡）都是这种类型的。它们的目的是让你与这些想法保持联系，直到你在写自己的卡片时仍然能保持对它们的了解。虽然可能有点怪，但我在创作过程中经常写这种关于自己的想法的卡片。它们帮助我在几周或几个月内能够持续沉思一个只有泛泛理解的事情或者是一个问题，直到其有希望发展出更多或更深入的东西。这是编写卡片的一种方式。使用这种方法可以比简单地从文本中获取知识创造出更深入的理解。 你应该想想 idea 可能在生活中用到的场景，并在写启明卡的时候代入，它们具有潜在的意义。例如很多人做饭可能不喜欢买整鸡，现在为了凑骨头，而打算略作让步。下面这张卡示例了如何针对某个特定场景制卡： 问：为了保持满冰箱的鸡肉高汤，我买鸡时一定要用？？？而不是？？？。答：买整只鸡；买鸡的部分 这个例子还辅助说明了一个更广泛的问题：「知道 idea 能解决什么问题，不等于解决问题时知道用什么 idea*」[16]。它们之间的区别是否有逻辑充分的解读，我目前不得而知。依我经验，带上下文的卡片（如刚才的例子）能帮助我们从理论迈向实践。我想，这正是另一个「新、旧想法要紧密结合（densely connect new ideas to old ones）」的理由，一如我们在「概念」类知识的学习中做的那样 —— 不准确地说，概念之间联系得越紧密，越容易触发新知。（*译注：原文 Just because you can answer a factual question about an idea, that doesn’t mean the idea will spontaneously occur to you when it’s useful） 最后思考：什么因素，是最可能让 SR 卡片改变你的行为/ 促进新的想法的？对刚才这类的卡片，如何安排 SR 策略？最后，如果不为记忆，回顾时的回答按钮（「忘记」/「记住」）又如何调整？这些仍是开放性问题。 练习：菜谱变体 材料里有一段是菜谱的变体版本。这仍然一定程度的「开放式清单」。写下卡片，展现你对它的理解： 如想尝尝偏法式的鸡肉高汤，可以用韭菜代替芹菜，再加入月桂叶、黑胡椒和百里香。为了获得更「深」的味道，可以先把鸡骨和蔬菜烤成所谓的「棕色鸡肉高汤」（原本的相对是「白色鸡肉高汤」，味道不强烈，但更细腻、通用）。 请在下面输入框中尝试练习，你写的东西不会被传送或保存。 【译者：假装此处有文本框】 实践写卡迭代式地写卡本指南为了演示写卡技术，刻意对案例进行了详尽分析。而实际上你如果是第一次碰菜谱，我绝不建议像前文那样，一次写上好几十个卡片。如此穷尽、全面地分析你的读物，很容易浪费大量时间，耗竭精力。 何况，你也不能指望第一次接触新的知识，就能轻松写出优质的卡片。此时的你尚在建立把握、区分重点的意识（无论是客观还是个人意义的重点）。因此你难以知道哪些内容特别难记（并特别关照），也可能不太了解作者的想法。所以编写的卡片要么无法连通其「本质」，要么不能捕捉其中微妙。因此，你还需和新学的知识 “相处” 一些时日，你才能写出好卡片，并与自己的情况鲜活地联系起来。 于是，一切都在呼唤一种迭代式的写卡方式： 想象你正在阅读一篇有趣的文章，试着给自己设下一个可触及的目标：一刷时，要求写下少量的卡片（ 如 5-10 张），描述任何看起来最重要、最有意义或最有用的东西。 设下这样的目标改变了我的阅读方式，无论是正式还是随性地阅读。在最初用 SRS 读书时，我有种强迫感，想把一切都写进卡里，这导致阅读体验极差。相比之下，每次只要求增添一点关键卡，会让我倍感自由[17]。于是我读得更积极了，脑海深处似有一种挠人的痒：「哦上帝，那看起来真多汁，让我来摘下它！」 如果材料相当简单，我们可能尚有余力一边阅读、一边写卡。但如果材料太难，或者不是熟悉的主题，那最好只标记或记录最重点 —— 写写停停地切换实在太打断思考了。之后你可以在文本的结尾或找一个合适的停顿处，一次性将你的理解写成卡。如果主题难度非常高，一开始先老老实实地聚焦在基本细节上面是最佳做法：比如「事实类」知识的原文、术语、符号约定等。 书籍阅读要比文章更复杂，因为种类多、阅读方式也多。虽然文章也可以多种多样，但「书」这类载体放大了它的复杂性。一方面，书不太可能像文章那样线性阅读（也就是逐步从头读到尾）；另一方面，它们的篇幅显然更长，制卡量也不会少。因此编卡没有固定的最佳做法，而是取决于你读它的「目的」和「方式」（Why &amp; How）。不过一般来说，如果我要内化一本书（非小说虚构类），我会在我第一遍读某个章节或者主要部分时，设一个目标作为起点（「写上一些关键卡」）。 至少最初阶段，好多材料写一遍卡足矣。但如果有一段文本是「富矿」，你正试图彻底内化它，那么哪怕是首个阅读环节，也常常值得反复多写几次卡。这么做不一定会让负担翻倍，因为每次就只要添一点点比较关键的卡片[18]。每次迭代时，你可能会发现，自己能理解（并卡片化）越来越复杂的细节。你的关注点可能逐渐转移到其中的模式（pattern）、联接（connection）乃至图景更宏大的洞察（insight）。更妙的是，你或许会跳出作者的内容，开始聚焦在自己的观察和疑问上。但同样要注意见好就收，不能永无尽头地去深化。实际上，事无巨细地写下全部细节并非一种美行，保持住对兴趣和好奇心的敏锐响应，远远比一丝不漏地卡片化重要。 如果感到「收集所有细节」的强迫症发作，请默念「以后总有机会继续」。事实上，卡片的价值不止是细节控，能让你被有意义的东西鼓舞[19]或许会更好 —— 比如发现新的知识联系，或者理解上的漏洞，你因此鼓舞。 让我们再来考虑一次我们的菜谱，这次我是个有抱负却孤陋寡闻的厨师，以前没听说过什么「高汤」。对我来说，可能会做的全部就是先写一些卡片指向概念本身 ：「高汤是什么」、「高汤的意义」—— 这些细节的覆盖面看起来不止一个菜谱，而且和我有过的美食经历相关。直到我真做完一罐高汤后，我就清楚哪些步骤很显然、哪些细节还得查菜谱了。此时若期待下一次制作，那就将这些更细节的东西提出来，写到卡上 —— 原料的配比、时间控制之类。我还会留意之前制作过程中感到费力的地方，我知道它们的相关内容我「读过，但不能确定细节」。等我用完第一批高汤后，我大概会将使用经验添进卡组，如此往复 有效性检测写散文时，文法检查器可以帮你避免容易犯的错误，而 SRS 方面，没有「卡片低级错误检查器」。因此找一些简单的测验会有所帮助。 1. 检测「假阳性*」：在不真正了解目标信息的情况下，你如何确定正确答案是怎么产生的？（*译注：统计黑话，指标阳性 ≠ 推论阳性，此处应指「回答正确」不等于「了解信息」） 抑制模式匹配 ：如果你写了一个长问题，措辞上用了不常见的词或线索（提示你这是哪张卡），你最终可能会记住这个问题的「形状」和它对应的答案 —— 你只是通过机械的模式关联答题，而不是真的思考了相关知识。「完形填空」类的卡片似乎容易产生此种问题，尤其要留意复制/ 段落编辑而来的卡。最好的避免办法，是让问题简短。 避免二元提问 : 要求回答「是/否」或「这个/那个」的问题往往不需要努力提取，而且产生不了深层理解。我个人经常可以不加理解地答对这样的卡片。解决二元化的提问，最佳做法是转述成开放性的问题。例如，对下面第一问进行改进： 问：鸡肉高汤是否会使素菜吃起来像鸡肉？答：不会。 问：鸡肉高汤如何影响素菜的味道的？（根据「安迪的菜谱」）答：它使它们的味道更「全面」。 要改进二元提问，往往需要结合其他东西，如一个例子或一个暗示。前文的「概念类知识」中提供的思考视角在这方面很有用。 2. 检测「假阴性*」的方法： 有没有可能知道卡片指向的信息，但是没 能正确作答？这类错答往往由于上下文给的不够充分。（*译注：统计用语，指标阴性 ≠ 效应阴性，比如核酸阴性不代表一定没感染新冠） 你很容易不小心写出一问多答的卡片 —— 正确答案不止卡背上的那一个。因此卡片必须给足语境，能显然排除掉合理的替代答案，但又不能给太多，避免把问题写太长，导致模式匹配或卡片「失焦」。 例如，如果你读完一个煎蛋菜谱立即提问「做煎蛋的第一个步骤是什么？」 ，此时答案可能是显而易见的：「用平底锅热黄油」！但六个月后再次回答，你可能想到很多合理的答案：「打蛋」，「用平底锅热黄油」，「把蘑菇剁碎做馅」等等，这不好。 一个解决方案是提供极其精确的背景：「Bon Appetit 18 年 6 月的煎蛋菜谱的第一步是什么？」但这种强限定，表明知识本身就比实际上更广。如果可能，在能避免歧义的情况下，普遍性强的知识应当被普遍地表达。这或许也意味着你需要换个切入点提问；例如这样：「做煎蛋时，在加入鸡蛋之前，锅必须如何准备？」 假阴性的卡片常像是学校考试中最无聊的废话：「哦，是的，回答正确，但它不是标准答案。再试试？」Soren Bjornstad 指出，一个不能排除多种回答的卡片，需要你记住设问的信息本身，还要额外记住「卡片在问什么」。 随时间推移修订卡片很多问题在写卡的同时我们往往不明显，而只在复习时暴露，有时还在好几轮复习之后（那时重复间隔甚至可以长达数月）。卡片 bug 的反馈周期并不短，因此其修订也重在渐进，一如渐进地写卡，此过程中，你也会留意其中的问题和机会。 复习环节中，请警惕「望卡兴叹」的感觉：「哦上帝，这个卡片 ——我永远都记不住答案」或者「每当刷到这张卡，我都知道答案，但并不真正理解它的含义」。倾听这些内心反应，并由其驱动你的修订。为了避免打断复习，大部分 SRS 允许在复习中标记待订正的卡片。你可以在复习完后，查看它们，并做改进。 学习卡片编写，就像学习散文的遣词造句。[20] 所用技能看似平凡，但个个上限很高。无论写卡或炼句，修订它们都要从整体着手。散文里的单句比较糟糕时，可能要合并整个段落、修改叙事方式，或大段大段变更文本结构。我在改卡时也有类似如上的观察，有时可以单独提改，但每当我理解有变时，常希望对整套卡组开刀 —— 这里合并、这里重构、那里细分。[21] 不幸的是，大部分 SRS 界面都将卡片视作一个独立的单元，这让自下而上做修订变得困难。就仿佛要改的论文被锁定住，必须申请一句、改一句。未来的 SRS 可能优化这方面问题，但当下按我的观察，只需主观上保持一个对整体性的渴望，即可更高效地修改。 在前文 ，除了细筛案例、陈例制卡的效用原则，数量上也有所建议：制卡应超出你的舒适量（write more prompts than might feel natural.）所以，我想提供一个反向考虑下的建议来结束全文。 我们探索的重点，始终是如何用卡片对多种多样的『理解』进行有效地表达。但仅满足有效性规则的卡片，却不一定值得重复。我相信最重要的、可以「优化」SR 练习的方面，莫过于「重复」本身与「重复内容」之间产生的情绪联系（the emotional connection to your review sessions and their contents）。如果突然发现，所重复的内容不再是自己关心的，你应有所行动 —— 要是想起当初制卡的动机，你可以通过修订来提示它，但绝大多数时候，直接砍掉是最佳做法。 我们可以从制卡的反面来理解这个建议：什么材料应该 是你写卡的？何时是 SRS 值得一用的？许多人刚开始用 SRS 时感到棘手，虽然兴致盎然，却对自己的情况无从下手。另一些人从背诵所谓「你应该知道的xxx件事」开始（如所有美国总统的名字），通常会倍感无聊、萌生退意。最好的开始，是研究怎么用它做一些事情，和自己息息相关的那种 —— 例如，用来撬动 idea，强化你核心工作里对创意的理解。随着积累，你对 SRS 的收益和成本便深有体会了，这可能带来更多应用点（就像我的烹饪）。如果你找不到任何方法，将 SRS 用于自己的重要事情上，那或许本就不该费心去用它。 进一步阅读这些资源对我来说特别有用，因为我已经对如何写出好卡片有了一定的了解： Piotr Wozniak 的有效学习：制定知识的二十条原则[2]和更详细的基于主动回忆的学习中的知识结构和表述[3]从不同的角度处理了与本指南相同的问题。 Michael Nielsen 的增强长期记忆[4]：全面回顾了 SR 的原理，以及你为什么应该关心；更详细地介绍了如何实际地将卡片写作结合进你的阅读实践，特别是在阅读学术文献、对创造性工作记笔记时；以及更多。 Michael Nielsen 的利用间隔重复系统看透数学作品[5]展示了如何利用间隔重复卡片作为杠杆，迭代加深对数学作品的理解。 更多观点和相关话题，请参见： Soren Bjornstad 的记忆系统系列涵盖了维护卡片库的许多实用主题，包括一些关于写卡的建议。 Nicky Case 的如何永远记住任何事情介绍了间隔重复法，并通过有趣的插图介绍了一些卡片写作的技巧。 我们怎样才能开发变革性的思想工具？[6]（来自 Michael Nielsen 和本 Andy）讨论了卡片写作在「助记媒介」的挑战，其中包括将卡片嵌入叙事性散文中。 致谢感谢 Peter Hartree、Michael Nielsen、Ben Reinhardt 和 Can Sar 对本指南的有益反馈；感谢我在编写本指南时举办的卡片写作研讨会的许多与会者；感谢 Gwern Branwen 和 Taylor Rogalski 对写卡的有益讨论，这些讨论为本工作提供了信息。我特别感谢 Michael Nielsen 多年来围绕记忆系统进行的对话和合作，这些对话和合作塑造了我对这一主题思考的各个方面。 本指南（和 Orbit，其内嵌的间隔重复系统）是由我的 Patreon 社区提供的众筹研究经费促成的。如果你觉得我的工作有趣，你可以成为会员，以获得持续的幕后更新和新作品的早期访问。 特别感谢我的赞助商级别的赞助者。Adam Wiggins, Andrew Sutherland, Bert Muthalaly, Calvin French-Owen, Dwight Crow, fnnch, James Hill-Khurana, Lambda AI Hardware, Ludwig Petersson, Mickey McManus, Mintter, Patrick Collison, Paul Sutter, Peter Hartree, Sana Labs, Shripriya Mahesh, Tim O’Reilly. 许可证和署名本作品以 CC BY-NC 4.0 授权，这意味着你可以复制、分享和建立在这篇论文上（注明出处），但不能出售。 在学术工作中，请将此引用为： Andy Matuschak, “How to write good prompts: using spaced repetition to create understanding”, https://andymatuschak.org/prompts, San Francisco (2020). 注释 [1] 本指南假定你对间隔重复系统有基本的熟悉。有关介绍，请参阅 Michael Nielsen 的《增强长期记忆》[4](2018年)，该文也是「让记忆成为一种选择」这句话的来源。 [2] 如果你没用过间隔重复系统，我建议你下载 Anki 并阅读之前提过的那篇 Michael 的文章[4]。 [3] 更多的背景资料，请参阅 Roediger 和 Karpicke 的 《测试记忆的力量》 (2006)。Gwern Branwen 关于间隔重复的文章[7]是比较公认的一个的好综述。 [4] 例如，见 Karpicke 和 Blunt 的 提取练习比使用概念图的精细学习产生更多的学习效果 (2011)；以及 Blunt 和 Karpicke 的《用基于提取的概念图学习》 (2014)。 [5] 关于助记媒介的更多背景，见 Matuschak 和 Nielsen， 我们如何才能开发出变革性的思想工具？[6](2019)。 [Jarrett 1] 遗憾的是，嵌入卡片需要 Orbit 项目的支持，无法在普通的网站上实现这一效果。想要了解这种嵌入卡片具体形式的读者，可以阅读原文，亲自体验一番。 [6] 你可能会发现在两个地方复习卡片很烦人。随着 Orbit 的成熟，我们将发布导入/导出工具来解决这个问题。 [7] 这种效应已经在许多实验中产生，但还没有得到很好的理解。概述见Murayama 等人的 《遗忘是提取的结果：提取诱导遗忘的元分析回顾》(2014)。 [8] SuperMemo 的算法（也被大多数其他主要系统使用）被调整为 90% 的准确率。如果你以更低的准确率为目标，每一次复习都可能对你的记忆产生更大的影响——参阅例如 Carpenter 等人的 《使用间隔来增强不同形式的学习》 (2012)。更高的准确率目标以效率换取可靠性。 [9] 关于困难的提取比容易的提取有更大的影响这一概念，见关于 Bjork 的讨论，以及 Bjork的 《废用新理论和刺激性波动旧理论》 (1992)。Pyc 和 Rawson 的《测试提取努力假说：更大的正确回忆信息的难度是否会导致更高的记忆水平？》 (2009) 对这一理论提供了一些集中的实验测试，他们将其称为「提取努力假说」。 [10] 如果你是一个素食主义者，我希望你能看淡关于骨头的讨论：选择这个例子涉及到许多权衡。 [11] 例如，见 Bradshaw 和 Anderson 的 《精细编码是对加工水平的一种解释》 (1982). [12] 一个令人信服的证明，可以见 Chase 和 Simon 的 《国际象棋中的感知》(1973)，它通过实验证实了国际象棋大师是如何操作较大的组块的。 [13] 事实上，如果您是一位经验丰富的厨师，您可能会将鸡肉高汤的原料也视作开放式清单——如果是这样，最好以这种方式代表它们！ 这是人类尺度下，封闭式清单的共同命运。 [14] 见 Slamecka and Graf, The Generation Effect: Delineation of a Phenomenon (1978). [15] Michael Nielsen 和我在量子力学中尝试了以应用为中心的SR卡片，但我们觉得并没理解它们。 [*] 私人通讯中 [16] 这是教育心理学中称为「学习迁移」的一个广泛问题的一个方面：人们如何将他们在一种情况下学到的东西转移到另一种情况？ [17] 正如 Michael Nielsen 笔记，类似的轻量级卡片写作目标可以活跃研讨会、专业对话、活动等。 [18] 有关数学中这一过程的生动描述，请参见 Michael Nielsen， 使用间隔重复系统看穿一段数学[5] (2019)。 [19] 间隔重复的先驱 Piotr Wozniak 一直在开发一种他称之为 渐进阅读[8] 的系统，该系统试图积极支持这种迭代、增量卡片写作。 [20] 对句子的类比来自 Matuschak 和 Nielsen， 我们如何开发思维变革工具？[6] (2019)。 [21] 如果您尝试过这些练习，您可能会注意到，在同一文本字段中撰写多个问题时，跨问题边界进行修改要比仅单卡修改会更容易。 作为一项实验， 我 2020 年所写的全部新卡片都是简单的“Q. / A. 一种。” 使用老式文本编辑器而不是专用界面嵌入明文笔记中的行（如本指南中的示例）。 我发现在大多数情况下我更喜欢这种方法。 以后我可能会发布一些工具，允许其他人以这种方式编写卡片。 更多有关制卡原则的内容，请关注： 原文：How to write good promptsAndy Matuschak December 2020 参考 ^可使用间隔重复系统对注意力编程 https://zhuanlan.zhihu.com/p/414293765 ^有效的学习：处理知识的20条规则[直译版] https://www.yuque.com/supermemo/articles/20rules ^基于主动回忆的学习中的知识结构与表述 https://zhuanlan.zhihu.com/p/297790034 ^abc量子物理学家是如何使用 Anki 的？ https://zhuanlan.zhihu.com/p/65131722 ^ab如何用Anki学数学? https://zhuanlan.zhihu.com/p/359350968 ^abc我们如何才能开发出变革性的思想工具？ https://zhuanlan.zhihu.com/p/394795804 ^渐进阅读 https://www.yuque.com/supermemo/wiki/incremental%5Freading 发布于 2021-11-16 21:40・IP 属地广东 ，编辑于 2023-09-06 10:21・IP 属地广东","link":"/2024/05/7b8abae622a6.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note Python is simpler to use, available on Windows, macOS, and Unix operating systems, and will help you get the job done more quickly.更加轻量级的脚本语言 ^bafd84be Python is simple to use, but it is a real programming language, offering much more structure and support for large programs than shell scripts or batch files can offer.相较于shell与batch files,能够提供更多接近编程语言的特性 ^51317e08 Python is an interpreted language_- 编译性语言 解释性语言 脚本语言脚本语言是解释性语言的一种.Python is scripting language. But it is more than just a scripting language._ ^b49ea4e9 ContentIf you do much work on computers, eventually you find that there’s some task you’d like to automate. For example, you may wish to perform a search-and-replace over a large number of text files, or rename and rearrange a bunch of photo files in a complicated way. Perhaps you’d like to write a small custom database, or a specialized GUI application, or a simple game. If you’re a professional software developer, you may have to work with several C/C++/Java libraries but find the usual write/compile/test/re-compile cycle is too slow. Perhaps you’re writing a test suite for such a library and find writing the testing code a tedious task. Or maybe you’ve written a program that could use an extension language, and you don’t want to design and implement a whole new language for your application. Python is just the language for you. You could write a Unix shell script or Windows batch files for some of these tasks, but shell scripts are best at moving around files and changing text data, not well-suited for GUI applications or games. You could write a C/C++/Java program, but it can take a lot of development time to get even a first-draft program. ==Python is simpler to use, available on Windows, macOS, and Unixoperating systems, and will help you get the job done more quickly.== Python is simple to use, but it is a real programming language, offering much more structure and support for large programs than shell scripts or batch files can offer. On the other hand, Python also offers much more error checking than C, and, being a very-high-level language, it has high-level data types built in, such as flexible arrays and dictionaries. Because of its more general data types Python is applicable to a much larger problem domain than Awk or even Perl, yet many things are at least as easy in Python as in those languages. Python allows you to split your program into modules that can be reused in other Python programs. It comes with a large collection of standard modules that you can use as the basis of your programs — or as examples to start learning to program in Python. Some of these modules provide things like file I/O, system calls, sockets, and even interfaces to graphical user interface toolkits like Tk. Python is an interpreted language, which can save you considerable time during program development because no compilation and linking is necessary. The interpreter can be used interactively, which makes it easy to experiment with features of the language, to write throw-away programs, or to test functions during bottom-up program development. It is also a handy desk calculator. Python enables programs to be written compactly and readably. Programs written in Python are typically much shorter than equivalent C, C++, or Java programs, for several reasons: the high-level data types allow you to express complex operations in a single statement; statement grouping is done by indentation instead of beginning and ending brackets; no variable or argument declarations are necessary. Python is extensible: if you know how to program in C it is easy to add a new built-in function or module to the interpreter, either to perform critical operations at maximum speed, or to link Python programs to libraries that may only be available in binary form (such as a vendor-specific graphics library). Once you are really hooked, you can link the Python interpreter into an application written in C and use it as an extension or command language for that application. By the way, the language is named after the BBC show “Monty Python’s Flying Circus” and has nothing to do with reptiles. Making references to Monty Python skits in documentation is not only allowed, it is encouraged! Now that you are all excited about Python, you’ll want to examine it in some more detail. Since the best way to learn a language is to use it, the tutorial invites you to play with the Python interpreter as you read. In the next chapter, the mechanics of using the interpreter are explained. This is rather mundane information, but essential for trying out the examples shown later. The rest of the tutorial introduces various features of the Python language and system through examples, beginning with simple expressions, statements and data types, through functions and modules, and finally touching upon advanced concepts like exceptions and user-defined classes.","link":"/2024/05/7e83434de45f.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note Faster RCNN使用CNN提取图像特征，然后使用region proposal network（RPN）去提取出ROI，然后使用ROI pooling将这些ROI全部变成固定尺寸，再喂给全连接层进行Bounding box回归和分类预测。 多尺度检测在目标检测中变得越来越重要，对小目标的检测尤其如此。现在主流的目标检测方法很多都用到了多尺度的方法，包括最新的yolo v3。Feature Pyramid Network (FPN)则是一种精心设计的多尺度检测方法特征金字塔是为了多尺度检测 FPN结构中包括自下而上，自上而下和横向连接三个部分，如下图所示。这种结构可以将各个层级的特征进行融合，使其同时具有强语义信息和强空间信息，在特征学习中算是一把利器了。 Mask RCNN定义多任务损失：L=L_{cls}+L_{box}+L_{mask} Content不断更新目标检测和语义分割的文章，感兴趣的请关注我。最近在做一个目标检测项目，用到了Mask RCNN。我仅仅用了50张训练照片，训练了1000步之后进行测试，发现效果好得令人称奇。就这个任务，很久之前用yolo v1训练则很难收敛。不过把它们拿来比当然不公平，但我更想说的是，mask RCNN效果真的很好。 所以这篇文章来详细地总结一下Mask RCNN。 Mask RCNN沿用了Faster RCNN的思想，特征提取采用ResNet-FPN的架构，另外多加了一个Mask预测分支。可见Mask RCNN综合了很多此前优秀的研究成果。为了更好地讲解Mask RCNN，我会先回顾一下几个部分： Faster RCNN ResNet-FPN ResNet-FPN+Fast RCNN 回顾完之后讲ResNet-FPN+Fast RCNN+Mask，实际上就是Mask RCNN。 一、Faster RCNNFaster RCNN是两阶段的目标检测算法，包括阶段一的Region proposal以及阶段二的bounding box回归和分类。用一张图来直观展示Faster RCNN的整个流程： ==Faster RCNN使用CNN提取图像特征，然后使用region proposal network（RPN）去提取出ROI，然后使用ROI pooling将这些ROI全部变成固定尺寸，再喂给全连接层进行Bounding box回归和分类预测。== 这里只是简单地介绍了Faster RCNN前向预测的过程，但Faster RCNN本身的细节非常多，比一阶段的算法复杂度高不少，并非三言两语能说得清。如果对Faster RCNN算法不熟悉，想了解更多的同学可以看这篇文章：一文读懂Faster RCNN，这是我看过的解释得最清晰的文章。 二、ResNet-FPN==多尺度检测在目标检测中变得越来越重要，对小目标的检测尤其如此。现在主流的目标检测方法很多都用到了多尺度的方法，包括最新的yolo v3。Feature Pyramid Network (====FPN====)则是一种精心设计的多尺度检测方法==，下面就开始简要介绍FPN。 ==FPN结构中包括自下而上，自上而下和横向连接三个部分，如下图所示。这种结构可以将各个层级的特征进行融合，使其同时具有强语义信息和强空间信息，在特征学习中算是一把利器了。== FPN实际上是一种通用架构，可以结合各种骨架网络使用，比如VGG，ResNet等。Mask RCNN文章中使用了ResNNet-FPN网络结构。如下图： ResNet-FPN包括3个部分，自下而上连接，自上而下连接和横向连接。下面分别介绍。 自下而上 从下到上路径。可以明显看出，其实就是简单的特征提取过程，和传统的没有区别。具体就是将ResNet作为骨架网络，根据feature map的大小分为5个stage。stage2，stage3，stage4和stage5各自最后一层输出conv2，conv3，conv4和conv5分别定义为 C_2,C_3,C_4,C_5 ，他们相对于原始图片的stride是{4,8,16,32}。需要注意的是，考虑到内存原因，stage1的conv1并没有使用。 自上而下和横向连接 自上而下是从最高层开始进行上采样，这里的上采样直接使用的是最近邻上采样，而不是使用反卷积操作，一方面简单，另外一方面可以减少训练参数。横向连接则是将上采样的结果和自底向上生成的相同大小的feature map进行融合。具体就是对 C_2,C_3,C_4,C_5 中的每一层经过一个conv 1x1操作（1x1卷积用于降低通道数），无激活函数操作，输出通道全部设置为相同的256通道，然后和上采样的feature map进行加和操作。在融合之后还会再采用3*3的卷积核对已经融合的特征进行处理，目的是消除上采样的混叠效应（aliasing effect）。 实际上，上图少绘制了一个分支：M5经过步长为2的max pooling下采样得到 P6，作者指出使用P6是想得到更大的anchor尺度512×512。但P6是只用在 RPN中用来得到region proposal的，并不会作为后续Fast RCNN的输入。 总结一下，ResNet-FPN作为RPN输入的feature map是 [P2,P3,P4,P5,P6] ，而作为后续Fast RCNN的输入则是 [P2,P3,P4,P5] 。 三、ResNet-FPN+Fast RCNN 将ResNet-FPN和Fast RCNN进行结合，实际上就是Faster RCNN的了，但与最初的Faster RCNN不同的是，FPN产生了特征金字塔 [P2,P3,P4,P5,P6] ，而并非只是一个feature map。金字塔经过RPN之后会产生很多region proposal。这些region proposal是分别由 P2,P3,P4,P5,P6 经过RPN产生的，但用于输入到Fast RCNN中的是 [P2,P3,P4,P5] ，也就是说要在 [P2,P3,P4,P5] 中根据region proposal切出ROI进行后续的分类和回归预测。问题来了，我们要选择哪个feature map来切出这些ROI区域呢？实际上，我们会选择最合适的尺度的feature map来切ROI。具体来说，我们通过一个公式来决定宽w和高h的ROI到底要从哪个P_k 来切： 这里224表示用于预训练的ImageNet图片的大小。 k_0 表示面积为 w×h=224×224 的ROI所应该在的层级。作者将 k_0 设置为4，也就是说 w×h=224×224 的ROI应该从 P4 中切出来。假设ROI的scale小于224（比如说是112 * 112）， k = k_0-1 = 4-1 = 3 ，就意味着要从更高分辨率的 P_3 中产生。另外，k 值会做取整处理，防止结果不是整数。 这种做法很合理，大尺度的ROI要从低分辨率的feature map上切，有利于检测大目标，小尺度的ROI要从高分辨率的feature map上切，有利于检测小目标。 四、ResNet-FPN+Fast RCNN+mask我们再进一步，将ResNet-FPN+Fast RCNN+mask，则得到了最终的Mask RCNN，如下图： Mask RCNN的构建很简单，只是在ROI pooling（实际上用到的是ROIAlign，后面会讲到）之后添加卷积层，进行mask预测的任务。 下面总结一下Mask RCNN的网络： 骨干网络ResNet-FPN，用于特征提取，另外，ResNet还可以是：ResNet-50,ResNet-101,ResNeXt-50,ResNeXt-101； 头部网络，包括边界框识别（分类和回归）+mask预测。头部结构见下图： 五、ROI Align实际上，Mask RCNN中还有一个很重要的改进，就是ROIAlign。Faster R-CNN存在的问题是：特征图与原始图像是不对准的（mis-alignment），所以会影响检测精度。而Mask R-CNN提出了RoIAlign的方法来取代ROI pooling，RoIAlign可以保留大致的空间位置。 为了讲清楚ROI Align，这里先插入两个知识，双线性插值和ROI pooling。 1.双线性插值在讲双线性插值之前，还得看最简单的线性插值。 线性插值 已知数据 (x_0, y_0) 与 (x_1, y_1) ，要计算 [x_0, x_1] 区间内某一位置 x 在直线上的 y 值，如下图所示。 计算方法很简单，通过斜率相等就可以构建y和x之间的关系，如下：\\frac{y - y_0}{x - x_0} = \\frac{y - y_1}{x - x_1} ====&gt; y=\\frac{x-x_0}{x_1-x_0}y_1+\\frac{x_1-x}{x_1-x_0}y_0仔细看就是用 x 和 x_0 ， x_1 的距离作为一个权重（除以 x-x_0 是归一化的作用），用于 y_0 和 y_1 的加权。这个思想很重要，因为知道了这个思想，理解双线性插值就非常简单了。 双线性插值 双线性插值本质上就是在两个方向上做线性插值。 如图，假设我们想得到P点的插值，我们可以先在x方向上，对 Q_{11} 和 Q_{21} 之间做线性插值得到 R_1 ， R_2 同理可得。然后在y方向上对 R_1 和 R_2 进行线性插值就可以得到最终的P。其实知道这个就已经理解了双线性插值的意思了，如果用公式表达则如下（注意 f 前面的系数看成权重就很好理解了）。 首先在 x 方向进行线性插值，得到 然后在 y 方向进行线性插值，得到 这样就得到所要的结果 f(x,y) 参考：维基百科：双线性插值 2.ROIpoolingROI pooling就不多解释了，直接通过一个例子来形象理解。假设现在我们有一个8x8大小的feature map，我们要在这个feature map上得到ROI，并且进行ROI pooling到2x2大小的输出。 假设ROI的bounding box为 [x_1,y_1,x_2,y_2]=[0,3,7,8] 。如图： 将它划分为2x2的网格，因为ROI的长宽除以2是不能整除的，所以会出现每个格子大小不一样的情况。 进行max pooling的最终2x2的输出为： 最后以一张动图形象概括之： 参考：Region of interest pooling explained 3. ROI Align在Faster RCNN中，有两次整数化的过程： region proposal的xywh通常是小数，但是为了方便操作会把它整数化。 将整数化后的边界区域平均分割成 k x k 个单元，对每一个单元的边界进行整数化。 两次整数化的过程如下图所示： 事实上，经过上述两次整数化，此时的候选框已经和最开始回归出来的位置有一定的偏差，这个偏差会影响检测或者分割的准确度。在论文里，作者把它总结为“不匹配问题”（misalignment）。 为了解决这个问题，ROI Align方法取消整数化操作，保留了小数，使用以上介绍的双线性插值的方法获得坐标为浮点数的像素点上的图像数值。但在实际操作中，ROI Align并不是简单地补充出候选区域边界上的坐标点，然后进行池化，而是重新进行设计。 下面通过一个例子来讲解ROI Align操作。如下图所示，虚线部分表示feature map，实线表示ROI，这里将ROI切分成2x2的单元格。如果采样点数是4，那我们首先将每个单元格子均分成四个小方格（如红色线所示），每个小方格中心就是采样点。这些采样点的坐标通常是浮点数，所以需要对采样点像素进行双线性插值（如四个箭头所示），就可以得到该像素点的值了。然后对每个单元格内的四个采样点进行maxpooling，就可以得到最终的ROIAlign的结果。 需要说明的是，在相关实验中，作者发现将采样点设为4会获得最佳性能，甚至直接设为1在性能上也相差无几。事实上，ROI Align 在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了misalignment的问题。 六、损失==Mask RCNN定义多任务损失：====L=L{cls}+L{box}+L_{mask}== L_{cls}和 L_{box} 与faster rcnn的定义没有区别。需要具体说明的是 L_{mask} ，假设一共有K个类别，则mask分割分支的输出维度是 K*m*m , 对于 m*m 中的每个点，都会输出K个二值Mask（每个类别使用sigmoid输出）。需要注意的是，计算loss的时候，并不是每个类别的sigmoid输出都计算二值交叉熵损失，而是该像素属于哪个类，哪个类的sigmoid输出才要计算损失(如图红色方形所示)。并且在测试的时候，我们是通过分类分支预测的类别来选择相应的mask预测。这样，mask预测和分类预测就彻底解耦了。 这与FCN方法是不同，FCN是对每个像素进行多类别softmax分类，然后计算交叉熵损失，很明显，这种做法是会造成类间竞争的，而每个类别使用sigmoid输出并计算二值损失，可以避免类间竞争。实验表明，通过这种方法，可以较好地提升性能。 七、代码我用到的代码是github上star最多的Mask RCNN代码：Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow 由于篇幅所限，不会在本文中讲解代码。但会由我的一个同事（ 知乎用户）视频讲解，视频即将录制，录好之后我会把视频链接发在这里，感兴趣的可以关注。如果对视频内容有什么需求，欢迎留言。 参考文章中有些图片来自medium博主：Jonathan Hui 如果这篇文章对你有帮助，就给点个赞呗。","link":"/2024/05/d0a3a062784e.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note torch.utils.data.DataLoader and torch.utils.data.Dataset.Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.Dataset 用于定义和存储数据及标签，而 DataLoader 则将 Dataset 包装成一个可迭代对象，方便进行批量数据处理和多线程数据加载。 ^40d33fcf PyTorch offers domain-specific libraries such as TorchText,TorchVision, and TorchAudio ^03b16e1a To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU or MPS if available. Using cuda deviceNeuralNetwork( (flatten): Flatten(startdim=1, end_dim=-1) (linear_relu_stack): Sequential( (0): Linear(in_features=784, out_features=512, bias=True) (1): ReLU() (2): Linear(in_features=512, out_features=512, bias=True) (3): ReLU() (4): Linear(in_features=512, out_features=10, bias=True) )) 继承自nn.Module的类来定义一个新的神经网络_ ^60509680 ContentNote Click hereto download the full example code Learn the Basics ||Quickstart ||Tensors ||Datasets &amp; DataLoaders ||Transforms ||Build Model ||Autograd ||Optimization ||Save &amp; Load Model QuickstartThis section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper. Working with dataPyTorch has two primitives to work with data:==torch====.utils====.data====.DataLoader== ==and== ==torch====.utils====.data====.Dataset====.====Dataset== ==stores the samples and their corresponding labels, and== ==DataLoader== ==wraps an iterable aroundthe== ==Dataset====.== import torchfrom torch import nnfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision.transforms import ToTensor ==PyTorch offers domain-specific libraries such as== ==TorchText====,====TorchVision====, and== ==TorchAudio==, all of which include datasets. For this tutorial, we will be using a TorchVision dataset. The torchvision.datasets module contains Dataset objects for many real-world vision data like CIFAR, COCO (full list here). In this tutorial, we use the FashionMNIST dataset. Every TorchVision Dataset includes two arguments: transform andtarget_transform to modify the samples and labels respectively. Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz 0%| | 0/26421880 [00:00&lt;?, ?it/s] 0%| | 65536/26421880 [00:00&lt;01:11, 367533.95it/s] 1%| | 229376/26421880 [00:00&lt;00:38, 687510.81it/s] 3%|3 | 917504/26421880 [00:00&lt;00:12, 2122627.18it/s] 12%|#1 | 3145728/26421880 [00:00&lt;00:03, 6173840.09it/s] 32%|###1 | 8323072/26421880 [00:00&lt;00:01, 14317420.15it/s] 52%|#####2 | 13860864/26421880 [00:01&lt;00:00, 19911191.27it/s] 73%|#######2 | 19169280/26421880 [00:01&lt;00:00, 23027294.46it/s] 95%|#########4| 25001984/26421880 [00:01&lt;00:00, 26015038.29it/s]100%|##########| 26421880/26421880 [00:01&lt;00:00, 18290784.99it/s]Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz 0%| | 0/29515 [00:00&lt;?, ?it/s]100%|##########| 29515/29515 [00:00&lt;00:00, 325111.24it/s]Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz 0%| | 0/4422102 [00:00&lt;?, ?it/s] 1%|1 | 65536/4422102 [00:00&lt;00:12, 362694.62it/s] 5%|5 | 229376/4422102 [00:00&lt;00:06, 682437.48it/s] 16%|#5 | 688128/4422102 [00:00&lt;00:02, 1525993.86it/s] 27%|##6 | 1179648/4422102 [00:00&lt;00:01, 1995322.62it/s] 39%|###9 | 1736704/4422102 [00:00&lt;00:01, 2382528.91it/s] 53%|#####2 | 2326528/4422102 [00:01&lt;00:00, 2683842.12it/s] 67%|######7 | 2981888/4422102 [00:01&lt;00:00, 2990009.04it/s] 84%|########4 | 3735552/4422102 [00:01&lt;00:00, 3358051.05it/s]100%|##########| 4422102/4422102 [00:01&lt;00:00, 2867549.97it/s]Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz 0%| | 0/5148 [00:00&lt;?, ?it/s]100%|##########| 5148/5148 [00:00&lt;00:00, 38765308.78it/s]Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels. Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])Shape of y: torch.Size([64]) torch.int64 Read more about loading data in PyTorch. Creating Models==To define a neural network in PyTorch, we create a class that inheritsfrom== ==nn.Module====. We define the layers of the networkin the== ==__init__== ==function and specify how data will pass through the network in the== ==forward== ==function. To accelerateoperations in the neural network, we move it to the GPU or MPS if available.== ==Using cuda deviceNeuralNetwork( (flatten): Flatten(start_dim=1, end_dim=-1) (linear_relu_stack): Sequential( (0): Linear(in_features=784, out_features=512, bias=True) (1): ReLU() (2): Linear(in_features=512, out_features=512, bias=True) (3): ReLU() (4): Linear(in_features=512, out_features=10, bias=True) ))== Read more about building neural networks in PyTorch. Optimizing the Model ParametersTo train a model, we need a loss functionand an optimizer. In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters. def train(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) model.train() for batch, (X, y) in enumerate(dataloader): X, y = X.to(device), y.to(device) # Compute prediction error [pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;) = model([X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;)) loss = [loss_fn](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss &quot;torch.nn.CrossEntropyLoss&quot;)([pred](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;), y) # Backpropagation loss.backward() [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.step &quot;torch.optim.SGD.step&quot;)() [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD.zero%5Fgrad &quot;torch.optim.SGD.zero_grad&quot;)() if batch % 100 == 0: loss, current = loss.item(), (batch + 1) * len([X](https://pytorch.org/docs/stable/tensors.html#torch.Tensor &quot;torch.Tensor&quot;)) print(f&quot;loss: {loss:&gt;7f} [{current:&gt;5d}/{size:&gt;5d}]&quot;) We also check the model’s performance against the test dataset to ensure it is learning. def test(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) model.eval() test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: X, y = X.to(device), y.to(device) pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f”Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n”) The training process is conducted over several iterations (epochs). During each epoch, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch. Epoch 1loss: 2.303494 [ 64/60000]loss: 2.294637 [ 6464/60000]loss: 2.277102 [12864/60000]loss: 2.269977 [19264/60000]loss: 2.254235 [25664/60000]loss: 2.237146 [32064/60000]loss: 2.231055 [38464/60000]loss: 2.205037 [44864/60000]loss: 2.203240 [51264/60000]loss: 2.170889 [57664/60000]Test Error: Accuracy: 53.9%, Avg loss: 2.168588 Epoch 2loss: 2.177787 [ 64/60000]loss: 2.168083 [ 6464/60000]loss: 2.114910 [12864/60000]loss: 2.130412 [19264/60000]loss: 2.087473 [25664/60000]loss: 2.039670 [32064/60000]loss: 2.054274 [38464/60000]loss: 1.985457 [44864/60000]loss: 1.996023 [51264/60000]loss: 1.917241 [57664/60000]Test Error: Accuracy: 60.2%, Avg loss: 1.920374 Epoch 3loss: 1.951705 [ 64/60000]loss: 1.919516 [ 6464/60000]loss: 1.808730 [12864/60000]loss: 1.846550 [19264/60000]loss: 1.740618 [25664/60000]loss: 1.698733 [32064/60000]loss: 1.708889 [38464/60000]loss: 1.614436 [44864/60000]loss: 1.646475 [51264/60000]loss: 1.524308 [57664/60000]Test Error: Accuracy: 61.4%, Avg loss: 1.547092 Epoch 4loss: 1.612695 [ 64/60000]loss: 1.570870 [ 6464/60000]loss: 1.424730 [12864/60000]loss: 1.489542 [19264/60000]loss: 1.367256 [25664/60000]loss: 1.373464 [32064/60000]loss: 1.376744 [38464/60000]loss: 1.304962 [44864/60000]loss: 1.347154 [51264/60000]loss: 1.230661 [57664/60000]Test Error: Accuracy: 62.7%, Avg loss: 1.260891 Epoch 5loss: 1.337803 [ 64/60000]loss: 1.313278 [ 6464/60000]loss: 1.151837 [12864/60000]loss: 1.252142 [19264/60000]loss: 1.123048 [25664/60000]loss: 1.159531 [32064/60000]loss: 1.175011 [38464/60000]loss: 1.115554 [44864/60000]loss: 1.160974 [51264/60000]loss: 1.062730 [57664/60000]Test Error: Accuracy: 64.6%, Avg loss: 1.087374 Done! Read more about Training your model. Saving ModelsA common way to save a model is to serialize the internal state dictionary (containing the model parameters). Saved PyTorch Model State to model.pth Loading ModelsThe process for loading a model includes re-creating the model structure and loading the state dictionary into it. This model can now be used to make predictions. classes = [ “T-shirt/top”, “Trouser”, “Pullover”, “Dress”, “Coat”, “Sandal”, “Shirt”, “Sneaker”, “Bag”, “Ankle boot”,] model.eval()x, y = test_data[0][0], test_data[0][1]with torch.no_grad(): x = x.to(device) pred = model(x) predicted, actual = classes[pred[0].argmax(0)], classes[y] print(f’Predicted: “{predicted}”, Actual: “{actual}”‘) Predicted: “Ankle boot”, Actual: “Ankle boot” Read more about Saving &amp; Loading your model. Total running time of the script: ( 1 minutes 5.911 seconds) Gallery generated by Sphinx-Gallery","link":"/2024/05/0299e012aa35.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note Understand the difference between one-, two- and n-dimensional arrays in NumPy; Understand how to apply some linear algebra operations to n-dimensional arrays without using for-loops; Understand axis and shape properties for n-dimensional arrays.理解不同维度的数组不适用for循环计算数组n-数组的axis与shape值 ^39b79e0f For example, the array for the coordinates of a point in 3D space,[1, 2, 1], has one axis. That axis has 3 elements in it, so we say it has a length of 3. In the example pictured below, the array has 2 axes. The first axis has a length of 2, the second axis has a length of 3. [[1., 0., 0.], [0., 1., 2.]] ^b040311e ndarray.shape the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with n rows and m columns, shape will be (n,m). The length of theshape tuple is therefore the number of axes, ndim.对于矩阵[n,m]shape是矩阵的形状,(n,m)shape的length是矩阵的维度ndim,2 ^6158dbf4 ndarray.size the total number of elements of the array. This is equal to the product of the elements of shape. ^5372022b ndarray.dtype an object describing the type of the elements in the array. ^61d148c0 ndarray.itemsize the size in bytes of each element of the array.字节表示每个元素的大小 ^730f1b36 ndarray.data the buffer containing the actual elements of the array. Normally, we won’t need to use this attribute because we will access the elements in an array using indexing facilities. ^fa4f67a3 A frequent error consists in calling array with multiple arguments, rather than providing a single sequence as an argument.一个常见的错误在于使用多个参数调用 array，而不是提供单个序列作为参数。 a = np.array(1, 2, 3, 4) # WRONGTraceback (most recent call last): …TypeError: array() takes from 1 to 2 positional arguments but 4 were givena = np.array([1, 2, 3, 4]) # RIGHTarray的参数必须是一个sequence ^a234bfbc The function zeros creates an array full of zeros, the functionones creates an array full of ones, and the function emptycreates an array whose initial content is random and depends on the state of the memory. By default, the dtype of the created array isfloat64, but it can be specified via the key word argument dtype. ^2bad5ac5 >&gt;&gt; np.zeros((3, 4)) array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) >&gt;&gt; np.ones((2, 3, 4), dtype\\=np.int16) array([[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int16) >&gt;&gt; np.empty((2, 3)) array([[3.73603959e-262, 6.02658058e-154, 6.55490914e-260], # may vary [5.30498948e-313, 3.14673309e-307, 1.00000000e+000]]) ^1f138b37 >&gt;&gt; np.arange(10, 30, 5) array([10, 15, 20, 25]) >&gt;&gt; np.arange(0, 2, 0.3) # it accepts float arguments array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]) ^68bb8c26 >&gt;&gt; from numpy import pi >&gt;&gt; np.linspace(0, 2, 9) # 9 numbers from 0 to 2 array([0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ]) >&gt;&gt; x \\= np.linspace(0, 2 * pi, 100) # useful to evaluate function at lots of points >&gt;&gt; f \\= np.sin(x)linspace(x,y,z)指定x,y之间有z个数字,类似于arange ^bf128867 To disable this behaviour and force NumPy to print the entire array, you can change the printing options using set_printoptions.要禁用此行为并强制 NumPy 打印整个数组，您可以使用 set_printoptions 更改打印选项。 np.set_printoptions(threshold=sys.maxsize) # sys module should be imported ^937fe440 Arithmetic operators on arrays apply elementwise. A new array is created and filled with the result.数组上的算术运算符按元素应用。将创建一个新数组，并用结果填充。 ^3c9128ad >&gt;&gt; A \\= np.array([[1, 1], … [0, 1]]) >&gt;&gt; B \\= np.array([[2, 0], … [3, 4]]) >&gt;&gt; A * B # elementwise product array([[2, 0], [0, 4]]) >&gt;&gt; A @ B # matrix product array([[5, 4], [3, 4]]) >&gt;&gt; A.dot(B) # another matrix product array([[5, 4], [3, 4]]) ^84b7670d a = np.ones(3, dtype=np.int32)b = np.linspace(0, pi, 3)b.dtype.name‘float64’c = a + bcarray([1. , 2.57079633, 4.14159265])c.dtype.name‘float64’d = np.exp(c * 1j)darray([ 0.54030231+0.84147098j, -0.84147098+0.54030231j, -0.54030231-0.84147098j])d.dtype.name‘complex128’ Many unary operations, such as computing the sum of all the elements in the array, are implemented as methods of the ndarray class. a = rg.random((2, 3))aarray([[0.82770259, 0.40919914, 0.54959369], [0.02755911, 0.75351311, 0.53814331]])a.sum()3.1057109529998157a.min()0.027559113243068367a.max()0.8277025938204418上播 ^15c010ff Some operations, such as += and *=, act in place to modify an existing array rather than create a new one. ^a8e4f6ef By default, these operations apply to the array as though it were a list of numbers, regardless of its shape. However, by specifying the axisparameter you can apply an operation along the specified axis of an array: b = np.arange(12).reshape(3, 4)barray([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) b.sum(axis=0) # sum of each columnarray([12, 15, 18, 21]) b.min(axis=1) # min of each rowarray([0, 4, 8]) b.cumsum(axis=1) # cumulative sum along each rowarray([[ 0, 1, 3, 6], [ 4, 9, 15, 22], [ 8, 17, 27, 38]])默认operations是直接对list操作,不管它们的形状大部分ndarray的函数中,都可以指定axis值,实现对于某个axis上的操作 ^aa844997 When operating with arrays of different types, the type of the resulting array corresponds to the more general or precise one (a behavior known as upcasting). ^c379c845 One-dimensional arrays can be indexed, sliced and iterated over, much likelistsand other Python sequences. a = np.arange(10)**3aarray([ 0, 1, 8, 27, 64, 125, 216, 343, 512, 729])a[2]8a[2:5]array([ 8, 27, 64]) equivalent to a[0:6:2] = 1000;from start to position 6, exclusive, set every 2nd element to 1000a[:6:2] = 1000aarray([1000, 1, 1000, 27, 1000, 125, 216, 343, 512, 729])a[::-1] # reversed aarray([ 729, 512, 343, 216, 125, 1000, 27, 1000, 1, 1000])for i in a:… print(i**(1 / 3.))…9.999999999999998 # may vary1.09.9999999999999983.09.9999999999999984.9999999999999995.9999999999999996.9999999999999997.9999999999999998.999999999999998下标对于array的作用很大指定某个,指定范围等等 ^f66d7aca The shape of an array can be changed with various commands. Note that the following three commands all return a modified array, but do not change the original array: a.ravel() # returns the array, flattenedarray([3., 7., 3., 4., 1., 4., 2., 2., 7., 2., 4., 9.])a.reshape(6, 2) # returns the array with a modified shapearray([[3., 7.], [3., 4.], [1., 4.], [2., 2.], [7., 2.], [4., 9.]])a.T # returns the array, transposedarray([[3., 1., 7.], [7., 4., 2.], [3., 2., 4.], [4., 2., 9.]])a.T.shape(4, 3)a.shape(3, 4) ^c83fe768 The reshape function returns its argument with a modified shape, whereas thendarray.resize method modifies the array itself: aarray([[3., 7., 3., 4.], [1., 4., 2., 2.], [7., 2., 4., 9.]])a.resize((2, 6))aarray([[3., 7., 3., 4., 1., 4.], [2., 2., 7., 2., 4., 9.]])a.resize修改本身 ^c002e38a If a dimension is given as -1 in a reshaping operation, the other dimensions are automatically calculated: a.reshape(3, -1)array([[3., 7., 3., 4.], [1., 4., 2., 2.], [7., 2., 4., 9.]])a.resize(x,-1),use “-1” to automatically resize the dimensions ^3b6bcac5 In general, for arrays with more than two dimensions,hstack stacks along their second axes, vstack stacks along their first axes, and concatenateallows for an optional arguments giving the number of the axis along which the concatenation should happen.hstack与vstack,主要区别在于v默认在第一个轴堆栈h默认在第二个轴堆栈 ^c53a62aa When operating and manipulating arrays, their data is sometimes copied into a new array and sometimes not. This is often a source of confusion for beginners. There are three cases:_对数组进行操作时,有时候它们会被复制,有时候却不会.令人困惑三种情况 no copy view or shallow copy deep copy_ ^fafd9028 ContentPrerequisites#You’ll need to know a bit of Python. For a refresher, see the Python tutorial. To work the examples, you’ll need matplotlib installed in addition to NumPy. Learner profile This is a quick overview of arrays in NumPy. It demonstrates how n-dimensional (n>=2) arrays are represented and can be manipulated. In particular, if you don’t know how to apply common functions to n-dimensional arrays (without using for-loops), or if you want to understand axis and shape properties for n-dimensional arrays, this article might be of help. Learning Objectives After reading, you should be able to: ==Understand the difference between one-, two- and n-dimensional arrays inNumPy;== ==Understand how to apply some linear algebra operations to n-dimensionalarrays without using for-loops;== ==Understand axis and shape properties for n-dimensional arrays.== The Basics#NumPy’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of non-negative integers. In NumPy dimensions are called axes. ==For example, the array for the coordinates of a point in 3D space,====[====1====,== ==2====,== ==1====]====, has one axis. That axis has 3 elements in it, so we sayit has a length of 3. In the example pictured below, the array has 2axes. The first axis has a length of 2, the second axis has a length of3.== ==[[====1.====,== ==0.====,== ==0.====],== ==[====0.====,== ==1.====,== ==2.====]]== NumPy’s array class is called ndarray. It is also known by the aliasarray. Note that numpy.array is not the same as the Standard Python Library class array.array, which only handles one-dimensional arrays and offers less functionality. The more important attributes of an ndarray object are: ndarray.ndim the number of axes (dimensions) of the array. ndarray.shape the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with n rows and m columns, shape will be (n,m). The length of theshape tuple is therefore the number of axes, ndim. ndarray.size the total number of elements of the array. This is equal to the product of the elements of shape. ndarray.dtype an object describing the type of the elements in the array. One can create or specify dtype’s using standard Python types. Additionally NumPy provides types of its own. numpy.int32, numpy.int16, and numpy.float64 are some examples. ndarray.itemsize the size in bytes of each element of the array. For example, an array of elements of type float64 has itemsize 8 (=64/8), while one of type complex32 has itemsize 4 (=32/8). It is equivalent to ndarray.dtype.itemsize. ndarray.data the buffer containing the actual elements of the array. Normally, we won’t need to use this attribute because we will access the elements in an array using indexing facilities. An example# import numpy as npa = np.arange(15).reshape(3, 5)aarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]])a.shape(3, 5)a.ndim2a.dtype.name‘int64’a.itemsize8a.size15type(a) b = np.array([6, 7, 8])barray([6, 7, 8])type(b) Array Creation#There are several ways to create arrays. For example, you can create an array from a regular Python list or tuple using the array function. The type of the resulting array is deduced from the type of the elements in the sequences. import numpy as npa = np.array([2, 3, 4])aarray([2, 3, 4])a.dtypedtype(‘int64’)b = np.array([1.2, 3.5, 5.1])b.dtypedtype(‘float64’) ==A frequent error consists in calling== ==array== ==with multiple arguments,rather than providing a single sequence as an argument.== ==&gt;====&gt;====&gt;== ==a== ===== ==np====.====array====(====1====,== ==2====,== ==3====,== ==4====)== ==# WRONG====Traceback (most recent call last):== ==…====TypeError====:== ==array() takes from 1 to 2 positional arguments but 4 were given====&gt;====&gt;====&gt;== ==a== ===== ==np====.====array====([====1====,== ==2====,== ==3====,== ==4====])== ==# RIGHT== array transforms sequences of sequences into two-dimensional arrays, sequences of sequences of sequences into three-dimensional arrays, and so on. b = np.array([(1.5, 2, 3), (4, 5, 6)])barray([[1.5, 2. , 3. ], [4. , 5. , 6. ]]) The type of the array can also be explicitly specified at creation time: c = np.array([[1, 2], [3, 4]], dtype=complex)carray([[1.+0.j, 2.+0.j], [3.+0.j, 4.+0.j]]) Often, the elements of an array are originally unknown, but its size is known. Hence, NumPy offers several functions to create arrays with initial placeholder content. These minimize the necessity of growing arrays, an expensive operation. The function zeros creates an array full of zeros, the functionones creates an array full of ones, and the function emptycreates an array whose initial content is random and depends on the state of the memory. By default, the dtype of the created array isfloat64, but it can be specified via the key word argument dtype. np.zeros((3, 4))array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]])np.ones((2, 3, 4), dtype=np.int16)array([[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int16) np.empty((2, 3))array([[3.73603959e-262, 6.02658058e-154, 6.55490914e-260], # may vary [5.30498948e-313, 3.14673309e-307, 1.00000000e+000]]) To create sequences of numbers, NumPy provides the arange function which is analogous to the Python built-in range, but returns an array. np.arange(10, 30, 5)array([10, 15, 20, 25])np.arange(0, 2, 0.3) # it accepts float argumentsarray([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]) When arange is used with floating point arguments, it is generally not possible to predict the number of elements obtained, due to the finite floating point precision. For this reason, it is usually better to use the function linspace that receives as an argument the number of elements that we want, instead of the step: from numpy import pinp.linspace(0, 2, 9) # 9 numbers from 0 to 2array([0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ])x = np.linspace(0, 2 * pi, 100) # useful to evaluate function at lots of pointsf = np.sin(x) See also array,zeros,zeros_like,ones,ones_like,empty,empty_like,arange,linspace,numpy.random.Generator.rand,numpy.random.Generator.randn,fromfunction,fromfile Printing Arrays#When you print an array, NumPy displays it in a similar way to nested lists, but with the following layout: the last axis is printed from left to right, the second-to-last is printed from top to bottom, the rest are also printed from top to bottom, with each slice separated from the next by an empty line. One-dimensional arrays are then printed as rows, bidimensionals as matrices and tridimensionals as lists of matrices. a = np.arange(6) # 1d arrayprint(a)[0 1 2 3 4 5] b = np.arange(12).reshape(4, 3) # 2d arrayprint(b)[[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] c = np.arange(24).reshape(2, 3, 4) # 3d arrayprint(c)[[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] See below to get more details on reshape. If an array is too large to be printed, NumPy automatically skips the central part of the array and only prints the corners: print(np.arange(10000))[ 0 1 2 … 9997 9998 9999] print(np.arange(10000).reshape(100, 100))[[ 0 1 2 … 97 98 99] [ 100 101 102 … 197 198 199] [ 200 201 202 … 297 298 299] … [9700 9701 9702 … 9797 9798 9799] [9800 9801 9802 … 9897 9898 9899] [9900 9901 9902 … 9997 9998 9999]] ==To disable this behaviour and force NumPy to print the entire array, youcan change the printing options using== ==set====_printoptions====.== ==&gt;====&gt;====&gt;== ==np====.====set_printoptions====(====threshold=========sys====.====maxsize====)== ==# sys module should be imported== Basic Operations#Arithmetic operators on arrays apply elementwise. A new array is created and filled with the result. a = np.array([20, 30, 40, 50])b = np.arange(4)barray([0, 1, 2, 3])c = a - bcarray([20, 29, 38, 47])b*2array([0, 1, 4, 9])10 np.sin(a)array([ 9.12945251, -9.88031624, 7.4511316 , -2.62374854])a &lt; 35array([ True, True, False, False]) Unlike in many matrix languages, the product operator * operates elementwise in NumPy arrays. The matrix product can be performed using the @ operator (in python &gt;=3.5) or the dot function or method: A = np.array([[1, 1],… [0, 1]])B = np.array([[2, 0],… [3, 4]])A * B # elementwise productarray([[2, 0], [0, 4]])A @ B # matrix productarray([[5, 4], [3, 4]])A.dot(B) # another matrix productarray([[5, 4], [3, 4]]) Some operations, such as += and *=, act in place to modify an existing array rather than create a new one. rg = np.random.default_rng(1) # create instance of default random number generatora = np.ones((2, 3), dtype=int)b = rg.random((2, 3))a *= 3aarray([[3, 3, 3], [3, 3, 3]])b += abarray([[3.51182162, 3.9504637 , 3.14415961], [3.94864945, 3.31183145, 3.42332645]])a += b # b is not automatically converted to integer typeTraceback (most recent call last): …numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc ‘add’ output from dtype(‘float64’) to dtype(‘int64’) with casting rule ‘same_kind’ When operating with arrays of different types, the type of the resulting array corresponds to the more general or precise one (a behavior known as upcasting). ==&gt;====&gt;====&gt;== ==a== ===== ==np====.====ones====(====3====,== ==dtype=========np====.====int32====)====&gt;====&gt;====&gt;== ==b== ===== ==np====.====linspace====(====0====,== ==pi====,== ==3====)====&gt;====&gt;====&gt;== ==b====.====dtype====.====name====’float64’====&gt;====&gt;====&gt;== ==c== ===== ==a== ==+== ==b====&gt;====&gt;====&gt;== ==c====array([1. , 2.57079633, 4.14159265])====&gt;====&gt;====&gt;== ==c====.====dtype====.====name====’float64’====&gt;====&gt;====&gt;== ==d== ===== ==np====.====exp====(====c== ==*== ==1====j====)====&gt;====&gt;====&gt;== ==d====array([ 0.54030231+0.84147098j, -0.84147098+0.54030231j,== ==-0.54030231-0.84147098j])====&gt;====&gt;====&gt;== ==d====.====dtype====.====name====’complex128’== ==Many unary operations, such as computing the sum of all the elements inthe array, are implemented as methods of the== ==ndarray== ==class.== ==&gt;====&gt;====&gt;== ==a== ===== ==rg====.====random====((====2====,== ==3====))====&gt;====&gt;====&gt;== ==a====array([[0.82770259, 0.40919914, 0.54959369],== ==[0.02755911, 0.75351311, 0.53814331]])====&gt;====&gt;====&gt;== ==a====.====sum====()====3.1057109529998157====&gt;====&gt;====&gt;== ==a====.====min====()====0.027559113243068367====&gt;====&gt;====&gt;== ==a====.====max====()====0.8277025938204418== ==By default, these operations apply to the array as though it were a listof numbers, regardless of its shape. However, by specifying the== ==axis====parameter you can apply an operation along the specified axis of anarray:== ==&gt;====&gt;====&gt;== ==b== ===== ==np====.====arange====(====12====)====.====reshape====(====3====,== ==4====)====&gt;====&gt;====&gt;== ==b====array([[ 0, 1, 2, 3],== ==[ 4, 5, 6, 7],== ==[ 8, 9, 10, 11]])====&gt;====&gt;====&gt;====&gt;====&gt;====&gt;== ==b====.====sum====(====axis=========0====)== ==# sum of each column====array([12, 15, 18, 21])====&gt;====&gt;====&gt;====&gt;====&gt;====&gt;== ==b====.====min====(====axis=========1====)== ==# min of each row====array([0, 4, 8])====&gt;====&gt;====&gt;====&gt;====&gt;====&gt;== ==b====.====cumsum====(====axis=========1====)== ==# cumulative sum along each row====array([[ 0, 1, 3, 6],== ==[ 4, 9, 15, 22],== ==[ 8, 17, 27, 38]])== Universal Functions#NumPy provides familiar mathematical functions such as sin, cos, and exp. In NumPy, these are called “universal functions” (ufunc). Within NumPy, these functions operate elementwise on an array, producing an array as output. B = np.arange(3)Barray([0, 1, 2])np.exp(B)array([1. , 2.71828183, 7.3890561 ])np.sqrt(B)array([0. , 1. , 1.41421356])C = np.array([2., -1., 4.])np.add(B, C)array([2., 0., 6.]) See also all,any,apply_along_axis,argmax,argmin,argsort,average,bincount,ceil,clip,conj,corrcoef,cov,cross,cumprod,cumsum,diff,dot,floor,inner,invert,lexsort,max,maximum,mean,median,min,minimum,nonzero,outer,prod,re,round,sort,std,sum,trace,transpose,var,vdot,vectorize,where Indexing, Slicing and Iterating#==One-dimensional== ==arrays can be indexed, sliced and iterated over,much like====lists====and other Python sequences.== ==&gt;====&gt;====&gt;== ==a== ===== ==np====.====arange====(====10====)========3====&gt;====&gt;====&gt;== ==a====array([ 0, 1, 8, 27, 64, 125, 216, 343, 512, 729])====&gt;====&gt;====&gt;== ==a====[====2====]====8====&gt;====&gt;====&gt;== ==a====[====2====:====5====]====array([ 8, 27, 64])====&gt;====&gt;====&gt;== ==# equivalent to a[0:6:2] = 1000;====&gt;====&gt;====&gt;== ==# from start to position 6, exclusive, set every 2nd element to 1000====&gt;====&gt;====&gt;== ==a====[:====6====:====2====]== ===== ==1000====&gt;====&gt;====&gt;== ==a====array([1000, 1, 1000, 27, 1000, 125, 216, 343, 512, 729])====&gt;====&gt;====&gt;== ==a====[::====-====1====]== ==# reversed a====array([ 729, 512, 343, 216, 125, 1000, 27, 1000, 1, 1000])====&gt;====&gt;====&gt;== ==for== ==i== ==in== ==a====:====…== ==print====(====i========(====1== ==/== ==3.====))====…====9.999999999999998 # may vary====1.0====9.999999999999998====3.0====9.999999999999998====4.999999999999999====5.999999999999999====6.999999999999999====7.999999999999999====8.999999999999998== Multidimensional arrays can have one index per axis. These indices are given in a tuple separated by commas: def f(x, y):… return 10 * x + y…b = np.fromfunction(f, (5, 4), dtype=int)barray([[ 0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33], [40, 41, 42, 43]])b[2, 3]23b[0:5, 1] # each row in the second column of barray([ 1, 11, 21, 31, 41])b[:, 1] # equivalent to the previous examplearray([ 1, 11, 21, 31, 41])b[1:3, :] # each column in the second and third row of barray([[10, 11, 12, 13], [20, 21, 22, 23]]) When fewer indices are provided than the number of axes, the missing indices are considered complete slices: b[-1] # the last row. Equivalent to b[-1, :]array([40, 41, 42, 43]) The expression within brackets in b[i] is treated as an ifollowed by as many instances of : as needed to represent the remaining axes. NumPy also allows you to write this using dots asb[i, ...]. The dots (...) represent as many colons as needed to produce a complete indexing tuple. For example, if x is an array with 5 axes, then x[1, 2, ...] is equivalent to x[1, 2, :, :, :], x[..., 3] to x[:, :, :, :, 3] and x[4, ..., 5, :] to x[4, :, :, 5, :]. c = np.array([[[ 0, 1, 2], # a 3D array (two stacked 2D arrays)… [ 10, 12, 13]],… [[100, 101, 102],… [110, 112, 113]]])c.shape(2, 2, 3)c[1, …] # same as c[1, :, :] or c[1]array([[100, 101, 102], [110, 112, 113]])c[…, 2] # same as c[:, :, 2]array([[ 2, 13], [102, 113]]) Iterating over multidimensional arrays is done with respect to the first axis: for row in b:… print(row)…[0 1 2 3][10 11 12 13][20 21 22 23][30 31 32 33][40 41 42 43] However, if one wants to perform an operation on each element in the array, one can use the flat attribute which is aniteratorover all the elements of the array: for element in b.flat:… print(element)…012310111213202122233031323340414243 Shape Manipulation#Changing the shape of an array#An array has a shape given by the number of elements along each axis: a = np.floor(10 * rg.random((3, 4)))aarray([[3., 7., 3., 4.], [1., 4., 2., 2.], [7., 2., 4., 9.]])a.shape(3, 4) ==The shape of an array can be changed with various commands. Note that thefollowing three commands all return a modified array, but do not changethe original array:== ==&gt;====&gt;====&gt;== ==a====.====ravel====()== ==# returns the array, flattened====array([3., 7., 3., 4., 1., 4., 2., 2., 7., 2., 4., 9.])====&gt;====&gt;====&gt;== ==a====.====reshape====(====6====,== ==2====)== ==# returns the array with a modified shape====array([[3., 7.],== ==[3., 4.],== ==[1., 4.],== ==[2., 2.],== ==[7., 2.],== ==[4., 9.]])====&gt;====&gt;====&gt;== ==a====.====T== ==# returns the array, transposed====array([[3., 1., 7.],== ==[7., 4., 2.],== ==[3., 2., 4.],== ==[4., 2., 9.]])====&gt;====&gt;====&gt;== ==a====.====T====.====shape====(4, 3)====&gt;====&gt;====&gt;== ==a====.====shape====(3, 4)== The order of the elements in the array resulting from ravel is normally “C-style”, that is, the rightmost index “changes the fastest”, so the element after a[0, 0] is a[0, 1]. If the array is reshaped to some other shape, again the array is treated as “C-style”. NumPy normally creates arrays stored in this order, so ravel will usually not need to copy its argument, but if the array was made by taking slices of another array or created with unusual options, it may need to be copied. The functions ravel and reshape can also be instructed, using an optional argument, to use FORTRAN-style arrays, in which the leftmost index changes the fastest. ==The== reshape ==function returns itsargument with a modified shape, whereas the==ndarray.resize ==method modifies the arrayitself:== ==&gt;====&gt;====&gt;== ==a====array([[3., 7., 3., 4.],== ==[1., 4., 2., 2.],== ==[7., 2., 4., 9.]])====&gt;====&gt;====&gt;== ==a====.====resize====((====2====,== ==6====))====&gt;====&gt;====&gt;== ==a====array([[3., 7., 3., 4., 1., 4.],== ==[2., 2., 7., 2., 4., 9.]])== ==If a dimension is given as== ==-1== ==in a reshaping operation, the otherdimensions are automatically calculated:== ==&gt;====&gt;====&gt;== ==a====.====reshape====(====3====,== ==-====1====)====array([[3., 7., 3., 4.],== ==[1., 4., 2., 2.],== ==[7., 2., 4., 9.]])== Stacking together different arrays#Several arrays can be stacked together along different axes: a = np.floor(10 rg.random((2, 2)))aarray([[9., 7.], [5., 2.]])b = np.floor(10 rg.random((2, 2)))barray([[1., 9.], [5., 1.]])np.vstack((a, b))array([[9., 7.], [5., 2.], [1., 9.], [5., 1.]])np.hstack((a, b))array([[9., 7., 1., 9.], [5., 2., 5., 1.]]) The function column_stack stacks 1D arrays as columns into a 2D array. It is equivalent to hstack only for 2D arrays: from numpy import newaxisnp.column_stack((a, b)) # with 2D arraysarray([[9., 7., 1., 9.], [5., 2., 5., 1.]])a = np.array([4., 2.])b = np.array([3., 8.])np.column_stack((a, b)) # returns a 2D arrayarray([[4., 3.], [2., 8.]])np.hstack((a, b)) # the result is differentarray([4., 2., 3., 8.])a[:, newaxis] # view a as a 2D column vectorarray([[4.], [2.]])np.column_stack((a[:, newaxis], b[:, newaxis]))array([[4., 3.], [2., 8.]])np.hstack((a[:, newaxis], b[:, newaxis])) # the result is the samearray([[4., 3.], [2., 8.]]) On the other hand, the function row_stack is equivalent to vstackfor any input arrays. In fact, row_stack is an alias for vstack: np.column_stack is np.hstackFalsenp.row_stack is np.vstackTrue In general, for arrays with more than two dimensions,hstack stacks along their second axes, vstack stacks along their first axes, and concatenateallows for an optional arguments giving the number of the axis along which the concatenation should happen. Note In complex cases, r_ and c_ are useful for creating arrays by stacking numbers along one axis. They allow the use of range literals :. np.r_[1:4, 0, 4]array([1, 2, 3, 0, 4]) When used with arrays as arguments,r_ andc_ are similar tovstack andhstack in their default behavior, but allow for an optional argument giving the number of the axis along which to concatenate. Splitting one array into several smaller ones#Using hsplit, you can split an array along its horizontal axis, either by specifying the number of equally shaped arrays to return, or by specifying the columns after which the division should occur: a = np.floor(10 * rg.random((2, 12)))aarray([[6., 7., 6., 9., 0., 5., 4., 0., 6., 8., 5., 2.], [8., 5., 5., 7., 1., 8., 6., 7., 1., 8., 1., 0.]]) Split a into 3np.hsplit(a, 3)[array([[6., 7., 6., 9.], [8., 5., 5., 7.]]), array([[0., 5., 4., 0.], [1., 8., 6., 7.]]), array([[6., 8., 5., 2.], [1., 8., 1., 0.]])] Split a after the third and the fourth columnnp.hsplit(a, (3, 4))[array([[6., 7., 6.], [8., 5., 5.]]), array([[9.], [7.]]), array([[0., 5., 4., 0., 6., 8., 5., 2.], [1., 8., 6., 7., 1., 8., 1., 0.]])] vsplit splits along the vertical axis, and array_split allows one to specify along which axis to split. Copies and Views#When operating and manipulating arrays, their data is sometimes copied into a new array and sometimes not. This is often a source of confusion for beginners. There are three cases: No Copy at All#Simple assignments make no copy of objects or their data. a = np.array([[ 0, 1, 2, 3],… [ 4, 5, 6, 7],… [ 8, 9, 10, 11]])b = a # no new object is createdb is a # a and b are two names for the same ndarray objectTrue Python passes mutable objects as references, so function calls make no copy. def f(x):… print(id(x))…id(a) # id is a unique identifier of an object148293216 # may varyf(a)148293216 # may vary View or Shallow Copy#Different array objects can share the same data. The view method creates a new array object that looks at the same data. c = a.view()c is aFalsec.base is a # c is a view of the data owned by aTruec.flags.owndataFalse c = c.reshape((2, 6)) # a’s shape doesn’t changea.shape(3, 4)c[0, 4] = 1234 # a’s data changesaarray([[ 0, 1, 2, 3], [1234, 5, 6, 7], [ 8, 9, 10, 11]]) Slicing an array returns a view of it: s = a[:, 1:3]s[:] = 10 # s[:] is a view of s. Note the difference between s = 10 and s[:] = 10aarray([[ 0, 10, 10, 3], [1234, 10, 10, 7], [ 8, 10, 10, 11]]) Deep Copy#The copy method makes a complete copy of the array and its data. d = a.copy() # a new array object with new data is createdd is aFalsed.base is a # d doesn’t share anything with aFalsed[0, 0] = 9999aarray([[ 0, 10, 10, 3], [1234, 10, 10, 7], [ 8, 10, 10, 11]]) Sometimes copy should be called after slicing if the original array is not required anymore. For example, suppose a is a huge intermediate result and the final result b only contains a small fraction of a, a deep copy should be made when constructing b with slicing: a = np.arange(int(1e8))b = a[:100].copy()del a # the memory of a can be released. If b = a[:100] is used instead, a is referenced by b and will persist in memory even if del a is executed. Functions and Methods Overview#Here is a list of some useful NumPy functions and methods names ordered in categories. See Routines for the full list. Array Creation arange,array,copy,empty,empty_like,eye,fromfile,fromfunction,identity,linspace,logspace,mgrid,ogrid,ones,ones_like,r_,zeros,zeros_like Conversions ndarray.astype,atleast_1d,atleast_2d,atleast_3d,mat Manipulations array_split,column_stack,concatenate,diagonal,dsplit,dstack,hsplit,hstack,ndarray.item,newaxis,ravel,repeat,reshape,resize,squeeze,swapaxes,take,transpose,vsplit,vstack Questions all,any,nonzero,where Ordering argmax,argmin,argsort,max,min,ptp,searchsorted,sort Operations choose,compress,cumprod,cumsum,inner,ndarray.fill,imag,prod,put,putmask,real,sum Basic Statistics cov,mean,std,var Basic Linear Algebra cross,dot,outer,linalg.svd,vdot Less Basic#Broadcasting rules#Broadcasting allows universal functions to deal in a meaningful way with inputs that do not have exactly the same shape. The first rule of broadcasting is that if all input arrays do not have the same number of dimensions, a “1” will be repeatedly prepended to the shapes of the smaller arrays until all the arrays have the same number of dimensions. The second rule of broadcasting ensures that arrays with a size of 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension. The value of the array element is assumed to be the same along that dimension for the “broadcast” array. After application of the broadcasting rules, the sizes of all arrays must match. More details can be found in Broadcasting. Advanced indexing and index tricks#NumPy offers more indexing facilities than regular Python sequences. In addition to indexing by integers and slices, as we saw before, arrays can be indexed by arrays of integers and arrays of booleans. Indexing with Arrays of Indices# a = np.arange(12)**2 # the first 12 square numbersi = np.array([1, 1, 3, 8, 5]) # an array of indicesa[i] # the elements of a at the positions iarray([ 1, 1, 9, 64, 25]) j = np.array([[3, 4], [9, 7]]) # a bidimensional array of indicesa[j] # the same shape as jarray([[ 9, 16], [81, 49]]) When the indexed array a is multidimensional, a single array of indices refers to the first dimension of a. The following example shows this behavior by converting an image of labels into a color image using a palette. palette = np.array([[0, 0, 0], # black… [255, 0, 0], # red… [0, 255, 0], # green… [0, 0, 255], # blue… [255, 255, 255]]) # whiteimage = np.array([[0, 1, 2, 0], # each value corresponds to a color in the palette… [0, 3, 4, 0]])palette[image] # the (2, 4, 3) color imagearray([[[ 0, 0, 0], [255, 0, 0], [ 0, 255, 0], [ 0, 0, 0]], [[ 0, 0, 0], [ 0, 0, 255], [255, 255, 255], [ 0, 0, 0]]]) We can also give indexes for more than one dimension. The arrays of indices for each dimension must have the same shape. a = np.arange(12).reshape(3, 4)aarray([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])i = np.array([[0, 1], # indices for the first dim of a… [1, 2]])j = np.array([[2, 1], # indices for the second dim… [3, 3]]) a[i, j] # i and j must have equal shapearray([[ 2, 5], [ 7, 11]]) a[i, 2]array([[ 2, 6], [ 6, 10]]) a[:, j]array([[[ 2, 1], [ 3, 3]], [[ 6, 5], [ 7, 7]], [[10, 9], [11, 11]]]) In Python, arr[i, j] is exactly the same as arr[(i, j)]—so we can put i and j in a tuple and then do the indexing with that. l = (i, j) equivalent to a[i, j]a[l]array([[ 2, 5], [ 7, 11]]) However, we can not do this by putting i and j into an array, because this array will be interpreted as indexing the first dimension of a. s = np.array([i, j]) not what we wanta[s]Traceback (most recent call last): File ““, line 1, in IndexError: index 3 is out of bounds for axis 0 with size 3 same as a[i, j]a[tuple(s)]array([[ 2, 5], [ 7, 11]]) Another common use of indexing with arrays is the search of the maximum value of time-dependent series: time = np.linspace(20, 145, 5) # time scaledata = np.sin(np.arange(20)).reshape(5, 4) # 4 time-dependent seriestimearray([ 20. , 51.25, 82.5 , 113.75, 145. ])dataarray([[ 0. , 0.84147098, 0.90929743, 0.14112001], [-0.7568025 , -0.95892427, -0.2794155 , 0.6569866 ], [ 0.98935825, 0.41211849, -0.54402111, -0.99999021], [-0.53657292, 0.42016704, 0.99060736, 0.65028784], [-0.28790332, -0.96139749, -0.75098725, 0.14987721]]) index of the maxima for each seriesind = data.argmax(axis=0)indarray([2, 0, 3, 1]) times corresponding to the maximatime_max = time[ind] data_max = data[ind, range(data.shape[1])] # =&gt; data[ind[0], 0], data[ind[1], 1]…time_maxarray([ 82.5 , 20. , 113.75, 51.25])data_maxarray([0.98935825, 0.84147098, 0.99060736, 0.6569866 ])np.all(data_max == data.max(axis=0))True You can also use indexing with arrays as a target to assign to: a = np.arange(5)aarray([0, 1, 2, 3, 4])a[[1, 3, 4]] = 0aarray([0, 0, 2, 0, 0]) However, when the list of indices contains repetitions, the assignment is done several times, leaving behind the last value: a = np.arange(5)a[[0, 0, 2]] = [1, 2, 3]aarray([2, 1, 3, 3, 4]) This is reasonable enough, but watch out if you want to use Python’s+= construct, as it may not do what you expect: a = np.arange(5)a[[0, 0, 2]] += 1aarray([1, 1, 3, 3, 4]) Even though 0 occurs twice in the list of indices, the 0th element is only incremented once. This is because Python requires a += 1 to be equivalent to a = a + 1. Indexing with Boolean Arrays#When we index arrays with arrays of (integer) indices we are providing the list of indices to pick. With boolean indices the approach is different; we explicitly choose which items in the array we want and which ones we don’t. The most natural way one can think of for boolean indexing is to use boolean arrays that have the same shape as the original array: a = np.arange(12).reshape(3, 4)b = a &gt; 4b # b is a boolean with a‘s shapearray([[False, False, False, False], [False, True, True, True], [ True, True, True, True]])a[b] # 1d array with the selected elementsarray([ 5, 6, 7, 8, 9, 10, 11]) This property can be very useful in assignments: a[b] = 0 # All elements of a higher than 4 become 0aarray([[0, 1, 2, 3], [4, 0, 0, 0], [0, 0, 0, 0]]) You can look at the following example to see how to use boolean indexing to generate an image of the Mandelbrot set: import numpy as npimport matplotlib.pyplot as pltdef mandelbrot(h, w, maxit=20, r=2):… “””Returns an image of the Mandelbrot fractal of size (h,w).”””… x = np.linspace(-2.5, 1.5, 4h+1)… y = np.linspace(-1.5, 1.5, 3w+1)… A, B = np.meshgrid(x, y)… C = A + B1j… z = np.zeros_like(C)… divtime = maxit + np.zeros(z.shape, dtype=int)…… for i in range(maxit):… z = z*2 + C… diverge = abs(z) &gt; r # who is diverging… div_now = diverge &amp; (divtime == maxit) # who is diverging now… divtime[div_now] = i # note when… z[diverge] = r # avoid diverging too much…… return divtimeplt.clf()plt.imshow(mandelbrot(400, 400)) The second way of indexing with booleans is more similar to integer indexing; for each dimension of the array we give a 1D boolean array selecting the slices we want: a = np.arange(12).reshape(3, 4)b1 = np.array([False, True, True]) # first dim selectionb2 = np.array([True, False, True, False]) # second dim selection a[b1, :] # selecting rowsarray([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) a[b1] # same thingarray([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) a[:, b2] # selecting columnsarray([[ 0, 2], [ 4, 6], [ 8, 10]]) a[b1, b2] # a weird thing to doarray([ 4, 10]) Note that the length of the 1D boolean array must coincide with the length of the dimension (or axis) you want to slice. In the previous example, b1 has length 3 (the number of rows in a), andb2 (of length 4) is suitable to index the 2nd axis (columns) ofa. The ix_() function#The ix_ function can be used to combine different vectors so as to obtain the result for each n-uplet. For example, if you want to compute all the a+b*c for all the triplets taken from each of the vectors a, b and c: a = np.array([2, 3, 4, 5])b = np.array([8, 5, 4])c = np.array([5, 4, 6, 8, 3])ax, bx, cx = np.ix_(a, b, c)axarray([[[2]], [[3]], [[4]], [[5]]]) bxarray([[[8], [5], [4]]])cxarray([[[5, 4, 6, 8, 3]]])ax.shape, bx.shape, cx.shape((4, 1, 1), (1, 3, 1), (1, 1, 5))result = ax + bx * cxresultarray([[[42, 34, 50, 66, 26], [27, 22, 32, 42, 17], [22, 18, 26, 34, 14]], [[43, 35, 51, 67, 27], [28, 23, 33, 43, 18], [23, 19, 27, 35, 15]], [[44, 36, 52, 68, 28], [29, 24, 34, 44, 19], [24, 20, 28, 36, 16]], [[45, 37, 53, 69, 29], [30, 25, 35, 45, 20], [25, 21, 29, 37, 17]]]) result[3, 2, 4]17a[3] + b[2] * c[4]17 You could also implement the reduce as follows: def ufuncreduce(ufct, *vectors):… vs = np.ix(*vectors)… r = ufct.identity… for v in vs:… r = ufct(r, v)… return r and then use it as: ufunc_reduce(np.add, a, b, c)array([[[15, 14, 16, 18, 13], [12, 11, 13, 15, 10], [11, 10, 12, 14, 9]], [[16, 15, 17, 19, 14], [13, 12, 14, 16, 11], [12, 11, 13, 15, 10]], [[17, 16, 18, 20, 15], [14, 13, 15, 17, 12], [13, 12, 14, 16, 11]], [[18, 17, 19, 21, 16], [15, 14, 16, 18, 13], [14, 13, 15, 17, 12]]]) The advantage of this version of reduce compared to the normal ufunc.reduce is that it makes use of thebroadcasting rulesin order to avoid creating an argument array the size of the output times the number of vectors. Indexing with strings#See Structured arrays. Tricks and Tips#Here we give a list of short and useful tips. “Automatic” Reshaping#To change the dimensions of an array, you can omit one of the sizes which will then be deduced automatically: a = np.arange(30)b = a.reshape((2, -1, 3)) # -1 means “whatever is needed”b.shape(2, 5, 3)barray([[[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11], [12, 13, 14]], [[15, 16, 17], [18, 19, 20], [21, 22, 23], [24, 25, 26], [27, 28, 29]]]) Vector Stacking#How do we construct a 2D array from a list of equally-sized row vectors? In MATLAB this is quite easy: if x and y are two vectors of the same length you only need do m=[x;y]. In NumPy this works via the functions column_stack, dstack, hstack and vstack, depending on the dimension in which the stacking is to be done. For example: x = np.arange(0, 10, 2)y = np.arange(5)m = np.vstack([x, y])marray([[0, 2, 4, 6, 8], [0, 1, 2, 3, 4]])xy = np.hstack([x, y])xyarray([0, 2, 4, 6, 8, 0, 1, 2, 3, 4]) The logic behind those functions in more than two dimensions can be strange. Histograms#The NumPy histogram function applied to an array returns a pair of vectors: the histogram of the array and a vector of the bin edges. Beware:matplotlib also has a function to build histograms (called hist, as in Matlab) that differs from the one in NumPy. The main difference is that pylab.hist plots the histogram automatically, whilenumpy.histogram only generates the data. import numpy as nprg = np.random.default_rng(1)import matplotlib.pyplot as plt Build a vector of 10000 normal deviates with variance 0.5^2 and mean 2mu, sigma = 2, 0.5v = rg.normal(mu, sigma, 10000) Plot a normalized histogram with 50 binsplt.hist(v, bins=50, density=True) # matplotlib version (plot)(array…) Compute the histogram with numpy and then plot it(n, bins) = np.histogram(v, bins=50, density=True) # NumPy version (no plot)plt.plot(.5 * (bins[1:] + bins[:-1]), n) With Matplotlib &gt;=3.4 you can also use plt.stairs(n, bins). Further reading# The Python tutorial NumPy reference SciPy Tutorial SciPy Lecture Notes A matlab, R, IDL, NumPy/SciPy dictionary tutorial-svd","link":"/2024/05/8aed5eeb78cc.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy).Tensor与np.ndarray非常相似 ^baaea2f8 Tensors can be created from NumPy arrays (and vice versa ^60681efc Bridge with NumPy Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other. Tensor to NumPy arrayt = torch.ones(5)print(f”t: {t}”)n = t.numpy()print(f”n: {n}”) t: tensor([1., 1., 1., 1., 1.])n: [1. 1. 1. 1. 1.] A change in the tensor reflects in the NumPy array. t.add_(1)print(f”t: {t}”)print(f”n: {n}”) t: tensor([2., 2., 2., 2., 2.])n: [2. 2. 2. 2. 2.]tensor与np.ndarray实在是太相似了两个甚至使用同一个memory location修改tensor,对应的array也会改变 ^5d6d8dd1 Bridge with NumPy ^86073604 ContentNote Click hereto download the full example code Learn the Basics ||Quickstart ||Tensors ||Datasets &amp; DataLoaders ||Transforms ||Build Model ||Autograd ||Optimization ||Save &amp; Load Model TensorsTensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters. Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autogradsection). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along! import torchimport numpy as np Initializing a TensorTensors can be initialized in various ways. Take a look at the following examples: Directly from data Tensors can be created directly from data. The data type is automatically inferred. From a NumPy array ==Tensors can be created from NumPy arrays (and vice versa== - see Bridge with NumPy). From another tensor: The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden. Ones Tensor: tensor([[1, 1], [1, 1]]) Random Tensor: tensor([[0.8823, 0.9150], [0.3829, 0.9593]]) With random or constant values: shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor. Random Tensor: tensor([[0.3904, 0.6009, 0.2566], [0.7936, 0.9408, 0.1332]]) Ones Tensor: tensor([[1., 1., 1.], [1., 1., 1.]]) Zeros Tensor: tensor([[0., 0., 0.], [0., 0., 0.]]) Attributes of a TensorTensor attributes describe their shape, datatype, and the device on which they are stored. Shape of tensor: torch.Size([3, 4])Datatype of tensor: torch.float32Device tensor is stored on: cpu Operations on TensorsOver 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described here. Each of these operations can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to Runtime &gt; Change runtime type &gt; GPU. By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using.to method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory! Try out some of the operations from the list. If you’re familiar with the NumPy API, you’ll find the Tensor API a breeze to use. Standard numpy-like indexing and slicing: First row: tensor([1., 1., 1., 1.])First column: tensor([1., 1., 1., 1.])Last column: tensor([1., 1., 1., 1.])tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) Joining tensors You can use torch.cat to concatenate a sequence of tensors along a given dimension. See also torch.stack, another tensor joining operator that is subtly different from torch.cat. tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]]) Arithmetic operations tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) Single-element tensors If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item(): agg = tensor.sum()agg_item = agg.item()print(agg_item, type(agg_item)) In-place operationsOperations that store the result into the operand are called in-place. They are denoted by a _ suffix. For example: x.copy_(y), x.t_(), will change x. tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) tensor([[6., 5., 6., 6.], [6., 5., 6., 6.], [6., 5., 6., 6.], [6., 5., 6., 6.]]) Note In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged. ==Bridge with NumPy====Tensors on the CPU and NumPy arrays can share their underlying memorylocations, and changing one will change the other.== ==Tensor to NumPy array==t ===== torch.ones==(====5====)====print====(====f====”t:== =={==t==}====”====)====n== ===== t==.====numpy====()====print====(====f====”n:== =={====n====}====”====)== ==t: tensor([1., 1., 1., 1., 1.])n: [1. 1. 1. 1. 1.]== ==A change in the tensor reflects in the NumPy array.== t==.====add_====(====1====)====print====(====f====”t:== =={==t==}====”====)====print====(====f====”n:== =={====n====}====”====)== ==t: tensor([2., 2., 2., 2., 2.])n: [2. 2. 2. 2. 2.]== NumPy array to TensorChanges in the NumPy array reflects in the tensor. np.add(n, 1, out=n)print(f”t: {t}”)print(f”n: {n}”) t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)n: [2. 2. 2. 2. 2.] Total running time of the script: ( 0 minutes 0.023 seconds) Gallery generated by Sphinx-Gallery","link":"/2024/05/502c5eddc639.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 一般情况下，东大是不愿意在东南亚这片地方谈“历史”的，因为这片地方没有历史，唯一存在的历史，就是东大的历史。 很多人觉得东大的南海九段线太霸道，直接画到了很多国家的家门口，那是你理解错了，因为历史上东大的影响力就是这么大，甚至更大，有这些线的时候，还没有这些所谓的“国家”。 ^5fe65c01 举个例子，1946年之前，这里是没有什么狗屁菲律宾的，不存在这个国家，这里只是一些乱七八糟的人类土著部落、割据王国……长达三百年都是西班牙的殖民地，后来又被美国、日本侵略，这是个被创造出来的国家。 ^dab1e344 Content录音记录面前菲官员继续狡辩东大拿出了和菲律宾之间的录音文件，但菲律宾官方居然回应“录音很容易伪造”…… 全世界没有几个国家比东大更温和、包容、讲道理，因为东大近代200年曾经也是弱者，也曾饱受强权欺凌，东大明白这种感觉，所以己所不欲，勿施于人。 东大一般不愿意以强权和武力对周边的邻居们说话，但实际上这是全世界大多数人唯一听得懂的沟通方式。 东大也是全世界最讲契约精神的国家，说“搁置争议”，就“搁置争议”，绝不会首先改变态度。 但人与人不同，国与国不同，东大总是把全世界所有国家都当做独立自主、平等相待、讲素质讲礼貌、有理性有担当、说话算数负责任的正人君子……实际上，正人君子在全世界整个人类历史上都是异类，堂堂正正独立自主站着做人，更是异类中的异类。 所以，东大面对一些无厘头邻居的时候，往往会产生一种“想了十天十夜都想不明白”的困惑——“我对你够尊重了，你在发什么疯”？ 面对美帝国主义的时候，东大没有这样的困惑，毕竟那是“亡我之心不死”的敌人，是“能不讲道理，就不讲道理”，“打得越狠，它越舒服”的强盗……但面对一些实力极弱、也没有什么不共戴天大仇，却忽然发疯寻思死的角色，东大难免有点“从未听过有这种要求”的感觉。 ==一般情况下，东大是不愿意在东南亚这片地方谈“历史”的，因为这片地方没有历史，唯一存在的历史，就是东大的历史。== ==很多人觉得东大的南海九段线太霸道，直接画到了很多国家的家门口，那是你理解错了，因为历史上东大的影响力就是这么大，甚至更大，有这些线的时候，还没有这些所谓的“国家”。== ==举个例子，1946年之前，这里是没有什么狗屁菲律宾的，不存在这个国家，这里只是一些乱七八糟的人类土著部落、割据王国……长达三百年都是西班牙的殖民地，后来又被美国、日本侵略，这是个被创造出来的国家。== 如果菲律宾和和气气和东大交朋友，东大是讲道理的，东大也没有必要非去讨论历史问题，东大甚至可以对菲律宾很好。但自从小马科斯上台后，菲律宾似乎被下了弱智光环一样，卯足了劲要和东大“辩经”，讨论“历史问题”，甚至还勾结美国，试图在东大卧榻之侧部署美国中程导弹，甚至还直接否认和东大直接的口头协议，信口雌黄说“录音文件是伪造”的。 这已经不是一般意义下的“作死”了。 菲律宾确实有一亿多人，但它是个群岛国家，资源极其有限，武器装备大多数都是些老掉牙的货色，甚至还有二战时期的老古董在充数，就算有美军基地，有美国的中程导弹，但在世界第一大工业国的无尽钢铁覆盖下，这些连毛都算不上。 东盟10国，其中9国已经给东大纳了投名状，“环菲律宾朋友圈”已经形成，只有菲律宾活在梦里。 东大历史上就有个强迫症，叫做“师出有名”。历史上美国、印度、越南……都体验过这种正人君子的作风，前不久，缅甸其实也有所体会，但菲律宾体会还不深。 不得承认，在旧的世界秩序下，很多“国家”对自己有误解，它们真的以为自己是个“大国”，真的以为可以左右横跳、火中取栗、认贼作父、欺辱君子、牟取最大利益。 它们存在的时间太短，对真正的历史缺乏了解。 它们不知道，此前的东大，是最好说话的东大，此前的条件，是历史上最优渥的条件。菲律宾微博新知博主","link":"/2024/05/701bcf6a5860.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note feature在CNN中也被成为卷积核（filter），一般是3X3，或者5X5的大小 ^3ecb3c65 卷积神经网络在本质和原理上还是和卷积运算有一定的联系的 ^e3448be7 好了,经过一系列卷积对应相乘，求均值运算后，我们终于把一张完整的feature map填满了。 ^3775cc34 非线性激活层 卷积层对原图运算多个卷积产生一组线性激活响应，而非线性激活层是对之前的结果进行一个非线性的激活响应。指的是对卷积得到的结果再次处理.非线性激活使用的就是非线性激活函数 ^a7676697 卷积操作后，我们得到了一张张有着不同值的feature map，尽管数据量比原图少了很多，但还是过于庞大（比较深度学习动不动就几十万张训练图片），因此接下来的池化操作就可以发挥作用了，它最大的目标就是减少数据量。 池化分为两种，Max Pooling 最大池化、Average Pooling平均池化。顾名思义，最大池化就是取最大值，平均池化就是取平均值。 ^251b2749 拿最大池化举例：选择池化尺寸为2x2，因为选定一个2x2的窗口，在其内选出最大值更新进新的feature map。 同样向右依据步长滑动窗口。 最终得到池化后的feature map。可明显发现数据量减少了很多。 ^14292521 在常见的几种CNN中，这三层都是可以堆叠使用的，将前一层的输入作为后一层的输出。比如： 卷积,激活,池化三大层可以一直叠加欸 ^11d0531b Content目录导读 【1】导论 【2】卷积运算 【3】非线性激活 【4】池化层 【5】全连接层 【6】神经网络的训练与优化 【7】想到再补充 【1】导论 先来说一写题外话… 研究生入学后就被导师逼着学习神经网络，一开始非常盲目，先是在网上搜了一大堆的资料，各种什么“一文读懂卷积神经纹网络”，“叫你三分钟搭建属于自己的神经网络框架”，“五分钟速读神经网络全解”，之类的文章层出不穷。看了太多导致的结果是，学了很久都没能真正意义上地入门。 而后自己艰辛摸索才慢慢了解了卷积神经网络的真谛。（好官方啊哈哈哈哈哈哈） 首先最需要明确的一点就是，卷积神经网络，也就是convolutional neural networks （简称CNN），现在已经被用来应用于各个领域，物体分割啦，风格转换啦，自动上色啦blahblah，但是！！CNN真正能做的，只是起到一个特征提取器的作用！所以这些应用，都是建立在CNN对图像进行特征提取的基础上进行的。 这篇文章呢，我不打算和传统介绍CNN的文章一样先介绍生物神经元、突触什么的，就直接从最简单的实例讲起。 废话不多说，开始。 拿到一张图片，要对它进行识别，最简单的栗子是，这张图是什么？ 比如，我现在要训练一个最简单的CNN，用来识别一张图片里的字母是X还是O。 我们人眼一看，很简单嘛，明显就是X啊，但是计算机不知道，它不明白什么是X。所以我们给这张图片加一个标签，也就是俗称的Label，Label=X，就告诉了计算机这张图代表的是X。它就记住了X的长相。 但是并不是所有的X都长这样呀。比如说… 这四个都是X，但它们和之前那张X明显不一样，计算机没见过它们，又都不认识了。 （这里可以扯出机器学习中听起来很高冷的名词 “ 欠拟合 ”） 不认识了怎么办，当然是回忆看看是不是见过差不多的呀。这时候CNN要做的，就是如何提取内容为X的图片的特征。 我们都知道，图片在计算机内部以像素值的方式被存储，也就是说两张X在计算机看来，其实是这样子的。 其中1代表白色，-1代表黑色。 如果按照每像素逐个比较肯定是不科学的，结果不对而且效率低下，因此提出其他匹配方法。 我们称之为patch匹配。 观察这两张X图，可以发现尽管像素值无法一一对应，但也存在着某些共同点。 如上图所示，两张图中三个同色区域的结构完全一致！ 因此，我们就考虑，要将这两张图联系起来，无法进行全体像素对应，但是否能进行局部地匹配？ 答案当然是肯定的。 相当于如果我要在一张照片中进行人脸定位，但是CNN不知道什么是人脸，我就告诉它：人脸上有三个特征，眼睛鼻子嘴巴是什么样，再告诉它这三个长啥样，只要CNN去搜索整张图，找到了这三个特征在的地方就定位到了人脸。 同理，从标准的X图中我们提取出三个特征（feature） 我们发现只要用这三个feature便可定位到X的某个局部。 ==feature在CNN中也被成为卷积核（filter），一般是3X3，或者5X5的大小==。 【2】卷积运算 说了那么久终于扯到了卷积二字！ 但是！！胖友们！卷积神经网络和信号处理里面那个卷积运算！毛关系都没有啊！当初我还特意去复习了一下高数里的卷积运算！摔! 这些！！都和我们的CNN没有关系！！！ (二稿修改：经知友提醒，此处的确说的不对，==卷积神经网络在本质和原理上还是和卷积运算有一定的联系的==，只是之前本人才疏学浅未能看出它们二者实质相关联的地方，若有误导之处还请各位谅解，抱歉！） 好了，下面继续讲怎么计算。四个字：对应相乘。 看下图。 取 feature里的（1，1）元素值，再取图像上蓝色框内的（1，1）元素值，二者相乘等于1。把这个结果1填入新的图中。 同理再继续计算其他8个坐标处的值 9个都计算完了就会变成这样。 接下来的工作是对右图九个值求平均，得到一个均值，将均值填入一张新的图中。 这张新的图我们称之为 feature map （特征图） 可能有小盆友要举手问了，为什么蓝色框要放在图中这个位置呢？ 这只是个栗子嘛。 这个蓝色框我们称之为 “窗口”，窗口的特性呢，就是要会滑动。 其实最开始，它应该在起始位置。 进行卷积对应相乘运算并求得均值后，滑动窗便开始向右边滑动。根据步长的不同选择滑动幅度。 比如，若 步长 stride=1，就往右平移一个像素。 若 步长 stride=2，就往右平移两个像素。 就这么移动到最右边后，返回左边，开始第二排。同样，若步长stride=1，向下平移一个像素；stride=2则向下平移2个像素。 ==好了,经过一系列卷积对应相乘，求均值运算后，我们终于把一张完整的feature map填满了。== feature map是每一个feature从原始图像中提取出来的“特征”。其中的值，越接近为1表示对应位置和feature的匹配越完整，越是接近-1，表示对应位置和feature的反面匹配越完整，而值接近0的表示对应位置没有任何匹配或者说没有什么关联。 一个feature作用于图片产生一张feature map，对这张X图来说，我们用的是3个feature，因此最终产生3个 feature map。 至此，卷积运算的部分就讲完啦！~ 【3】==非线性激活层== ==卷积层对原图运算多个卷积产生一组线性激活响应，而非线性激活层是对之前的结果进行一个非线性的激活响应。== 这是一个很官方的说法，不知道大家看到上面这句话是不是都觉得要看晕了。 嗯~ o(*￣▽￣*)o 其实真的没有那么复杂啦！ 本系列的文章秉承着“说人话！”的原则，着力于用最简单通俗的语言来为大家解释书上那些看不懂的概念。 在神经网络中用到最多的非线性激活函数是Relu函数，它的公式定义如下： f(x)=max(0,x) 即，保留大于等于0的值，其余所有小于0的数值直接改写为0。 为什么要这么做呢？上面说到，卷积后产生的特征图中的值，越靠近1表示与该特征越关联，越靠近-1表示越不关联，而我们进行特征提取时，为了使得数据更少，操作更方便，就直接舍弃掉那些不相关联的数据。 如下图所示：&gt;=0的值不变 而&lt;0的值一律改写为0 得到非线性激活函数作用后 的结果： 【4】pooling池化层 ==卷积操作后，我们得到了一张张有着不同值的feature map，尽管数据量比原图少了很多，但还是过于庞大（比较深度学习动不动就几十万张训练图片），因此接下来的池化操作就可以发挥作用了，它最大的目标就是减少数据量。== ==池化分为两种，Max Pooling 最大池化、Average Pooling平均池化。顾名思义，最大池化就是取最大值，平均池化就是取平均值。== ==拿最大池化举例：选择池化尺寸为2x2，因为选定一个2x2的窗口，在其内选出最大值更新进新的feature map。== ==同样向右依据步长滑动窗口。== ==最终得到池化后的feature map。可明显发现数据量减少了很多。== 因为最大池化保留了每一个小块内的最大值，所以它相当于保留了这一块最佳匹配结果（因为值越接近1表示匹配越好）。这也就意味着它不会具体关注窗口内到底是哪一个地方匹配了，而只关注是不是有某个地方匹配上了。这也就能够看出，CNN能够发现图像中是否具有某种特征，而不用在意到底在哪里具有这种特征。这也就能够帮助解决之前提到的计算机逐一像素匹配的死板做法。 到这里就介绍了CNN的基本配置—-卷积层、Relu层、池化层。 ==在常见的几种CNN中，这三层都是可以堆叠使用的，将前一层的输入作为后一层的输出。比如：== 也可以自行添加更多的层以实现更为复杂的神经网络。 而最后的全连接层、神经网络的训练与优化，更多内容将在下一篇文章中继续。 （文章更新多说几句： 感谢大家的赞与评论，我本来只是打算为自己的深度学习之路做一个记录，没想到真的有人在认真看这篇文章，很开心自己写的东西能被大家喜欢。 也很遗憾我只是一个还在继续学习中的学生，因此无法做到全面讲述到位，只是为和曾经的我一样为入门而苦恼的初学者提供另一种学习思路，这篇文章很是浅显，若是读者朋友有什么意见与批评，欢迎在评论栏里一起讨论！谢谢）","link":"/2024/05/dd6f485710e2.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note Detectron2 的基本思路就是利用配置文件搭积木。 第一步，将模型拆分为多个模块，每个模块可以叫做一个类型的积木。 第二步，构建配置文件。 第三步，通过配置文件，选择对应的积木。 有一个默认配置文件，即 detectron2/config/default.py 文件。 示例配置文件放在 configs 文件夹中，且使用yaml形式。 所有示例配置文件都是建立在默认配置文件基础上的，即所有示例配置文件中的配置其实都是不全的，缺失的配置需要到默认配置文件中寻找。 detectron2 的配置文件比 mmdetection 看起来简洁很多。 有得必有失，虽然简洁，但在看源码的时候经常需要查看默认配置文件，也不是特别方便。 示例配置文件中有一个_BASE_属性，可以将其他示例配置文件作为基础，如果有冲突则用当前配置文件的信息覆盖。 Content 版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。 参考 Detectron2入门教程 - 云+社区 - 腾讯云 目录 1. 概述 1.1. 自己的源码阅读流程 1.2. 目录结构 1.3. 搭积木过程 1.4. 官方文档阅读 2. 数据处理 2.1. 概述 2.2. 基本流程 2.3. build_detection_train_loader 方法解析 2.4. 其他 3. 模型搭建 3.1. 概述 3.2. 基本流程 3.3. 其他 4. 训练/评估/预测 4.1. 概述 4.2. 训练代码结构 1. 概述1.1. 自己的源码阅读流程 设定目标： 刚刚从TF转向PyTorch，所以希望进一步熟悉PyTorch。 进一步熟悉目标检测、实例分割、关键点检测等模型。 寻找/研究源码中存在的一些tricks。 后续需要通过detectron2来复现新论文。 总结自己之前的一些步骤 第一步：阅读所有官方文档。 第二步：尝试根据 Getting Started 文档内容，运行 demo 中的脚本。 第三步：从数据处理、模型构建、模型训练/预测/评估三个方面，分别浏览源码。 个人感受： PyTorch代码比TensorFlow代码容易多了。 Detectron2源码比TensorFlow Object Detection API源码直观多了，上手容易多了。 1.2. 目录结构 configs：示例配置文件合集。 datasets：数据集准备工作，主要就是各个数据集的基本结构，以及需要如何预处理。 demo：快速体验Detectron2，与Getting Started文档对应。如果想要体验Model ZOO中结果的内容就可以用这个。 detectron2：项目主要代码都在这里了。 dev：一些开发者会用到的脚本。 docker：没啥好介绍的。 docs：一些官方文档。 projects：基于Detectron2的三个项目，DensePose/TensorMask/TridentNet。 Detectron2的开发人员介绍，如果想要利用detectron2直接复现所有论文可能比较困难（我的理解就是直接修改detectron2中的代码），一种比较好的方式就是将detectron2作为一个包来调用来构建新的模型。 tests：单元测试类。 tools：常用脚本，如训练、benchmark、展示数据集等。 ==Detectron2 的基本思路就是利用配置文件搭积木。== ==第一步，将模型拆分为多个模块，每个模块可以叫做一个类型的积木。== ==第二步，构建配置文件。== ==第三步，通过配置文件，选择对应的积木。== 配置文件概述 ==有一个====默认配置文件====，即== ==detectron2/====config====/====default====.py== ==文件。== ==示例配置文件====放在== ==configs== ==文件夹中，且使用yaml形式。== ==所有====示例配置文件====都是建立在====默认配置文件====基础上的，即所有====示例配置文件====中的配置其实都是不全的，缺失的配置需要到====默认配置文件====中寻找。== * ==detectron2 的配置文件比 mmdetection 看起来简洁很多。== * ==有得必有失，虽然简洁，但在看源码的时候经常需要查看默认配置文件，也不是特别方便。== ==示例配置文件====中有一个====_BASE_====属性，可以将其他====示例配置文件====作为基础，如果有冲突则用当前配置文件的信息覆盖。== 如何使用配置文件搭积木 模型搭建的Registry机制 * 调用了 [fvcore.common.registry.Registry](https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/fvcore/blob/master/fvcore/common/registry.py &quot;fvcore.common.registry.Registry&quot;)，该对象的作用是保存一个字典，key为方法/类的名称，value为方法/类，利用 `@registry_object.register` 修饰目标方法/类，这样可以在导入detectron2的同时将 key/value 保存起来。 * 对于每一个类型的积木（如backbone, anchor generator, proposal generator, roi head等）都对应一个Registry对象。更多类型可以看 `detectron2/modeling/__init__.py` 文件。 * 一般，一个Registry对应一个`build.py`，主要就是从Registry中通过名称获取方法/类，然后将**示例配置文件**中参数导入目标方法/类中。 数据集的Registry机制 * 主要使用了 `detectron2/data/catalog.py` 中的 `MetadataCatalog` 与 `DatasetCatalog`，前者保存了数据集的元数据，后者保留了一个方法，该方法用于获取数据集 `list(dict)`。 * 使用了Registry机制，但不是通过注解实现的，而是在 `detectron2/data/datasets/buildin.py` 中调用了 `register_all_coco()` 等四个方法，这些方法调用了 `MetadataCatalog` 和 `DatasetCatalog`的注册方法。 * 一般建数据集会调用 `build_detection_train_loader` 方法，该方法会调用`DatasetCatalog`中的方法，获取 `list(dict)`。 模型训练/预测/评估的的搭积木不复杂，就是根据配置文件，直接创建对应的对象（如lr, optimizer等）。 1.4. 官方文档阅读 官方文档地址，如果想了解Detectron2的源码，强烈建议先看看。 tutorials Installation：安装，没啥好说的。 Getting Started with Detectron2：跑个Demo，没啥好说的。 Extend Detectron2’s Defaults * 谈了谈Detectron2的基本设计思路。一方面要有足够的灵活性（做研究总是要做新东西），一方面要有较好的高层抽象。 * 基本设计思路：所有的方法和类都可以从一个配置文件中获取所需要的参数（配置文件中没有的，就使用默认参数）。 * 介绍了扩展detectron2的一些相关文档。 Use Custom Datasets * dataset只是解析数据集，而没有进行数据处理（数据处理在后面dataloader中进行）。 * dataset的输出将会作为后续dataloader的输入。 * 自定义数据集步骤： * 注册数据集，需要制定数据集名称以及一个 `get_dict` 方法，该方法用于获取一个 `list[dict]` 对象，每个字典就是一条输入数据，具体的key列表可以到文档中自己看。 * 可以注册一些自定义 metadata。 * 数据集的metadata介绍 * 一个记录数据库相关信息的字典，比如primitive information that helps interpret what's in the dataset, e.g., names of classes, colors of classes, root of files, etc. * 可以通过 `MetadataCatalog.get(dataset_name).set(name, value)` 为新数据库添加元数据。 Use Custom Dataloaders * 介绍数据处理模块，其实就是一系列数据增强等操作，以上述dataset的结果作为输入，并作为后续Model的输入。 * 具体过程如下： * 首先，根据数据集名称获取一个已经注册的数据集（就是上面的dataset），获取 `list[dict]` 对象。 * 其次，数据增强等其他数据处理流程都内置于 `DatasetMapeer` 中。 * 最后，需要batch数据，batch后的数据一般就作为 `model.forward()` 的输入。 * 介绍如何自定义Dataloader、使用自定义Dataloader可以参考DensePose的代码。 Use Models * 主要介绍如何构建模型。 * 构建模型方式：通过调用 `build_model`, `build_backbone`，`build_roi_heads` 等方法来构建。 * 要导入权重可以使用 `DetectionCheckpointer(model).load(file_path)`。 * 使用模型就是 `outputs = model(inputs)` * 模型输入使用的参数通过 `list[dict]` 来实现，即上面dataloader的输出，具体的key形式可以参考这个页面中的内容。 * 模型输出也是一个 `list[dict]`，具体的形式可以参考这篇文章中的内容。 Write Models * 自定义模型相关。 * 举了个例子如果自定义backbone该怎么做。 Training * 就提了下训练相关的代码。 * 一般使用 `tools/plain_train_net.py` 来训练模型。 * 最简单的训练结构是 `SimpleTrainer().train()`。 * 一般使用的类是 `DefaultTrainer().train()`。 Use Configs * 介绍了配置系统的基本结构，即使用yaml和yacs来配置。 * 配置文件的使用，其实就是对 `CfgNode` 对象的使用。 * 建议使用配置文件的方式，我比较在意的是 使用`_BASE_`参数来重复配置定义到一个文件中。 notes Benchmarks * 记录一下训练时间，与其他库也比较比较。 Compatibility with Other Libraries * 与其他目标检测库的Compatibility。 Contributing to detectron2 Change Log API Documentation 2. 数据处理2.1. 概述 实现的功能： 解析COCO、cityscapes等数据集。 提供数据预处理以及增强的接口。 通过配置文件即可实现数据集解析、预处理、增强等操作。 主要入口： detectron2/data/build.py 中的 build_detection_train_loader或build_detection_test_loader 方法。 相关代码：主要位于 detectron2/detectron2/data 目录下。 相关配置：detectron2/config/defaults.py 中 _C.INPUT _C.DATASETS _C.DATALOADER 开头的配置。 2.2. 基本流程 第一步：在导入 detectron2 模块时，通过Register机制注册一些常用的数据集。 注册机制可以参考 1.3. 中的内容。 注册代码在 detectron2/detectron2/data/datasets/builtin.py。 第二步：通过数据集名称以及完成注册的 DatasetCatalog 对象以及 MetadataCatalog 对象，解析数据集并获取数据集基本信息。 从源码角度看，就是调用了 DatasetCatalog 中的对应的方法，获取 list[dict] 对象。 第三步：通过mapper函数，对解析完的数据集进行进一步处理，包括数据增强，并将修改数据的结构，使之可以直接作为后续模型的输入。 从源码角度理解就是，从 DatasetCatalog 获取的是 list[dict]，mapper函数输出的也是 list[dict]，但前后两个字典的形式是不一样的，具体可以参考官方文档，里面都有具体的描述。 2.3. build_detection_train_loader 方法解析 源码位于 detectron2/detectron2/data/build.py 中。 流程： 第一步：获取 list[dict] 对象。先根据数据库名称调用 DatasetCatalog 中的方法，获取原始 list[dict] 对象，再通过一些条件进行筛选。 第二步：构建 DatasetFromList 对象，该类是 torch.utils.data.Dataset 的子类。 第三步：根据mapper对上面的dataset对象进行进一步处理。 * 浏览了下 `DatasetMapper`的源码，主要工作包括读取图像、resize、crop、flip、转换数据与标签的形式等。 第四步：构建 torch.utils.data.sampler.Sampler 对象，实现的功能好像包括Repeat Sample、shuffle、batch功能。 第五步：根据上面的 dataset, sampler 等对象构建 torch.utils.data.DataLoader 对象。 感想： 好像也没有什么特别的数据增强工作。 Detectron2实现的 DatasetFromList、MapDataset等，有点 tf.data 的感觉，挺有意思。 2.4. 其他 数据增强 方法主要都在 detectron2/detectron2/data/transforms/transform_gen.py 中定义。 调用的话主要是通过 from detectron2.data import transforms as T 以及 T.ResizeShortestEdge 来实现。 在默认实现中，就没用到什么特别的数据增强。具体的可以到 DatasetMapper 的源码中看。 3.1. 概述 实现的功能：通过配置文件构建模型。 主要入口：detectron2/detectron2/modeling/meta_arch/build.py 中的 def build_model(cfg) 方法。 相关代码：detectron2/detectron2/modeling 目录下。 相关配置：detectron2/config/defaults.py中_C.MODEL 开头的配置。 3.2. 基本流程 第一步：根据注册机制，在导入 detectron2 时，将各个类型的积木通过注解的方式保存到 Registry 对象中。 第二步：根据配置文件中 META_ARCHITECTURE 参数，选择基本框架，也就是 meta arch。 基本框架(meta arch)的类型没集中，包括 rcnn, retinanet, semantic seg, panoptic 四种。 每个基本框架(meta arch)中都定义了一系列子部件，也都是用Register机制来管理（即通过配置文件与Register对象来构建）。 基本框架的定义中，就包含了模型如何构建、如何训练、如何预测等相关功能。 第三步：通过配置文件分别构建选中meta arch中各个部件。 3.3. 其他 Registry对象列表 ANCHOR_GENERATOR_REGISTRY：如何生成anchors。 BACKBONE_REGISTRY：主干网络，包括FPN。 META_ARCH_REGISTRY：基本网络，总体结构。 SEM_SEG_HEADS_REGISTRY：应该是用来做语义分隔的。 PROPOSAL_GENERATOR_REGISTRY：Faster RCNN中的Region proposal Network，即如何生成proposals。 RPN_HEAD_REGISTRY：第一阶段训练所需的输入。 ROI_BOX_HEAD_REGISTRY：ROI Head中的bbox分支。 ROI_HEADS_REGISTRY：通过特征图和第一阶段的proposals得到ROI。 ROI_KEYPOINT_HEAD_REGISTRY：ROI Head中的keypoint分支。 ROI_MASK_HEAD_REGISTRY：ROI Head中的mask分支。 除了通过注册机制管理的部件外，还有一系列模型所需的部件，具体的可以参考 meta_arch 中的相关源码。 4.1. 概述 实现的功能：通过配置文件构建模型。 主要入口：detectron2/detectron2/engine/defaults.py 中的 DefaultTrainer, DefaultPredictor。 相关代码：主要在 detectron2/detectron2/engine 和 detectron2/detectron2/solver 中 相关配置：detectron2/config/defaults.py中_C.SOLVER _C.TEST 开头的配置。 主要包括了：TrainerBase, SimpleTrainer, DefaultTrainer 三个类。 TrainerBase： 定义在 detectron2/detectron2/engine/train_loop.py 中。 主要功能： * 提供了 hooks 机制，可以通过导入 `HookBase` 对象，在训练过程的各个时间点进行自定义处理。 * 定义了训练函数为 `train(self, start_iter: int, max_iter: int)`，且维训练提供了一个 `EventStorage` 对象。 这个与TF中的SessionRunHook类似，只不过TF已经实现在源码里，而Detectron2中是自己实现的。 SimpleTrainer： 定义在 detectron2/detectron2/engine/train_loop.py 中。 主要功能：在 TrainerBase 的基础上添加了训练所需的基本参数以及最基本的训练过程代码。 基本训练参数指的是 model/data_loader/optimizer 基本训练过程包括位于 run_step 函数中，主要包括的功能是： * 导入数据。 * 计算损失函数（并确保损失函数是有效的）。 * 记录一些性能指标（包括损失函数、时间点），保存到 `EventStorage` 对象中。 * 进行梯度下降操作。 DefaultTrainer 定义在 detectron2/detectron2/engine/defaults.py 中。 主要功能： * 在 `SimpleTrainer` 的基础上，提供了通过配置文件创建模型、数据集、优化器、学习率等一系列操作。 * 提供了 checkpoint 功能。 * 使用了一系列常见的 hooks。 hooks的定义都在 detectron2/detectron2/engine/hooks.py 中。 文章知识点与官方知识档案匹配，可进一步学习相关知识","link":"/2024/05/322c356ea11b.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 建思路，将整体实践方法论进行拆解。 ^54df8fcd ContentMatrix 首页推荐 Matrix 是少数派的写作社区，我们主张分享真实的产品体验，有实用价值的经验与思考。我们会不定期挑选 Matrix 最优质的文章，展示来自用户的最真实的体验和观点。 文章代表作者个人观点，少数派仅对标题和排版略作修改。 限制个人潜能的从来不是某套工具，而是思维模式。——《打造第二大脑》 引言哪种笔记形态才是我们大脑的理想「外挂」？我的答案是卢曼卡片盒笔记法 + Obsidian 。 这套组合，让我逐渐在「工具」与「笔记」之间找到了平衡，不再为收藏不完的「干货」焦虑，不再为没及时用上宝藏软件而沮丧，转而专注自身知识体系建设。 至此，「笔记」不再消耗我注意力，开始逐渐生出滋养我的能力。而这背后是我和笔记软件十年的「爱恨情仇」，也许也是众多「笔记侠」共同的心路历程。希望本文能给大家带来点滴启发。 在「效率成瘾」的路上狂奔折腾笔记这件事，从 2014 年使用 Evernote 开始，就再也没停下来过。从最初的 Evernote、OneNote 到 Bear、Noted，到习得「第二大脑」相关思路之后，转战 Notion、Roma Research、Obsidian、Read wise 、Pocket、Hypothesis、Anki 等，甚至一度搭建起一个十分复杂信息系统。 这背后学习各类软件的沉没成本。大量时间用在了研究使用教程及搭建体系上，特别是 Notion、Obsidian 这类高使用门槛软件。我曾经一个「五一」假期，端坐在电脑前，研究从 0-1 搭建 Notion。在 Youtube 上，看各路大神的使用教程；改造他们各类逻辑复杂的模板；之后间歇性的，借助看起来高大上模板升级，对系统进行迭代，并为自己取得的进展而沾沾自喜。 结果可想而知。系统庞杂，尾大不掉，且启动成本极高，很难养成使用习惯。在各自坚持使用了一段时间之后，便七零八落了。 以上实践，正如蒂亚戈.福特在《打造第二大脑》中所揭示的： 信息组织过程中一个最容易踏入的误区就是追求完美，并将组织过程本身视为目的。 回顾这十年，无论身处哪个笔记软件为主导的阶段，都一直在这个误区徘徊，「将组织过程本身视为目的」。 在 Evernote 、Bear 时代，变身「人形存储器」，间歇性的折腾文件夹、标签分类方式，但随着收集的笔记日渐增多，最终沦为「思想的坟场」。面对成百上千条笔记，无力拯救。 到 Notion 时代，一边惊叹它的 all-in-one 能力，一边陷入 block、page、database 构建的大而可无限延展的迷宫之中。 同步使用的 Obsidian 这类「双向链接」工具，因对其可能性认知不足，且不是主力笔记应用，导致积累不足。因而整体使用中也未感知到其价值。 整体而言，在信息爆炸带来的「浅薄」浪潮中，「效率成瘾」，但却始终没有找到理想的笔记软件及知识管理方式。直到接触到了「卢曼卡片盒笔记法」，并按图索骥，在「少数派」中研究了相关实践文章。 凭借多年的「折腾」经验，我深刻地意识到「卡片盒笔记法」+ Obsidian「双向链接」的双强组合，可以重溯我的笔记体系乃至知识体系。这种感觉就像是一个习武久无长进之人，因缘际会，得到一本秘籍，突然找到了进阶的法门。 鲁曼卡片盒笔记法「卢曼卡片盒笔记法」，是德国社会学家尼可拉斯·卢曼首创的笔记方法论。非科班出身的他著作等身。而这套方法正是他的生产力引擎。这套方法论的核心是将笔记到卡片上，收集到卡片盒中，并通过不断的标注及思考，建立笔记之间的联系，使想法逐步形成想法集群，日积月累，经过长期的迭代，衍生出系统性的思想，为写作做准备。 整体方法论的践行流程： 记录「闪念笔记」 ：捕捉大脑的每个想法，想怎么写怎么写，任何载体都可以，但要在一两天内及时整理。 撰写「文献笔记」 ：无论你读什么都要记笔记，写下你任何你不想忘记的内容，或者你认为可能会在自己思考或者写作中使用的东西。尽量使用自己的语言记录，但是要留存参考片书目的信息，便于存档及后续准确引用。 撰写「永久笔记」：写下针对「闪念笔记」、「文献笔记」两类笔记的想法，尽量做到言简意赅。如果脱离上述两类笔记单独呈现，则要标注好来源。闪念、文献笔记的的最终目的是为了衍生想法、论点和讨论，支持永久笔记。 把新的「永久笔记」添加到卡片盒，在相关笔记之间建立链接。并关注卡片盒内哪些已经形成「笔记链」，哪里已经形成「想法集群」。 从卡片盒系统内部自下而上发展主题，用于写作或者主题研究拓展等。并基于现有卡片，思考缺失什么，出现了什么问题，采取下一步行动。 卡片笔记的信息特质： 原子性：以单个知识卡片为最小单位，信息可以重新组合，可服务于任何相关主题。 可见性强：信息复现更容易。知识自下而上沉淀，每个想法都嵌入了丰富的上下文，并且附带了可以使用的素材。 可传递性：与未经深入加工的信息相比，实用性及复用性强，打破信息存完即弃的魔咒，为未来的自己提供信息支撑。 卡片盒笔记法 + Obsidian 实践下面结合个人生产力专家蒂亚戈.福特提出的「信管法则」，以及卡片盒笔记法在Obsidin的搭==建思路，将整体实践方法论进行拆解。== 《打造第二大脑》信管法则 信息的抓取：闪念笔记、文献笔记 学会如何思考实际上意味着学会如何控制你的思考形式和思考内容。这意味着你要非常清楚，自己应当选择关注哪些内容，选择怎样从经验中构建信息、获取知识。 ——戴维·华莱士 2005 年在凯尼恩大学毕业典礼上的演讲 在信息抓取阶段，我们往往沉溺在信息获取的快感中，而忽略了对内容的质量把关。因而使用「卢曼卡片盒笔记法」重溯笔记体系的第 0 步，除了习得这套笔记方法论，以及掌握Obsidian的使用外，最重要的是审视自己的信息抓取策略。审慎的选择关注哪些内容。我自身的实践思路： 优化思考内容： 将图书作为核心信息源，分阶段增加超越现有认知书籍的比例，只有「阅读超越你头脑的书」，才能帮助你的思想增长。减少畅销书的比例。 网络信息以 RSS 订阅、邮件订阅的形式进行聚焦整合，该部分是发作「错失恐惧症」的重灾区，尽量做到少而精，否则它大概率会沦为信息的「坟场」。 选择自己强关注领域的付费订阅，就信息价值而言，这是一个更有性价比的选项。 优化阅读策略： 从一本书中所得到的 80% 的知识，其实都来自于全书 20% 的内容。因此，想要高效地阅读并收获知识，一个极大的关键就是要看我们如何找出书中这 20% 的精华部分了。——《知识变现》 借鉴信息获取中的「二八法则」，在实践卡片盒笔记法之后，我对自身的阅读现状进行了分析：整体可以做到主动的阅读及分析阅读，但努力可能有大一大半是浪费掉了，因为没有掌握如何才能合理地读快一点。另外除个别论证性、知识点密级的书籍外，每阅读一本书都花了差不多同样的时间与努力。这就导致阅读量受限，该好好阅读的书没读好，不值得注意的书上没少花时间。 综上，我的优化策略是重新复盘阅读方法，对于不同价值及题材书籍，采用更多元化的阅读策略，强化「检视阅读」「主题阅读」以及「杠铃阅读法1 」的应用，提升信息获取的效率。 第一层 基础阅读 初级阅读，识字后拥有的基础阅读能力。 第二层 检视阅读 在一定时间内抓住一本书的重点，确定一本书是否值得一读。 第三层 分析阅读 全盘阅读、完整的阅读。 第四层 主题阅读 同一主题，多本相关书籍比较阅读，并能提出新的主题分析。 （阅读的四个层次，总结自《如何阅读一本书》） （注：杠铃阅读，一套综合阅读方法。即通过泛读抓取有价值的信息，进而通过对有价值信息的分析阅读以及深加工，实现对信息的有效提取。） 铺垫了这么多，让我们进入正题。在「卢曼卡片盒笔记法」中，我把「闪念笔记」以及「文献笔记」归入信息「抓取」阶段。这两类笔记载体是我们灵感的源头。 「闪念笔记」来自日常见闻，及所思所想。这些偶尔迸发的奇思妙想，可能带来不一样的惊喜。我记录的载体主要是纸质笔记本、备忘录 App 以及语音备忘录 App。主要应用场景是突然有某个想法，但是没有足够的时间去完成「永久笔记」。比如在路上，在看某个影视作品，在吃饭的空档，或者睡觉前。切记要一两天内完成整理完成，升级成「永久笔记」形态。 「文献笔记」则来自阅读，你读的书、文章。它用于记录你阅读中你不想忘记的东西，或者你认为后续可能会在自己思考、写作中使用的内容。 这部分相当于文献（所读之物）+ 思考概述；既对思考的源头进行留痕，又加入自己的理解阐释。切记不要只是抄写。要使用自己的语言阐释，对引文也要格外挑剔。同时为了保证信息的完整性，这些笔记和参考书目信息，将一起保存到「文献笔记盒」中。 在 Obsidian 实践中，对应着两类笔记分开设置卡片盒（文件夹）。同时在记笔记时，要有意识的加入概念、观点、方法论等关键词的「双向链接」，积累到一定量级，高频词汇可以在「关系图谱」中查看，这是我们发展写作「主题」的基础。 对于整体笔记体系，质和量都非常重要，这也是我为什么在这部分开篇强调阅读能力及阅读策略的原因。只有笔记达到一定量级，我们才能看到卡片笔记的整体势能。它作为一个思考工具、生产力引擎，也才能更好的塑造我们的思维。 信息的组织：永久笔记 如果你理解了你所读到的东西，并把它融入自己的思维系统，再做成笔记添加到卡片盒中，你就已经把别人的发现和思想转化为属于自己的新想法了。——《卡片笔记写作法》 「永久笔记」是对「闪念笔记」以及「文献笔记」的思考笔记， 思考它们与自己的研究、思考或兴趣所在的相关内容的关联性。针对以上笔记的想法、论点或者讨论。它以单独的笔记呈现，标注清楚来源，便于后续使用。 永久笔记要求精准、清晰、简短（此阶段仍然是短小精悍的笔记总结，并非写作，不要混淆）。完成这部分笔记后，「闪念笔记」可以删除，「文献笔记」视后续需求存档。 在 Obsidian 实践中，在建立「永久笔记」笔记盒（文件夹）的同时，我会在它的下一层建立若干个高频主题文件夹，比如读书、写作、营销等任何你长期关注的领域。因为有 Obsidian 的「双向链接」功能，也可以不进行这层主题分类，而是利用软件的「入链」「出链」功能，或者「关系图谱」查看这一关键主题内容的全景。 在信息的抓取与组织阶段，相比传统笔记，「输入」难度明显增加。不再是单纯的收藏、标注、记录，而是进行体系化处理。它们不再是一闪而过的念头、观点，而是经过你过滤，且留有你思考的痕迹的笔记，每条笔记的撰写难度增加。而「存储与提取负相关」，有难度的的信息输入，会让我们在知识提取及使用时更加容易。 信息的提炼：想法集群当有质量的「永久笔记」达到一定量级之后，就会逐步形成「群聚效应」，「每一个想法都会增加群聚效应的临界量，最后你可以把一个个单纯的想法集合起来，变成一个想法生成器」，这时候你就可以查看「关系图谱」，寻找里面最突出的「主题」，也可以通过 Obsidian 的「白板」功能，将同一主题的信息拖拽进来，可视化的查看目前的信息全景。看看里面目前有什么，缺少什么，有什么问题点值得思考的。随着卡片盒内容的丰富，你的思维也变得越丰富。 Obsidian 关系图谱 以如何「读书」这一关键词为例，当你阅读的相关书籍或文章增多，会形成诸如「阅读的乐趣」「阅读方法论」「阅读实用价值」等思想集群。这时候你可以按照关注程度决定下一步的阅读方向。 思想集群 在相关主题不断聚集之后，你也拥有了更多可能性。比如随着「阅读策略」 这一主题不断增加迭代后，你会有意识地应用到自己阅读策略中。去迭代其中的低效能部分，去增加阅读超越现有思想书籍的比例，以「生吞」的策略，拿下之前望而却步的大部头。这可能是之前不会尝试的，但现在的笔记体系会在潜移默化中，改变你的思维模式，也会在它壮大的同时，带着前向的势能，推动你行动上的改变，成为你真正的生产力引擎。 信息的表达：写作在以往的笔记体系中，我们自上而下按主题进行存储信息，且未经深入加工，越积累越多越困惑，大概率是不会激发出主动写作的动力的；即使要写作，也指望不上我们的笔记系统，而需要转向求助我们的大脑，或者搜索引擎了。 「卢曼卡片盒笔记法」这一自下而上的笔记构建体系，则会在信息的组织、提炼阶段，让思考交融而产生洞见。「它的可用性随着其规模的增长而增长，而且是指数增长，不是线性增长。卡片盒中包含的内在联系将不仅提供孤立的事实，还会为我们提供一系列成熟的思想。」 另外，在写作中，它的另一个巨大的优势，即「想法都嵌入了丰富的上下文中，并且附带了可以使用的素材，而不是凭空产生的」，这会让你的大脑专注于新观点的思考，而不是得时时想论据站不站得住脚。当我们践行这一方法，将它加入到学习流、工作流中运转起来时，我们就不会再陷入无主题可写，无材料可用的尴尬境地。 在写作阶段，我们可以根据已有想法，确定写作主题。而不用临时去读什么文章或者书「可能提供的未知想法」。此时在 Obsidian 实操时，我们可以在将相关「永久笔记」汇聚在「白板」中，思考素材之间的内在联系，查缺补漏，并提炼核心论点、论据，编写文章的大纲。以这篇文章的素材支持卡片为例： 使用「白板」汇聚相关卡片 在大纲完善后，我们就可以依托笔记撰写初稿，这里需要提别注意的是，不要直接复制笔记。要重新思考在这一主题，以及大纲的论述结构之下，笔记如何服务文章内容，如何为论点做支撑。同时在创作中要注意「查论点中的漏洞，想办法完善或改变论点。」 另外写作中，不要为了追求某段的表述效果，而不断的删除、重写，这会影响写作的节奏，同时也极其影响写作的信心。这阶段最重要的是写，是完成。之后站在整体文章的视角进行审视、修改，当然还有后续的编辑、校对，以及开始写下一篇。 总结「卢曼卡片盒笔记法」最大的难点正如《卡片笔记写作法》作者申克·阿伦斯所言，使用者仅孤立的关注方法本身，未能嵌入自己的日常工作流、学习流。这就导致笔记系统启动成本高，且无法坚持下来。在使用的过程中，我深刻的体会到，这不是一套「速赢」的方法。它无法在你某天突发奇想想要写点什么时，给予支持。只有长期积累，才能显现信息的「复利」，整体体系才能发挥能效，并逐步带你走向「正向循环」。这时它会吸引你做笔记、写文章。 第二大难点是卡片盒技术本身的应用。这套方法操作起来并不没有想象的那么简单。虽然有 Obsidian 等「双向链接」工具的加持，但是各类笔记的制作、不同类型笔记的流转，以及定期的思考、复盘，都依赖于笔记使用者。这就要求我们从被动的笔记「收藏家」，要转变为主动的笔记「生成者」、「思考者」。未经加工的文章、未加整理的读书笔记，未经二次思考的备忘录，扔进这里是没有意义的。「Garbage in, garbage out」，只有有价值笔记的积累，才能推动笔记系统走向正向循环。 同时要十分清楚卡片盒笔记法的各项使用逻辑及细则，结合 Obsidian 的系统能力，构架符合自己使用习惯的笔记体系，并在此过程中不断根据实践不断优化。要有灵活性，比如为一本论述性的书籍做读书笔记，它可能同时包含「闪念笔记」「文献笔记」以及「永久笔记」，这时我的做法不是按照笔记的类型拆分读书笔记，而是以书为主题，聚合这三类笔记。同时因为属于高频使用场景，便在「template」里制作了相应的模板，其他的笔记类型同理。具体样式如下： 读书笔记主题模板 难点三是 Obsidian 的使用，切记不要去折腾各类进阶版的插件。就卡片盒笔记法的应用而言，Obsidian 的基础配置和自带插件已够用了。我们的核心是借助这一工具落地卡片盒笔记体系，实现各类笔记的记录、流转、思考、复盘，以及为写作服务。不要舍本求末。 以上是此次个人笔记系统升级迭代至：卡片盒笔记法 + Obsidian 的整体复盘。时间尚短，理解及表述如有疏漏，请各位「盒友」、同好，不吝指正。 主要参考资料： 《卡片笔记写作法》[德 ]申克·阿伦斯 《打造第二大脑》[美] 蒂亚戈.福特 《如何阅读一本书》[美] 莫提默·艾德勒 查尔斯·范多伦 > 下载少数派 客户端、关注 少数派小红书，感受精彩数字生活 🍃 > 实用、好用的 正版软件，少数派为你呈现 🚀 1一套综合阅读方法。即通过泛读抓取有价值的信息，进而通过对有价值信息的分析阅读以及深加工，实现对信息的有效提取 © 本文著作权归作者所有，并授权少数派独家使用，未经少数派许可，不得转载使用。","link":"/2024/05/b858a0f006ac.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 作为日本人来说，站在日本的视角，是找不到其他出路的。因为这本就和日本无关，是朝贡体系崩坏后的结果，这是中国的问题而不是日本的问题，因此压根和日本无关。东亚混乱的根源是宗主国本身的衰弱 ^d8b6d633 Content逛2CH的，就知道日本人的意识形态。日本人是真心觉得二战那会，日本是为了解放在白人统治下的亚洲和欧美人作战的。其实到现在部分人还有那种心思。 这种思想你也不能说全错：因为当年亚洲尤其是东南亚就是在欧美统治下的，且二战结束后，东南亚确实和欧洲人作战，且把欧洲人驱逐了，问题在于，日本人实际上替代了欧美，成了新一代的殖民者，日本人认为自己这个殖民者比欧美的殖民者更友善。然后再去看鸟山明的作品，那就很正常了，鸟山明的意识形态，和2CH的网民没什么两样。 ==作为日本人来说，站在日本的视角，是找不到其他出路的。====因为这本就和日本无关，是朝贡体系崩坏后的结果，====这是中国的问题而不是日本的问题，====因此压根和日本无关。==所以日本人就算绞尽脑汁也想不出什么解决办法的。 沙漠大冒险鸟山明龙珠","link":"/2024/05/6858510a114d.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 速度： 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则(采用Selective Search方法)预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上(采用CNN)提取特征，进行判断。相较于传统算法,通过滑动窗口寻找,rcnn使用了selective search,再在可能的区域上进行CNN提取特征 RCNN算法分为4个步骤 候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法） 特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN） 类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类 位置精修： 使用回归器精细修正候选框位置 Selective Search 主要思想: 使用一种过分割手段，将图像分割成小区域 (1k~2k 个) 查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置 输出所有曾经存在过的区域，所谓候选区域 其中合并规则如下： 优先合并以下四种区域： 颜色（颜色直方图）相近的 纹理（梯度直方图）相近的 合并后总面积小的： 保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域 （例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -&gt; abcd-efgh -&gt; abcdefgh。 不好的合并方法是：ab-c-d-e-f-g-h -&gt;abcd-e-f-g-h -&gt;abcdef-gh -&gt; abcdefgh） 合并后，总面积在其BBOX中所占比例大的： 保证合并后形状规则。 上述四条规则只涉及区域的颜色直方图、梯度直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。 所谓的有监督预训练也可以把它称之为迁移学习。比如你已经有一大堆标注好的人脸年龄分类的图片数据，训练了一个CNN，用于人脸的年龄识别。然后当你遇到新的项目任务时：人脸性别识别，那么这个时候你可以利用已经训练好的年龄识别CNN模型，去掉最后一层，然后其它的网络层参数就直接复制过来，继续进行训练，让它输出性别。这就是所谓的迁移学习，说的简单一点就是把一个任务训练好的参数，拿到另外一个任务，作为神经网络的初始参数值,这样相比于你直接采用随机初始化的方法，精度可以有很大的提高。把一个类似的训练好的模型,去掉最后一个输出层,把网络层参数直接拿来用,修改修改,就可以变成另外一个模型例如从训练好的人脸年龄模型可以迁移训练成为人脸性别模型 对于bounding box的定位精度，有一个很重要的概念： 因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式：IOU。 它定义了两个bounding box的重叠度，如下图所示 就是矩形框A、B的重叠面积占A、B并集的面积比例。 非极大值抑制（NMS）顾名思义就是抑制不是极大值的元素，搜索局部的极大值。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。这里不讨论通用的NMS算法，而是用于在目标检测中用于提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。*对于从小到大排列的矩形框A,B,C,D,E,设定一个阈值LA,B对E的重叠度超过了L,可以认为A,B在E的邻域内.C,D对F的重叠度小于L,可以认为C,D不在E的邻域内 对于某个矩形框alpha进行NMS,意味着所有超出阈值的矩形框都要比较大小,仅仅保留最大的小于阈值的矩形框暂时保留,因为它们不在alpha的邻域中 NMS意味着,每个矩形框邻域内,仅仅保留最大的矩形框* 首先对每一个输入的图片产生近2000个不分种类的候选区域（region proposals），然后使用CNNs从每个候选框中提取一个固定长度的特征向量（4096维度），接着对每个取出的特征向量使用特定种类的线性SVM进行分类。也就是总个过程分为三个程序：a、找出候选框；b、利用CNN提取特征向量；c、利用SVM进行特征向量分类。 为什么是固定长度的特征向量4096维度 paper试验了两种不同的处理方法： (1)各向异性缩放 这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示； (2)各向同性缩放 因为图片扭曲后，估计会对后续CNN的训练精度有影响，于是作者也测试了“各向同性缩放”方案。有两种办法 A、先扩充后裁剪： 直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如上图(B)所示; B、先裁剪后扩充：先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如上图(C)所示; 对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0,第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。 Content前面一直在写传统机器学习。从本篇开始写一写 深度学习的内容。 可能需要一定的神经网络基础（可以参考 Neural networks and deep learning 日后可能会在专栏发布自己的中文版笔记）。 RCNN (论文：Rich feature hierarchies for accurate object detection and semantic segmentation) 是将CNN方法引入目标检测领域， 大大提高了目标检测效果，可以说改变了目标检测领域的主要研究思路， 紧随其后的系列文章：（ RCNN）,Fast RCNN, Faster RCNN 代表该领域当前最高水准。 【论文主要特点】（相对传统方法的改进） ==速度： 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则(采用Selective Search方法)预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上(采用CNN)提取特征，进行判断。== 训练集： 经典的目标检测算法在区域中提取人工设定的特征。本文则采用深度网络进行特征提取。使用两个数据库： 一个较大的识别库（ImageNet ILSVC 2012）：标定每张图片中物体的类别。一千万图像，1000类。 一个较小的检测库（PASCAL VOC 2007）：标定每张图片中，物体的类别和位置，一万图像，20类。 本文使用识别库进行预训练得到CNN（有监督预训练），而后用检测库调优参数，最后在检测库上评测。 看到这里也许你已经对很多名词很困惑，下面会解释。先来看看它的基本流程： 【基本流程 ===================================】 ==RCNN算法分为4个步骤== ==候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法）== ==特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN）== ==类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类== ==位置精修： 使用回归器精细修正候选框位置== 【基础知识 ===================================】 ==Selective Search== ==主要思想:== ==使用一种过分割手段，将图像分割成小区域 (1k~2k 个)== ==查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置== ==输出所有曾经存在过的区域，所谓候选区域== ==其中合并规则如下： 优先合并以下四种区域：== ==颜色（颜色直方图）相近的== ==纹理（梯度直方图）相近的== ==合并后总面积小的： 保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域 （例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -====&gt;== ==abcd-efgh -====&gt;== ==abcdefgh。 不好的合并方法是：ab-c-d-e-f-g-h -====&gt;====abcd-e-f-g-h -====&gt;====abcdef-gh -====&gt;== ==abcdefgh）== ==合并后，总面积在其BBOX中所占比例大的： 保证合并后形状规则。== ==上述四条规则只涉及区域的颜色直方图、梯度直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。== 有监督预训练与无监督预训练: (1)无监督预训练(Unsupervised pre-training) 预训练阶段的样本不需要人工标注数据，所以就叫做无监督预训练。 (2)有监督预训练(Supervised pre-training) ==所谓的有监督预训练也可以把它称之为迁移学习。比如你已经有一大堆标注好的人脸年龄分类的图片数据，训练了一个CNN，用于人脸的年龄识别。然后当你遇到新的项目任务时：人脸性别识别，那么这个时候你可以利用已经训练好的年龄识别CNN模型，去掉最后一层，然后其它的网络层参数就直接复制过来，继续进行训练，让它输出性别。这就是所谓的迁移学习，说的简单一点就是把一个任务训练好的参数，拿到另外一个任务，作为神经网络的初始参数值,这样相比于你直接采用随机初始化的方法，精度可以有很大的提高。== 对于目标检测问题： 图片分类标注好的训练数据非常多，但是物体检测的标注数据却很少，如何用少量的标注数据，训练高质量的模型，这就是文献最大的特点，这篇论文采用了迁移学习的思想： 先用了ILSVRC2012这个训练数据库（这是一个图片分类训练数据库），先进行网络图片分类训练。这个数据库有大量的标注数据，共包含了1000种类别物体，因此预训练阶段CNN模型的输出是1000个神经元（当然也直接可以采用Alexnet训练好的模型参数）。 重叠度（IOU）: 物体检测需要定位出物体的bounding box，就像下面的图片一样，我们不仅要定位出车辆的bounding box 我们还要识别出bounding box 里面的物体就是车辆。 ==对于bounding box的定位精度，有一个很重要的概念： 因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式：IOU。 它定义了两个bounding box的重叠度，如下图所示== ==就是矩形框A、B的重叠面积占A、B并集的面积比例。== 非极大值抑制（NMS）： RCNN会从一张图片中找出n个可能是物体的矩形框，然后为每个矩形框为做类别分类概率： 就像上面的图片一样，定位一个车辆，最后算法就找出了一堆的方框，我们需要判别哪些矩形框是没用的。非极大值抑制的方法是：先假设有6个矩形框，根据分类器的类别分类概率做排序，假设从小到大属于车辆的概率 分别为A、B、C、D、E、F。 (1)从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值; (2)假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。 (3)从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。 就这样一直重复，找到所有被保留下来的矩形框。 ==非极大值抑制（NMS）顾名思义就是抑制不是极大值的元素，搜索局部的极大值。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。这里不讨论通用的NMS算法，而是用于在目标检测中用于提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。== VOC物体检测任务: 相当于一个竞赛，里面包含了20个物体类别：PASCAL VOC2011 Example Images 还有一个背景，总共就相当于21个类别，因此一会设计fine-tuning CNN的时候，我们softmax分类输出层为21个神经元。 【各个阶段详解 ===================================】 总体思路再回顾： ==首先对每一个输入的图片产生近2000个不分种类的候选区域（region proposals），然后使用CNNs从每个候选框中提取一个固定长度的特征向量（4096维度），接着对每个取出的特征向量使用特定种类的线性SVM进行分类。也就是总个过程分为三个程序：a、找出候选框；b、利用CNN提取特征向量；c、利用SVM进行特征向量分类。== 候选框搜索阶段： 当我们输入一张图片时，我们要搜索出所有可能是物体的区域，这里采用的就是前面提到的Selective Search方法，通过这个算法我们搜索出2000个候选框。然后从上面的总流程图中可以看到，搜出的候选框是矩形的，而且是大小各不相同。然而CNN对输入图片的大小是有固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。因此对于每个输入的候选框都需要缩放到固定的大小。下面我们讲解要怎么进行缩放处理，为了简单起见我们假设下一阶段CNN所需要的输入图片大小是个正方形图片227*227。因为我们经过selective search 得到的是矩形框，==paper试验了两种不同的处理方法：== ==(1)各向异性缩放== ==这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示；== ==(2)各向同性缩放== ==因为图片扭曲后，估计会对后续CNN的训练精度有影响，于是作者也测试了“各向同性缩放”方案。有两种办法== ==A、先扩充后裁剪： 直接在原始图片中，把bounding box的边界进行扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充；如上图(B)所示;== ==B、先裁剪后扩充：先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如上图(C)所示;== ==对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0,第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高。== （备注：候选框的搜索策略作者也考虑过使用一个滑动窗口的方法，然而由于更深的网络，更大的输入图片和滑动步长，使得使用滑动窗口来定位的方法充满了挑战。） CNN特征提取阶段： 1、算法实现 a、网络结构设计阶段 网络架构两个可选方案：第一选择经典的Alexnet；第二选择VGG16。经过测试Alexnet精度为58.5%，VGG16精度为66%。VGG这个模型的特点是选择比较小的卷积核、选择较小的跨步，这个网络的精度高，不过计算量是Alexnet的7倍。后面为了简单起见，我们就直接选用Alexnet，并进行讲解；Alexnet特征提取部分包含了5个卷积层、2个全连接层，在Alexnet中p5层神经元个数为9216、 f6、f7的神经元个数都是4096，通过这个网络训练完毕后，最后提取特征每个输入候选框图片都能得到一个4096维的特征向量。 b、网络有监督预训练阶段 （图片数据库：ImageNet ILSVC ） 参数初始化部分：物体检测的一个难点在于，物体标签训练数据少，如果要直接采用随机初始化CNN参数的方法，那么目前的训练数据量是远远不够的。这种情况下，最好的是采用某些方法，把参数初始化了，然后在进行有监督的参数微调，这里文献采用的是有监督的预训练。所以paper在设计网络结构的时候，是直接用Alexnet的网络，然后连参数也是直接采用它的参数，作为初始的参数值，然后再fine-tuning训练。网络优化求解时采用随机梯度下降法，学习率大小为0.001； C、fine-tuning阶段 （图片数据库： PASCAL VOC） 我们接着采用 selective search 搜索出来的候选框 （PASCAL VOC 数据库中的图片） 继续对上面预训练的CNN模型进行fine-tuning训练。假设要检测的物体类别有N类，那么我们就需要把上面预训练阶段的CNN模型的最后一层给替换掉，替换成N+1个输出的神经元(加1，表示还有一个背景) (20 + 1bg = 21)，然后这一层直接采用参数随机初始化的方法，其它网络层的参数不变；接着就可以开始继续SGD训练了。开始的时候，SGD学习率选择0.001，在每次训练的时候，我们batch size大小选择128，其中32个事正样本、96个事负样本。 关于正负样本问题： 一张照片我们得到了2000个候选框。然而人工标注的数据一张图片中就只标注了正确的bounding box，我们搜索出来的2000个矩形框也不可能会出现一个与人工标注完全匹配的候选框。因此在CNN阶段我们需要用IOU为2000个bounding box打标签。如果用selective search挑选出来的候选框与物体的人工标注矩形框（PASCAL VOC的图片都有人工标注）的重叠区域IoU大于0.5，那么我们就把这个候选框标注成物体类别（正样本），否则我们就把它当做背景类别（负样本）。 （备注： 如果不针对特定任务进行fine-tuning，而是把CNN当做特征提取器，卷积层所学到的特征其实就是基础的共享特征提取层，就类似于SIFT算法一样，可以用于提取各种图片的特征，而f6、f7所学习到的特征是用于针对特定任务的特征。打个比方：对于人脸性别识别来说，一个CNN模型前面的卷积层所学习到的特征就类似于学习人脸共性特征，然后全连接层所学习的特征就是针对性别分类的特征了） 2. 疑惑点： CNN训练的时候，本来就是对bounding box的物体进行识别分类训练，在训练的时候最后一层softmax就是分类层。那么为什么作者闲着没事干要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练svm分类器？ 这个是因为svm训练和cnn训练过程的正负样本定义方式各有不同，导致最后采用CNN softmax输出比采用svm精度还低。事情是这样的，cnn在训练的时候，对训练数据做了比较宽松的标注，比如一个bounding box可能只包含物体的一部分，那么我也把它标注为正样本，用于训练cnn；采用这个方法的主要原因在于因为CNN容易过拟合，所以需要大量的训练数据，所以在CNN训练阶段我们是对Bounding box的位置限制条件限制的比较松(IOU只要大于0.5都被标注为正样本了)；然而svm训练的时候，因为svm适用于少样本训练，所以对于训练样本数据的IOU要求比较严格，我们只有当bounding box把整个物体都包含进去了，我们才把它标注为物体类别，然后训练svm，具体请看下文。 SVM训练、测试阶段 训练阶段： 这是一个二分类问题，我么假设我们要检测车辆。我们知道只有当bounding box把整量车都包含在内，那才叫正样本；如果bounding box 没有包含到车辆，那么我们就可以把它当做负样本。但问题是当我们的检测窗口只有部分包含物体，那该怎么定义正负样本呢？作者测试了IOU阈值各种方案数值0,0.1,0.2,0.3,0.4,0.5。最后通过训练发现，如果选择IOU阈值为0.3效果最好（选择为0精度下降了4个百分点，选择0.5精度下降了5个百分点）,即当重叠度小于0.3的时候，我们就把它标注为负样本。一旦CNN f7层特征被提取出来，那么我们将为每个物体类训练一个svm分类器。当我们用CNN提取2000个候选框，可以得到2000*4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096*N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，就可以得到结果了。 得到的特征输入到SVM进行分类看看这个feature vector所对应的region proposal是需要的物体还是无关的实物(background) 。 排序，canny边界检测之后就得到了我们需要的bounding-box。 再回顾总结一下：整个系统分为三个部分：1.产生不依赖与特定类别的region proposals，这些region proposals定义了一个整个检测器可以获得的候选目标2.一个大的卷积神经网络，对每个region产生一个固定长度的特征向量3.一系列特定类别的线性SVM分类器。 位置精修： 目标检测问题的衡量标准是重叠面积：许多看似准确的检测结果，往往因为候选框不够准确，重叠面积很小。故需要一个位置精修步骤。 回归器：对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。 输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。 训练样本：判定为本类的候选框中和真值重叠面积大于0.6的候选框。 测试阶段： 使用selective search的方法在测试图片上提取2000个region propasals ，将每个region proposals归一化到227x227，然后再CNN中正向传播，将最后一层得到的特征提取出来。然后对于每一个类别，使用为这一类训练的SVM分类器对提取的特征向量进行打分，得到测试图片中对于所有region proposals的对于这一类的分数，再使用贪心的非极大值抑制（NMS）去除相交的多余的框。再对这些框进行canny边缘检测，就可以得到bounding-box(then B-BoxRegression)。 （非极大值抑制（NMS）先计算出每一个bounding box的面积，然后根据score进行排序，把score最大的bounding box作为选定的框，计算其余bounding box与当前最大score与box的IoU，去除IoU大于设定的阈值的bounding box。然后重复上面的过程，直至候选bounding box为空，然后再将score小于一定阈值的选定框删除得到这一类的结果（然后继续进行下一个分类）。作者提到花费在region propasals和提取特征的时间是13s/张-GPU和53s/张-CPU，可以看出时间还是很长的，不能够达到及时性。 完。 本文主要整理自以下文章： RCNN学习笔记(0):rcnn简介 RCNN学习笔记(1):Rich feature hierarchies for accurate object detection and semantic segmentation RCNN学习笔记(2):Rich feature hierarchies for accurate object detection and semantic segmentation 《Rich feature hierarchies for Accurate Object Detection and Segmentation》 《Spatial 《Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》","link":"/2024/06/b493414e15d0.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note 机器学习（machine learning，ML）是一类强大的可以从经验中学习的技术。 通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。机器学习是用来解决任务内部关系过于复杂的情况,或者超过人类意识理解的东西,例如:图像识别 ^231222a7 通常，即使我们不知道怎样明确地告诉计算机如何从输入映射到输出，大脑仍然能够自己执行认知功能。 换句话说，即使我们不知道如何编写计算机程序来识别“Alexa”这个词，大脑自己也能够识别它。 有了这一能力，我们就可以收集一个包含大量音频样本的数据集（dataset），并对包含和不包含唤醒词的样本进行标记。 利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。 相反，我们只需要定义一个灵活的程序算法，其输出由许多参数（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数通过某种性能度量方式来达到完成任务的最佳性能。输入与输出的关系是模糊的通过多参数灵活映射输入与输出 ^e2164f0a 那么到底什么是参数呢？ 参数可以被看作旋钮，旋钮的转动可以调整程序的行为。 任一调整参数后的程序被称为模型（model）。 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为学习算法（learning algorithm）。 ^bc5cc8ed 但如果模型所有的按钮（模型参数）都被随机设置，就不太可能识别出“Alexa”“Hey Siri”或任何其他单词。 在机器学习中，学习（learning）是一个训练模型的过程。 通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。 ^ef363967 训练过程通常包含如下步骤： 从一个随机初始化参数的模型开始，这个模型基本没有“智能”； 获取一些数据样本（例如，音频片段以及对应的是或否标签）； 调整参数，使模型在这些样本中表现得更好； 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。 ^6403cc68 我们没有编写唤醒词识别器，而是编写了一个“学习”程序。 如果我们用一个巨大的带标签的数据集，它很可能可以“学习”识别唤醒词。机器学习的程序是一个学习程序 ^a6d8fb02 当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数（dimensionality）。 ^d95af809 固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本。 然而，并不是所有的数据都可以用“固定长度”的向量表示。 以图像数据为例，如果它们全部来自标准显微镜设备，那么“固定长度”是可取的； 但是如果图像数据来自互联网，它们很难具有相同的分辨率或形状。 这时，将图像裁剪成标准尺寸是一种方法，但这种办法很局限，有丢失信息的风险。 此外，文本数据更不符合“固定长度”的要求。 比如，对于亚马逊等电子商务网站上的客户评论，有些文本数据很简短（比如“好极了”），有些则长篇大论。 与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。 ^8384344e 监督学习的学习过程一般可以分为三大步骤： 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集； 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”； 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。 整个监督学习过程如 图1.3.1 所示。 ^5ee8c4d7 当人们在市场上寻找新房子时，可能需要估计一栋房子的公平市场价值。 为什么这个任务可以归类为回归问题呢？本质上是输出决定的。 销售价格（即标签）是一个数值。 当标签取任意数值时，我们称之为回归问题，此时的目标是生成一个模型，使它的预测非常接近实际标签值。回归到一个值或者一个formula ^c0450690 生活中的许多问题都可归类为回归问题。 比如，预测用户对一部电影的评分可以被归类为一个回归问题。 这里有一个小插曲：在2009年，如果有人设计了一个很棒的算法来预测电影评分，那可能会赢得100万美元的奈飞奖。 再比如，预测病人在医院的住院时间也是一个回归问题。 总而言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。比如： 这个手术需要多少小时； 在未来6小时，这个镇会有多少降雨量。 即使你以前从未使用过机器学习，可能在不经意间，已经解决了一些回归问题。 例如，你让人修理了排水管，承包商花了3小时清除污水管道中的污物，然后他寄给你一张350美元的账单。 而你的朋友雇了同一个承包商2小时，他收到了250美元的账单。 如果有人请你估算清理污物的费用，你可以假设承包商收取一些基本费用，然后按小时收费。 如果这些假设成立，那么给出这两个数据样本，你就已经可以确定承包商的定价结构：50美元上门服务费，另外每小时100美元。 在不经意间，你就已经理解并应用了线性回归算法。 ^3277e01e Content1. 引言¶时至今日，人们常用的计算机程序几乎都是软件开发人员从零编写的。 比如，现在开发人员要编写一个程序来管理网上商城。 经过思考，开发人员可能提出如下一个解决方案： 首先，用户通过Web浏览器（或移动应用程序）与应用程序进行交互； 紧接着，应用程序与数据库引擎进行交互，以保存交易历史记录并跟踪每个用户的动态； 其中，这个应用程序的核心——“业务逻辑”，详细说明了应用程序在各种情况下进行的操作。 为了完善业务逻辑，开发人员必须细致地考虑应用程序所有可能遇到的边界情况，并为这些边界情况设计合适的规则。 当买家单击将商品添加到购物车时，应用程序会向购物车数据库表中添加一个条目，将该用户ID与商品ID关联起来。 虽然一次编写出完美应用程序的可能性微乎其微，但在大多数情况下，开发人员可以从上述的业务逻辑出发，编写出符合业务逻辑的应用程序，并不断测试直到满足用户的需求。 根据业务逻辑设计自动化系统，驱动正常运行的产品和系统，是一个人类认知上的非凡壮举。 幸运的是，对日益壮大的机器学习科学家群体来说，实现很多任务的自动化并不再屈从于人类所能考虑到的逻辑。 想象一下，假如开发人员要试图解决以下问题之一： 编写一个应用程序，接受地理信息、卫星图像和一些历史天气信息，并预测明天的天气； 编写一个应用程序，接受自然文本表示的问题，并正确回答该问题； 编写一个应用程序，接受一张图像，识别出该图像所包含的人，并在每个人周围绘制轮廓； 编写一个应用程序，向用户推荐他们可能喜欢，但在自然浏览过程中不太可能遇到的产品。 在这些情况下，即使是顶级程序员也无法提出完美的解决方案， 原因可能各不相同。有时任务可能遵循一种随着时间推移而变化的模式，我们需要程序来自动调整。 有时任务内的关系可能太复杂（比如像素和抽象类别之间的关系），需要数千或数百万次的计算。 即使人类的眼睛能毫不费力地完成这些难以提出完美解决方案的任务，这其中的计算也超出了人类意识理解范畴。==机器学习====（machine learning，ML）是一类强大的可以从经验中学习的技术。通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。==相反，对于刚刚所说的电子商务平台，如果它一直执行相同的业务逻辑，无论积累多少经验，都不会自动提高，除非开发人员认识到问题并更新软件。 本书将带读者开启机器学习之旅，并特别关注深度学习（deep learning，DL）的基础知识。 深度学习是一套强大的技术，它可以推动计算机视觉、自然语言处理、医疗保健和基因组学等不同领域的创新。 1.1. 日常生活中的机器学习¶机器学习应用在日常生活中的方方面面。 现在，假设本书的作者们一起驱车去咖啡店。 阿斯顿拿起一部iPhone，对它说道：“Hey Siri！”手机的语音识别系统就被唤醒了。 接着，李沐对Siri说道：“去星巴克咖啡店。”语音识别系统就自动触发语音转文字功能，并启动地图应用程序， 地图应用程序在启动后筛选了若干条路线，每条路线都显示了预计的通行时间…… 由此可见，机器学习渗透在生活中的方方面面，在短短几秒钟的时间里，人们与智能手机的日常互动就可以涉及几种机器学习模型。 现在，假如需要我们编写程序来响应一个“唤醒词”（比如“Alexa”“小爱同学”和“Hey Siri”）。 我们试着用一台计算机和一个代码编辑器编写代码，如图1.1.1中所示。 问题看似很难解决：麦克风每秒钟将收集大约44000个样本，每个样本都是声波振幅的测量值。而该测量值与唤醒词难以直接关联。那又该如何编写程序，令其输入麦克风采集到的原始音频片段,输出{是,否}（表示该片段是否包含唤醒词）的可靠预测呢？我们对编写这个程序毫无头绪，这就是需要机器学习的原因。 图1.1.1 识别唤醒词¶ ==通常，即使我们不知道怎样明确地告诉计算机如何从输入映射到输出，大脑仍然能够自己执行认知功能。换句话说，即使我们不知道如何编写计算机程序来识别“Alexa”这个词，大脑自己也能够识别它。有了这一能力，我们就可以收集一个包含大量音频样本的====数据集====（dataset），并对包含和不包含唤醒词的样本进行标记。利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。相反，我们只需要定义一个灵活的程序算法，其输出由许多====参数====（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数通过某种性能度量方式来达到完成任务的最佳性能。== ==那么到底什么是参数呢？参数可以被看作旋钮，旋钮的转动可以调整程序的行为。任一调整参数后的程序被称为====模型====（model）。通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。使用数据集来选择参数的元程序被称为====学习算法====（learning algorithm）。== 在开始用机器学习算法解决问题之前，我们必须精确地定义问题，确定输入（input）和输出（output）的性质，并选择合适的模型族。 在本例中，模型接收一段音频作为输入，然后在是或否中生成一个选择作为输出。 如果一切顺利，经过一番训练，模型对于“片段是否包含唤醒词”的预测通常是正确的。 现在模型每次听到“Alexa”这个词时都会发出“是”的声音。 由于这里的唤醒词是任意选择的自然语言，因此我们可能需要一个足够丰富的模型族，使模型多元化。 比如，模型族的另一个模型只在听到“Hey Siri”这个词时发出“是”。 理想情况下，同一个模型族应该适合于“Alexa”识别和“Hey Siri”识别，因为从直觉上看，它们似乎是相似的任务。 然而，如果我们想处理完全不同的输入或输出，比如：从图像映射到字幕，或从英语映射到中文，可能需要一个完全不同的模型族。 ==但如果模型所有的按钮（模型参数）都被随机设置，就不太可能识别出“Alexa”“HeySiri”或任何其他单词。在机器学习中，====学习====（learning）是一个训练模型的过程。通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。==换句话说，我们用数据训练（train）模型。 如图1.1.2所示，==训练过程通常包含如下步骤：== ==从一个随机初始化参数的模型开始，这个模型基本没有“智能”；== ==获取一些数据样本（例如，音频片段以及对应的是或否标签）；== ==调整参数，使模型在这些样本中表现得更好；== ==重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。== 图1.1.2 一个典型的训练过程¶ 总而言之，==我们没有编写唤醒词识别器，而是编写了一个“学习”程序。如果我们用一个巨大的带标签的数据集，它很可能可以“学习”识别唤醒词。==这种“通过用数据集来确定程序行为”的方法可以被看作用数据编程（programming with data）。 比如，我们可以通过向机器学习系统，提供许多猫和狗的图片来设计一个“猫图检测器”。 检测器最终可以学会：如果输入是猫的图片就输出一个非常大的正数，如果输入是狗的图片就会输出一个非常小的负数。 如果检测器不确定输入的图片中是猫还是狗，它会输出接近于零的数…… 这个例子仅仅是机器学习常见应用的冰山一角， 而深度学习是机器学习的一个主要分支，本节稍后的内容将对其进行更详细的解析。 1.2. 机器学习中的关键组件¶首先介绍一些核心组件。无论什么类型的机器学习问题，都会遇到这些组件： 可以用来学习的数据（data）； 如何转换数据的模型（model）； 一个目标函数（objective function），用来量化模型的有效性； 调整模型参数以优化目标函数的算法（algorithm）。 1.2.1. 数据¶毋庸置疑，如果没有数据，那么数据科学毫无用武之地。 每个数据集由一个个样本（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 样本有时也叫做数据点（data point）或者数据实例（data instance），通常每个样本由一组称为特征（features，或协变量（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为标签（label，或目标（target））。 当处理图像数据时，每一张单独的照片即为一个样本，它的特征由每个像素数值的有序列表表示。 比如，200×200彩色照片由200×200×3\\=120000个数值组成，其中的“3”对应于每个空间位置的红、绿、蓝通道的强度。 再比如，对于一组医疗数据，给定一组标准的特征（如年龄、生命体征和诊断），此数据可以用来尝试预测患者是否会存活。 ==当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的====维数====（dimensionality）。==固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本。 ==然而，并不是所有的数据都可以用“固定长度”的向量表示。以图像数据为例，如果它们全部来自标准显微镜设备，那么“固定长度”是可取的；但是如果图像数据来自互联网，它们很难具有相同的分辨率或形状。这时，将图像裁剪成标准尺寸是一种方法，但这种办法很局限，有丢失信息的风险。此外，文本数据更不符合“固定长度”的要求。比如，对于亚马逊等电子商务网站上的客户评论，有些文本数据很简短（比如“好极了”），有些则长篇大论。与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。== 一般来说，拥有越多数据的时候，工作就越容易。 更多的数据可以被用来训练出更强大的模型，从而减少对预先设想假设的依赖。 数据集的由小变大为现代深度学习的成功奠定基础。 在没有大数据集的情况下，许多令人兴奋的深度学习模型黯然失色。 就算一些深度学习模型在小数据集上能够工作，但其效能并不比传统方法高。 请注意，仅仅拥有海量的数据是不够的，我们还需要正确的数据。 如果数据中充满了错误，或者如果数据的特征不能预测任务目标，那么模型很可能无效。 有一句古语很好地反映了这个现象：“输入的是垃圾，输出的也是垃圾。”（“Garbage in, garbage out.”） 此外，糟糕的预测性能甚至会加倍放大事态的严重性。 在一些敏感应用中，如预测性监管、简历筛选和用于贷款的风险模型，我们必须特别警惕垃圾数据带来的后果。 一种常见的问题来自不均衡的数据集，比如在一个有关医疗的训练数据集中，某些人群没有样本表示。 想象一下，假设我们想要训练一个皮肤癌识别模型，但它（在训练数据集中）从未“见过”黑色皮肤的人群，这个模型就会顿时束手无策。 再比如，如果用“过去的招聘决策数据”来训练一个筛选简历的模型，那么机器学习模型可能会无意中捕捉到历史残留的不公正，并将其自动化。 然而，这一切都可能在不知情的情况下发生。 因此，当数据不具有充分代表性，甚至包含了一些社会偏见时，模型就很有可能有偏见。 1.2.2. 模型¶大多数机器学习会涉及到数据的转换。 比如一个“摄取照片并预测笑脸”的系统。再比如通过摄取到的一组传感器读数预测读数的正常与异常程度。 虽然简单的模型能够解决如上简单的问题，但本书中关注的问题超出了经典方法的极限。 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。 在讨论深度模型的过程中，本书也将提及一些传统方法。 1.2.3. 目标函数¶前面的内容将机器学习介绍为“从经验中学习”。 这里所说的“学习”，是指自主提高模型完成某些任务的效能。 但是，什么才算真正的提高呢？ 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。 但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点。 这两个函数本质上是相同的，只是翻转一下符号。 当任务在试图预测数值时，最常见的损失函数是平方误差（squared error），即预测值与实际值之差的平方。 当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符的样本比例。 有些目标函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。 在这些情况下，通常会优化替代目标。 通常，损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为训练数据集（training dataset，或称为训练集（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为测试数据集（test dataset，或称为测试集（test set））。 综上所述，可用数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。 然后我们观察模型在这两部分数据集的性能。 “一个模型在训练数据集上的性能”可以被想象成“一个学生在模拟考试中的分数”。 这个分数用来为一些真正的期末考试做参考，即使成绩令人鼓舞，也不能保证期末考试成功。 换言之，测试性能可能会显著偏离训练性能。 当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为过拟合（overfitting）的。 就像在现实生活中，尽管模拟考试考得很好，真正的考试不一定百发百中。 1.2.4. 优化算法¶当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。 深度学习中，大多流行的优化算法通常基于一种基本方法–梯度下降（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。 1.3. 各种机器学习问题¶在机器学习的广泛应用中，唤醒词问题只是冰山一角。 前面唤醒词识别的例子，只是机器学习可以解决的众多问题中的一个。 下面将列出一些常见的机器学习问题和应用，为之后本书的讨论做铺垫。 接下来会经常引用前面提到的概念，如数据、模型和优化算法。 1.3.1. 监督学习¶监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个样本（example）。 有时，即使标签是未知的，样本也可以指代输入特征。 我们的目标是生成一个模型，能够将任何输入特征映射到标签（即预测）。 举一个具体的例子： 假设我们需要预测患者的心脏病是否会发作，那么观察结果“心脏病发作”或“心脏病没有发作”将是样本的标签。 输入特征可能是生命体征，如心率、舒张压和收缩压等。 监督学习之所以能发挥作用，是因为在训练参数时，我们为模型提供了一个数据集，其中每个样本都有真实的标签。 用概率论术语来说，我们希望预测“估计给定输入特征的标签”的条件概率。 虽然监督学习只是几大类机器学习问题之一，但是在工业中，大部分机器学习的成功应用都使用了监督学习。 这是因为在一定程度上，许多重要的任务可以清晰地描述为，在给定一组特定的可用数据的情况下，估计未知事物的概率。比如： 根据计算机断层扫描（Computed Tomography，CT）肿瘤图像，预测是否为癌症； 给出一个英语句子，预测正确的法语翻译； 根据本月的财务报告数据，预测下个月股票的价格； ==监督学习的学习过程一般可以分为三大步骤：== ==从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集；== ==选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；== ==将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。== ==整个监督学习过程如== 图1.3.1 ==所示。== 图1.3.1 监督学习¶ 综上所述，即使使用简单的描述给定输入特征的预测标签，监督学习也可以采取多种形式的模型，并且需要大量不同的建模决策，这取决于输入和输出的类型、大小和数量。 例如，我们使用不同的模型来处理“任意长度的序列”或“固定长度的序列”。 1.3.1.1. 回归¶回归（regression）是最简单的监督学习任务之一。 假设有一组房屋销售数据表格，其中每行对应一个房子，每列对应一个相关的属性，例如房屋的面积、卧室的数量、浴室的数量以及到镇中心的步行距离，等等。 每一行的属性构成了一个房子样本的特征向量。 如果一个人住在纽约或旧金山，而且他不是亚马逊、谷歌、微软或Facebook的首席执行官，那么他家的特征向量（房屋面积，卧室数量，浴室数量，步行距离）可能类似于：[600,1,1,60]。 如果一个人住在匹兹堡，这个特征向量可能更接近[3000,4,3,10]……==当人们在市场上寻找新房子时，可能需要估计一栋房子的公平市场价值。为什么这个任务可以归类为回归问题呢？本质上是输出决定的。销售价格（即标签）是一个数值。当标签取任意数值时，我们称之为====回归====问题，此时的目标是生成一个模型，使它的预测非常接近实际标签值。== ==生活中的许多问题都可归类为回归问题。比如，预测用户对一部电影的评分可以被归类为一个回归问题。这里有一个小插曲：在2009年，如果有人设计了一个很棒的算法来预测电影评分，那可能会赢得====100万美元的奈飞奖====。再比如，预测病人在医院的住院时间也是一个回归问题。总而言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。比如：== ==这个手术需要多少小时；== ==在未来6小时，这个镇会有多少降雨量。== ==即使你以前从未使用过机器学习，可能在不经意间，已经解决了一些回归问题。例如，你让人修理了排水管，承包商花了3小时清除污水管道中的污物，然后他寄给你一张350美元的账单。而你的朋友雇了同一个承包商2小时，他收到了250美元的账单。如果有人请你估算清理污物的费用，你可以假设承包商收取一些基本费用，然后按小时收费。如果这些假设成立，那么给出这两个数据样本，你就已经可以确定承包商的定价结构：50美元上门服务费，另外每小时100美元。在不经意间，你就已经理解并应用了线性回归算法。== 然而，以上假设有时并不可取。 例如，一些差异是由于两个特征之外的几个因素造成的。 在这些情况下，我们将尝试学习最小化“预测值和实际标签值的差异”的模型。 本书大部分章节将关注平方误差损失函数的最小化。 1.3.1.2. 分类¶虽然回归模型可以很好地解决“有多少”的问题，但是很多问题并非如此。 例如，一家银行希望在其移动应用程序中添加支票扫描功能。 具体地说，这款应用程序能够自动理解从图像中看到的文本，并将手写字符映射到对应的已知字符之上。 这种“哪一个”的问题叫做分类（classification）问题。分类问题希望模型能够预测样本属于哪个类别（category，正式称为类（class））。 例如，手写数字可能有10类，标签被设置为数字0～9。 最简单的分类问题是只有两类，这被称之为二项分类（binomial classification）。 例如，数据集可能由动物图像组成，标签可能是{猫,狗}两类。 回归是训练一个回归函数来输出一个数值； 分类是训练一个分类器来输出预测的类别。 然而模型怎么判断得出这种“是”或“不是”的硬分类预测呢？ 我们可以试着用概率语言来理解模型。 给定一个样本特征，模型为每个可能的类分配一个概率。 比如，之前的猫狗分类例子中，分类器可能会输出图像是猫的概率为0.9。 0.9这个数字表达什么意思呢？ 可以这样理解：分类器90%确定图像描绘的是一只猫。 预测类别的概率的大小传达了一种模型的不确定性，本书后面章节将讨论其他运用不确定性概念的算法。 当有两个以上的类别时，我们把这个问题称为多项分类（multiclass classification）问题。 常见的例子包括手写字符识别{0,1,2,…9,a,b,c,…}。 与解决回归问题不同，分类问题的常见损失函数被称为交叉熵（cross-entropy），本书3.4节 将详细阐述。 请注意，最常见的类别不一定是最终用于决策的类别。 举个例子，假设后院有一个如 图1.3.2 所示的蘑菇。 图1.3.2 死帽蕈——不能吃！！¶ 现在，我们想要训练一个毒蘑菇检测分类器，根据照片预测蘑菇是否有毒。 假设这个分类器输出 图1.3.2 包含死帽蕈的概率是0.2。 换句话说，分类器80%确定图中的蘑菇不是死帽蕈。 尽管如此，我们也不会吃它，因为不值得冒20%的死亡风险。 换句话说，不确定风险的影响远远大于收益。 因此，我们需要将“预期风险”作为损失函数，即需要将结果的概率乘以与之相关的收益（或伤害）。 在这种情况下，食用蘑菇造成的损失为0.2×∞+0.8×0\\=∞，而丢弃蘑菇的损失为0.2×0+0.8×1\\=0.8。 事实上，谨慎是有道理的，图1.3.2中的蘑菇实际上是一个死帽蕈。 分类可能变得比二项分类、多项分类复杂得多。 例如，有一些分类任务的变体可以用于寻找层次结构，层次结构假定在许多类之间存在某种关系。 因此，并不是所有的错误都是均等的。 人们宁愿错误地分入一个相关的类别，也不愿错误地分入一个遥远的类别，这通常被称为层次分类(hierarchical classification)。 早期的一个例子是卡尔·林奈，他对动物进行了层次分类。 在动物分类的应用中，把一只狮子狗误认为雪纳瑞可能不会太糟糕。 但如果模型将狮子狗与恐龙混淆，就滑稽至极了。 层次结构相关性可能取决于模型的使用者计划如何使用模型。 例如，响尾蛇和乌梢蛇血缘上可能很接近，但如果把响尾蛇误认为是乌梢蛇可能会是致命的。 因为响尾蛇是有毒的，而乌梢蛇是无毒的。 1.3.1.3. 标记问题¶有些分类问题很适合于二项分类或多项分类。 例如，我们可以训练一个普通的二项分类器来区分猫和狗。 运用最前沿的计算机视觉的算法，这个模型可以很轻松地被训练。 尽管如此，无论模型有多精确，当分类器遇到新的动物时可能会束手无策。 比如图1.3.3所示的这张“不来梅的城市音乐家”的图像 （这是一个流行的德国童话故事），图中有一只猫、一只公鸡、一只狗、一头驴，背景是一些树。 取决于我们最终想用模型做什么，将其视为二项分类问题可能没有多大意义。 取而代之，我们可能想让模型描绘输入图像的内容，一只猫、一只公鸡、一只狗，还有一头驴。 图1.3.3 一只猫、一只公鸡、一只狗、一头驴¶ 学习预测不相互排斥的类别的问题称为多标签分类（multi-label classification）。 举个例子，人们在技术博客上贴的标签，比如“机器学习”“技术”“小工具”“编程语言”“Linux”“云计算”“AWS”。 一篇典型的文章可能会用5～10个标签，因为这些概念是相互关联的。 关于“云计算”的帖子可能会提到“AWS”，而关于“机器学习”的帖子也可能涉及“编程语言”。 此外，在处理生物医学文献时，我们也会遇到这类问题。 正确地标记文献很重要，有利于研究人员对文献进行详尽的审查。 在美国国家医学图书馆（The United States National Library of Medicine），一些专业的注释员会检查每一篇在PubMed中被索引的文章，以便将其与Mesh中的相关术语相关联（Mesh是一个大约有28000个标签的集合）。 这是一个十分耗时的过程，注释器通常在归档和标记之间有一年的延迟。 这里，机器学习算法可以提供临时标签，直到每一篇文章都有严格的人工审核。 事实上，近几年来，BioASQ组织已经举办比赛来完成这项工作。 1.3.1.4. 搜索¶有时，我们不仅仅希望输出一个类别或一个实值。 在信息检索领域，我们希望对一组项目进行排序。 以网络搜索为例，目标不是简单的“查询（query）-网页（page）”分类，而是在海量搜索结果中找到用户最需要的那部分。 搜索结果的排序也十分重要，学习算法需要输出有序的元素子集。 换句话说，如果要求我们输出字母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。 即使结果集是相同的，集内的顺序有时却很重要。 该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。PageRank，谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子，但它的奇特之处在于它不依赖于实际的查询。 在这里，他们依靠一个简单的相关性过滤来识别一组相关条目，然后根据PageRank对包含查询条件的结果进行排序。 如今，搜索引擎使用机器学习和用户行为模型来获取网页相关性得分，很多学术会议也致力于这一主题。 1.3.1.5. 推荐系统¶另一类与搜索和排名相关的问题是推荐系统（recommender system），它的目标是向特定用户进行“个性化”推荐。 例如，对于电影推荐，科幻迷和喜剧爱好者的推荐结果页面可能会有很大不同。 类似的应用也会出现在零售产品、音乐和新闻推荐等等。 在某些应用中，客户会提供明确反馈，表达他们对特定产品的喜爱程度。 例如，亚马逊上的产品评级和评论。 在其他一些情况下，客户会提供隐性反馈。 例如，某用户跳过播放列表中的某些歌曲，这可能说明这些歌曲对此用户不大合适。 总的来说，推荐系统会为“给定用户和物品”的匹配性打分，这个“分数”可能是估计的评级或购买的概率。 由此，对于任何给定的用户，推荐系统都可以检索得分最高的对象集，然后将其推荐给用户。以上只是简单的算法，而工业生产的推荐系统要先进得多，它会将详细的用户活动和项目特征考虑在内。 推荐系统算法经过调整，可以捕捉一个人的偏好。 比如，图1.3.4是亚马逊基于个性化算法推荐的深度学习书籍，成功地捕捉了作者的喜好。 图1.3.4 亚马逊推荐的深度学习书籍¶ 尽管推荐系统具有巨大的应用价值，但单纯用它作为预测模型仍存在一些缺陷。 首先，我们的数据只包含“审查后的反馈”：用户更倾向于给他们感觉强烈的事物打分。 例如，在五分制电影评分中，会有许多五星级和一星级评分，但三星级却明显很少。 此外，推荐系统有可能形成反馈循环：推荐系统首先会优先推送一个购买量较大（可能被认为更好）的商品，然而目前用户的购买习惯往往是遵循推荐算法，但学习算法并不总是考虑到这一细节，进而更频繁地被推荐。 综上所述，关于如何处理审查、激励和反馈循环的许多问题，都是重要的开放性研究问题。 1.3.1.6. 序列学习¶以上大多数问题都具有固定大小的输入和产生固定大小的输出。 例如，在预测房价的问题中，我们考虑从一组固定的特征：房屋面积、卧室数量、浴室数量、步行到市中心的时间； 图像分类问题中，输入为固定尺寸的图像，输出则为固定数量（有关每一个类别）的预测概率； 在这些情况下，模型只会将输入作为生成输出的“原料”，而不会“记住”输入的具体内容。 如果输入的样本之间没有任何关系，以上模型可能完美无缺。 但是如果输入是连续的，模型可能就需要拥有“记忆”功能。 比如，我们该如何处理视频片段呢？ 在这种情况下，每个视频片段可能由不同数量的帧组成。 通过前一帧的图像，我们可能对后一帧中发生的事情更有把握。 语言也是如此，机器翻译的输入和输出都为文字序列。 再比如，在医学上序列输入和输出就更为重要。 设想一下，假设一个模型被用来监控重症监护病人，如果他们在未来24小时内死亡的风险超过某个阈值，这个模型就会发出警报。 我们绝不希望抛弃过去每小时有关病人病史的所有信息，而仅根据最近的测量结果做出预测。 这些问题是序列学习的实例，是机器学习最令人兴奋的应用之一。 序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。 具体来说，输入和输出都是可变长度的序列，例如机器翻译和从语音中转录文本。 虽然不可能考虑所有类型的序列转换，但以下特殊情况值得一提。 标记和解析。这涉及到用属性注释文本序列。 换句话说，输入和输出的数量基本上是相同的。 例如，我们可能想知道动词和主语在哪里，或者可能想知道哪些单词是命名实体。 通常，目标是基于结构和语法假设对文本进行分解和注释，以获得一些注释。 这听起来比实际情况要复杂得多。 下面是一个非常简单的示例，它使用“标记”来注释一个句子，该标记指示哪些单词引用命名实体。 标记为“Ent”，是实体（entity）的简写。 Tom has dinner in Washington with SallyEnt - - - Ent - Ent 自动语音识别。在语音识别中，输入序列是说话人的录音（如图1.3.5 所示），输出序列是说话人所说内容的文本记录。 它的挑战在于，与文本相比，音频帧多得多（声音通常以8kHz或16kHz采样）。 也就是说，音频和文本之间没有1:1的对应关系，因为数千个样本可能对应于一个单独的单词。 这也是“序列到序列”的学习问题，其中输出比输入短得多。 图1.3.5 -D-e-e-p- L-ea-r-ni-ng- 在录音中。¶ 文本到语音。这与自动语音识别相反。 换句话说，输入是文本，输出是音频文件。 在这种情况下，输出比输入长得多。 虽然人类很容易识判断发音别扭的音频文件，但这对计算机来说并不是那么简单。 机器翻译。 在语音识别中，输入和输出的出现顺序基本相同。 而在机器翻译中，颠倒输入和输出的顺序非常重要。 换句话说，虽然我们仍将一个序列转换成另一个序列，但是输入和输出的数量以及相应序列的顺序大都不会相同。 比如下面这个例子，“错误的对齐”反应了德国人喜欢把动词放在句尾的特殊倾向。 德语: Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?英语: Did you already check out this excellent tutorial?错误的对齐: Did you yourself already this excellent tutorial looked-at? 其他学习任务也有序列学习的应用。 例如，确定“用户阅读网页的顺序”是二维布局分析问题。 再比如，对话问题对序列的学习更为复杂：确定下一轮对话，需要考虑对话历史状态以及现实世界的知识…… 如上这些都是热门的序列学习研究领域。 1.3.2. 无监督学习¶到目前为止，所有的例子都与监督学习有关，即需要向模型提供巨大数据集：每个样本包含特征和相应标签值。 打趣一下，“监督学习”模型像一个打工仔，有一份极其专业的工作和一位极其平庸的老板。 老板站在身后，准确地告诉模型在每种情况下应该做什么，直到模型学会从情况到行动的映射。 取悦这位老板很容易，只需尽快识别出模式并模仿他们的行为即可。 相反，如果工作没有十分具体的目标，就需要“自发”地去学习了。 比如，老板可能会给我们一大堆数据，然后要求用它做一些数据科学研究，却没有对结果有要求。 这类数据中不含有“目标”的机器学习问题通常被为无监督学习（unsupervised learning）， 本书后面的章节将讨论无监督学习技术。 那么无监督学习可以回答什么样的问题呢？来看看下面的例子。 聚类（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？ 主成分分析（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?这可以用来描述实体及其关系，例如“罗马”− “意大利” + “法国” \\= “巴黎”。 因果关系（causality）和概率图模型（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？ 生成对抗性网络（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。 1.3.3. 与环境互动¶有人一直心存疑虑：机器学习的输入（数据）来自哪里？机器学习的输出又将去往何方？ 到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为离线学习（offline learning）。 对于监督学习，从环境中收集数据的过程类似于图1.3.6。 图1.3.6 从环境中为监督学习收集数据。¶ 这种简单的离线学习有它的魅力。 好的一面是，我们可以孤立地进行模式识别，而不必分心于其他问题。 但缺点是，解决的问题相当有限。 这时我们可能会期望人工智能不仅能够做出预测，而且能够与真实环境互动。 与预测不同，“与真实环境互动”实际上会影响环境。 这里的人工智能是“智能代理”，而不仅是“预测模型”。 因此，我们必须考虑到它的行为可能会影响未来的观察结果。 考虑“与真实环境互动”将打开一整套新的建模问题。以下只是几个例子。 环境还记得我们以前做过什么吗？ 环境是否有助于我们建模？例如，用户将文本读入语音识别器。 环境是否想要打败模型？例如，一个对抗性的设置，如垃圾邮件过滤或玩游戏？ 环境是否重要？ 环境是否变化？例如，未来的数据是否总是与过去相似，还是随着时间的推移会发生变化？是自然变化还是响应我们的自动化工具而发生变化？ 当训练和测试数据不同时，最后一个问题提出了分布偏移（distribution shift）的问题。 接下来的内容将简要描述强化学习问题，这是一类明确考虑与环境交互的问题。 1.3.4. 强化学习¶如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于强化学习（reinforcement learning）。 这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。深度强化学习（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。 突破性的深度Q网络（Q-network）在雅达利游戏中仅使用视觉输入就击败了人类， 以及 AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。 在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。 在每个特定时间点，智能体从环境接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得奖励（reward）。 此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。 强化学习的过程在 图1.3.7 中进行了说明。 请注意，强化学习的目标是产生一个好的策略（policy）。 强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。 图1.3.7 强化学习和环境之间的相互作用¶ 强化学习框架的通用性十分强大。 例如，我们可以将任何监督学习问题转化为强化学习问题。 假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。 然后，我们可以创建一个环境，该环境给予智能体的奖励。 这个奖励与原始监督学习问题的损失函数是一致的。 当然，强化学习还可以解决许多监督学习无法解决的问题。 例如，在监督学习中，我们总是希望输入与正确的标签相关联。 但在强化学习中，我们并不假设环境告诉智能体每个观测的最优动作。 一般来说，智能体只是得到一些奖励。 此外，环境甚至可能不会告诉是哪些行为导致了奖励。 以强化学习在国际象棋的应用为例。 唯一真正的奖励信号出现在游戏结束时：当智能体获胜时，智能体可以得到奖励1；当智能体失败时，智能体将得到奖励-1。 因此，强化学习者必须处理学分分配（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。 就像一个员工升职一样，这次升职很可能反映了前一年的大量的行动。 要想在未来获得更多的晋升，就需要弄清楚这一过程中哪些行为导致了晋升。 强化学习可能还必须处理部分可观测性问题。 也就是说，当前的观察结果可能无法阐述有关当前状态的所有信息。 比方说，一个清洁机器人发现自己被困在一个许多相同的壁橱的房子里。 推断机器人的精确位置（从而推断其状态），需要在进入壁橱之前考虑它之前的观察结果。 最后，在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过的。 强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）。 一般的强化学习问题是一个非常普遍的问题。 智能体的动作会影响后续的观察，而奖励只与所选的动作相对应。 环境可以是完整观察到的，也可以是部分观察到的,解释所有这些复杂性可能会对研究人员要求太高。 此外，并不是每个实际问题都表现出所有这些复杂性。 因此，学者们研究了一些特殊情况下的强化学习问题。 当环境可被完全观察到时，强化学习问题被称为马尔可夫决策过程（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为上下文赌博机（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的多臂赌博机（multi-armed bandit problem）。 1.4. 起源¶为了解决各种各样的机器学习问题，深度学习提供了强大的工具。 虽然许多深度学习方法都是最近才有重大突破，但使用数据和神经网络编程的核心思想已经研究了几个世纪。 事实上，人类长期以来就有分析数据和预测未来结果的愿望，而自然科学大部分都植根于此。 例如，伯努利分布是以雅各布•伯努利（1654-1705）命名的。 而高斯分布是由卡尔•弗里德里希•高斯（1777-1855）发现的， 他发明了最小均方算法，至今仍用于解决从保险计算到医疗诊断的许多问题。 这些工具算法催生了自然科学中的一种实验方法——例如，电阻中电流和电压的欧姆定律可以用线性模型完美地描述。 即使在中世纪，数学家对估计（estimation）也有敏锐的直觉。 例如，雅各布·克贝尔 (1460–1533)的几何学书籍举例说明，通过平均16名成年男性的脚的长度，可以得出一英尺的长度。 图1.4.1 估计一英尺的长度¶ 图1.4.1 说明了这个估计器是如何工作的。 16名成年男子被要求脚连脚排成一行。 然后将它们的总长度除以16，得到现在等于1英尺的估计值。 这个算法后来被改进以处理畸形的脚——将拥有最短和最长脚的两个人送走，对其余的人取平均值。 这是最早的修剪均值估计的例子之一。 随着数据的收集和可获得性，统计数据真正实现了腾飞。罗纳德·费舍尔（1890-1962）对统计理论和在遗传学中的应用做出了重大贡献。 他的许多算法（如线性判别分析）和公式（如费舍尔信息矩阵）至今仍被频繁使用。 甚至，费舍尔在1936年发布的鸢尾花卉数据集，有时仍然被用来解读机器学习算法。 他也是优生学的倡导者，这提醒我们：数据科学在道德上存疑的使用，与其在工业和自然科学中的生产性使用一样，有着悠远而持久的历史。 机器学习的第二个影响来自克劳德·香农(1916–2001)的信息论和艾伦·图灵（1912-1954）的计算理论。 图灵在他著名的论文《计算机器与智能》 (Turing, 1950)中提出了“机器能思考吗？”的问题。 在他所描述的图灵测试中，如果人类评估者很难根据文本互动区分机器和人类的回答，那么机器就可以被认为是“智能的”。 另一个影响可以在神经科学和心理学中找到。 其中，最古老的算法之一是唐纳德·赫布 (1904–1985)开创性的著作《行为的组织》(Hebb and Hebb, 1949) 。 他提出神经元通过积极强化学习，是Rosenblatt感知器学习算法的原型，被称为“赫布学习”。 这个算法也为当今深度学习的许多随机梯度下降算法奠定了基础：强化期望行为和减少不良行为，从而在神经网络中获得良好的参数设置。 神经网络（neural networks）的得名源于生物灵感。 一个多世纪以来（追溯到1873年亚历山大·贝恩和1890年詹姆斯·谢林顿的模型），研究人员一直试图组装类似于相互作用的神经元网络的计算电路。 随着时间的推移，对生物学的解释变得不再肤浅，但这个名字仍然存在。 其核心是当今大多数网络中都可以找到的几个关键原则： 线性和非线性处理单元的交替，通常称为层（layers）； 使用链式规则（也称为反向传播（backpropagation））一次性调整网络中的全部参数。 经过最初的快速发展，神经网络的研究从1995年左右开始停滞不前，直到2005年才稍有起色。 这主要是因为两个原因。 首先，训练网络（在计算上）非常昂贵。 在上个世纪末，随机存取存储器（RAM）非常强大，而计算能力却很弱。 其次，数据集相对较小。 事实上，费舍尔1932年的鸢尾花卉数据集是测试算法有效性的流行工具， 而MNIST数据集的60000个手写数字的数据集被认为是巨大的。 考虑到数据和计算的稀缺性，核方法（kernel method）、决策树（decision tree）和图模型（graph models）等强大的统计工具（在经验上）证明是更为优越的。 与神经网络不同的是，这些算法不需要数周的训练，而且有很强的理论依据，可以提供可预测的结果。 1.5. 深度学习的发展¶大约2010年开始，那些在计算上看起来不可行的神经网络算法变得热门起来，实际上是以下两点导致的： 其一，随着互联网的公司的出现，为数亿在线用户提供服务，大规模数据集变得触手可及； 另外，廉价又高质量的传感器、廉价的数据存储（克莱德定律）以及廉价计算（摩尔定律）的普及，特别是GPU的普及，使大规模算力唾手可得。 这一点在 表1.5.1 中得到了说明。 表1.5.1 数据集vs计算机内存和计算能力¶| 年代 | 数据规模 | 内存 | 每秒浮点运算 || —— | ——————- | ——— | —————————- || 1970 | 100 （鸢尾花卉） | 1 KB | 100 KF (Intel 8080) || 1980 | 1 K （波士顿房价） | 100 KB | 1 MF (Intel 80186) || 1990 | 10 K （光学字符识别） | 10 MB | 10 MF (Intel 80486) || 2000 | 10 M （网页） | 100 MB | 1 GF (Intel Core) || 2010 | 10 G （广告） | 1 GB | 1 TF (Nvidia C2050) || 2020 | 1 T （社交网络） | 100 GB | 1 PF (Nvidia DGX-2) | 很明显，随机存取存储器没有跟上数据增长的步伐。 与此同时，算力的增长速度已经超过了现有数据的增长速度。 这意味着统计模型需要提高内存效率（这通常是通过添加非线性来实现的），同时由于计算预算的增加，能够花费更多时间来优化这些参数。 因此，机器学习和统计的关注点从（广义的）线性模型和核方法转移到了深度神经网络。 这也造就了许多深度学习的中流砥柱，如多层感知机(McCulloch and Pitts, 1943) 、卷积神经网络(LeCun et al., 1998) 、长短期记忆网络(Graves and Schmidhuber, 2005) 和Q学习 (Watkins and Dayan, 1992)，在相对休眠了相当长一段时间之后，在过去十年中被“重新发现”。 最近十年，在统计模型、应用和算法方面的进展就像寒武纪大爆发——历史上物种飞速进化的时期。 事实上，最先进的技术不仅仅是将可用资源应用于几十年前的算法的结果。 下面列举了帮助研究人员在过去十年中取得巨大进步的想法（虽然只触及了皮毛）。 新的容量控制方法，如dropout (Srivastava et al., 2014)，有助于减轻过拟合的危险。这是通过在整个神经网络中应用噪声注入(Bishop, 1995) 来实现的，出于训练目的，用随机变量来代替权重。 注意力机制解决了困扰统计学一个多世纪的问题：如何在不增加可学习参数的情况下增加系统的记忆和复杂性。研究人员通过使用只能被视为可学习的指针结构(Bahdanau et al., 2014)找到了一个优雅的解决方案。不需要记住整个文本序列（例如用于固定维度表示中的机器翻译），所有需要存储的都是指向翻译过程的中间状态的指针。这大大提高了长序列的准确性，因为模型在开始生成新序列之前不再需要记住整个序列。 多阶段设计。例如，存储器网络(Sukhbaatar et al., 2015) 和神经编程器-解释器(Reed and De Freitas, 2015)。它们允许统计建模者描述用于推理的迭代方法。这些工具允许重复修改深度神经网络的内部状态，从而执行推理链中的后续步骤，类似于处理器如何修改用于计算的存储器。 另一个关键的发展是生成对抗网络(Goodfellow et al., 2014)的发明。传统模型中，密度估计和生成模型的统计方法侧重于找到合适的概率分布（通常是近似的）和抽样算法。因此，这些算法在很大程度上受到统计模型固有灵活性的限制。生成式对抗性网络的关键创新是用具有可微参数的任意算法代替采样器。然后对这些数据进行调整，使得鉴别器（实际上是一个双样本测试）不能区分假数据和真实数据。通过使用任意算法生成数据的能力，它为各种技术打开了密度估计的大门。驰骋的斑马(Zhu et al., 2017) 和假名人脸(Karras et al., 2017)的例子都证明了这一进展。即使是业余的涂鸦者也可以根据描述场景布局的草图生成照片级真实图像（(Park et al., 2019) ）。 在许多情况下，单个GPU不足以处理可用于训练的大量数据。在过去的十年中，构建并行和分布式训练算法的能力有了显著提高。设计可伸缩算法的关键挑战之一是深度学习优化的主力——随机梯度下降，它依赖于相对较小的小批量数据来处理。同时，小批量限制了GPU的效率。因此，在1024个GPU上进行训练，例如每批32个图像的小批量大小相当于总计约32000个图像的小批量。最近的工作，首先是由(Li, 2017) 完成的，随后是 (You et al., 2017)和 (Jia et al., 2018)，将观察大小提高到64000个，将ResNet-50模型在ImageNet数据集上的训练时间减少到不到7分钟。作为比较——最初的训练时间是按天为单位的。 并行计算的能力也对强化学习的进步做出了相当关键的贡献。这导致了计算机在围棋、雅达里游戏、星际争霸和物理模拟（例如，使用MuJoCo）中实现超人性能的重大进步。有关如何在AlphaGo中实现这一点的说明，请参见如(Silver et al., 2016)。简而言之，如果有大量的（状态、动作、奖励）三元组可用，即只要有可能尝试很多东西来了解它们之间的关系，强化学习就会发挥最好的作用。仿真提供了这样一条途径。 深度学习框架在传播思想方面发挥了至关重要的作用。允许轻松建模的第一代框架包括Caffe、Torch和Theano。许多开创性的论文都是用这些工具写的。到目前为止，它们已经被TensorFlow（通常通过其高级APIKeras使用）、CNTK、Caffe 2和Apache MXNet所取代。第三代工具，即用于深度学习的命令式工具，可以说是由Chainer率先推出的，它使用类似于Python NumPy的语法来描述模型。这个想法被PyTorch、MXNet的Gluon API和Jax都采纳了。 “系统研究人员构建更好的工具”和“统计建模人员构建更好的神经网络”之间的分工大大简化了工作。 例如，在2014年，对卡内基梅隆大学机器学习博士生来说，训练线性回归模型曾经是一个不容易的作业问题。 而现在，这项任务只需不到10行代码就能完成，这让每个程序员轻易掌握了它。 1.6. 深度学习的成功案例¶人工智能在交付结果方面有着悠久的历史，它能带来用其他方法很难实现的结果。例如，使用光学字符识别的邮件分拣系统从20世纪90年代开始部署，毕竟，这是著名的手写数字MNIST数据集的来源。这同样适用于阅读银行存款支票和对申请者的信用进行评分。系统会自动检查金融交易是否存在欺诈。这成为许多电子商务支付系统的支柱，如PayPal、Stripe、支付宝、微信、苹果、Visa和万事达卡。国际象棋的计算机程序已经竞争了几十年。机器学习在互联网上提供搜索、推荐、个性化和排名。换句话说，机器学习是无处不在的，尽管它经常隐藏在视线之外。 直到最近，人工智能才成为人们关注的焦点，主要是因为解决了以前被认为难以解决的问题，这些问题与消费者直接相关。许多这样的进步都归功于深度学习。 智能助理，如苹果的Siri、亚马逊的Alexa和谷歌助手，都能够相当准确地回答口头问题。这包括一些琐碎的工作，比如打开电灯开关（对残疾人来说是个福音）甚至预约理发师和提供电话支持对话。这可能是人工智能正在影响我们生活的最明显的迹象。 数字助理的一个关键要素是准确识别语音的能力。逐渐地，在某些应用中，此类系统的准确性已经提高到与人类同等水平的程度(Xiong et al., 2018)。 物体识别同样也取得了长足的进步。估计图片中的物体在2010年是一项相当具有挑战性的任务。在ImageNet基准上，来自NEC实验室和伊利诺伊大学香槟分校的研究人员获得了28%的Top-5错误率(Lin et al., 2010) 。到2017年，这一错误率降低到2.25%(Hu et al., 2018)。同样，在鉴别鸟类或诊断皮肤癌方面也取得了惊人的成果。 游戏曾经是人类智慧的堡垒。从TD-Gammon开始，一个使用时差强化学习的五子棋游戏程序，算法和计算的进步导致了算法被广泛应用。与五子棋不同的是，国际象棋有一个复杂得多的状态空间和一组动作。深蓝公司利用大规模并行性、专用硬件和高效搜索游戏树(Campbell et al., 2002) 击败了加里·卡斯帕罗夫(Garry Kasparov)。围棋由于其巨大的状态空间，难度更大。AlphaGo在2015年达到了相当于人类的棋力，使用和蒙特卡洛树抽样(Silver et al., 2016)相结合的深度学习。扑克中的挑战是状态空间很大，而且没有完全观察到（我们不知道对手的牌）。在扑克游戏中，库图斯使用有效的结构化策略超过了人类的表现(Brown and Sandholm, 2017)。这说明了游戏取得了令人瞩目的进步以及先进的算法在其中发挥了关键作用的事实。 人工智能进步的另一个迹象是自动驾驶汽车和卡车的出现。虽然完全自主还没有完全触手可及，但在这个方向上已经取得了很好的进展，特斯拉（Tesla）、英伟达（NVIDIA）和Waymo等公司的产品至少实现了部分自主。让完全自主如此具有挑战性的是，正确的驾驶需要感知、推理和将规则纳入系统的能力。目前，深度学习主要应用于这些问题的计算机视觉方面。其余部分则由工程师进行大量调整。 同样，上面的列表仅仅触及了机器学习对实际应用的影响之处的皮毛。 例如，机器人学、物流、计算生物学、粒子物理学和天文学最近取得的一些突破性进展至少部分归功于机器学习。 因此，机器学习正在成为工程师和科学家必备的工具。 关于人工智能的非技术性文章中，经常提到人工智能奇点的问题：机器学习系统会变得有知觉，并独立于主人来决定那些直接影响人类生计的事情。 在某种程度上，人工智能已经直接影响到人类的生计：信誉度的自动评估，车辆的自动驾驶，保释决定的自动准予等等。 甚至，我们可以让Alexa打开咖啡机。 幸运的是，我们离一个能够控制人类创造者的有知觉的人工智能系统还很远。 首先，人工智能系统是以一种特定的、面向目标的方式设计、训练和部署的。 虽然他们的行为可能会给人一种通用智能的错觉，但设计的基础是规则、启发式和统计模型的结合。 其次，目前还不存在能够自我改进、自我推理、能够在试图解决一般任务的同时，修改、扩展和改进自己的架构的“人工通用智能”工具。 一个更紧迫的问题是人工智能在日常生活中的应用。 卡车司机和店员完成的许多琐碎的工作很可能也将是自动化的。 农业机器人可能会降低有机农业的成本，它们也将使收割作业自动化。 工业革命的这一阶段可能对社会的大部分地区产生深远的影响，因为卡车司机和店员是许多国家最常见的工作之一。 此外，如果不加注意地应用统计模型，可能会导致种族、性别或年龄偏见，如果自动驱动相应的决策，则会引起对程序公平性的合理关注。 重要的是要确保小心使用这些算法。 就我们今天所知，这比恶意超级智能毁灭人类的风险更令人担忧。 1.7. 特点¶到目前为止，本节已经广泛地讨论了机器学习，它既是人工智能的一个分支，也是人工智能的一种方法。 虽然深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么。 这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。 如前所述，机器学习可以使用数据来学习输入和输出之间的转换，例如在语音识别中将音频转换为文本。 在这样做时，通常需要以适合算法的方式表示数据，以便将这种表示转换为输出。 深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。 例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。 由于表示学习（representation learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。 本节到目前为止讨论的问题，例如从原始音频信号中学习，图像的原始像素值，或者任意长度的句子与外语中的对应句子之间的映射，都是深度学习优于传统机器学习方法的问题。 事实证明，这些多层模型能够以以前的工具所不能的方式处理低级的感知数据。 毋庸置疑，深度学习方法中最显著的共同点是使用端到端训练。 也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。 例如，在计算机视觉中，科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开。 Canny边缘检测器 (Canny, 1987) 和SIFT特征提取器(Lowe, 2004)作为将图像映射到特征向量的算法，在过去的十年里占据了至高无上的地位。 在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。 然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。 当深度学习开始时，这些特征抽取器被自动调整的滤波器所取代，产生了更高的精确度。 因此，深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。 此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。 除了端到端的训练，人们正在经历从参数统计描述到完全非参数模型的转变。 当数据稀缺时，人们需要依靠简化对现实的假设来获得有用的模型。 当数据丰富时，可以用更准确地拟合实际情况的非参数模型来代替。 在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步。 现在人们可以借助于相关偏微分方程的数值模拟，而不是用手来求解电子行为的参数近似。这导致了更精确的模型，尽管常常以牺牲可解释性为代价。 与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试。 这种在处理统计问题上新发现的经验主义，加上人才的迅速涌入，导致了实用算法的快速进步。 尽管在许多情况下，这是以修改和重新发明存在了数十年的工具为代价的。 最后，深度学习社区引以为豪的是，他们跨越学术界和企业界共享工具，发布了许多优秀的算法库、统计模型和经过训练的开源神经网络。 正是本着这种精神，本书免费分发和使用。我们努力降低每个人了解深度学习的门槛，希望读者能从中受益。 1.8. 小结¶ 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。 表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。 深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。 最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。 整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。 1.9. 练习¶ 你当前正在编写的代码的哪些部分可以“学习”，即通过学习和自动确定代码中所做的设计选择来改进？你的代码是否包含启发式设计选择？ 你遇到的哪些问题有许多解决它们的样本，但没有具体的自动化方法？这些可能是使用深度学习的主要候选者。 如果把人工智能的发展看作一场新的工业革命，那么算法和数据之间的关系是什么？它类似于蒸汽机和煤吗？根本区别是什么？ 你还可以在哪里应用端到端的训练方法，比如 图1.1.2、物理、工程和计量经济学？ Table Of Contents 1. 引言 日常生活中的机器学习 机器学习中的关键组件 * [1\\. 数据](#id4) * [2\\. 模型](#id5) * [3\\. 目标函数](#id6) * [4\\. 优化算法](#id7) 各种机器学习问题 * [1\\. 监督学习](#id9) * [1.1\\. 回归](#id10) * [1.2\\. 分类](#id11) * [1.3\\. 标记问题](#id12) * [1.4\\. 搜索](#id13) * [1.5\\. 推荐系统](#id14) * [1.6\\. 序列学习](#id15) * [2\\. 无监督学习](#id16) * [3\\. 与环境互动](#id17) * [4\\. 强化学习](#id18) 起源 深度学习的发展 深度学习的成功案例 特点 小结 练习","link":"/2024/06/7507f258be7f.html"},{"title":"","text":"LinkRead on OmnivoreRead Original Highlights&amp;&amp;Note SSH之所以能够保证安全，原因在于它采用了公钥加密。 整个过程是这样的：（1）远程主机收到用户的登录请求，把自己的公钥发给用户。（2）用户使用这个公钥，将登录密码加密后，发送回来。（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 如果你是第一次登录对方主机，系统会出现下面的提示： $ ssh user@host The authenticity of host ‘host (12.18.429.21)’ can’t be established. RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d. Are you sure you want to continue connecting (yes/no)? 这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？ 所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。 用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。公钥是暴露的 每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 ContentSSH是每一台Linux电脑的标准配置。 随着Linux设备从电脑逐渐扩展到手机、外设和家用电器，SSH的使用范围也越来越广。不仅程序员离不开它，很多普通用户也每天使用。 SSH具备多种功能，可以用于很多场合。有些事情，没有它就是办不成。本文是我的学习笔记，总结和解释了SSH的常见用法，希望对大家有用。 虽然本文内容只涉及初级应用，较为简单，但是需要读者具备最基本的”Shell知识”和了解”公钥加密”的概念。如果你对它们不熟悉，我推荐先阅读《UNIX / Linux 初学者教程》和《数字签名是什么？》。 \\======================================= SSH原理与运用 作者：阮一峰 一、什么是SSH？ 简单说，SSH是一种网络协议，用于计算机之间的加密登录。 如果一个用户从本地计算机，使用SSH协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露。 最早的时候，互联网通信都是明文通信，一旦被截获，内容就暴露无疑。1995年，芬兰学者Tatu Ylonen设计了SSH协议，将登录信息全部加密，成为互联网安全的一个基本解决方案，迅速在全世界获得推广，目前已经成为Linux系统的标准配置。 需要指出的是，SSH只是一种协议，存在多种实现，既有商业实现，也有开源实现。本文针对的实现是OpenSSH，它是自由软件，应用非常广泛。 此外，本文只讨论SSH在Linux Shell中的用法。如果要在Windows系统中使用SSH，会用到另一种软件PuTTY，这需要另文介绍。 二、最基本的用法 SSH主要用于远程登录。假定你要以用户名user，登录远程主机host，只要一条简单命令就可以了。 $ ssh user@host 如果本地用户名与远程用户名一致，登录时可以省略用户名。 $ ssh host SSH的默认端口是22，也就是说，你的登录请求会送进远程主机的22端口。使用p参数，可以修改这个端口。 $ ssh -p 2222 user@host 上面这条命令表示，ssh直接连接远程主机的2222端口。 三、中间人攻击 ==SSH之所以能够保证安全，原因在于它采用了公钥加密。== ==整个过程是这样的：（1）远程主机收到用户的登录请求，把自己的公钥发给用户。（2）用户使用这个公钥，将登录密码加密后，发送回来。（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。== 这个过程本身是安全的，但是实施的时候存在一个风险：如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。 可以设想，如果攻击者插在用户与远程主机之间（比如在公共的wifi区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么SSH的安全机制就荡然无存了。这种风险就是著名的“中间人攻击”（Man-in-the-middle attack）。 SSH协议是如何应对的呢？ 四、口令登录 ==如果你是第一次登录对方主机，系统会出现下面的提示：== ==$ ssh user@host== ==The authenticity of host ‘host (12.18.429.21)’ can’t be established.== ==RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.== ==Are you sure you want to continue connecting (yes/no)?== ==这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？== ==所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。== 很自然的一个问题就是，==用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。== 假定经过风险衡量以后，用户决定接受这个远程主机的公钥。 Are you sure you want to continue connecting (yes/no)? yes 系统会出现一句提示，表示host主机已经得到认可。 Warning: Permanently added ‘host,12.18.429.21’ (RSA) to the list of known hosts. 然后，会要求输入密码。 Password: (enter password) 如果密码正确，就可以登录了。 当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 ==每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。== 五、公钥登录 使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。 所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。 这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个： $ ssh-keygen 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。 运行结束以后，在$HOME/.ssh/目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。 这时再输入下面的命令，将公钥传送到远程主机host上面： $ ssh-copy-id user@host 好了，从此你再登录，就不需要输入密码了。 如果还是不行，就打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面”#”注释是否取掉。 RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 然后，重启远程主机的ssh服务。 // ubuntu系统service ssh restart // debian系统/etc/init.d/ssh restart 六、authorized_keys文件 远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。 这里不使用上面的ssh-copy-id命令，改用下面的命令，解释公钥的保存过程： $ ssh user@host ‘mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys’ &lt; ~/.ssh/id_rsa.pub 这条命令由多个语句组成，依次分解开来看：（1）”$ ssh user@host”，表示登录远程主机；（2）单引号中的mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys，表示登录后在远程shell上执行的命令：（3）”$ mkdir -p .ssh”的作用是，如果用户主目录中的.ssh目录不存在，就创建一个；（4）’cat &gt;&gt; .ssh/authorized_keys’ &lt; ~/.ssh/id_rsa.pub的作用是，将本地的公钥文件~/.ssh/id_rsa.pub，重定向追加到远程文件authorized_keys的末尾。 写入authorized_keys文件后，公钥登录的设置就完成了。 \\============================================== 关于shell远程登录的部分就写到这里，下一次接着介绍《远程操作和端口转发》。 （完）","link":"/2024/06/3cd4bee38875.html"},{"title":"102","text":"Lec1 课程介绍GAMES:Graphics And Mixed Environment Symposium 101偏渲染201偏动画102偏建模 图像是由像素表达的离散的点图形是具有数学表达的几何对象,矢量图 光栅化文字都是矢量图,不论怎么放大都是清晰的储存的是点线的坐标,在经过重新计算之后,会清晰的呈现出来 渲染光的计算科学 光源 几何 纹理 材质 仿真运动的计算科学 偏微分方程 拟合集合 集合 无限 可数 自然数N,有理数Q 不可数 实数R,无理数对于有理数可数,无理数不可数的证明 有限","link":"/2024/02/b9ad7cf6c2c0.html"},{"title":"配置环境","text":"环境配置难绷,论坛上给的虚拟机是ubuntu18 并且是virtual box的版本.想用vmware虚拟机跑.将vdi格式转化为vmdk,并创建对应的虚拟机.问题在于VMware tools安装失败.每次安装完成之后,再reboot,就会变成没有VMware tools…搞不懂.还是在windows上配置环境算了… 看了下windows配置eigen和opencv有点麻烦,选择换成虚拟机ubuntu20.04LTS自己配置 更新breaking news!官方给的虚拟机,转换为vmware之后,vmwaretools安装成功了…直接用就行了.配置环境结束. ubuntu具体设置参考 遇上vscode编译时候报错1/usr/bin/gcc -fdiagnostics-color=always -g /home/l4rk/games101/pa0.c -o /home/l4rk/games101/pa0 /usr/bin/ld: /tmp/ccjPHxdQ.o: in function `main': /home/l4rk/games101/pa0.c:6: undefined reference to `sin' collect2: error: ld returned 1 exit status不能调用math.h库中的函数 修改编译设置添加了-lm一行1234567891011121314151617181920212223242526272829{ &quot;tasks&quot;: [ { &quot;type&quot;: &quot;cppbuild&quot;, &quot;label&quot;: &quot;C/C++: gcc 生成活动文件&quot;, &quot;command&quot;: &quot;/usr/bin/gcc&quot;, &quot;args&quot;: [ &quot;-fdiagnostics-color=always&quot;, &quot;-g&quot;, &quot;${file}&quot;, &quot;-o&quot;, &quot;${fileDirname}/${fileBasenameNoExtension}&quot;, &quot;-lm&quot; ], &quot;options&quot;: { &quot;cwd&quot;: &quot;${fileDirname}&quot; }, &quot;problemMatcher&quot;: [ &quot;$gcc&quot; ], &quot;group&quot;: { &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true }, &quot;detail&quot;: &quot;调试器生成的任务。&quot; } ], &quot;version&quot;: &quot;2.0.0&quot;}或者使用命令行1gcc -fdiagnostics-color=always -g test.c -o test -lm参考 配置环境还是有点问题,最终选择使用闫令琪老师提供的环境.","link":"/2024/02/30c25fc19e6a.html"},{"title":"hw1","text":"总的来说,hw1是比较简单的.本次作业的任务是填写一个旋转矩阵和一个透视投影矩阵,只要记得上课时候给的公式,写进去就行. 旋转矩阵注意,cos,sin等,需要的参数为弧度制(rad),而不是角度制12345678910111213Eigen::Matrix4f get_model_matrix(float rotation_angle) { Eigen::Matrix4f model = Eigen::Matrix4f::Identity(); // TODO: Implement this function // Create the model matrix for rotating the triangle around the Z axis. // Then return it. rotation_angle = rotation_angle / 180 * MY_PI; Eigen::Matrix4f rotate; rotate &lt;&lt; cos(rotation_angle), -sin(rotation_angle), 0, 0, sin(rotation_angle), cos(rotation_angle), 0, 0, 0, 0, 1, 0, 0, 0, 0, 1; model = rotate * model; return model;} 先进行挤压,再进行正交投影得到结果 persp2ortho 透视投影到正交投影的变化矩阵 ortho 正交矩阵projection = ortho * persp2ortho * projection;1234567891011121314151617181920212223242526272829Eigen::Matrix4f get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar) { // Students will implement this function Eigen::Matrix4f projection = Eigen::Matrix4f::Identity(); // TODO: Implement this function // Create the projection matrix for the given parameters. // Then return it. Eigen::Matrix4f persp2ortho = Eigen::Matrix4f::Identity(); Eigen::Matrix4f ortho = Eigen::Matrix4f::Identity(); float top = abs(zNear) * tan(eye_fov / 2 / 180 * MY_PI); float bottom = -top; float right = top * aspect_ratio; float left = -right; persp2ortho &lt;&lt; zNear, 0, 0, 0, 0, zNear, 0, 0, 0, 0, zNear + zFar, -zNear * zFar, 0, 0, 1, 0; ortho &lt;&lt; 2 / (right - left), 0, 0, -(right + left) / (right - left), 0, 2 / (top - bottom), 0, -(top + bottom) / (top - bottom), 0, 0, 2 / (zNear - zFar), -(zNear + zFar) / (zNear - zFar), 0, 0, 0, 1; projection = ortho * persp2ortho * projection; return projection;} 最后得到的结果与官方答案不同,图形倒转了.这是zNear值导致的.根据课上的内容,看向的是Z轴负半轴,Z0; 小问题懒得修改了. 顺便学习了一下cmake的相关知识[[07archive/tech/cmake|cmake]]","link":"/2024/02/38644185a72a.html"},{"title":"hw2","text":"在屏幕上画出一个实心三角形.相较于hw1,多了一些内容,需要好好看下框架. 判断$(x,y)$对应的pixel否在三角形内部.12345678910111213141516171819202122232425262728293031static bool insideTriangle(int x, int y, const Vector3f* _v){ // TODO : Implement this function to check if the point (x, y) is inside the triangle represented by _v[0], _v[1], _v[2] Vector2f vertex2p[3], vertex2vertex[3]; int i; //储存顶点到测试点的向量 for (i = 0;i &lt; 3;i++) { vertex2p[i] &lt;&lt; x - _v[i].x(), y - _v[i].y(); } //储存顶点到顶点之间的向量 for (i = 0;i &lt; 3;i++) { vertex2vertex[i] &lt;&lt; _v[(i + 1) % 3].x() - _v[i].x(), _v[(i + 1) % 3].y() - _v[i].y(); } //计算叉乘法. int result[3]; for (i = 0;i &lt; 3;i++) { result[i] = vertex2vertex[i].x()*vertex2p[i].y() -vertex2vertex[i].y()*vertex2p[i].x(); } if(result[0]&gt;0 &amp;&amp; result[1]&gt;0 &amp;&amp; result[2]&gt;0){ return true; } else if(result[0]&lt;0 &amp;&amp; result[1]&lt;0 &amp;&amp; result[2]&lt;0){ return true; } else{ return false; }} 先限定下founding box范围,提高效率 12345678910111213141516171819202122232425262728293031void rst::rasterizer::rasterize_triangle(const Triangle&amp; t) { auto v = t.toVector4(); // TODO : Find out the bounding box of current triangle. // iterate through the pixel and find if the current pixel is inside the triangle float xmin,ymin,xmax,ymax; xmin=std::min(std::min(v[0].x(),v[1].x()),v[2].x()); ymin=std::min(std::min(v[0].y(),v[1].y()),v[2].y()); xmax=std::max(std::max(v[0].x(),v[1].x()),v[2].x()); ymax=std::max(std::max(v[0].y(),v[1].y()),v[2].y()); xmin=std::floor(xmin); xmax=std::ceil(xmax); ymin=std::floor(ymin); ymax=std::ceil(ymax); for(int x=xmin;x&lt;=xmax;x++){ for(int y=ymin;y&lt;=ymax;y++){ if(insideTriangle(x+0.5,y+0.5,t.v)){ // If so, use the following code to get the interpolated z value. auto[alpha, beta, gamma] = computeBarycentric2D(x, y, t.v); float w_reciprocal = 1.0/(alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w()); float z_interpolated = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w(); z_interpolated *= w_reciprocal; // TODO : set the current pixel (use the set_pixel function) to the color of the triangle (use getColor function) if it should be painted. if (z_interpolated&lt;depth_buf[get_index(x,y)]){ set_pixel(Vector3f(x,y,z_interpolated),t.getColor()); depth_buf[get_index(x,y)]=z_interpolated; } } } }","link":"/2024/02/e5b4e7a073d8.html"},{"title":"","text":"","link":"/2024/02/4a0e4c432013.html"},{"title":"101","text":"Lec1 overview of Computer Graphic判断游戏画面水平如何可以去看画面的明暗.亮的,一般都是采用了全局光照技术.从技术层面来看更加优秀 特效是最简单的图形学技术应用特效是特殊的效果.在平常生活中见得很少,即使特效出错,观众不一定看得出来.而对日常东西的渲染更为困难 VisualizationVirtual RealityDigital Illustration数字图像处理SimulationGraphic User InterfaceTypography矢量字体? course topic Rasterazation Curves and Meshes Ray Tracing Animation / Simulation CG与CV一切需要理解,猜测的都是计算机视觉的内容.no clear boundaries Lec2 Review of Linear AlgebraA Swift and Brutal Introduction to Linear Algebra Vectors$\\vec {a}$ 或者$\\boldsymbol {a}$ dot product 点乘$\\vec {a} \\cdot \\vec{b}=\\lvert \\vec{a} \\rvert \\lvert \\vec{b} \\rvert \\cos\\theta$$\\cos\\theta=\\frac{\\vec{a} \\cdot \\vec{b}}{\\lvert\\vec{a}\\rvert\\lvert \\vec{b} \\rvert}0$for unit Vectors$\\cos \\theta=\\hat{a} \\cdot \\hat{b}$符合 交换律 结合律 分配律 用矩阵表达的点乘计算更加简单直接在二维$\\vec{a} \\cdot \\vec{b}=\\begin{pmatrix}x{a} \\ y{a} \\ \\end{pmatrix}\\cdot \\begin{pmatrix}x{b} \\ y{b}\\end{pmatrix}=x{a}x{b}+y{a} y{b}$ 同理对于三维 $\\vec{a} \\cdot \\vec{b}=\\begin{pmatrix}x{a} \\ y{a} \\z{a} \\end{pmatrix}\\cdot \\begin{pmatrix}x{b} \\ y{b} \\ z{b}\\end{pmatrix}=x{a} x{b}+y{a} y{b}+z{a} z{b}$ 主要是用来寻找投影 对于$\\vec{b}$在$\\vec{a}$上的投影$\\vec{b}\\perp$$\\vec{b}\\perp=\\lvert\\vec{b}\\perp\\rvert \\cdot\\hat{a}=\\lvert\\vec{b}\\rvert\\hat{a} \\cos\\theta$若$\\vec{a}$为$\\hat{a}$,则$\\vec{b}\\perp=\\lvert\\vec{b}\\rvert \\vec{a} \\cos\\theta =(\\vec{b} \\cdot \\vec{a})\\vec{a}$ ^fae5ki 用处:观察点乘结果判断 两个向量是否接近 两个向量的前后位置关系 cross product$\\vec{a} \\times \\vec{b}=-\\vec{b} \\times \\vec{a}$ $\\lvert \\vec{a} \\times \\vec{b} \\rvert=\\lvert \\vec{a} \\rvert \\lvert \\vec{b} \\rvert \\sin\\theta$ 方向上采用右手定则 没有交换律但符合分配律和结合律 $\\vec{a} \\times \\vec{a}=\\vec{0}$ 是向量,不是单纯的$0$ $\\vec{a}\\times\\vec{b}=A^{*}b=\\left(\\begin{array}{l l l}0&amp;{-z{a}}&amp;{y{a}}\\ {z{a}}&amp;{0}&amp;{-x{a}}\\ {-y{a}}&amp;{x{a}}&amp;0\\end{array}\\right)\\left(\\begin{array}{l}{x{b}}\\ {y{b}}\\ {z_{b}}\\end{array}\\right)$ $\\vec{a}\\times\\vec{b}\\;=\\;\\left(\\begin{array}{l l}{y{a}z{b}-y{b}z{a}}\\ {z{a}x{b}-x{a}z{b}}\\ {x{a}y{b}-y{a}x{b}}\\end{array}\\right)$ 作用:通过叉乘结果判断 左和右 if($\\vec{a} \\times \\vec{b}=\\vec{z}$) then,$\\vec{b}$在$\\vec{a}$左侧 if($\\vec{a} \\times \\vec{b}=-\\vec{z}$) then,$\\vec{b}$在$\\vec{a}$右侧 内和外 利用左右判断 if($\\overrightarrow{AP} \\times \\overrightarrow{AB}=\\overrightarrow{BP} \\times \\overrightarrow{BC}=\\overrightarrow{CP} \\times \\overrightarrow{CA}$) then,p在内侧 在3D情况下寻找投影类似于二维的情况 若$\\begin{array}{c}{||\\overrightarrow{v}||=||\\overrightarrow{w}||=||\\overrightarrow{v}||=1}\\ {\\overrightarrow{u}\\cdot\\overrightarrow{v}=\\overrightarrow{u}\\cdot\\overrightarrow{w}=\\overrightarrow{v}\\cdot\\overrightarrow{w}=0}\\ {\\overrightarrow{w}=\\overrightarrow{u}\\times\\overrightarrow{v}}&amp;{\\scriptscriptstyle\\mathrm{(右手系)}}\\end{array}$则$\\vec{p}\\perp=(\\vec{p}\\cdot\\vec{u})\\vec{u}+(\\vec{p}\\cdot\\vec{v})\\vec{v}+(\\vec{p}\\cdot\\vec{w})\\vec{w}$ matrix矩阵的乘法$\\begin{pmatrix}1&amp;3 \\ 2&amp;4 \\3&amp;3 \\ \\end{pmatrix} \\begin{pmatrix}2 &amp;5\\ 1&amp;6\\end{pmatrix}=\\begin{pmatrix}x&amp;x \\ x&amp;x \\ x&amp;x\\end{pmatrix}$不符合交换律但符合结合律和分配律将向量vector视作列向量m*1的矩阵 矩阵的转置$(AB)^T=B^{T}A^T$ 单位矩阵$I_{3*3}=\\begin{pmatrix}1&amp;0&amp;0 \\ 0&amp;1&amp;0 \\ 0&amp;0&amp;1 \\ \\end{pmatrix}$对于逆运算$A^{-1}$$AA^{-1}=A^{-1}A=I$$(AB)^{-1}=B^{-1}A^{-1}$ 将点乘与叉乘转换为矩阵乘法 Lec3 Transformation A transformation modeling rotation scaling viewing projection homogeneous coordinate 齐次坐标为解决Translation问题,齐次坐标堂堂登场 $2D point=\\begin{pmatrix}x \\ y \\ 1\\end{pmatrix}$ $2D vector=\\begin{pmatrix}x \\ y \\ 0\\end{pmatrix}$ 为什么 point用1补位 vector用0补位?对于向量来说,人类希望它由平移不变的性质.所以用0来保护它 1的情况\\left(\\begin{array}{c c c}{x^{\\prime}}\\\\ {y^{\\prime}}\\\\ {w^{\\prime}}\\end{array}\\right)\\ =\\ \\left(\\begin{array}{c c c}1&{0}&{t_{x}}\\\\ 0&1&{t_{y}}\\\\ 0&0&1\\end{array}\\right)\\cdot\\left(\\begin{array}{c}\\\\ \\\\ 1\\end{array}\\right)=\\ \\left(\\begin{array}{c}{x+t_{x}}\\\\ {y+t_{y}}\\\\ 1\\end{array}\\right)\\ 0的情况\\left(\\begin{array}{c c c}{x^{\\prime}}\\\\ {y^{\\prime}}\\\\ {w^{\\prime}}\\end{array}\\right)\\ =\\ \\left(\\begin{array}{c c c}1&0&{t_{x}}\\\\ 0&1&{t_{y}}\\\\ 0&0&1\\end{array}\\right)\\cdot\\left(\\begin{array}{c}\\\\ \\\\ 0\\end{array}\\right)=\\ \\left(\\begin{array}{c}{x+t_{x}}\\\\ {y+t_{y}}\\\\ 0\\end{array}\\right)\\确保了即使是利用矩阵乘法计算向量平移不变 或者换一个角度看 $vector+vector=vector$ $point-point=vector$ $point+vector=point$ 某个点沿着向量平移 $point+point=midpoint$对于点$\\begin{pmatrix}x \\ y \\ w \\end{pmatrix}=\\begin{pmatrix}x/w \\ y/w \\ 1\\end{pmatrix}$ 题外话:trade off是一个在工程学科中必然存在的策略.齐次坐标虽然需要更多的性能但能够将基础的变换统一起来 增加的储存数据只有最后一列的$\\begin{pmatrix}0 \\ 0 \\ 1\\end{pmatrix}$与最后一行的$\\begin{pmatrix}0,0,1\\end{pmatrix}$,而且在大部分情况下,$\\begin{pmatrix}0,0,1\\end{pmatrix}$只要储存一个1就够了.性能开销不大的情况下实现了相当好的效果 modeling先线性变换再平移 线性变换除了平移之外都是线性变换? 都可以用一个统一的矩阵来表示$x \\prime=ax+by$$y \\prime=cx+dy$ \\left[\\begin{array}{l}{x^{\\prime}}\\\\ {y^{\\prime}}\\end{array} \\right] =\\left[ \\begin{array}{l l}{a}&{b}\\\\ &\\end{array}\\right] \\left [\\begin{array}{l}\\\\ \\end{array} \\right]scale缩放矩阵,缩放系数为$S{x}=0.5,S{y}=1.0$$\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=\\left[\\begin{array}{l l}{s_x}&amp;0\\ 0&amp;{s_y}\\end{array}\\right]\\left[\\begin{array}{l}\\ \\end{array}\\right]$ reflection$\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=\\left[\\begin{array}{l l}1&amp;0\\ 0&amp;1\\end{array}\\right]\\left[\\begin{array}{l}{x}\\ {y}\\end{array}\\right]$ sheer 拉伸 $\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=\\left[\\begin{array}{l l}1&amp;{a}\\ 0&amp;{1}\\end{array}\\right]\\left[\\begin{array}{l}{x}\\ {y}\\end{array}\\right]$ rotate写出正确的旋转矩阵,只需要找到前后变化的点的相对位置关系$\\left[\\begin{array}{l}{x^{ \\prime}}\\ {y^{\\prime}}\\end{array}\\right]=R{\\theta}\\left[\\begin{array}{l}{x}\\ {y}\\end{array}\\right]$$\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=\\left[\\begin{array}{l l}{?}&amp;{?}\\ {?}&amp;{?}\\end{array}\\right]\\left[\\begin{array}{l}{x}\\ {y}\\end{array}\\right]$推导$R{\\theta}$的值,可以由特殊到一般,$\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=(\\cos\\theta,\\sin\\theta)$带入推导随便算对于旋转来说$R{-\\theta}=\\left[\\begin{array}{c c}\\cos\\theta&amp;\\sin\\theta \\ -\\sin\\theta&amp;\\cos\\theta\\end{array}\\right]$存在下列关系:$R{-\\theta}=R{\\theta}^{T}$可以用转秩简单求得$R{-\\theta}$ 线性变换的齐次坐标表示 非线性变换Translation 平移变换平移不是一个线性变换为了避免这样的情况引入了齐次坐标来解决 在齐次坐标下平移的表示$\\left(\\begin{array}{c c c}{x^{\\prime}}\\ {y^{\\prime}}\\ {w^{\\prime}}\\end{array}\\right)\\ =\\ \\left(\\begin{array}{c c c}1&amp;0&amp;{t{x}}\\ 0&amp;1&amp;{t{y}}\\ 0&amp;0&amp;1\\end{array}\\right)\\cdot\\left(\\begin{array}{c}{x}\\ {y}\\ 1\\end{array}\\right)$ affine transform仿射变换仿射变换:线性变换再接上平移对于这样的操作来说,无法简单的写成与上方统一的矩阵相乘的形式只能写成$\\left[\\begin{array}{l}{x^{\\prime}}\\ {y^{\\prime}}\\end{array}\\right]=\\left[\\begin{array}{l l}{a}&amp;{b}\\ {c}&amp;{d}\\end{array}\\right]\\left[\\begin{array}{l}{x}\\ {y}\\end{array}\\right]+\\left[\\begin{array}{l}{t{x}}\\ {t{y}}\\end{array}\\right]$ 但通过齐次坐标可以写成 \\left(\\begin{array}{c c c}{x^{\\prime}}\\\\ {y^{\\prime}}\\\\ 1\\end{array}\\right)\\ =\\ \\left(\\begin{array}{c c c}&&{t_{x}}\\\\ &&{t_{y}}\\\\ 0&0&1\\end{array}\\right)\\cdot\\left(\\begin{array}{c}\\\\ \\\\ 1\\end{array}\\right)=\\ \\left(\\begin{array}{c}{ax+by+t_{x}}\\\\ {cx+dy+t_{y}}\\\\ 1\\end{array}\\right)\\composing transform 组合变换矩阵乘法的顺序会影响结果所以变换顺序的不同也会影响结果$R{45}\\cdot T{(1,0)} \\neq T{(1,0)} \\cdot R{45}$ 默认情况下先做旋转再做平移对于下式来说$T{(1,0)}\\cdot R{45}\\ \\left [\\begin{array}{c}x\\ y\\1\\end{array}\\right]$先做旋转再做平移 对于一系列操作来说$A{n}(A{n-1}(A{n-2}…(A{1})))$可以先合成之前的矩阵,最终变成$A{(3*3)} \\cdot \\begin{pmatrix}x \\ y \\ 1\\end{pmatrix}$$A{(3*3})$能够表达无数多的复杂变换 非原点旋转$T{c} \\cdot R{\\alpha} \\cdot T_{-c}$顺序是从左到右先平移到原点,再旋转,最后再平移回去 inverse transform 逆变换使用逆矩阵就可以完成逆变换 Lec4 Transformation BHow to get a photo? 摆pose modeling transformation 选相机位置 viewing transformation 按快门 projection transformationMVP!modeling viewing projection 三维下的模型变换 $3D point=\\begin{pmatrix}x \\ y \\ z\\ 1\\end{pmatrix}$ $3D vector=\\begin{pmatrix}x \\ y \\z \\ 0\\end{pmatrix}$$\\begin{pmatrix}x \\ y \\ z\\ w\\end{pmatrix}=\\begin{pmatrix}x /w\\ y/w \\ z/w\\ 1\\end{pmatrix}$ affine transform平移仍然在最后一列 \\left(\\begin{array}{c c c}{x^{\\prime}}\\\\ {y^{\\prime}}\\\\ \\\\1\\end{array}\\right)\\ =\\ \\left(\\begin{array}{c c c c}{a}&{b}&c&{t_{x}}\\\\ {d}&{e}&f&{t_{y}}\\\\g&h&i&t_{z}\\\\ 0&0&0&1\\end{array}\\right)\\cdot\\left(\\begin{array}{c}{x}\\\\ {y}\\\\z\\\\ 1\\end{array}\\right)=\\ \\left(\\begin{array}{c}{ax+by+cz+t_{x}}\\\\ {dx+ey+fz+t_{y}}\\\\gx+hy+di+t_{z}\\\\ 1\\end{array}\\right)\\scaleS_(s_{x},s_{y},s_{z})=\\begin{pmatrix}s_{x}&0&0&0 \\\\ 0&s_{y}&0&0 \\\\ 0&0&s_{z}&0 \\\\ 0&0&0&1 \\\\ \\end{pmatrix}reflectionTranslationT_(t_{x},t_{y}t_{z})=\\begin{pmatrix} 1&0&0&t_{x} \\\\ 0&1&0&t_{y} \\\\ 0&0&1&y_{z} \\\\ 0&0&0&1 \\\\ \\end{pmatrix}sheerRotate 沿着x轴旋转\\mathbf{R}_{x}(\\alpha)={\\left(\\begin{array}{l l l l}{1}&{0}&{0}&{0}\\\\ {0}&{\\cos\\alpha}&{-\\sin\\alpha}&{0}\\\\ {0}&{\\sin\\alpha}&{\\cos\\alpha}&{0}\\\\ {0}&{0}&{0}&{1}\\end{array}\\right)} 沿着y轴旋转是最特殊的一个,右上角是$\\sin\\alpha$下见推算过程 \\mathbf{R}_{y}(\\alpha)={\\left(\\begin{array}{l l l l}{\\cos\\alpha}&{0}&{\\sin\\alpha}&{0}\\\\ {0}&{1}&{0}&{0}\\\\ {-\\sin\\alpha}&{0}&{\\cos\\alpha}&{0}\\\\ {0}&{0}&{0}&{1}\\end{array}\\right)} 沿着z轴旋转 \\mathbf{R}_{y}(\\alpha)={\\left(\\begin{array}{l l l l}{\\cos\\alpha}&{-\\sin\\alpha}&{0}&{0}\\\\ {\\sin\\alpha}&{\\cos\\alpha}&{0}&{0}\\\\ {0}&{0}&{1}&{0}\\\\ {0}&{0}&{0}&{1}\\end{array}\\right)} 对于任意的3D旋转来说,可以分解为一个在3D直角坐标系中的$R{xyz}(\\alpha\\beta\\gamma)=R{x}(\\alpha)R{y}(\\beta)R{z}(\\gamma)$三个绕各个轴旋转的矩阵相乘$\\alpha,\\beta,\\gamma$叫做欧拉角(Euler Angles)战地中的开飞机也是这样 Rodrigues’ Rotation Formularotation by angle $\\alpha$ around axis $n$ \\mathrm{R}({\\bf n},\\alpha)~=~\\mathrm{cos}(\\alpha){\\bf I}~+~(1-\\cos(\\alpha))~{\\bf n}^{T}~+~\\sin(\\alpha)\\left(\\begin{array}{l l l}0&{-n_{z}}&{n_{y}}\\\\ {n_{z}}&0&{-n_{x}}\\\\ {-n_{y}}&{n_{x}}&0\\\\ \\end{array}\\right)这部分$\\sin\\alpha\\left(\\begin{array}{l l l}0&amp;{-n{z}}&amp;{n{y}}\\ {n{z}}&amp;0&amp;{-n{x}}\\ {-n{y}}&amp;{n{x}}&amp;0\\ \\end{array}\\right)$是叉乘的矩阵表达形式 viewing/camera 视图变换基础:相机的位置 $\\vec{e}$ 人的位置相机看向的方向 $\\hat{g}$ 眼睛朝向相机顶部向量 $\\hat{t}$ 脑袋歪斜方向 在物理学的角度,可以将物体的移动看成,相机位置不动,其他物体相对运动.于是把相机固定在标准位置,即相机位于原点,永远看向-z轴,顶部指向y轴正方向即$\\vec{e}=(0,0,0)$$\\hat{g}=(0,0,-1)$$\\hat{t}=(0,1,0)$让操作计简化 标准化流程 $T{view}=\\left[\\begin{array}{c c c c}1&amp;0&amp;0&amp;-x{e}\\ 0&amp;1&amp;0&amp;-y{e}\\0&amp;0&amp;1&amp;-z{e}\\0&amp;0&amp;0&amp;1\\end{array}\\right]$ 将后面几步旋转矩阵计算为同一个矩阵可得逆矩阵$R{view}^{-1}$.由于矩阵$R{view}$计算困难,故使用逆矩阵第一行为(g x t) To X 结果第二行为t To Y的结果第三行为g To -Z的结果 projection 投影变换 orthographic projection 正交投影 perspective projection 透视投影orthographic projection 正交投影 把z轴直接去掉,再进行平移与缩放到$[-1,1]^{2}$范围内,就可以得到正交投影的结果 工程上的做法注意, 左右的范围为[l,r],left\\&lt;right 上下的范围为[b,t],bottom\\&lt;top 前后的范围为[f,n],far\\&lt;near.因为我们看向的方向是-z,例如f=-9,n=1. 变换矩阵为 M_{ortho}=\\left[\\begin{array}{c c c c}\\frac{2}{r-l}&0&0&0\\\\0&\\frac{2}{t-b}&0&0\\\\0&0&\\frac{2}{n-f}&0\\\\0&0&0&1 \\end{array}\\right] \\left[\\begin{array}{c c c c}1&0&0&-\\frac{r+l}{2}\\\\0&1&0&-\\frac{t+b}{2}\\\\0&0&1&-\\frac{f+n}{2}\\\\0&0&0&1 \\end{array}\\right]前一个为了缩放立方体到$[-1,1]^{2}$范围后一个为了平移立方体中点至原点 但现在并没有完全完成变换,因为缩放的过程中存在拉伸,还需要后续的视口变换来矫正也存在精度上的问题.把大的立方体缩放到小立方体,会导致信息损失 perspective transformation 透视投影 视锥如何定义?定义一个fov-Y(垂直可视角度),再定义一个aspect ratio(宽高比),就可以确定视锥的形状其他的数据都可以简单计算出来$n,t,l$等等 将从视锥通过投影面截出来的截锥体挤压成cuboid,再进行正交投影,就可以得到透视投影只要求得$M_{persp\\rightarrow ortho}$就行力 显而易见$y^\\prime=\\frac{n}{z}y$$x^\\prime=\\frac{n}{z}x$但$z^{\\prime}$仍然不清楚 得到 \\begin{pmatrix} x^\\prime \\\\ y^\\prime \\\\ z^\\prime \\\\ 1 \\end{pmatrix}= \\begin{pmatrix} \\frac{n}{z}x\\\\\\frac{n }{z}y \\\\ unknown\\\\1 \\end{pmatrix}= \\begin{pmatrix} nx \\\\ nz \\\\ still\\ unknown \\\\ z \\end{pmatrix}M_{persp\\rightarrow ortho}\\begin{pmatrix} x\\\\y \\\\ z \\\\ 1 \\\\ \\end{pmatrix}=\\begin{pmatrix} x^\\prime \\\\ y^\\prime \\\\ z^\\prime \\\\ 1 \\end{pmatrix}= \\begin{pmatrix} nx \\\\ nz \\\\ still\\ unknown \\\\ z \\end{pmatrix}可推算得 M_{persp\\rightarrow ortho}=\\begin{pmatrix} n&0&0&0 \\\\ 0&n&0&0 \\\\ ?&?&?&? \\\\ 0&0&1&0 \\end{pmatrix}而根据定义,近平面,z不变可知将$z=n$带入 \\begin{pmatrix} x^\\prime \\\\ y^\\prime \\\\ z^\\prime \\\\ 1 \\end{pmatrix}= \\begin{pmatrix} \\frac{n}{z}x\\\\\\frac{n }{z}y \\\\ n\\\\1 \\end{pmatrix}= \\begin{pmatrix} nx \\\\ nz \\\\ n^{2} \\\\ n \\end{pmatrix}M_{persp\\rightarrow ortho}\\begin{pmatrix} x\\\\y \\\\ n \\\\ 1 \\\\ \\end{pmatrix}=\\begin{pmatrix} x^\\prime \\\\ y^\\prime \\\\ z^\\prime \\\\ 1 \\end{pmatrix}= \\begin{pmatrix} nx \\\\ nz \\\\ n^{2} \\\\ n \\end{pmatrix}得 M_{persp\\rightarrow ortho}=\\begin{pmatrix} n&0&0&0 \\\\ 0&n&0&0 \\\\ ?&?&?&? \\\\ 0&0&1&0 \\end{pmatrix}=\\begin{pmatrix} n&0&0&0 \\\\ 0&n&0&0 \\\\ 0&0&A&B \\\\ 0&0&1&0 \\end{pmatrix}\\begin{pmatrix} 0&0&A&B \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ n \\\\ 1 \\end{pmatrix}=n^{2}再由远平面点经过变换f不变,同理可得 \\begin{pmatrix} 0&0&A&B \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ f \\\\ 1 \\end{pmatrix}=f^{2}由上两式可得 \\begin{align}A=n+f \\\\ B=-nf\\end{align}M_{persp\\rightarrow ortho}=\\begin{pmatrix} n&0&0&0 \\\\ 0&n&0&0 \\\\ 0&0&n+f&-nf \\\\ 0&0&1&0 \\end{pmatrix}最后得到透视矩阵$M{persp}=M{ortho}M_{persp\\rightarrow ortho}$ 思考题:对于$\\frac{n+f}{2}$,经过变形之后,会更加靠近$n$还是$f$? \\begin{align} M_{persp\\rightarrow ortho}\\begin{pmatrix} x \\\\ y \\\\ \\frac{n+f}{2} \\\\ 1 \\\\ \\end{pmatrix}=\\begin{pmatrix} n&0&0&0 \\\\ 0&n&0&0 \\\\ 0&0&n+f&-nf \\\\ 0&0&1&0 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ \\frac{n+f}{2} \\\\ 1 \\\\ \\end{pmatrix}=\\begin{pmatrix} nx \\\\ ny \\\\ \\frac{n^{2}+f^{2}}{2} \\\\ \\frac{n+f}{2} \\end{pmatrix}=\\begin{pmatrix} \\frac{2n}{n+f}x \\\\ \\frac{2n}{n+f}y \\\\ \\frac{n^{2}+f^{2}}{n+f} \\\\ 1 \\end{pmatrix} \\end{align}比较$\\frac{n^{2}+f^{2}}{n+f}$与$\\frac{n+f}{2}$得$\\frac{n^{2}+f^{2}}{n+f}\\geq\\frac{n+f}{2}$更靠近n面 Lec5 Rasterazation Triangle 屏幕是一个数组,数组的单个元素是颜色信息 Raster\\==screen in German Pixel\\==short for “picture for element” canonical(规范的) cube to screen rules 用(x,y)的形式表示 x,y为整数 像素表示范围为(0,0)到(width-1,height-1) 中心点在(x+0.5,y+0.5) 因为单个像素占有1*1空间,所以像素实际占据的屏幕空间为(0,0)~(width,height) view port 视口变换将之前Transformation得到的$[-1,1]\\times[-1,1]$的正方形变换到$[0,width]\\times[0,height]$上,$z$先不管viewport transform matrix M_{viewport}= \\begin{pmatrix} \\frac{width}{2}&0&0&\\frac{width}{2} \\\\ 0&\\frac{height}{2}&0&\\frac{height }{2} \\\\ 0&0&1&0 \\\\ 0&0&0&1 \\end{pmatrix}左上$3\\times3$负责缩放第四列负责平移和$z$有关的都不变 显示原理显示的图像,存在于显卡的memory中.告诉显示器读取哪块内存就能展示 LCDliquid crystal display用液晶光栅对光偏振进行改变 LEDlight emitting diode 发光二极管 electronic inktriangle Meshwhy triangle? 最基础的多边形 能够用三角形表示其他的多边形 三角形的三个点确保了他们在同一个平面中 内部外部很容易区分,可以用向量的叉积进行判断 定义了三个点$v{1},v{2},v_{3}$ value属性的值,就可以判断三角形内部某个点.value 光栅化方法采样对风景采样=拍照对时间采样=video 将函数离散化的方法采样算法示例判断像素中心点是否在三角形中1234567for (int x = 0; x &lt; xmax; ++x) for (int y = 0; y &lt; ymax; ++y) image[x][y] = inside(tri, x + 0.5, y + 0.5); # inside 函数的具体实现,依靠叉积判断点是否在三角形中 # 对于中心点在边上的情况,可以自行决断 加速方法bounding box用bounding box包围核来减少判断 锯齿问题信号走样 Lec6 Rasterazation anti-aliasing and z-bufferSampling Artifacts (Errors / Mistakes / Inaccuracies) in Computer Graphics artifacts Jaggies (Staircase Pattern) 锯齿 Moiré Patterns in Imaging 摩尔纹 Wagon Wheel Illusion (False Motion) 原因:Signals are changing too fast (high frequency),but sampled too slowly 滤波采样对原有的信号模糊(滤波)再采样 为什么不能先采样再模糊?按照下面的理论来看,先采样会有频域的重叠,即使进行模糊之后,频域还是会重叠,导致信号出现较大的差错 Fourier series傅里叶级数是采样定理原始证明的核心任何周期函数都可以用正弦函数和余弦函数构成的无穷级数来表示 Fourier Transform傅里叶变换的正变换与负变换 通过频率分析,发现,对于变化太快的函数来说,采样不能够很好地体现函数本身的性质低级傅里叶级数采样 失真较小高级傅里叶级数采样 失真较大 甚至会有对于完全不同的函数进行采样,结果相同仅仅通过采样,无法区分两种函数区别所以才会有aliasing sample出现aliasing的原因分析频域与时域Filtering = Getting rid of certain frequency contents从时域到频域越靠外频率越高 怎么样的图像是高频?画面变化大的地方,边界,经过傅里叶变换之后生成的就是高频信号.同理,图像变化小的地方,经过傅里叶变换之后生成的就是低频信号. 亮度代表在某个频率下,信号的强度横竖的两条亮线先不管 高通滤波的效果仅让高频通过,再经过逆傅里叶变换,生成图像发现生成的图像是有意义的,大体描述了图像内容的边界 低通滤波的效果能看到大致的图像,但看不见细节与边界 卷积filter=average=convolution 在时域上的卷积等于频域上的乘积同时验证了,卷积=滤波,最左边的频域图像进行类似低通滤波效果的操作之后,变成了最右边的频域 时域上的乘积等于频域上的卷积 bigger box=lower frequency用越大的box进行卷积,得到的图像越模糊,通过的频率越低 从频域看采样的本质Sampling = Repeating Frequency Contents左边为函数的频域右边为函数的时域$f(c)$为频域冲击函数$f(e)$为$f(c)$经过傅里叶变换之后生成的时域冲击函数$f(a)\\times f(c)=f(e)$$f(b)\\otimes f(d)=f(f)$频域上的乘积等于时域上的卷积 从$f(f)$可知,采样在一直重复某个信号的频谱 如果时域采样越稀疏,频域上,频谱就越密集,重叠在一起就会发生走样 how can we reduce aliasing error 提升采样率拥有更高分辨率的显示器 antialiasing先做模糊再做采样即低通滤波,把高频去除再采样这样即使稀疏采样也能够得到足够好的采样结果 在工程上,把图像模糊,即用低通滤波器,对图像进行卷积filter之后像素内部的值就是卷积之后的结果但计算原像素内部黑色占据的百分比不是一件简单的事情,所以我们有一项新技术:MSAA 超采样 超采样运用于模糊操作这个过程既然单独计算原像素内部黑色占据的百分比不是一件简单的事情,那我们就在单个像素中进行超采样,将一个完整的像素视为多个小像素的组合.再次采样后的结果近似于直接计算黑色占比从而实现更好的抗锯齿效果 the cost of MSAA增大了计算量 其他反走样方法 FXAA Fast Approximate AA通过图像对比的方法,直接把锯齿换成没有锯齿 TAA Temporal AA通过学习上一帧的图像,在静态中效果不错 Super Resolution /Super Sampling把小图,低分辨率的图,拉大为高分辨率DLSS(Deep Learning Super Sampling) Lec7 shading 1visibility / occlusion由于z轴的存在,图像投射到2D上会有遮挡问题 painter’s algorithm由远及近,对图像进行光栅化paint from back to front 但对于这种情况,画家算法无能为力哪个三角形在前,哪个在后,很难排 z-buffering既然,对于三角形排序存在困难,那不如直接对像素进行排序Idea: Store current min. z-value for each sample (pixel) Needs an additional buffer for depth values frame buffer stores color values depth buffer (z-buffer) stores depth用两个buffer储存数据.一个存生成图像,一个存深度数据 在这里,z的值一直都是正的,且越小越近,越大越远 算法先认定所有的三角形中的所有像素都会被画出来通过zbuffer中的值判断如果该像素是最近的,就更新framebuffer与zbuffer中的值并且与画三角形的顺序无关12345678910//Z-Buffer Algorithm//Initialize depth buffer to ∞//During rasterization:for (each triangle T) for (each sample (x,y,z) in T) if (z &lt; zbuffer[x,y]) // closest sample so far framebuffer[x,y] = rgb; // update color zbuffer[x,y] = z; // update depth else ; // do nothing, this sample is occluded 在GPU加速的情况下,性能非常好 复杂度分析$O(n)$复杂度 深度相同如何处理没讲… 缺陷处理不了透明物体 shadingThe process of applying a material to an object.材质处理 shading is local只看这个点的局部，不管光线的遮挡不能实现阴影的生成shading is different with shadow Blinn-Phong reflectance model三种光线类型 specular highlights diffuse reflection ambient lighting 几个输入数据 diffuse reflection 漫反射光接受能力$\\hat{l}$与$\\hat{n}$的夹角决定能量的接受能力计算时仅仅考虑单位面积$\\cos\\theta=\\hat{l}\\cdot\\hat{n}$ 光衰减把射出的光看作球壳,单位面积上的光强度为$I$则对于距离点光源距离为$1$与$r$的球壳来说 \\begin{align*} 4\\pi1^{2}I&=4\\pi r^{2}I^\\prime\\\\ I^{\\prime}&=\\frac{1}{r^{2}} \\end{align*} $k_{d}$漫反射系数 $I/R^{2}$单位面积的能量 $max(0,\\hat{n}\\cdot\\hat{l})$能量吸收率,若$\\hat{n}\\cdot\\hat{l}$为负数,则值为0 为什么与$v$没关系?由于漫反射对于各个方向都一样,观察$v$在哪个位置没有区别，所以漫反射公式与$v$无关 漫反射公式 Lec8 shading2shadingBlinn-Phong reflectance modeling一个简化模型,与现实存在差距 Specular Term 高光原理it depends on the direction of your view当观察角度$v$与镜面反射$R$足够接近的时候,才会观察到高光 高光公式算法实现上,判断$R$与$v$的接近程度$\\Leftrightarrow$半程向量$\\hat{h}$与法线向量$\\hat{n}$的接近程度,这样就不需要计算镜面反射.半程向量实在是太好算 求$\\hat{h}$只要用$\\hat{l}+\\hat{v}$,再归一化就行 $k_{s}$为镜面反射系数 为什么不考虑能量被吸收?blinn-phong把这点简化了. $max(0,\\cos \\alpha)$后面为什么会有一个指数?$\\cos \\alpha$本身存在变化太慢的问题,不能够很好地表达高光情况,指数$p$越大,值变化更快,高光区域更小 ambient term 环境光照定义不依赖于任何东西从任何一个角度看都一样,与$\\hat{v}$无关从实现效果来看就是进行最基础的颜色填充 This is approximate / fake!$La = ka Ia$ conclusion shading frequencies在着色的时候存在精度问题 flat shading gouraud shadingshading each pixel在每个顶点上进行着色 phong shadingshade each pixel 顶点法向量算法将$v$对应的法向量$n_{v}$视作与$v$有关的面所对应的法向量的和,再进行归一化简单平均与加权平均都可以 N_{v}={\\frac{\\sum_{i}N_{i}}{\\|\\sum_{i}N_{i}\\|}} Barycentric interpolation重心插值算法 Graphic pipeline 实时渲染 shader用来定义对某个像素进行如何操作 编辑了一个基础的根据lambertian shading模型的DiffuseShader123456789101112uniform sampler2D myTexture;// program parameteruniform vec3 lightDir;// program parametervarying vec2 uv;// per fragment value (interp. by rasterizer)varying vec3 norm;// per fragment value (interp. by rasterizer)void diffuseShader(){vec3 kd;}kd = texture2d(myTexture, uv);// material color from texturekd *= clamp(dot(–lightDir, norm), 0.0, 1.0);// Lambertian shading modelgl_FragColor = vec4(kd, 1.0);// output fragment color} 可以在shadertoy.com上联系观看别人的shader GPU并行度高,特别适合做图形学的运算CPU并行计算能力差点意思 texture mapping模型本身是3D的,而他们的纹理是2D的.要做到模型上的三角形对应到纹理上的三角形是很有难度的.我们默认已知 纹理映射默认$u,v$大小都在$(0,1)$模型上每个顶点都有一个对应的$(u,v)$坐标且$(u,v)$坐标已知 纹理的无缝衔接合成一种方案:Wang tile可以依靠源砖,来产生相对较好的纹理,拼贴出的结果不会有太明显的重复，且没有周期性wiki Lec9 shading3Barycentric coordinates定义坐标角度在任意的坐标系中,在一个三角形所在的平面上,已知三角形的三个点$A,B,C$,任意点$(x,y)$都可以用$(\\alpha ,\\beta ,\\gamma)$来表示,并且和为1 \\begin{align} &(x,y)=\\alpha A+\\beta Y+ \\gamma C\\\\ &\\alpha + \\beta +\\gamma=1 \\end{align}注意: 在三角形内部,要求$\\alpha ,\\beta ,\\gamma \\geq0$ 由于$\\alpha + \\beta +\\gamma=1$的特性,知道$\\alpha \\beta \\gamma$中的任意两个就可以求得另外一个,未知数其实为2个$A=(1,0,0)$$B=(0,1,0)$$C=(0,0,1)$ 几何角度从面积的角度求重心坐标 不用去记 using Barycentric coordinatesLinearly interpolate values对于任何一个点,已知其重心坐标$(\\alpha,\\beta,\\gamma)$,可以计算出该点的属性值，例如颜色，亮度，向量等等 V=\\alpha V_{a}+\\beta V_{b}+\\gamma V_{c}可以在投影之前3D空间中的三角形做线性插值，经过投影之后不行但可以通过逆变换，将二维的三角形变为三维的三角形，再做插值 Texture Mapping在原来的纹理中,只有三角形顶点的坐标而经过重心坐标的处理之后,texture中的每一个点$(u,v)$都可以用$\\alpha A+\\beta Y+ \\gamma C$表示只要在texture上对$(u,v)$进行查询,就可以知道该点对应的纹理的信息(颜色,亮度等等) 从而可以知道在经过光栅化之后的显示器上显示的效果 问题texture magnificationsmall case如果纹理太小了,将到较大的屏幕映射到较小的纹理上有问题.大集合映射到小集合上,会出现大集合中的多个元素同时映射到小集合的同一个元素上.从观感上来说,是纹理放大,用一张画去贴图整个墙面,把画放大之后再去贴几种处理方式: nearest bilinear bicubic 从效果上来看,bicubic最好,bilinear不错,差距主要在眼角的位置.但是bicubic性能开销大 nearest将pixel坐标映射到纹理坐标上,选择最近的纹理顶点如图,选择$u11$ 疑问:既然前面介绍了重心坐标,可以计算texture上每一个点的属性,为什么还要用这种方法?和采用的纹理本身有关.这里使用的纹理是由是纹素组成 线性插值 bilinear interpolationlinear interpolation 公式: \\begin{align} lerp(x,v_{0},v_{1})&=v_{0}+x(v_{1}-v_{0})\\\\ x&\\in(0,1) \\end{align}对于这幅图来说从红点的位置可以推算出来两个单线性插值 \\begin{align} u_{0}&=lerp(s,u_{00},u_{10})\\\\ u_{1}&=lerp(s,u_{01},u_{11})\\\\ \\end{align}两个单线性插值能够计算出$u{1},u{0}$再根据$u{1},u{0}$再进行一次插值 f(x,y)=lerp(t,u_{0},u_{1})这就是双线性插值,从步骤上看,第一次插值:四个点插值为两个点第二次插值:两个点插值为一个点双线性对应的是$2^{2}$的指数$2$ bicubic性能开销太大,效果最好 big casetexture太大,而screen太小一个像素对应的texture范围过大,会造成走样.从信号的角度看,单个像素对应的texel中,内容变换过快,信号变化频率高,而采样次数太少,从而产生了走样 传统方法处理最右边的情况效果就很差了 处理方式: super-samping super Sampling例如单个像素中采样512次,通过提高采样频率避免走样但是对性能消耗太高 range query既然采样会出现走样的问题,那我就不采样了😡对于一个像素包含大范围的texture的情况,进行range query获取某一像素下对应的纹理区域颜色 mipmapwhat is mipmapAllowing (fast, approximate, square) range queries仅限于正方形,被操作对象为texture“Mip” comes from the Latin “multum in parvo”, meaning a multitude in a small space 以原图为$n \\times n$为例在原图的基础上,削减像素数量,为原来的一半,最后图像$level=log_{2}n$.,例如当$n=128$时,最终图为$level 7$从性能开销上来看,储存仅仅为原来的$\\frac{4}{3}$ 1^{2}+2^{2}+ \\ldots+(\\frac{n}{2})^{2}+n^{2}=\\frac{4}{3}n^{2}mipmap的生成是在range query之前完成 左边为屏幕像素,右边为纹理上的texel如果要对点$(u,v){00}$进行mipmap计算找到这个点周围距离为一个pixel的几个点,计算它们的textue坐标.再计算中心点与周围点的距离,用最大的$L$值画一个正方形,进行range query查询的图像的$level=log{2}L$.一个像素对应的$L \\times L$texel.既然已经对纹理进行过mipmap的操作,那就可以在对应level上查询到$L \\times L$的范围内的颜色.例如,当$L=4$的时候,$level=2$,只要查询$level_{2}$上$(u,v)$坐标对应的块的数据就行 trilinear interpolation 三线性插值根据不同位置查询的层数的值进行渲染.但也有这不理想的地方.因为mipmap生成的图是离散的,导致,查询的层数是离散的,两个相邻的像素点,一个查询1,一个查询2,可能结果图像会有一条缝隙,做不到查询1.8层. 优化方法:三线性插值法trilinear interpolation 查询相邻的两个level的mipmap,对D level进行一次bilinear interpolation,对D+1 level也进行一次bilinear interpolation.最后对双线性插值的结果进行线性插值. 效果非常漂亮 三线性插值在游戏中经常用到,可以自己开关试试效果 overblur问题mipmap本身还是存在问题,因为查询的是像素对应的texture范围上的颜色,所以会出现模糊 pixel应该对应的范围是矩形,而mipmap算法用square对应,差错就会很大了 Anisotropic Filtering各向异性过滤各向异性:各个方向上表现不同 这时候就需要我各向异性过滤来优化,效果很不错 沿着图像对角线为mipmap,横向为横向压缩图,纵向为纵向压缩图 游戏中,各项异性过滤有不同的层数,例如4层,16层等.但是实际上,改变各项异性层数对于性能开销不大.层数代表在各个方向上运算的次数.2层表示各个方向上压缩两次,开销为:而4层,开销为:差距非常小一旦开启各向异性,层数区别不大,并且,无限层的开销趋向于原来的三倍.显存够,开最高就行 可以根据ripmaps查询,比较好处理蓝色的矩形,但对于红色的斜矩形,效果还是差 可以用EWA方法进行优化 Applications of texturesIn modern GPUs, texture = memory + range query (filtering).纹理就是一些内存,使用内存就是内存查询的过程. Environment Map你能看到的任何东西都有光照信息 用纹理描述环境光照将环境光照的texture贴到茶壶上.光照最好有方向和距离两个定义,单单方向会有问题. Spherical Environment Map将环境光记录在球体上好处在于,方便查询,任意方向的光线,直接在球体上找对应的方向就行,但也有问题 像世界地图一样,上方和下方会有扭曲 Cube Map用立方体描述环境光好处在于图像展开没有变形坏处在于,查询的时候,需要计算下方向才能查找到正确的点 Bump map如何实现凹凸不平的表面效果?model可以是一个光滑的球体,而贴图采用凹凸贴图.凹凸贴图上记录一个相对高度信息,或者一个新的法向量,来实现凹凸的shading效果.从而欺骗眼睛.用复杂的贴图代替复杂的模型 凹凸贴图法向量计算使用凹凸贴图后的表面 1D 贴图flatland求导求切线,再对切线变换,算出向量注意要对向量进行归一化操作 2D 贴图处理2D贴图,默认原来表面的向量为(0,0,1) 2D texture上有两个方向,$u,v$,对两个方向分别求导,再取负数,可得到法向量注意归一化 displacement mapping会去真的移动几何结构,例如移动顶点为了弥补bump map的缺点,在图像边缘,和由于本身高度变换带来的阴影显示效果不好 需要足够精细的模型 3D纹理定义一个三维的纹理,劈开之后还能看到内部的纹理实际上并没有纹理,而是一个三维噪声函数,通过一系列的操作,可以得到图形 记录信息Provide Precomputed shading先计算好环境光遮蔽,再存储到texture中. 3D Textures and Volume Rendering三维的纹理 Lec10 Geometry1 Introduction to Geometry隐式几何 implicit做光线追踪方便 Algebraic Surfaces通过对点进行分类,实现的隐式表达.例如对于球体$x^{2}+y^{2}+z^{2}=1$,对点进行分类,分成符合该式子,与不符合.$(x,y,z)$这个点就是我定义的球体表面上的点. 便于判断某个点在不在面上,但不好列举哪些点在面上,从而不便推断出图像的样子 不好采样 Constructive Solid Geometry (Implicit)CSG方式对隐式表达进行布尔运算 signed distance function表示能力非常强大 求空间中,各个点到边界的距离,并且是有方向的距离(signed).blend距离,就等于blend他们的边界 level set 水平集描述从用distance function生成的数据集中,使用插值的方法,找到$f(x)=0$的线,绘制出$f(x)=0$的表面 医疗数据,组织密度渲染物理仿真 fractals 分形法类似万花筒,细节非常到位,但控制它生成什么形状存在困难 显式几何 explicit直接定义或是参数定义 直接直接告诉三角形的各个坐标,来显式构造球体, 参数映射的方式对于二维平面$(u,v)$上的各个点,通过一个函数$f$映射到三维空间中,实现显式构造采样非常方便,判断里外艰难 point cloud一个$(x,y,z)$的列表就行,是最简单的方法,绘制对采样的精度要求高.精度过低,效果不好, polygon mesh应用最为广泛的图形表达方式对各种操作的支持度都不错. .obj格式v 储存点信息vt储存纹理vn储存法向量 f为v/vt/vn Lec11 Curves and SurfacesBézier Curves 贝塞尔曲线Bézier Curves 之 de Casteljau 算法进行递归运算,一次减少一个点,最后一个点的轨迹就是该算法得到的贝塞尔曲线使用的是显式几何,引入时间参数$t$,$t\\in(0,1)$,来定义贝塞尔曲线先找到在$t$时间,$b{0},b{1}$之间的点$b{0}^{1}$,同理得到$b{1}^{1},b{2}^{1}$再处理$t$时间$b{0}^{1},b{1}^{1},b{2}^{1}$三点,得到$b{0}^{2},b{1}^{2}$最后同理得到$t$时间的$b_{0}^{3}$ 从流程的图来看,a,b,c,d为控制点 数学定义 总共有$n+1$个点$b^{n}(t)$为表达最终生成点$b{0}^{n}(t)$的$n$次多项式.$B{j}^{n}(t)$是伯恩斯坦多项式 \\begin{align} b^{n}(t)&=b_{0}^{n}(t)=\\sum^{n}_{j=0}b_{j}B_{j}^{n}(t)\\\\ B_{i}^{n}(t)&=\\ {\\binom{n}{i}}t^{i}(1-t)^{n-i} \\end{align} 对于四个控制点的贝塞尔曲线应用${\\bf b}^{n}(t)={\\bf b}{0}\\,(1-t)^{3}+{\\bf b}{1}\\,3t(1-t)^{2}+{\\bf b}{2}\\,3t^{2}(1-t)+{\\bf b}{3}\\,t^{3}$ 伯恩斯坦方程具有对称性 Properties of Bézier Curves例子中是四个控制点$b{0},b{1},b{2},b{3}$的三维贝塞尔曲线三维贝塞尔曲线,起点是$b{0}$,终点是$b{3}$在控制点的切线是$b^\\prime(n)=3(b{n+1}-b{n})$,系数一定为3对于仿射变换具有良好性质.控制点直接生成的贝塞尔曲线经过仿射变换,和仿射变换之后的控制点生成的贝塞尔曲线,一摸一样,但对于其他的变换不适用具有凸包性质.生成的贝塞尔曲线一定在控制点形成的闭包之内. 什么是闭包最外面的一个圈就是 Piecewise Bézier Curves 分段贝塞尔曲线对于这样的控制点,生成的贝塞尔曲线,难以控制,并且生成难度高 所以人们选择分段生成贝塞尔曲线每段由四个控制点生成衔接的地方不一定平滑 为了描述平滑的情况,提出了不同级别的continuity $C^{0}$ continuity几何上的连续两段贝塞尔曲线都经过红点前段结束点为后段起始点 $C^{1}$ continuity公共点为左右两点的中点时 其他曲线splines 样条 有与分段贝塞尔曲线类似的性质,并且更可控.但也更难计算 surface贝塞尔曲面用$4\\times4$的控制点,两个时间参数$(u,v)$生成在时间$u$下,每组控制点生成一个新的点,共计四个新点四个新点在时间$v$下生成新的点,贝塞尔曲面点 mesh三大主题 subdivision 网格细分 simplification 网格化简 regularization 网格正规化,尽量接近正三角形,大小接近 Lec12 geometry3 meshsubdivisionloop subdivisionloop与循环没关系,发明这个的人姓loopFirst, create more triangles(vertices)Second, tune their positions先细分再调整位置 对于新vertices 对于旧vertices根据原来点的度来选择权重 catmull-clark subdivision适用于四边形网格.奇异点:degree != 4 每有一个非四边形,就会产生一个新的奇异点.取非四边形的边的中点,再选择一个点与他们相连,破坏原有的非四边形,生成四边形,与一个新的奇异点 调整各个vertice的权重计算 mesh simplificationedge collapse 边坍缩使用二次度量误差算法Quadric Error Metrics 简单对原来的点求平均的简化算法不够好,提出了二次度量误差算法二次:点到平面的距离的平方要求新的位置到原来各个面的距离的平方和最小 \\min(\\sum_{i=1}^{n}distance^{2}) 二次度量误差的数据结构采用堆(优先队列),能够迅速查询最小值,也能够快速更新 先对最小值的边进行坍缩,更新堆,再对最小值的边进行坍缩.贪心算法 局部最优!=全局最优,但在绝大部分情况下,这样的贪心算法效果很好 shadow mapping只能处理点光源,只能生成硬阴影(边界没有颜色过度,非常锐利)点光源没有大小,只是一个点 原图 记录从点光源方向看去的深度图 从相机或人眼看过去的点的深度 比较1,2的深度,来判断是否生成shadow mapping 浮点数本身的比较存在困难.判断浮点数是否相等,被精度问题困扰,比较难.method: 判断 from eye’s 大于 from light’s,就生成shadow mapping 引入bias,若from eye’s大于 from light’s + bias,就生成shadow mapping problem with shadow mapping Hard shadows (point lights only) Quality depends on shadow map resolution(general problem with image-based techniques) 不同的分辨率最后的阴影结果不同 Involves equality comparison of floating point depth values means issues of scale, bias, tolerance Lec13 ray tracing 1光线追踪是另一种成像方式.主要是为了解决rasterization上的不足: soft shadow 光的二次,多次反射 间接光照 glossy reflection 质量低 Ray tracing is accurate, but is very slow Rasterization: real-time(每秒至少30frame), ray tracing: offline Basic Ray-Tracing Algorithm三条定义 光以直线传播,忽略波动性 与其他光线碰撞不会发生交互 光线从光源到眼睛(工程上的实现与这个恰好相反,光路可逆性的应用) ray casting算法仅仅考虑了光的一次发射,没有考虑多次反射的光线 从每个像素发出光线 判断物体与光线的交点,与光源的连线是否有遮挡,判断阴影情况 Pinhole Camera Model根据与光源的相对情况给进行着色Recursive (Whitted-Style) Ray Tracing对光线进行多次递归运算,再进行shading.光线名称做出分类: primary ray secondary ray shadow ray效果也不错 Ray-Surface Intersection (交点)光线由三个参数来定义.t为时间 o为原点 d为单位方向向量光线被定义为射线,只有一个方向 r(t)=o+td,0\\leq t","link":"/2024/02/3e1449d4cce6.html"}],"tags":[{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"计网","slug":"计网","link":"/tags/%E8%AE%A1%E7%BD%91/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"vpn","slug":"vpn","link":"/tags/vpn/"},{"name":"anki","slug":"anki","link":"/tags/anki/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"bazel","slug":"bazel","link":"/tags/bazel/"},{"name":"编译","slug":"编译","link":"/tags/%E7%BC%96%E8%AF%91/"},{"name":"cmake","slug":"cmake","link":"/tags/cmake/"},{"name":"code","slug":"code","link":"/tags/code/"},{"name":"istore","slug":"istore","link":"/tags/istore/"},{"name":"wireguard","slug":"wireguard","link":"/tags/wireguard/"},{"name":"dn11","slug":"dn11","link":"/tags/dn11/"},{"name":"#linux","slug":"linux","link":"/tags/linux/"},{"name":"软路由","slug":"软路由","link":"/tags/%E8%BD%AF%E8%B7%AF%E7%94%B1/"},{"name":"openwrt","slug":"openwrt","link":"/tags/openwrt/"},{"name":"rsshub","slug":"rsshub","link":"/tags/rsshub/"},{"name":"rss","slug":"rss","link":"/tags/rss/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"scoop","slug":"scoop","link":"/tags/scoop/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"firewall","slug":"firewall","link":"/tags/firewall/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"minio","slug":"minio","link":"/tags/minio/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"tutorial","slug":"tutorial","link":"/tags/tutorial/"},{"name":"games","slug":"games","link":"/tags/games/"},{"name":"图形学","slug":"图形学","link":"/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"categories":[{"name":"07archive","slug":"07archive","link":"/categories/07archive/"},{"name":"02literature","slug":"02literature","link":"/categories/02literature/"},{"name":"tech","slug":"07archive/tech","link":"/categories/07archive/tech/"},{"name":"book","slug":"02literature/book","link":"/categories/02literature/book/"},{"name":"tutorial","slug":"07archive/tutorial","link":"/categories/07archive/tutorial/"},{"name":"Omnivore","slug":"Omnivore","link":"/categories/Omnivore/"},{"name":"2024-05-08","slug":"Omnivore/2024-05-08","link":"/categories/Omnivore/2024-05-08/"},{"name":"2020-07-25","slug":"Omnivore/2020-07-25","link":"/categories/Omnivore/2020-07-25/"},{"name":"2024-05-09","slug":"Omnivore/2024-05-09","link":"/categories/Omnivore/2024-05-09/"},{"name":"2020-08-06","slug":"Omnivore/2020-08-06","link":"/categories/Omnivore/2020-08-06/"},{"name":"2024-05-12","slug":"Omnivore/2024-05-12","link":"/categories/Omnivore/2024-05-12/"},{"name":"2024-05-14","slug":"Omnivore/2024-05-14","link":"/categories/Omnivore/2024-05-14/"},{"name":"2024-05-15","slug":"Omnivore/2024-05-15","link":"/categories/Omnivore/2024-05-15/"},{"name":"2024-05-11","slug":"Omnivore/2024-05-11","link":"/categories/Omnivore/2024-05-11/"},{"name":"2024-05-23","slug":"Omnivore/2024-05-23","link":"/categories/Omnivore/2024-05-23/"},{"name":"2024-05-20","slug":"Omnivore/2024-05-20","link":"/categories/Omnivore/2024-05-20/"},{"name":"2024-05-28","slug":"Omnivore/2024-05-28","link":"/categories/Omnivore/2024-05-28/"},{"name":"2024-06-12","slug":"Omnivore/2024-06-12","link":"/categories/Omnivore/2024-06-12/"},{"name":"2024-06-01","slug":"Omnivore/2024-06-01","link":"/categories/Omnivore/2024-06-01/"},{"name":"2024-06-05","slug":"Omnivore/2024-06-05","link":"/categories/Omnivore/2024-06-05/"},{"name":"games","slug":"07archive/tech/games","link":"/categories/07archive/tech/games/"},{"name":"101实验","slug":"07archive/tech/games/101实验","link":"/categories/07archive/tech/games/101%E5%AE%9E%E9%AA%8C/"}]}